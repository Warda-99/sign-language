{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix, accuracy_score, classification_report, roc_curve, auc, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import time\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('MP_Data')                     # Path for exported data, numpy arrays\n",
    "frames = 30                                             # Video frames\n",
    "\n",
    "actions = np.array(['car', 'coffee', 'face', 'fall', 'friday', 'gold', 'goodbye', 'heart', 'hello', 'iloveyou', 'key', 'monday', 'music', 'phone', 'pretty', 'saturday', 'spring', 'summer', 'sunday', 'tea', 'thanks', 'thursday', 'tuesday', 'wednesday', 'winter'])\n",
    "label_map = {label:num for num, label in enumerate(actions)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences collected: 3750\n",
      "Total labels collected: 3750\n"
     ]
    }
   ],
   "source": [
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    action_path = os.path.join(DATA_PATH, action)\n",
    "    if not os.path.exists(action_path):\n",
    "        print(f\"Action path does not exist: {action_path}\")\n",
    "        continue\n",
    "    \n",
    "    sequences_list = os.listdir(action_path)\n",
    "    if not sequences_list:\n",
    "        print(f\"No sequences found in path: {action_path}\")\n",
    "        continue\n",
    "    \n",
    "    for sequence in np.array(sequences_list).astype(int):\n",
    "        window = []\n",
    "        for frame_num in range(frames):\n",
    "            frame_path = os.path.join(action_path, str(sequence), f\"{frame_num}.npy\")\n",
    "            if not os.path.exists(frame_path):\n",
    "                print(f\"File does not exist: {frame_path}\")\n",
    "                continue\n",
    "            \n",
    "            res = np.load(frame_path)\n",
    "            window.append(res)\n",
    "        if window:\n",
    "            sequences.append(window)\n",
    "            labels.append(label_map[action])\n",
    "\n",
    "print(f\"Total sequences collected: {len(sequences)}\")\n",
    "print(f\"Total labels collected: {len(labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozmiar zbioru treningowego: 2625\n",
      "Rozmiar zbioru walidacyjnego: 562\n",
      "Rozmiar zbioru testowego: 563\n"
     ]
    }
   ],
   "source": [
    "# Przygotowanie danych\n",
    "X = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "\n",
    "# Podział na zbiór treningowy (70%) i zbiór tymczasowy (30%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Podział zbioru tymczasowego na zbiór walidacyjny (15%) i testowy (15%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Wyniki\n",
    "print(f\"Rozmiar zbioru treningowego: {len(X_train)}\")\n",
    "print(f\"Rozmiar zbioru walidacyjnego: {len(X_val)}\")\n",
    "print(f\"Rozmiar zbioru testowego: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/' \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import pydot\n",
    "import graphviz\n",
    "\n",
    "# Definicja modelu lstm\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(32, return_sequences=True, activation='relu', input_shape=(30, 258)))\n",
    "model_lstm.add(LSTM(64, return_sequences=True, activation='relu'))\n",
    "model_lstm.add(LSTM(32, return_sequences=False, activation='relu'))\n",
    "model_lstm.add(Dropout(0.1))\n",
    "model_lstm.add(Dense(32, activation='relu'))\n",
    "model_lstm.add(Dense(actions.shape[0], activation='softmax'))\n",
    "\n",
    "# Definicja modelu CNN\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(Conv1D(32, 3, activation='relu', input_shape=(30, 258)))\n",
    "model_cnn.add(MaxPooling1D(2))\n",
    "model_cnn.add(Dropout(0.1))\n",
    "model_cnn.add(Conv1D(64, 3, activation='relu'))\n",
    "model_cnn.add(MaxPooling1D(2))\n",
    "model_cnn.add(Dropout(0.1))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(64, activation='relu'))\n",
    "model_cnn.add(Dropout(0.1))\n",
    "model_cnn.add(Dense(actions.shape[0], activation='softmax'))\n",
    "\n",
    "# Generowanie diagramu architektury modelu\n",
    "plot_model(model_lstm, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)\n",
    "# plot_model(model_cnn, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicjalizacja callbacku wczesnego stopu\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',                     # Metryka do monitorowania \n",
    "    patience=10,                            # Liczba epok bez poprawy, po których trening zostanie zatrzymany\n",
    "    verbose=1,                              # Poziom logowania\n",
    "    restore_best_weights=True               # Przywrócenie najlepszych wag modelu\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grid LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kuba\\AppData\\Local\\Temp\\ipykernel_9768\\975009032.py:20: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=build_model, verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 3.1774 - categorical_accuracy: 0.0488Epoch 1: loss = 3.1773741245269775, val_loss = 3.0668222904205322\n",
      "82/82 [==============================] - 5s 27ms/step - loss: 3.1774 - categorical_accuracy: 0.0488 - val_loss: 3.0668 - val_categorical_accuracy: 0.0891\n",
      "Epoch 2/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 2.9453 - categorical_accuracy: 0.0799Epoch 2: loss = 2.940565586090088, val_loss = 2.858759641647339\n",
      "82/82 [==============================] - 2s 22ms/step - loss: 2.9406 - categorical_accuracy: 0.0808 - val_loss: 2.8588 - val_categorical_accuracy: 0.0838\n",
      "Epoch 3/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.7180 - categorical_accuracy: 0.0895Epoch 3: loss = 2.7199792861938477, val_loss = 2.659181833267212\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 2.7200 - categorical_accuracy: 0.0892 - val_loss: 2.6592 - val_categorical_accuracy: 0.0967\n",
      "Epoch 4/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.5488 - categorical_accuracy: 0.1196Epoch 4: loss = 2.54593825340271, val_loss = 2.476112127304077\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 2.5459 - categorical_accuracy: 0.1189 - val_loss: 2.4761 - val_categorical_accuracy: 0.1127\n",
      "Epoch 5/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.4001 - categorical_accuracy: 0.1728Epoch 5: loss = 2.3987040519714355, val_loss = 2.20894455909729\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 2.3987 - categorical_accuracy: 0.1738 - val_loss: 2.2089 - val_categorical_accuracy: 0.1759\n",
      "Epoch 6/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.4212 - categorical_accuracy: 0.1813Epoch 6: loss = 2.4222636222839355, val_loss = 2.655311346054077\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 2.4223 - categorical_accuracy: 0.1822 - val_loss: 2.6553 - val_categorical_accuracy: 0.1386\n",
      "Epoch 7/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.3840 - categorical_accuracy: 0.1654Epoch 7: loss = 2.3840065002441406, val_loss = 2.115952968597412\n",
      "82/82 [==============================] - 2s 22ms/step - loss: 2.3840 - categorical_accuracy: 0.1654 - val_loss: 2.1160 - val_categorical_accuracy: 0.2209\n",
      "Epoch 8/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.0358 - categorical_accuracy: 0.2531Epoch 8: loss = 2.0313026905059814, val_loss = 1.977671504020691\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 2.0313 - categorical_accuracy: 0.2553 - val_loss: 1.9777 - val_categorical_accuracy: 0.2391\n",
      "Epoch 9/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.9050 - categorical_accuracy: 0.2867Epoch 9: loss = 1.9038647413253784, val_loss = 1.8388432264328003\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.9039 - categorical_accuracy: 0.2881 - val_loss: 1.8388 - val_categorical_accuracy: 0.2742\n",
      "Epoch 10/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.8738 - categorical_accuracy: 0.2801Epoch 10: loss = 1.8717995882034302, val_loss = 1.8121322393417358\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.8718 - categorical_accuracy: 0.2790 - val_loss: 1.8121 - val_categorical_accuracy: 0.2772\n",
      "Epoch 11/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.7785 - categorical_accuracy: 0.3233Epoch 11: loss = 1.7749996185302734, val_loss = 1.8069323301315308\n",
      "82/82 [==============================] - 2s 23ms/step - loss: 1.7750 - categorical_accuracy: 0.3247 - val_loss: 1.8069 - val_categorical_accuracy: 0.3123\n",
      "Epoch 12/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.8062 - categorical_accuracy: 0.3194Epoch 12: loss = 1.8061679601669312, val_loss = 2.077129364013672\n",
      "82/82 [==============================] - 2s 22ms/step - loss: 1.8062 - categorical_accuracy: 0.3194 - val_loss: 2.0771 - val_categorical_accuracy: 0.2262\n",
      "Epoch 13/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.7422 - categorical_accuracy: 0.3308Epoch 13: loss = 1.7421796321868896, val_loss = 1.7933152914047241\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 1.7422 - categorical_accuracy: 0.3308 - val_loss: 1.7933 - val_categorical_accuracy: 0.2810\n",
      "Epoch 14/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.7302 - categorical_accuracy: 0.3316Epoch 14: loss = 1.7301825284957886, val_loss = 1.7450952529907227\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.7302 - categorical_accuracy: 0.3316 - val_loss: 1.7451 - val_categorical_accuracy: 0.3039\n",
      "Epoch 15/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.6452 - categorical_accuracy: 0.3503Epoch 15: loss = 1.6420336961746216, val_loss = 1.630426287651062\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.6420 - categorical_accuracy: 0.3506 - val_loss: 1.6304 - val_categorical_accuracy: 0.3275\n",
      "Epoch 16/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.5952 - categorical_accuracy: 0.3580Epoch 16: loss = 1.5962427854537964, val_loss = 1.5589762926101685\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.5962 - categorical_accuracy: 0.3575 - val_loss: 1.5590 - val_categorical_accuracy: 0.3572\n",
      "Epoch 17/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.5829 - categorical_accuracy: 0.3812Epoch 17: loss = 1.5856499671936035, val_loss = 1.5877412557601929\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.5856 - categorical_accuracy: 0.3819 - val_loss: 1.5877 - val_categorical_accuracy: 0.4090\n",
      "Epoch 18/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.5464 - categorical_accuracy: 0.3812Epoch 18: loss = 1.5438624620437622, val_loss = 1.4984138011932373\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.5439 - categorical_accuracy: 0.3826 - val_loss: 1.4984 - val_categorical_accuracy: 0.3831\n",
      "Epoch 19/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.0047 - categorical_accuracy: 0.2677Epoch 19: loss = 2.006103754043579, val_loss = 2.231553316116333\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 2.0061 - categorical_accuracy: 0.2675 - val_loss: 2.2316 - val_categorical_accuracy: 0.1759\n",
      "Epoch 20/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 2.1057 - categorical_accuracy: 0.2336Epoch 20: loss = 2.100703239440918, val_loss = 1.905504584312439\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 2.1007 - categorical_accuracy: 0.2348 - val_loss: 1.9055 - val_categorical_accuracy: 0.2696\n",
      "Epoch 21/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.8550 - categorical_accuracy: 0.3055Epoch 21: loss = 1.8578096628189087, val_loss = 1.719123125076294\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.8578 - categorical_accuracy: 0.3049 - val_loss: 1.7191 - val_categorical_accuracy: 0.3397\n",
      "Epoch 22/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 1.8123 - categorical_accuracy: 0.3212Epoch 22: loss = 1.8207077980041504, val_loss = 1.7123037576675415\n",
      "82/82 [==============================] - 2s 23ms/step - loss: 1.8207 - categorical_accuracy: 0.3216 - val_loss: 1.7123 - val_categorical_accuracy: 0.3450\n",
      "Epoch 23/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.6370 - categorical_accuracy: 0.3796Epoch 23: loss = 1.6365349292755127, val_loss = 1.526279091835022\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.6365 - categorical_accuracy: 0.3803 - val_loss: 1.5263 - val_categorical_accuracy: 0.4006\n",
      "Epoch 24/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 2.3125 - categorical_accuracy: 0.2664Epoch 24: loss = 2.3268444538116455, val_loss = 2.905625343322754\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 2.3268 - categorical_accuracy: 0.2614 - val_loss: 2.9056 - val_categorical_accuracy: 0.0899\n",
      "Epoch 25/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 2.3938 - categorical_accuracy: 0.1461Epoch 25: loss = 2.3907952308654785, val_loss = 2.4384288787841797\n",
      "82/82 [==============================] - 2s 22ms/step - loss: 2.3908 - categorical_accuracy: 0.1494 - val_loss: 2.4384 - val_categorical_accuracy: 0.1516\n",
      "Epoch 26/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.2263 - categorical_accuracy: 0.1860Epoch 26: loss = 2.226304292678833, val_loss = 2.124812126159668\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 2.2263 - categorical_accuracy: 0.1860 - val_loss: 2.1248 - val_categorical_accuracy: 0.2140\n",
      "Epoch 27/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.2773 - categorical_accuracy: 0.1852Epoch 27: loss = 2.2772624492645264, val_loss = 2.0775747299194336\n",
      "82/82 [==============================] - 2s 25ms/step - loss: 2.2773 - categorical_accuracy: 0.1852 - val_loss: 2.0776 - val_categorical_accuracy: 0.2125\n",
      "Epoch 28/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.0893 - categorical_accuracy: 0.2248Restoring model weights from the end of the best epoch: 18.\n",
      "Epoch 28: loss = 2.0892865657806396, val_loss = 2.0002574920654297\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 2.0893 - categorical_accuracy: 0.2248 - val_loss: 2.0003 - val_categorical_accuracy: 0.2239\n",
      "Epoch 28: early stopping\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 1.4984 - categorical_accuracy: 0.3831\n",
      "Epoch 1/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 3.1940 - categorical_accuracy: 0.0450Epoch 1: loss = 3.1940693855285645, val_loss = 3.1908462047576904\n",
      "83/83 [==============================] - 8s 50ms/step - loss: 3.1941 - categorical_accuracy: 0.0449 - val_loss: 3.1908 - val_categorical_accuracy: 0.0755\n",
      "Epoch 2/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 3.0100 - categorical_accuracy: 0.1088Epoch 2: loss = 3.0089263916015625, val_loss = 3.05047869682312\n",
      "83/83 [==============================] - 2s 27ms/step - loss: 3.0089 - categorical_accuracy: 0.1089 - val_loss: 3.0505 - val_categorical_accuracy: 0.0686\n",
      "Epoch 3/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.7684 - categorical_accuracy: 0.1319Epoch 3: loss = 2.7672317028045654, val_loss = 2.5362050533294678\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 2.7672 - categorical_accuracy: 0.1333 - val_loss: 2.5362 - val_categorical_accuracy: 0.1540\n",
      "Epoch 4/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.4423 - categorical_accuracy: 0.1723Epoch 4: loss = 2.442084789276123, val_loss = 2.2961535453796387\n",
      "83/83 [==============================] - 2s 28ms/step - loss: 2.4421 - categorical_accuracy: 0.1721 - val_loss: 2.2962 - val_categorical_accuracy: 0.1555\n",
      "Epoch 5/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.3141 - categorical_accuracy: 0.1639Epoch 5: loss = 2.3139073848724365, val_loss = 2.2179434299468994\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 2.3139 - categorical_accuracy: 0.1637 - val_loss: 2.2179 - val_categorical_accuracy: 0.1471\n",
      "Epoch 6/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.1706 - categorical_accuracy: 0.2050Epoch 6: loss = 2.1704251766204834, val_loss = 2.0840611457824707\n",
      "83/83 [==============================] - 3s 32ms/step - loss: 2.1704 - categorical_accuracy: 0.2049 - val_loss: 2.0841 - val_categorical_accuracy: 0.2477\n",
      "Epoch 7/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.0707 - categorical_accuracy: 0.2600Epoch 7: loss = 2.0679216384887695, val_loss = 1.9559605121612549\n",
      "83/83 [==============================] - 3s 34ms/step - loss: 2.0679 - categorical_accuracy: 0.2605 - val_loss: 1.9560 - val_categorical_accuracy: 0.2515\n",
      "Epoch 8/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.0071 - categorical_accuracy: 0.2536Epoch 8: loss = 2.0070955753326416, val_loss = 1.9259111881256104\n",
      "83/83 [==============================] - 2s 29ms/step - loss: 2.0071 - categorical_accuracy: 0.2536 - val_loss: 1.9259 - val_categorical_accuracy: 0.2668\n",
      "Epoch 9/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.5806 - categorical_accuracy: 0.1562Epoch 9: loss = 2.580562114715576, val_loss = 2.469517230987549\n",
      "83/83 [==============================] - 2s 30ms/step - loss: 2.5806 - categorical_accuracy: 0.1561 - val_loss: 2.4695 - val_categorical_accuracy: 0.1265\n",
      "Epoch 10/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.3421 - categorical_accuracy: 0.1683Epoch 10: loss = 2.3421449661254883, val_loss = 2.177236557006836\n",
      "83/83 [==============================] - 2s 30ms/step - loss: 2.3421 - categorical_accuracy: 0.1683 - val_loss: 2.1772 - val_categorical_accuracy: 0.2271\n",
      "Epoch 11/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.2037 - categorical_accuracy: 0.1874Epoch 11: loss = 2.2037458419799805, val_loss = 2.0844993591308594\n",
      "83/83 [==============================] - 2s 27ms/step - loss: 2.2037 - categorical_accuracy: 0.1874 - val_loss: 2.0845 - val_categorical_accuracy: 0.1905\n",
      "Epoch 12/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.3031 - categorical_accuracy: 0.1639Epoch 12: loss = 2.302783489227295, val_loss = 2.0860774517059326\n",
      "83/83 [==============================] - 3s 33ms/step - loss: 2.3028 - categorical_accuracy: 0.1637 - val_loss: 2.0861 - val_categorical_accuracy: 0.1822\n",
      "Epoch 13/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.0974 - categorical_accuracy: 0.2222Epoch 13: loss = 2.0939438343048096, val_loss = 1.8466744422912598\n",
      "83/83 [==============================] - 3s 31ms/step - loss: 2.0939 - categorical_accuracy: 0.2224 - val_loss: 1.8467 - val_categorical_accuracy: 0.3018\n",
      "Epoch 14/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.9837 - categorical_accuracy: 0.2616Epoch 14: loss = 1.979420781135559, val_loss = 1.868570327758789\n",
      "83/83 [==============================] - 3s 32ms/step - loss: 1.9794 - categorical_accuracy: 0.2650 - val_loss: 1.8686 - val_categorical_accuracy: 0.3422\n",
      "Epoch 15/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.6009 - categorical_accuracy: 0.1682Epoch 15: loss = 2.5949339866638184, val_loss = 2.170525312423706\n",
      "83/83 [==============================] - 3s 33ms/step - loss: 2.5949 - categorical_accuracy: 0.1691 - val_loss: 2.1705 - val_categorical_accuracy: 0.1944\n",
      "Epoch 16/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.0745 - categorical_accuracy: 0.2348Epoch 16: loss = 2.0766537189483643, val_loss = 1.8777819871902466\n",
      "83/83 [==============================] - 3s 33ms/step - loss: 2.0767 - categorical_accuracy: 0.2346 - val_loss: 1.8778 - val_categorical_accuracy: 0.2896\n",
      "Epoch 17/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.9256 - categorical_accuracy: 0.2805Epoch 17: loss = 1.9250777959823608, val_loss = 2.0078608989715576\n",
      "83/83 [==============================] - 3s 32ms/step - loss: 1.9251 - categorical_accuracy: 0.2803 - val_loss: 2.0079 - val_categorical_accuracy: 0.2805\n",
      "Epoch 18/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.8359 - categorical_accuracy: 0.3138Epoch 18: loss = 1.8359192609786987, val_loss = 1.709805965423584\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 1.8359 - categorical_accuracy: 0.3138 - val_loss: 1.7098 - val_categorical_accuracy: 0.3796\n",
      "Epoch 19/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.7195 - categorical_accuracy: 0.3491Epoch 19: loss = 1.7201573848724365, val_loss = 1.5877665281295776\n",
      "83/83 [==============================] - 2s 24ms/step - loss: 1.7202 - categorical_accuracy: 0.3488 - val_loss: 1.5878 - val_categorical_accuracy: 0.3941\n",
      "Epoch 20/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.6614 - categorical_accuracy: 0.3659Epoch 20: loss = 1.661246657371521, val_loss = 1.4831973314285278\n",
      "83/83 [==============================] - 2s 29ms/step - loss: 1.6612 - categorical_accuracy: 0.3656 - val_loss: 1.4832 - val_categorical_accuracy: 0.4177\n",
      "Epoch 21/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.5800 - categorical_accuracy: 0.3773Epoch 21: loss = 1.5795446634292603, val_loss = 1.5935755968093872\n",
      "83/83 [==============================] - 2s 28ms/step - loss: 1.5795 - categorical_accuracy: 0.3778 - val_loss: 1.5936 - val_categorical_accuracy: 0.4002\n",
      "Epoch 22/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.5287 - categorical_accuracy: 0.4174Epoch 22: loss = 1.5235615968704224, val_loss = 1.3471530675888062\n",
      "83/83 [==============================] - 3s 33ms/step - loss: 1.5236 - categorical_accuracy: 0.4196 - val_loss: 1.3472 - val_categorical_accuracy: 0.4505\n",
      "Epoch 23/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.5433 - categorical_accuracy: 0.4105Epoch 23: loss = 1.5432701110839844, val_loss = 1.3952367305755615\n",
      "83/83 [==============================] - 3s 31ms/step - loss: 1.5433 - categorical_accuracy: 0.4105 - val_loss: 1.3952 - val_categorical_accuracy: 0.4924\n",
      "Epoch 24/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.4763 - categorical_accuracy: 0.4291Epoch 24: loss = 1.4767783880233765, val_loss = 1.356782078742981\n",
      "83/83 [==============================] - 2s 27ms/step - loss: 1.4768 - categorical_accuracy: 0.4288 - val_loss: 1.3568 - val_categorical_accuracy: 0.4482\n",
      "Epoch 25/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.5433 - categorical_accuracy: 0.4040Epoch 25: loss = 1.5421034097671509, val_loss = 1.3981791734695435\n",
      "83/83 [==============================] - 2s 27ms/step - loss: 1.5421 - categorical_accuracy: 0.4044 - val_loss: 1.3982 - val_categorical_accuracy: 0.4657\n",
      "Epoch 26/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.2695 - categorical_accuracy: 0.2056Epoch 26: loss = 2.2695281505584717, val_loss = 1.9288289546966553\n",
      "83/83 [==============================] - 2s 29ms/step - loss: 2.2695 - categorical_accuracy: 0.2056 - val_loss: 1.9288 - val_categorical_accuracy: 0.2477\n",
      "Epoch 27/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.8248 - categorical_accuracy: 0.3302Epoch 27: loss = 1.8250528573989868, val_loss = 1.5963963270187378\n",
      "83/83 [==============================] - 2s 28ms/step - loss: 1.8251 - categorical_accuracy: 0.3267 - val_loss: 1.5964 - val_categorical_accuracy: 0.4116\n",
      "Epoch 28/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.7290 - categorical_accuracy: 0.3395Epoch 28: loss = 1.7299541234970093, val_loss = 1.6017543077468872\n",
      "83/83 [==============================] - 2s 28ms/step - loss: 1.7300 - categorical_accuracy: 0.3389 - val_loss: 1.6018 - val_categorical_accuracy: 0.3720\n",
      "Epoch 29/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.6719 - categorical_accuracy: 0.3450Epoch 29: loss = 1.6719410419464111, val_loss = 1.5249137878417969\n",
      "83/83 [==============================] - 2s 29ms/step - loss: 1.6719 - categorical_accuracy: 0.3450 - val_loss: 1.5249 - val_categorical_accuracy: 0.4078\n",
      "Epoch 30/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.5473 - categorical_accuracy: 0.3796Epoch 30: loss = 1.546439290046692, val_loss = 1.314296841621399\n",
      "83/83 [==============================] - 2s 28ms/step - loss: 1.5464 - categorical_accuracy: 0.3800 - val_loss: 1.3143 - val_categorical_accuracy: 0.5084\n",
      "Epoch 31/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.5491 - categorical_accuracy: 0.4070Epoch 31: loss = 1.5488046407699585, val_loss = 1.6708588600158691\n",
      "83/83 [==============================] - 2s 29ms/step - loss: 1.5488 - categorical_accuracy: 0.4075 - val_loss: 1.6709 - val_categorical_accuracy: 0.4093\n",
      "Epoch 32/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.4762 - categorical_accuracy: 0.4337Epoch 32: loss = 1.4771500825881958, val_loss = 1.3175064325332642\n",
      "83/83 [==============================] - 2s 28ms/step - loss: 1.4772 - categorical_accuracy: 0.4334 - val_loss: 1.3175 - val_categorical_accuracy: 0.4939\n",
      "Epoch 33/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.3886 - categorical_accuracy: 0.4406Epoch 33: loss = 1.3875839710235596, val_loss = 1.3393962383270264\n",
      "83/83 [==============================] - 2s 28ms/step - loss: 1.3876 - categorical_accuracy: 0.4410 - val_loss: 1.3394 - val_categorical_accuracy: 0.4825\n",
      "Epoch 34/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.3186 - categorical_accuracy: 0.4722Epoch 34: loss = 1.3185559511184692, val_loss = 1.2778635025024414\n",
      "83/83 [==============================] - 2s 30ms/step - loss: 1.3186 - categorical_accuracy: 0.4722 - val_loss: 1.2779 - val_categorical_accuracy: 0.5305\n",
      "Epoch 35/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.3344 - categorical_accuracy: 0.4798Epoch 35: loss = 1.3343700170516968, val_loss = 1.265372633934021\n",
      "83/83 [==============================] - 2s 29ms/step - loss: 1.3344 - categorical_accuracy: 0.4798 - val_loss: 1.2654 - val_categorical_accuracy: 0.5145\n",
      "Epoch 36/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.3707 - categorical_accuracy: 0.4463Epoch 36: loss = 1.3707268238067627, val_loss = 1.1067525148391724\n",
      "83/83 [==============================] - 3s 32ms/step - loss: 1.3707 - categorical_accuracy: 0.4463 - val_loss: 1.1068 - val_categorical_accuracy: 0.5808\n",
      "Epoch 37/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.2211 - categorical_accuracy: 0.5177Epoch 37: loss = 1.2230831384658813, val_loss = 1.147566795349121\n",
      "83/83 [==============================] - 2s 28ms/step - loss: 1.2231 - categorical_accuracy: 0.5171 - val_loss: 1.1476 - val_categorical_accuracy: 0.5480\n",
      "Epoch 38/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.2872 - categorical_accuracy: 0.4992Epoch 38: loss = 1.2885087728500366, val_loss = 1.5364423990249634\n",
      "83/83 [==============================] - 2s 28ms/step - loss: 1.2885 - categorical_accuracy: 0.4989 - val_loss: 1.5364 - val_categorical_accuracy: 0.3841\n",
      "Epoch 39/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.2767 - categorical_accuracy: 0.5095Epoch 39: loss = 1.276689887046814, val_loss = 1.036446213722229\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.2767 - categorical_accuracy: 0.5095 - val_loss: 1.0364 - val_categorical_accuracy: 0.6120\n",
      "Epoch 40/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.1570 - categorical_accuracy: 0.5468Epoch 40: loss = 1.1570067405700684, val_loss = 1.057119369506836\n",
      "83/83 [==============================] - 2s 27ms/step - loss: 1.1570 - categorical_accuracy: 0.5468 - val_loss: 1.0571 - val_categorical_accuracy: 0.6288\n",
      "Epoch 41/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.4499 - categorical_accuracy: 0.4699Epoch 41: loss = 1.4499437808990479, val_loss = 1.2871977090835571\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 1.4499 - categorical_accuracy: 0.4699 - val_loss: 1.2872 - val_categorical_accuracy: 0.5252\n",
      "Epoch 42/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.2540 - categorical_accuracy: 0.5244Epoch 42: loss = 1.2530237436294556, val_loss = 1.087182879447937\n",
      "83/83 [==============================] - 2s 24ms/step - loss: 1.2530 - categorical_accuracy: 0.5248 - val_loss: 1.0872 - val_categorical_accuracy: 0.6014\n",
      "Epoch 43/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.1726 - categorical_accuracy: 0.5457Epoch 43: loss = 1.171675443649292, val_loss = 1.2014739513397217\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 1.1717 - categorical_accuracy: 0.5461 - val_loss: 1.2015 - val_categorical_accuracy: 0.5732\n",
      "Epoch 44/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.1044 - categorical_accuracy: 0.5800Epoch 44: loss = 1.1035865545272827, val_loss = 1.1337904930114746\n",
      "83/83 [==============================] - 2s 27ms/step - loss: 1.1036 - categorical_accuracy: 0.5804 - val_loss: 1.1338 - val_categorical_accuracy: 0.5587\n",
      "Epoch 45/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.1951 - categorical_accuracy: 0.5438Epoch 45: loss = 1.1950726509094238, val_loss = 1.0120594501495361\n",
      "83/83 [==============================] - 2s 27ms/step - loss: 1.1951 - categorical_accuracy: 0.5438 - val_loss: 1.0121 - val_categorical_accuracy: 0.6380\n",
      "Epoch 46/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.0947 - categorical_accuracy: 0.5816Epoch 46: loss = 1.0964213609695435, val_loss = 1.1264489889144897\n",
      "83/83 [==============================] - 2s 27ms/step - loss: 1.0964 - categorical_accuracy: 0.5811 - val_loss: 1.1264 - val_categorical_accuracy: 0.5930\n",
      "Epoch 47/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.3151 - categorical_accuracy: 0.5191Epoch 47: loss = 1.3152799606323242, val_loss = 1.024157166481018\n",
      "83/83 [==============================] - 2s 27ms/step - loss: 1.3153 - categorical_accuracy: 0.5187 - val_loss: 1.0242 - val_categorical_accuracy: 0.6159\n",
      "Epoch 48/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.9786 - categorical_accuracy: 0.3735Epoch 48: loss = 1.9772570133209229, val_loss = 1.649868130683899\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 1.9773 - categorical_accuracy: 0.3740 - val_loss: 1.6499 - val_categorical_accuracy: 0.3948\n",
      "Epoch 49/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.5029 - categorical_accuracy: 0.4474Epoch 49: loss = 1.5036365985870361, val_loss = 1.3585951328277588\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 1.5036 - categorical_accuracy: 0.4471 - val_loss: 1.3586 - val_categorical_accuracy: 0.4756\n",
      "Epoch 50/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.3210 - categorical_accuracy: 0.4886Epoch 50: loss = 1.3216687440872192, val_loss = 1.263845682144165\n",
      "83/83 [==============================] - 2s 24ms/step - loss: 1.3217 - categorical_accuracy: 0.4890 - val_loss: 1.2638 - val_categorical_accuracy: 0.5206\n",
      "41/41 [==============================] - 1s 7ms/step - loss: 1.2638 - categorical_accuracy: 0.5206\n",
      "Epoch 1/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 3.1983 - categorical_accuracy: 0.0656Epoch 1: loss = 3.198268175125122, val_loss = 3.2019283771514893\n",
      "82/82 [==============================] - 6s 32ms/step - loss: 3.1983 - categorical_accuracy: 0.0648 - val_loss: 3.2019 - val_categorical_accuracy: 0.0472\n",
      "Epoch 2/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 3.0952 - categorical_accuracy: 0.0702Epoch 2: loss = 3.0901033878326416, val_loss = 2.791818857192993\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 3.0901 - categorical_accuracy: 0.0709 - val_loss: 2.7918 - val_categorical_accuracy: 0.0708\n",
      "Epoch 3/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.7290 - categorical_accuracy: 0.1196Epoch 3: loss = 2.7259159088134766, val_loss = 2.600837469100952\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 2.7259 - categorical_accuracy: 0.1204 - val_loss: 2.6008 - val_categorical_accuracy: 0.1241\n",
      "Epoch 4/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 2.6185 - categorical_accuracy: 0.1384Epoch 4: loss = 2.6151678562164307, val_loss = 2.54874849319458\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 2.6152 - categorical_accuracy: 0.1364 - val_loss: 2.5487 - val_categorical_accuracy: 0.0929\n",
      "Epoch 5/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 2.4890 - categorical_accuracy: 0.1531Epoch 5: loss = 2.4887423515319824, val_loss = 2.3616459369659424\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 2.4887 - categorical_accuracy: 0.1532 - val_loss: 2.3616 - val_categorical_accuracy: 0.1630\n",
      "Epoch 6/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.3819 - categorical_accuracy: 0.1813Epoch 6: loss = 2.3790440559387207, val_loss = 2.3552749156951904\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 2.3790 - categorical_accuracy: 0.1822 - val_loss: 2.3553 - val_categorical_accuracy: 0.2506\n",
      "Epoch 7/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.3472 - categorical_accuracy: 0.1952Epoch 7: loss = 2.346928358078003, val_loss = 2.19643497467041\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 2.3469 - categorical_accuracy: 0.1974 - val_loss: 2.1964 - val_categorical_accuracy: 0.2688\n",
      "Epoch 8/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 2.3149 - categorical_accuracy: 0.2047Epoch 8: loss = 2.3130671977996826, val_loss = 2.2230920791625977\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 2.3131 - categorical_accuracy: 0.2050 - val_loss: 2.2231 - val_categorical_accuracy: 0.2216\n",
      "Epoch 9/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.1799 - categorical_accuracy: 0.2492Epoch 9: loss = 2.1810336112976074, val_loss = 2.198253631591797\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 2.1810 - categorical_accuracy: 0.2470 - val_loss: 2.1983 - val_categorical_accuracy: 0.2399\n",
      "Epoch 10/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.8065 - categorical_accuracy: 0.1466Epoch 10: loss = 2.8046720027923584, val_loss = 2.4036524295806885\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 2.8047 - categorical_accuracy: 0.1463 - val_loss: 2.4037 - val_categorical_accuracy: 0.1988\n",
      "Epoch 11/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 2.3431 - categorical_accuracy: 0.2211Epoch 11: loss = 2.3458993434906006, val_loss = 2.224492311477661\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 2.3459 - categorical_accuracy: 0.2210 - val_loss: 2.2245 - val_categorical_accuracy: 0.2643\n",
      "Epoch 12/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.2767 - categorical_accuracy: 0.2785Epoch 12: loss = 2.2791738510131836, val_loss = 2.315046548843384\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 2.2792 - categorical_accuracy: 0.2767 - val_loss: 2.3150 - val_categorical_accuracy: 0.2186\n",
      "Epoch 13/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.2035 - categorical_accuracy: 0.2866Epoch 13: loss = 2.2034687995910645, val_loss = 2.0074093341827393\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 2.2035 - categorical_accuracy: 0.2866 - val_loss: 2.0074 - val_categorical_accuracy: 0.3168\n",
      "Epoch 14/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.0256 - categorical_accuracy: 0.3364Epoch 14: loss = 2.0232937335968018, val_loss = 1.92409086227417\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 2.0233 - categorical_accuracy: 0.3369 - val_loss: 1.9241 - val_categorical_accuracy: 0.3580\n",
      "Epoch 15/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.9210 - categorical_accuracy: 0.3480Epoch 15: loss = 1.9221144914627075, val_loss = 1.8178056478500366\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.9221 - categorical_accuracy: 0.3476 - val_loss: 1.8178 - val_categorical_accuracy: 0.3953\n",
      "Epoch 16/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.9113 - categorical_accuracy: 0.3659Epoch 16: loss = 1.911316990852356, val_loss = 1.8074132204055786\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.9113 - categorical_accuracy: 0.3659 - val_loss: 1.8074 - val_categorical_accuracy: 0.4151\n",
      "Epoch 17/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.8666 - categorical_accuracy: 0.3719Epoch 17: loss = 1.8684754371643066, val_loss = 1.7230032682418823\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.8685 - categorical_accuracy: 0.3720 - val_loss: 1.7230 - val_categorical_accuracy: 0.4349\n",
      "Epoch 18/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.7512 - categorical_accuracy: 0.4047Epoch 18: loss = 1.7512162923812866, val_loss = 1.714523196220398\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.7512 - categorical_accuracy: 0.4047 - val_loss: 1.7145 - val_categorical_accuracy: 0.4242\n",
      "Epoch 19/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.8008 - categorical_accuracy: 0.3866Epoch 19: loss = 1.7925381660461426, val_loss = 1.609724521636963\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.7925 - categorical_accuracy: 0.3887 - val_loss: 1.6097 - val_categorical_accuracy: 0.4379\n",
      "Epoch 20/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.6201 - categorical_accuracy: 0.4367Epoch 20: loss = 1.6188938617706299, val_loss = 1.48809015750885\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.6189 - categorical_accuracy: 0.4375 - val_loss: 1.4881 - val_categorical_accuracy: 0.4905\n",
      "Epoch 21/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.5828 - categorical_accuracy: 0.4375Epoch 21: loss = 1.5811833143234253, val_loss = 1.5199627876281738\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.5812 - categorical_accuracy: 0.4367 - val_loss: 1.5200 - val_categorical_accuracy: 0.4235\n",
      "Epoch 22/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.5509 - categorical_accuracy: 0.4414Epoch 22: loss = 1.5520938634872437, val_loss = 1.48061203956604\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.5521 - categorical_accuracy: 0.4398 - val_loss: 1.4806 - val_categorical_accuracy: 0.4928\n",
      "Epoch 23/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.5137 - categorical_accuracy: 0.4529Epoch 23: loss = 1.517016053199768, val_loss = 1.510811448097229\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.5170 - categorical_accuracy: 0.4535 - val_loss: 1.5108 - val_categorical_accuracy: 0.4570\n",
      "Epoch 24/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.4940 - categorical_accuracy: 0.4491Epoch 24: loss = 1.4940389394760132, val_loss = 1.5596120357513428\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.4940 - categorical_accuracy: 0.4482 - val_loss: 1.5596 - val_categorical_accuracy: 0.4265\n",
      "Epoch 25/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.4999 - categorical_accuracy: 0.4604Epoch 25: loss = 1.4999369382858276, val_loss = 1.6204583644866943\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.4999 - categorical_accuracy: 0.4604 - val_loss: 1.6205 - val_categorical_accuracy: 0.3884\n",
      "Epoch 26/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.4101 - categorical_accuracy: 0.4915Epoch 26: loss = 1.4066466093063354, val_loss = 1.3858036994934082\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.4066 - categorical_accuracy: 0.4931 - val_loss: 1.3858 - val_categorical_accuracy: 0.5179\n",
      "Epoch 27/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.3871 - categorical_accuracy: 0.5046Epoch 27: loss = 1.3906502723693848, val_loss = 1.2831095457077026\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.3907 - categorical_accuracy: 0.5030 - val_loss: 1.2831 - val_categorical_accuracy: 0.5362\n",
      "Epoch 28/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.3192 - categorical_accuracy: 0.5023Epoch 28: loss = 1.3196297883987427, val_loss = 1.1982741355895996\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.3196 - categorical_accuracy: 0.5023 - val_loss: 1.1983 - val_categorical_accuracy: 0.5910\n",
      "Epoch 29/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.3346 - categorical_accuracy: 0.5281Epoch 29: loss = 1.3329484462738037, val_loss = 1.2438303232192993\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.3329 - categorical_accuracy: 0.5282 - val_loss: 1.2438 - val_categorical_accuracy: 0.5324\n",
      "Epoch 30/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.2900 - categorical_accuracy: 0.5023Epoch 30: loss = 1.2900118827819824, val_loss = 1.2254502773284912\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.2900 - categorical_accuracy: 0.5023 - val_loss: 1.2255 - val_categorical_accuracy: 0.6040\n",
      "Epoch 31/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.3081 - categorical_accuracy: 0.5100Epoch 31: loss = 1.3024717569351196, val_loss = 1.2063636779785156\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.3025 - categorical_accuracy: 0.5137 - val_loss: 1.2064 - val_categorical_accuracy: 0.5308\n",
      "Epoch 32/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.2764 - categorical_accuracy: 0.5125Epoch 32: loss = 1.2745976448059082, val_loss = 1.2005417346954346\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.2746 - categorical_accuracy: 0.5130 - val_loss: 1.2005 - val_categorical_accuracy: 0.5704\n",
      "Epoch 33/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 3.8539 - categorical_accuracy: 0.2690Epoch 33: loss = 3.809049367904663, val_loss = 2.5967228412628174\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 3.8090 - categorical_accuracy: 0.2645 - val_loss: 2.5967 - val_categorical_accuracy: 0.1988\n",
      "Epoch 34/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 2.4831 - categorical_accuracy: 0.1914Epoch 34: loss = 2.485781669616699, val_loss = 2.321347713470459\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 2.4858 - categorical_accuracy: 0.1890 - val_loss: 2.3213 - val_categorical_accuracy: 0.1698\n",
      "Epoch 35/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.2763 - categorical_accuracy: 0.2157Epoch 35: loss = 2.2762818336486816, val_loss = 2.1667628288269043\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 2.2763 - categorical_accuracy: 0.2157 - val_loss: 2.1668 - val_categorical_accuracy: 0.2635\n",
      "Epoch 36/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 2.1040 - categorical_accuracy: 0.2641Epoch 36: loss = 2.10227370262146, val_loss = 2.006394147872925\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 2.1023 - categorical_accuracy: 0.2645 - val_loss: 2.0064 - val_categorical_accuracy: 0.3252\n",
      "Epoch 37/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.0274 - categorical_accuracy: 0.2677Epoch 37: loss = 2.0256409645080566, val_loss = 1.927402138710022\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 2.0256 - categorical_accuracy: 0.2675 - val_loss: 1.9274 - val_categorical_accuracy: 0.3503\n",
      "Epoch 38/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.9735 - categorical_accuracy: 0.3032Restoring model weights from the end of the best epoch: 28.\n",
      "Epoch 38: loss = 1.9807000160217285, val_loss = 1.8985812664031982\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.9807 - categorical_accuracy: 0.3018 - val_loss: 1.8986 - val_categorical_accuracy: 0.3595\n",
      "Epoch 38: early stopping\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 1.1983 - categorical_accuracy: 0.5910\n",
      "Epoch 1/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 3.2048 - categorical_accuracy: 0.0511Epoch 1: loss = 3.204773187637329, val_loss = 3.1475000381469727\n",
      "83/83 [==============================] - 7s 32ms/step - loss: 3.2048 - categorical_accuracy: 0.0510 - val_loss: 3.1475 - val_categorical_accuracy: 0.0869\n",
      "Epoch 2/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 3.0437 - categorical_accuracy: 0.0846Epoch 2: loss = 3.0438146591186523, val_loss = 2.9565000534057617\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 3.0438 - categorical_accuracy: 0.0845 - val_loss: 2.9565 - val_categorical_accuracy: 0.0709\n",
      "Epoch 3/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.8992 - categorical_accuracy: 0.0841Epoch 3: loss = 2.900569438934326, val_loss = 2.8122167587280273\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 2.9006 - categorical_accuracy: 0.0838 - val_loss: 2.8122 - val_categorical_accuracy: 0.0732\n",
      "Epoch 4/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.7730 - categorical_accuracy: 0.0877Epoch 4: loss = 2.773042678833008, val_loss = 2.79380202293396\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 2.7730 - categorical_accuracy: 0.0876 - val_loss: 2.7938 - val_categorical_accuracy: 0.0800\n",
      "Epoch 5/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.7232 - categorical_accuracy: 0.0800Epoch 5: loss = 2.723242998123169, val_loss = 2.7087271213531494\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 2.7232 - categorical_accuracy: 0.0800 - val_loss: 2.7087 - val_categorical_accuracy: 0.0732\n",
      "Epoch 6/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.6630 - categorical_accuracy: 0.0899Epoch 6: loss = 2.6629860401153564, val_loss = 2.609210252761841\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 2.6630 - categorical_accuracy: 0.0899 - val_loss: 2.6092 - val_categorical_accuracy: 0.1052\n",
      "Epoch 7/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.5972 - categorical_accuracy: 0.1014Epoch 7: loss = 2.597663402557373, val_loss = 2.540466070175171\n",
      "83/83 [==============================] - 2s 27ms/step - loss: 2.5977 - categorical_accuracy: 0.1013 - val_loss: 2.5405 - val_categorical_accuracy: 0.1418\n",
      "Epoch 8/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.5911 - categorical_accuracy: 0.1165Epoch 8: loss = 2.591059923171997, val_loss = 2.5880908966064453\n",
      "83/83 [==============================] - 3s 31ms/step - loss: 2.5911 - categorical_accuracy: 0.1165 - val_loss: 2.5881 - val_categorical_accuracy: 0.1319\n",
      "Epoch 9/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.5703 - categorical_accuracy: 0.1165Epoch 9: loss = 2.5684385299682617, val_loss = 2.4473443031311035\n",
      "83/83 [==============================] - 2s 29ms/step - loss: 2.5684 - categorical_accuracy: 0.1165 - val_loss: 2.4473 - val_categorical_accuracy: 0.1852\n",
      "Epoch 10/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.4625 - categorical_accuracy: 0.1497Epoch 10: loss = 2.463611364364624, val_loss = 2.1893043518066406\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 2.4636 - categorical_accuracy: 0.1500 - val_loss: 2.1893 - val_categorical_accuracy: 0.2210\n",
      "Epoch 11/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.5801 - categorical_accuracy: 0.1386Epoch 11: loss = 2.5800869464874268, val_loss = 2.3813023567199707\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 2.5801 - categorical_accuracy: 0.1386 - val_loss: 2.3813 - val_categorical_accuracy: 0.1471\n",
      "Epoch 12/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.5392 - categorical_accuracy: 0.1258Epoch 12: loss = 2.5386617183685303, val_loss = 2.413050889968872\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 2.5387 - categorical_accuracy: 0.1257 - val_loss: 2.4131 - val_categorical_accuracy: 0.1456\n",
      "Epoch 13/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.4012 - categorical_accuracy: 0.1631Epoch 13: loss = 2.4003026485443115, val_loss = 2.3113136291503906\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 2.4003 - categorical_accuracy: 0.1637 - val_loss: 2.3113 - val_categorical_accuracy: 0.1776\n",
      "Epoch 14/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.4030 - categorical_accuracy: 0.1683Epoch 14: loss = 2.403031826019287, val_loss = 2.1917200088500977\n",
      "83/83 [==============================] - 2s 28ms/step - loss: 2.4030 - categorical_accuracy: 0.1683 - val_loss: 2.1917 - val_categorical_accuracy: 0.2508\n",
      "Epoch 15/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.2620 - categorical_accuracy: 0.1874Epoch 15: loss = 2.261990785598755, val_loss = 2.038914918899536\n",
      "83/83 [==============================] - 2s 27ms/step - loss: 2.2620 - categorical_accuracy: 0.1874 - val_loss: 2.0389 - val_categorical_accuracy: 0.2797\n",
      "Epoch 16/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.0947 - categorical_accuracy: 0.2400Epoch 16: loss = 2.0922317504882812, val_loss = 2.0265536308288574\n",
      "83/83 [==============================] - 2s 27ms/step - loss: 2.0922 - categorical_accuracy: 0.2414 - val_loss: 2.0266 - val_categorical_accuracy: 0.2553\n",
      "Epoch 17/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.0021 - categorical_accuracy: 0.2483Epoch 17: loss = 2.0021462440490723, val_loss = 1.884840965270996\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 2.0021 - categorical_accuracy: 0.2483 - val_loss: 1.8848 - val_categorical_accuracy: 0.2698\n",
      "Epoch 18/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.8973 - categorical_accuracy: 0.2677Epoch 18: loss = 1.8969178199768066, val_loss = 1.7743854522705078\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 1.8969 - categorical_accuracy: 0.2658 - val_loss: 1.7744 - val_categorical_accuracy: 0.3224\n",
      "Epoch 19/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.9495 - categorical_accuracy: 0.2577Epoch 19: loss = 1.9452835321426392, val_loss = 1.7399351596832275\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 1.9453 - categorical_accuracy: 0.2589 - val_loss: 1.7399 - val_categorical_accuracy: 0.3011\n",
      "Epoch 20/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.8352 - categorical_accuracy: 0.2841Epoch 20: loss = 1.8351948261260986, val_loss = 1.7397682666778564\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 1.8352 - categorical_accuracy: 0.2841 - val_loss: 1.7398 - val_categorical_accuracy: 0.3201\n",
      "Epoch 21/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.7509 - categorical_accuracy: 0.3323Epoch 21: loss = 1.7508060932159424, val_loss = 1.6501026153564453\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 1.7508 - categorical_accuracy: 0.3328 - val_loss: 1.6501 - val_categorical_accuracy: 0.3552\n",
      "Epoch 22/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.7494 - categorical_accuracy: 0.3072Epoch 22: loss = 1.74885094165802, val_loss = 1.6160531044006348\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.7489 - categorical_accuracy: 0.3069 - val_loss: 1.6161 - val_categorical_accuracy: 0.3468\n",
      "Epoch 23/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.8603 - categorical_accuracy: 0.3049Epoch 23: loss = 1.8605293035507202, val_loss = 1.8344576358795166\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 1.8605 - categorical_accuracy: 0.3046 - val_loss: 1.8345 - val_categorical_accuracy: 0.2980\n",
      "Epoch 24/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.7149 - categorical_accuracy: 0.3380Epoch 24: loss = 1.7125200033187866, val_loss = 1.5611926317214966\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.7125 - categorical_accuracy: 0.3374 - val_loss: 1.5612 - val_categorical_accuracy: 0.4215\n",
      "Epoch 25/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.7395 - categorical_accuracy: 0.3252Epoch 25: loss = 1.7394856214523315, val_loss = 1.500806450843811\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.7395 - categorical_accuracy: 0.3252 - val_loss: 1.5008 - val_categorical_accuracy: 0.4352\n",
      "Epoch 26/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.6020 - categorical_accuracy: 0.3636Epoch 26: loss = 1.602158784866333, val_loss = 1.6668933629989624\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 1.6022 - categorical_accuracy: 0.3633 - val_loss: 1.6669 - val_categorical_accuracy: 0.2957\n",
      "Epoch 27/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.5914 - categorical_accuracy: 0.3747Epoch 27: loss = 1.5914149284362793, val_loss = 1.4137369394302368\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.5914 - categorical_accuracy: 0.3747 - val_loss: 1.4137 - val_categorical_accuracy: 0.4642\n",
      "Epoch 28/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.5664 - categorical_accuracy: 0.3869Epoch 28: loss = 1.5664010047912598, val_loss = 1.438513994216919\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.5664 - categorical_accuracy: 0.3869 - val_loss: 1.4385 - val_categorical_accuracy: 0.4245\n",
      "Epoch 29/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.6328 - categorical_accuracy: 0.3933Epoch 29: loss = 1.6327732801437378, val_loss = 1.9285979270935059\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 1.6328 - categorical_accuracy: 0.3938 - val_loss: 1.9286 - val_categorical_accuracy: 0.3552\n",
      "Epoch 30/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.8097 - categorical_accuracy: 0.3210Epoch 30: loss = 1.8087122440338135, val_loss = 1.8590635061264038\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.8087 - categorical_accuracy: 0.3222 - val_loss: 1.8591 - val_categorical_accuracy: 0.3262\n",
      "Epoch 31/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.6951 - categorical_accuracy: 0.3495Epoch 31: loss = 1.6940244436264038, val_loss = 1.5755360126495361\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.6940 - categorical_accuracy: 0.3488 - val_loss: 1.5755 - val_categorical_accuracy: 0.3902\n",
      "Epoch 32/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.5693 - categorical_accuracy: 0.3974Epoch 32: loss = 1.5692589282989502, val_loss = 1.5133544206619263\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 1.5693 - categorical_accuracy: 0.3953 - val_loss: 1.5134 - val_categorical_accuracy: 0.3979\n",
      "Epoch 33/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.5480 - categorical_accuracy: 0.3897Epoch 33: loss = 1.5469475984573364, val_loss = 1.3251451253890991\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 1.5469 - categorical_accuracy: 0.3892 - val_loss: 1.3251 - val_categorical_accuracy: 0.4909\n",
      "Epoch 34/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.8782 - categorical_accuracy: 0.3187Epoch 34: loss = 1.876803994178772, val_loss = 1.7962486743927002\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 1.8768 - categorical_accuracy: 0.3184 - val_loss: 1.7962 - val_categorical_accuracy: 0.3422\n",
      "Epoch 35/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.7096 - categorical_accuracy: 0.3316Epoch 35: loss = 1.7098138332366943, val_loss = 1.5302683115005493\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 1.7098 - categorical_accuracy: 0.3313 - val_loss: 1.5303 - val_categorical_accuracy: 0.4322\n",
      "Epoch 36/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.5143 - categorical_accuracy: 0.3910Epoch 36: loss = 1.5140856504440308, val_loss = 1.351780652999878\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.5141 - categorical_accuracy: 0.3915 - val_loss: 1.3518 - val_categorical_accuracy: 0.4855\n",
      "Epoch 37/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.4369 - categorical_accuracy: 0.4398Epoch 37: loss = 1.4352244138717651, val_loss = 1.2848610877990723\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.4352 - categorical_accuracy: 0.4402 - val_loss: 1.2849 - val_categorical_accuracy: 0.4794\n",
      "Epoch 38/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.5019 - categorical_accuracy: 0.4360Epoch 38: loss = 1.5024417638778687, val_loss = 1.436829924583435\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.5024 - categorical_accuracy: 0.4356 - val_loss: 1.4368 - val_categorical_accuracy: 0.4398\n",
      "Epoch 39/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.4083 - categorical_accuracy: 0.4437Epoch 39: loss = 1.4069082736968994, val_loss = 1.3896491527557373\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 1.4069 - categorical_accuracy: 0.4448 - val_loss: 1.3896 - val_categorical_accuracy: 0.5023\n",
      "Epoch 40/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.4035 - categorical_accuracy: 0.4213Epoch 40: loss = 1.4054231643676758, val_loss = 1.4139115810394287\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.4054 - categorical_accuracy: 0.4227 - val_loss: 1.4139 - val_categorical_accuracy: 0.4543\n",
      "Epoch 41/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.0146 - categorical_accuracy: 0.3110Epoch 41: loss = 2.013904333114624, val_loss = 1.4384995698928833\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 2.0139 - categorical_accuracy: 0.3115 - val_loss: 1.4385 - val_categorical_accuracy: 0.4665\n",
      "Epoch 42/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.4579 - categorical_accuracy: 0.4235Epoch 42: loss = 1.4578964710235596, val_loss = 1.355329990386963\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.4579 - categorical_accuracy: 0.4235 - val_loss: 1.3553 - val_categorical_accuracy: 0.5030\n",
      "Epoch 43/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.3994 - categorical_accuracy: 0.4669Epoch 43: loss = 1.3994159698486328, val_loss = 1.3781689405441284\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.3994 - categorical_accuracy: 0.4669 - val_loss: 1.3782 - val_categorical_accuracy: 0.4512\n",
      "Epoch 44/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.3498 - categorical_accuracy: 0.4527Epoch 44: loss = 1.349553108215332, val_loss = 1.3425151109695435\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 1.3496 - categorical_accuracy: 0.4532 - val_loss: 1.3425 - val_categorical_accuracy: 0.5168\n",
      "Epoch 45/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.3322 - categorical_accuracy: 0.4752Epoch 45: loss = 1.3322168588638306, val_loss = 1.2051315307617188\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 1.3322 - categorical_accuracy: 0.4752 - val_loss: 1.2051 - val_categorical_accuracy: 0.5602\n",
      "Epoch 46/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.2593 - categorical_accuracy: 0.4958Epoch 46: loss = 1.259321928024292, val_loss = 1.4798672199249268\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 1.2593 - categorical_accuracy: 0.4958 - val_loss: 1.4799 - val_categorical_accuracy: 0.4672\n",
      "Epoch 47/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.3253 - categorical_accuracy: 0.4787Epoch 47: loss = 1.3242923021316528, val_loss = 1.1775469779968262\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 1.3243 - categorical_accuracy: 0.4791 - val_loss: 1.1775 - val_categorical_accuracy: 0.5953\n",
      "Epoch 48/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.2376 - categorical_accuracy: 0.5095Epoch 48: loss = 1.2376399040222168, val_loss = 1.096235752105713\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 1.2376 - categorical_accuracy: 0.5095 - val_loss: 1.0962 - val_categorical_accuracy: 0.6098\n",
      "Epoch 49/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.1900 - categorical_accuracy: 0.5057Epoch 49: loss = 1.1900055408477783, val_loss = 1.0863099098205566\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.1900 - categorical_accuracy: 0.5057 - val_loss: 1.0863 - val_categorical_accuracy: 0.5915\n",
      "Epoch 50/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.1978 - categorical_accuracy: 0.5147Epoch 50: loss = 1.1974083185195923, val_loss = 1.1355291604995728\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.1974 - categorical_accuracy: 0.5156 - val_loss: 1.1355 - val_categorical_accuracy: 0.5320\n",
      "41/41 [==============================] - 1s 8ms/step - loss: 1.1355 - categorical_accuracy: 0.5320\n",
      "Epoch 1/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 3.1799 - categorical_accuracy: 0.0609Epoch 1: loss = 3.1780288219451904, val_loss = 3.209907054901123\n",
      "82/82 [==============================] - 5s 28ms/step - loss: 3.1780 - categorical_accuracy: 0.0610 - val_loss: 3.2099 - val_categorical_accuracy: 0.0388\n",
      "Epoch 2/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 3.1213 - categorical_accuracy: 0.0548Epoch 2: loss = 3.1187353134155273, val_loss = 2.9613380432128906\n",
      "82/82 [==============================] - 2s 22ms/step - loss: 3.1187 - categorical_accuracy: 0.0541 - val_loss: 2.9613 - val_categorical_accuracy: 0.0556\n",
      "Epoch 3/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 2.8385 - categorical_accuracy: 0.1148Epoch 3: loss = 2.839729070663452, val_loss = 2.76899790763855\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 2.8397 - categorical_accuracy: 0.1166 - val_loss: 2.7690 - val_categorical_accuracy: 0.0975\n",
      "Epoch 4/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.5368 - categorical_accuracy: 0.1799Epoch 4: loss = 2.536839485168457, val_loss = 2.4207398891448975\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 2.5368 - categorical_accuracy: 0.1799 - val_loss: 2.4207 - val_categorical_accuracy: 0.2399\n",
      "Epoch 5/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.4613 - categorical_accuracy: 0.1998Epoch 5: loss = 2.459099769592285, val_loss = 2.229031562805176\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 2.4591 - categorical_accuracy: 0.1989 - val_loss: 2.2290 - val_categorical_accuracy: 0.2186\n",
      "Epoch 6/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 2.2357 - categorical_accuracy: 0.2508Epoch 6: loss = 2.2394795417785645, val_loss = 2.1139297485351562\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 2.2395 - categorical_accuracy: 0.2500 - val_loss: 2.1139 - val_categorical_accuracy: 0.2719\n",
      "Epoch 7/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 2.1809 - categorical_accuracy: 0.2758Epoch 7: loss = 2.176755905151367, val_loss = 1.9655696153640747\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 2.1768 - categorical_accuracy: 0.2767 - val_loss: 1.9656 - val_categorical_accuracy: 0.3290\n",
      "Epoch 8/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.0442 - categorical_accuracy: 0.2816Epoch 8: loss = 2.04777193069458, val_loss = 1.8251053094863892\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 2.0478 - categorical_accuracy: 0.2790 - val_loss: 1.8251 - val_categorical_accuracy: 0.3458\n",
      "Epoch 9/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.8771 - categorical_accuracy: 0.3308Epoch 9: loss = 1.877120018005371, val_loss = 1.720947027206421\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.8771 - categorical_accuracy: 0.3308 - val_loss: 1.7209 - val_categorical_accuracy: 0.3610\n",
      "Epoch 10/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.8367 - categorical_accuracy: 0.3383Epoch 10: loss = 1.8314380645751953, val_loss = 1.74076509475708\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.8314 - categorical_accuracy: 0.3361 - val_loss: 1.7408 - val_categorical_accuracy: 0.2955\n",
      "Epoch 11/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.7679 - categorical_accuracy: 0.3341Epoch 11: loss = 1.7667275667190552, val_loss = 1.5304027795791626\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.7667 - categorical_accuracy: 0.3331 - val_loss: 1.5304 - val_categorical_accuracy: 0.3960\n",
      "Epoch 12/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.8341 - categorical_accuracy: 0.3410Epoch 12: loss = 1.8291045427322388, val_loss = 1.5037360191345215\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.8291 - categorical_accuracy: 0.3438 - val_loss: 1.5037 - val_categorical_accuracy: 0.4105\n",
      "Epoch 13/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 1.6611 - categorical_accuracy: 0.3647Epoch 13: loss = 1.6668614149093628, val_loss = 1.5835503339767456\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.6669 - categorical_accuracy: 0.3643 - val_loss: 1.5836 - val_categorical_accuracy: 0.4067\n",
      "Epoch 14/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.6558 - categorical_accuracy: 0.3867Epoch 14: loss = 1.6520498991012573, val_loss = 1.3627694845199585\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.6520 - categorical_accuracy: 0.3887 - val_loss: 1.3628 - val_categorical_accuracy: 0.4783\n",
      "Epoch 15/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.5722 - categorical_accuracy: 0.4012Epoch 15: loss = 1.5699634552001953, val_loss = 1.480075478553772\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.5700 - categorical_accuracy: 0.4009 - val_loss: 1.4801 - val_categorical_accuracy: 0.3968\n",
      "Epoch 16/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.5559 - categorical_accuracy: 0.4177Epoch 16: loss = 1.555863857269287, val_loss = 1.3129394054412842\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.5559 - categorical_accuracy: 0.4177 - val_loss: 1.3129 - val_categorical_accuracy: 0.5194\n",
      "Epoch 17/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.5213 - categorical_accuracy: 0.4105Epoch 17: loss = 1.5189862251281738, val_loss = 1.3874435424804688\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.5190 - categorical_accuracy: 0.4101 - val_loss: 1.3874 - val_categorical_accuracy: 0.4600\n",
      "Epoch 18/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.6028 - categorical_accuracy: 0.4055Epoch 18: loss = 1.602816104888916, val_loss = 1.3239384889602661\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.6028 - categorical_accuracy: 0.4055 - val_loss: 1.3239 - val_categorical_accuracy: 0.5377\n",
      "Epoch 19/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.4873 - categorical_accuracy: 0.4276Epoch 19: loss = 1.4872770309448242, val_loss = 1.2742655277252197\n",
      "82/82 [==============================] - 2s 22ms/step - loss: 1.4873 - categorical_accuracy: 0.4276 - val_loss: 1.2743 - val_categorical_accuracy: 0.4783\n",
      "Epoch 20/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.5831 - categorical_accuracy: 0.4313Epoch 20: loss = 1.58078134059906, val_loss = 1.2733979225158691\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.5808 - categorical_accuracy: 0.4291 - val_loss: 1.2734 - val_categorical_accuracy: 0.5476\n",
      "Epoch 21/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.4645 - categorical_accuracy: 0.4568Epoch 21: loss = 1.4594199657440186, val_loss = 1.3512496948242188\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.4594 - categorical_accuracy: 0.4596 - val_loss: 1.3512 - val_categorical_accuracy: 0.4722\n",
      "Epoch 22/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.5266 - categorical_accuracy: 0.4500Epoch 22: loss = 1.524043083190918, val_loss = 1.296399712562561\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.5240 - categorical_accuracy: 0.4497 - val_loss: 1.2964 - val_categorical_accuracy: 0.4836\n",
      "Epoch 23/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.4753 - categorical_accuracy: 0.4453Epoch 23: loss = 1.5125895738601685, val_loss = 1.5770474672317505\n",
      "82/82 [==============================] - 2s 22ms/step - loss: 1.5126 - categorical_accuracy: 0.4413 - val_loss: 1.5770 - val_categorical_accuracy: 0.4501\n",
      "Epoch 24/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 1.5691 - categorical_accuracy: 0.4288Epoch 24: loss = 1.554810643196106, val_loss = 1.2486778497695923\n",
      "82/82 [==============================] - 2s 22ms/step - loss: 1.5548 - categorical_accuracy: 0.4322 - val_loss: 1.2487 - val_categorical_accuracy: 0.5270\n",
      "Epoch 25/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.3615 - categorical_accuracy: 0.4812Epoch 25: loss = 1.3611396551132202, val_loss = 1.1504377126693726\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.3611 - categorical_accuracy: 0.4825 - val_loss: 1.1504 - val_categorical_accuracy: 0.5788\n",
      "Epoch 26/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.3562 - categorical_accuracy: 0.4954Epoch 26: loss = 1.3561800718307495, val_loss = 1.166918396949768\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.3562 - categorical_accuracy: 0.4954 - val_loss: 1.1669 - val_categorical_accuracy: 0.5666\n",
      "Epoch 27/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.3007 - categorical_accuracy: 0.4859Epoch 27: loss = 1.3008531332015991, val_loss = 1.087882161140442\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.3009 - categorical_accuracy: 0.4855 - val_loss: 1.0879 - val_categorical_accuracy: 0.5765\n",
      "Epoch 28/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.4292 - categorical_accuracy: 0.4657Epoch 28: loss = 1.4291620254516602, val_loss = 1.1068580150604248\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.4292 - categorical_accuracy: 0.4657 - val_loss: 1.1069 - val_categorical_accuracy: 0.5804\n",
      "Epoch 29/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.3640 - categorical_accuracy: 0.4909Epoch 29: loss = 1.364042043685913, val_loss = 1.1191902160644531\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.3640 - categorical_accuracy: 0.4909 - val_loss: 1.1192 - val_categorical_accuracy: 0.5712\n",
      "Epoch 30/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.3182 - categorical_accuracy: 0.4805Epoch 30: loss = 1.3154098987579346, val_loss = 1.0850785970687866\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.3154 - categorical_accuracy: 0.4840 - val_loss: 1.0851 - val_categorical_accuracy: 0.5765\n",
      "Epoch 31/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.3948 - categorical_accuracy: 0.4776Epoch 31: loss = 1.401414394378662, val_loss = 1.1505078077316284\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.4014 - categorical_accuracy: 0.4756 - val_loss: 1.1505 - val_categorical_accuracy: 0.5545\n",
      "Epoch 32/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.2373 - categorical_accuracy: 0.5266Epoch 32: loss = 1.2360780239105225, val_loss = 1.0690361261367798\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.2361 - categorical_accuracy: 0.5290 - val_loss: 1.0690 - val_categorical_accuracy: 0.5948\n",
      "Epoch 33/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.2550 - categorical_accuracy: 0.5152Epoch 33: loss = 1.2549716234207153, val_loss = 1.1671465635299683\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.2550 - categorical_accuracy: 0.5152 - val_loss: 1.1671 - val_categorical_accuracy: 0.5758\n",
      "Epoch 34/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 1.1648 - categorical_accuracy: 0.5435Epoch 34: loss = 1.164201021194458, val_loss = 0.9732878804206848\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.1642 - categorical_accuracy: 0.5419 - val_loss: 0.9733 - val_categorical_accuracy: 0.6085\n",
      "Epoch 35/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.1511 - categorical_accuracy: 0.5548Epoch 35: loss = 1.1535955667495728, val_loss = 1.002706527709961\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.1536 - categorical_accuracy: 0.5541 - val_loss: 1.0027 - val_categorical_accuracy: 0.5986\n",
      "Epoch 36/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.1009 - categorical_accuracy: 0.5648Epoch 36: loss = 1.0968602895736694, val_loss = 1.031425952911377\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.0969 - categorical_accuracy: 0.5633 - val_loss: 1.0314 - val_categorical_accuracy: 0.5781\n",
      "Epoch 37/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.1508 - categorical_accuracy: 0.5609Epoch 37: loss = 1.1404787302017212, val_loss = 1.0020215511322021\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.1405 - categorical_accuracy: 0.5648 - val_loss: 1.0020 - val_categorical_accuracy: 0.6238\n",
      "Epoch 38/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.1784 - categorical_accuracy: 0.5492Epoch 38: loss = 1.1816720962524414, val_loss = 1.1610157489776611\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.1817 - categorical_accuracy: 0.5465 - val_loss: 1.1610 - val_categorical_accuracy: 0.5666\n",
      "Epoch 39/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 1.1024 - categorical_accuracy: 0.5759Epoch 39: loss = 1.1026520729064941, val_loss = 1.0037446022033691\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.1027 - categorical_accuracy: 0.5770 - val_loss: 1.0037 - val_categorical_accuracy: 0.6131\n",
      "Epoch 40/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.0702 - categorical_accuracy: 0.5688Epoch 40: loss = 1.0680891275405884, val_loss = 1.023391842842102\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.0681 - categorical_accuracy: 0.5694 - val_loss: 1.0234 - val_categorical_accuracy: 0.5720\n",
      "Epoch 41/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.0310 - categorical_accuracy: 0.5727Epoch 41: loss = 1.037320613861084, val_loss = 0.8593666553497314\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.0373 - categorical_accuracy: 0.5709 - val_loss: 0.8594 - val_categorical_accuracy: 0.6816\n",
      "Epoch 42/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.2435 - categorical_accuracy: 0.5448Epoch 42: loss = 1.2369304895401, val_loss = 1.284030556678772\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.2369 - categorical_accuracy: 0.5465 - val_loss: 1.2840 - val_categorical_accuracy: 0.5278\n",
      "Epoch 43/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.4399 - categorical_accuracy: 0.4923Epoch 43: loss = 1.4395668506622314, val_loss = 1.3596796989440918\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.4396 - categorical_accuracy: 0.4931 - val_loss: 1.3597 - val_categorical_accuracy: 0.5050\n",
      "Epoch 44/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.3175 - categorical_accuracy: 0.5008Epoch 44: loss = 1.3104068040847778, val_loss = 1.1092966794967651\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.3104 - categorical_accuracy: 0.5000 - val_loss: 1.1093 - val_categorical_accuracy: 0.5499\n",
      "Epoch 45/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.2105 - categorical_accuracy: 0.5412Epoch 45: loss = 1.2104688882827759, val_loss = 0.9801968932151794\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.2105 - categorical_accuracy: 0.5412 - val_loss: 0.9802 - val_categorical_accuracy: 0.6466\n",
      "Epoch 46/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.0799 - categorical_accuracy: 0.5828Epoch 46: loss = 1.0788410902023315, val_loss = 0.9760619401931763\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.0788 - categorical_accuracy: 0.5831 - val_loss: 0.9761 - val_categorical_accuracy: 0.6519\n",
      "Epoch 47/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.0892 - categorical_accuracy: 0.5849Epoch 47: loss = 1.0854257345199585, val_loss = 0.9407552480697632\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.0854 - categorical_accuracy: 0.5869 - val_loss: 0.9408 - val_categorical_accuracy: 0.6740\n",
      "Epoch 48/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.0748 - categorical_accuracy: 0.5562Epoch 48: loss = 1.0831619501113892, val_loss = 1.0401540994644165\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.0832 - categorical_accuracy: 0.5526 - val_loss: 1.0402 - val_categorical_accuracy: 0.6047\n",
      "Epoch 49/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.0885 - categorical_accuracy: 0.5891Epoch 49: loss = 1.1003106832504272, val_loss = 2.0444884300231934\n",
      "82/82 [==============================] - 2s 20ms/step - loss: 1.1003 - categorical_accuracy: 0.5831 - val_loss: 2.0445 - val_categorical_accuracy: 0.4851\n",
      "Epoch 50/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 1.5396 - categorical_accuracy: 0.4628Epoch 50: loss = 1.5278077125549316, val_loss = 1.1819441318511963\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 1.5278 - categorical_accuracy: 0.4688 - val_loss: 1.1819 - val_categorical_accuracy: 0.5453\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 1.1819 - categorical_accuracy: 0.5453\n",
      "Epoch 1/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 3.1922 - categorical_accuracy: 0.0556Epoch 1: loss = 3.1921839714050293, val_loss = 3.200995445251465\n",
      "83/83 [==============================] - 7s 32ms/step - loss: 3.1922 - categorical_accuracy: 0.0556 - val_loss: 3.2010 - val_categorical_accuracy: 0.0480\n",
      "Epoch 2/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 3.1066 - categorical_accuracy: 0.0769Epoch 2: loss = 3.1066436767578125, val_loss = 3.0415408611297607\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 3.1066 - categorical_accuracy: 0.0769 - val_loss: 3.0415 - val_categorical_accuracy: 0.0816\n",
      "Epoch 3/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.8968 - categorical_accuracy: 0.0922Epoch 3: loss = 2.896467685699463, val_loss = 2.6599345207214355\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 2.8965 - categorical_accuracy: 0.0922 - val_loss: 2.6599 - val_categorical_accuracy: 0.1303\n",
      "Epoch 4/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.6943 - categorical_accuracy: 0.1174Epoch 4: loss = 2.6940758228302, val_loss = 2.5141477584838867\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 2.6941 - categorical_accuracy: 0.1173 - val_loss: 2.5141 - val_categorical_accuracy: 0.1174\n",
      "Epoch 5/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.5053 - categorical_accuracy: 0.1569Epoch 5: loss = 2.5052595138549805, val_loss = 2.322920083999634\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 2.5053 - categorical_accuracy: 0.1569 - val_loss: 2.3229 - val_categorical_accuracy: 0.2492\n",
      "Epoch 6/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.3712 - categorical_accuracy: 0.1706Epoch 6: loss = 2.37117600440979, val_loss = 2.1891980171203613\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 2.3712 - categorical_accuracy: 0.1706 - val_loss: 2.1892 - val_categorical_accuracy: 0.2104\n",
      "Epoch 7/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.2900 - categorical_accuracy: 0.1898Epoch 7: loss = 2.289355516433716, val_loss = 2.052276134490967\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 2.2894 - categorical_accuracy: 0.1904 - val_loss: 2.0523 - val_categorical_accuracy: 0.2607\n",
      "Epoch 8/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.2414 - categorical_accuracy: 0.2076Epoch 8: loss = 2.2409682273864746, val_loss = 2.2173287868499756\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 2.2410 - categorical_accuracy: 0.2094 - val_loss: 2.2173 - val_categorical_accuracy: 0.2332\n",
      "Epoch 9/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.2293 - categorical_accuracy: 0.2050Epoch 9: loss = 2.2280759811401367, val_loss = 2.1866352558135986\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 2.2281 - categorical_accuracy: 0.2056 - val_loss: 2.1866 - val_categorical_accuracy: 0.2500\n",
      "Epoch 10/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.0837 - categorical_accuracy: 0.2670Epoch 10: loss = 2.0835819244384766, val_loss = 1.8564153909683228\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 2.0836 - categorical_accuracy: 0.2658 - val_loss: 1.8564 - val_categorical_accuracy: 0.3064\n",
      "Epoch 11/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.9902 - categorical_accuracy: 0.2826Epoch 11: loss = 1.9901808500289917, val_loss = 1.8819146156311035\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.9902 - categorical_accuracy: 0.2826 - val_loss: 1.8819 - val_categorical_accuracy: 0.3369\n",
      "Epoch 12/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.9252 - categorical_accuracy: 0.2909Epoch 12: loss = 1.925218939781189, val_loss = 2.023712635040283\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.9252 - categorical_accuracy: 0.2909 - val_loss: 2.0237 - val_categorical_accuracy: 0.2492\n",
      "Epoch 13/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.9122 - categorical_accuracy: 0.2978Epoch 13: loss = 1.9122415781021118, val_loss = 1.7015081644058228\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.9122 - categorical_accuracy: 0.2978 - val_loss: 1.7015 - val_categorical_accuracy: 0.3552\n",
      "Epoch 14/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.8704 - categorical_accuracy: 0.3191Epoch 14: loss = 1.87041437625885, val_loss = 1.5596129894256592\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.8704 - categorical_accuracy: 0.3191 - val_loss: 1.5596 - val_categorical_accuracy: 0.4284\n",
      "Epoch 15/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.8151 - categorical_accuracy: 0.3179Epoch 15: loss = 1.8136972188949585, val_loss = 1.5096995830535889\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.8137 - categorical_accuracy: 0.3176 - val_loss: 1.5097 - val_categorical_accuracy: 0.4032\n",
      "Epoch 16/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.7994 - categorical_accuracy: 0.3465Epoch 16: loss = 1.7960317134857178, val_loss = 1.5332090854644775\n",
      "83/83 [==============================] - 2s 27ms/step - loss: 1.7960 - categorical_accuracy: 0.3473 - val_loss: 1.5332 - val_categorical_accuracy: 0.4207\n",
      "Epoch 17/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.7881 - categorical_accuracy: 0.3415Epoch 17: loss = 1.7886120080947876, val_loss = 1.7362821102142334\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.7886 - categorical_accuracy: 0.3412 - val_loss: 1.7363 - val_categorical_accuracy: 0.3498\n",
      "Epoch 18/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.7265 - categorical_accuracy: 0.3534Epoch 18: loss = 1.7265195846557617, val_loss = 1.562723159790039\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.7265 - categorical_accuracy: 0.3534 - val_loss: 1.5627 - val_categorical_accuracy: 0.4169\n",
      "Epoch 19/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.7501 - categorical_accuracy: 0.3346Epoch 19: loss = 1.7492260932922363, val_loss = 2.0428760051727295\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.7492 - categorical_accuracy: 0.3351 - val_loss: 2.0429 - val_categorical_accuracy: 0.3232\n",
      "Epoch 20/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.7185 - categorical_accuracy: 0.3598Epoch 20: loss = 1.7185275554656982, val_loss = 1.3942288160324097\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 1.7185 - categorical_accuracy: 0.3595 - val_loss: 1.3942 - val_categorical_accuracy: 0.5107\n",
      "Epoch 21/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.5300 - categorical_accuracy: 0.4158Epoch 21: loss = 1.5300302505493164, val_loss = 1.334298849105835\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.5300 - categorical_accuracy: 0.4158 - val_loss: 1.3343 - val_categorical_accuracy: 0.5191\n",
      "Epoch 22/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.5679 - categorical_accuracy: 0.3960Epoch 22: loss = 1.567924976348877, val_loss = 1.314691424369812\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.5679 - categorical_accuracy: 0.3960 - val_loss: 1.3147 - val_categorical_accuracy: 0.5534\n",
      "Epoch 23/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.4675 - categorical_accuracy: 0.4428Epoch 23: loss = 1.4668409824371338, val_loss = 1.2989388704299927\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.4668 - categorical_accuracy: 0.4433 - val_loss: 1.2989 - val_categorical_accuracy: 0.4985\n",
      "Epoch 24/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.5563 - categorical_accuracy: 0.4345Epoch 24: loss = 1.5560559034347534, val_loss = 1.4596636295318604\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.5561 - categorical_accuracy: 0.4349 - val_loss: 1.4597 - val_categorical_accuracy: 0.4352\n",
      "Epoch 25/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.4325 - categorical_accuracy: 0.4463Epoch 25: loss = 1.432504653930664, val_loss = 1.1809436082839966\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.4325 - categorical_accuracy: 0.4463 - val_loss: 1.1809 - val_categorical_accuracy: 0.5526\n",
      "Epoch 26/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.5567 - categorical_accuracy: 0.4215Epoch 26: loss = 1.5557994842529297, val_loss = 1.3222297430038452\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.5558 - categorical_accuracy: 0.4219 - val_loss: 1.3222 - val_categorical_accuracy: 0.5213\n",
      "Epoch 27/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.3792 - categorical_accuracy: 0.4631Epoch 27: loss = 1.3792409896850586, val_loss = 1.1194536685943604\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.3792 - categorical_accuracy: 0.4631 - val_loss: 1.1195 - val_categorical_accuracy: 0.6029\n",
      "Epoch 28/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.3677 - categorical_accuracy: 0.4799Epoch 28: loss = 1.3794647455215454, val_loss = 4.776859760284424\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.3795 - categorical_accuracy: 0.4775 - val_loss: 4.7769 - val_categorical_accuracy: 0.2279\n",
      "Epoch 29/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.1547 - categorical_accuracy: 0.2721Epoch 29: loss = 2.1545650959014893, val_loss = 1.3782856464385986\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 2.1546 - categorical_accuracy: 0.2719 - val_loss: 1.3783 - val_categorical_accuracy: 0.5152\n",
      "Epoch 30/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.4950 - categorical_accuracy: 0.4213Epoch 30: loss = 1.48980712890625, val_loss = 1.267562985420227\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.4898 - categorical_accuracy: 0.4227 - val_loss: 1.2676 - val_categorical_accuracy: 0.5191\n",
      "Epoch 31/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.6206 - categorical_accuracy: 0.3803Epoch 31: loss = 1.6200988292694092, val_loss = 1.3659477233886719\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.6201 - categorical_accuracy: 0.3808 - val_loss: 1.3659 - val_categorical_accuracy: 0.4985\n",
      "Epoch 32/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.4316 - categorical_accuracy: 0.4341Epoch 32: loss = 1.431591272354126, val_loss = 1.254927158355713\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.4316 - categorical_accuracy: 0.4341 - val_loss: 1.2549 - val_categorical_accuracy: 0.5114\n",
      "Epoch 33/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.3610 - categorical_accuracy: 0.4684Epoch 33: loss = 1.3594528436660767, val_loss = 1.1282492876052856\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.3595 - categorical_accuracy: 0.4676 - val_loss: 1.1282 - val_categorical_accuracy: 0.5808\n",
      "Epoch 34/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.4226 - categorical_accuracy: 0.4288Epoch 34: loss = 1.4226036071777344, val_loss = 1.1281588077545166\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.4226 - categorical_accuracy: 0.4288 - val_loss: 1.1282 - val_categorical_accuracy: 0.5549\n",
      "Epoch 35/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.3571 - categorical_accuracy: 0.4869Epoch 35: loss = 1.3539047241210938, val_loss = 1.0460736751556396\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.3539 - categorical_accuracy: 0.4859 - val_loss: 1.0461 - val_categorical_accuracy: 0.6502\n",
      "Epoch 36/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.2718 - categorical_accuracy: 0.4884Epoch 36: loss = 1.2698304653167725, val_loss = 0.9704593420028687\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.2698 - categorical_accuracy: 0.4897 - val_loss: 0.9705 - val_categorical_accuracy: 0.6220\n",
      "Epoch 37/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.2353 - categorical_accuracy: 0.5171Epoch 37: loss = 1.2352752685546875, val_loss = 1.0201191902160645\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.2353 - categorical_accuracy: 0.5171 - val_loss: 1.0201 - val_categorical_accuracy: 0.6098\n",
      "Epoch 38/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.4233 - categorical_accuracy: 0.4707Epoch 38: loss = 1.423256754875183, val_loss = 1.0698283910751343\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.4233 - categorical_accuracy: 0.4707 - val_loss: 1.0698 - val_categorical_accuracy: 0.5892\n",
      "Epoch 39/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.2568 - categorical_accuracy: 0.4886Epoch 39: loss = 1.2567989826202393, val_loss = 0.934097945690155\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.2568 - categorical_accuracy: 0.4890 - val_loss: 0.9341 - val_categorical_accuracy: 0.6494\n",
      "Epoch 40/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.4978 - categorical_accuracy: 0.4466Epoch 40: loss = 1.496623158454895, val_loss = 1.3524887561798096\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.4966 - categorical_accuracy: 0.4471 - val_loss: 1.3525 - val_categorical_accuracy: 0.4916\n",
      "Epoch 41/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.4393 - categorical_accuracy: 0.4436Epoch 41: loss = 1.4391378164291382, val_loss = 1.208280086517334\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.4391 - categorical_accuracy: 0.4440 - val_loss: 1.2083 - val_categorical_accuracy: 0.5213\n",
      "Epoch 42/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.3618 - categorical_accuracy: 0.4753Epoch 42: loss = 1.3645776510238647, val_loss = 1.1383347511291504\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.3646 - categorical_accuracy: 0.4760 - val_loss: 1.1383 - val_categorical_accuracy: 0.5389\n",
      "Epoch 43/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.3317 - categorical_accuracy: 0.5000Epoch 43: loss = 1.3311299085617065, val_loss = 1.0587011575698853\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.3311 - categorical_accuracy: 0.5004 - val_loss: 1.0587 - val_categorical_accuracy: 0.6006\n",
      "Epoch 44/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.3318 - categorical_accuracy: 0.4916Epoch 44: loss = 1.3307737112045288, val_loss = 1.0205926895141602\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.3308 - categorical_accuracy: 0.4920 - val_loss: 1.0206 - val_categorical_accuracy: 0.5915\n",
      "Epoch 45/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.2270 - categorical_accuracy: 0.5088Epoch 45: loss = 1.2270429134368896, val_loss = 1.0299922227859497\n",
      "83/83 [==============================] - 2s 29ms/step - loss: 1.2270 - categorical_accuracy: 0.5088 - val_loss: 1.0300 - val_categorical_accuracy: 0.6265\n",
      "Epoch 46/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.3236 - categorical_accuracy: 0.4874Epoch 46: loss = 1.3236300945281982, val_loss = 1.4671285152435303\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.3236 - categorical_accuracy: 0.4874 - val_loss: 1.4671 - val_categorical_accuracy: 0.4939\n",
      "Epoch 47/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.1760 - categorical_accuracy: 0.5427Epoch 47: loss = 1.1762375831604004, val_loss = 0.9780620336532593\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.1762 - categorical_accuracy: 0.5423 - val_loss: 0.9781 - val_categorical_accuracy: 0.5846\n",
      "Epoch 48/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.1483 - categorical_accuracy: 0.5293Epoch 48: loss = 1.1474581956863403, val_loss = 0.986062228679657\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.1475 - categorical_accuracy: 0.5316 - val_loss: 0.9861 - val_categorical_accuracy: 0.6113\n",
      "Epoch 49/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.2696 - categorical_accuracy: 0.4939Restoring model weights from the end of the best epoch: 39.\n",
      "Epoch 49: loss = 1.2687616348266602, val_loss = 1.211198091506958\n",
      "83/83 [==============================] - 2s 26ms/step - loss: 1.2688 - categorical_accuracy: 0.4943 - val_loss: 1.2112 - val_categorical_accuracy: 0.5130\n",
      "Epoch 49: early stopping\n",
      "41/41 [==============================] - 1s 8ms/step - loss: 0.9341 - categorical_accuracy: 0.6494\n",
      "Epoch 1/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 3.2380 - categorical_accuracy: 0.0321Epoch 1: loss = 3.237172842025757, val_loss = 3.1856331825256348\n",
      "41/41 [==============================] - 5s 41ms/step - loss: 3.2372 - categorical_accuracy: 0.0320 - val_loss: 3.1856 - val_categorical_accuracy: 0.0350\n",
      "Epoch 2/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 3.1391 - categorical_accuracy: 0.0312Epoch 2: loss = 3.1381843090057373, val_loss = 3.0573983192443848\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 3.1382 - categorical_accuracy: 0.0328 - val_loss: 3.0574 - val_categorical_accuracy: 0.0510\n",
      "Epoch 3/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 3.0106 - categorical_accuracy: 0.0766Epoch 3: loss = 3.0098838806152344, val_loss = 2.9107837677001953\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 3.0099 - categorical_accuracy: 0.0762 - val_loss: 2.9108 - val_categorical_accuracy: 0.0853\n",
      "Epoch 4/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 2.8494 - categorical_accuracy: 0.1322Epoch 4: loss = 2.8426647186279297, val_loss = 2.757228374481201\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 2.8427 - categorical_accuracy: 0.1326 - val_loss: 2.7572 - val_categorical_accuracy: 0.1295\n",
      "Epoch 5/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.8190 - categorical_accuracy: 0.1164Epoch 5: loss = 2.8197579383850098, val_loss = 2.6672418117523193\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 2.8198 - categorical_accuracy: 0.1159 - val_loss: 2.6672 - val_categorical_accuracy: 0.1942\n",
      "Epoch 6/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.5406 - categorical_accuracy: 0.1930Epoch 6: loss = 2.5401337146759033, val_loss = 2.5564308166503906\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 2.5401 - categorical_accuracy: 0.1913 - val_loss: 2.5564 - val_categorical_accuracy: 0.1736\n",
      "Epoch 7/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 2.5451 - categorical_accuracy: 0.1554Epoch 7: loss = 2.5263891220092773, val_loss = 2.3964579105377197\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 2.5264 - categorical_accuracy: 0.1585 - val_loss: 2.3965 - val_categorical_accuracy: 0.1752\n",
      "Epoch 8/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.3764 - categorical_accuracy: 0.1945Epoch 8: loss = 2.3747901916503906, val_loss = 2.5065205097198486\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 2.3748 - categorical_accuracy: 0.1944 - val_loss: 2.5065 - val_categorical_accuracy: 0.1059\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3434 - categorical_accuracy: 0.1966Epoch 9: loss = 2.343411445617676, val_loss = 2.15582013130188\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 2.3434 - categorical_accuracy: 0.1966 - val_loss: 2.1558 - val_categorical_accuracy: 0.2582\n",
      "Epoch 10/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 2.0939 - categorical_accuracy: 0.2548Epoch 10: loss = 2.105903387069702, val_loss = 2.0573487281799316\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 2.1059 - categorical_accuracy: 0.2508 - val_loss: 2.0573 - val_categorical_accuracy: 0.2856\n",
      "Epoch 11/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.9995 - categorical_accuracy: 0.2949Epoch 11: loss = 2.0075013637542725, val_loss = 2.135277032852173\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 2.0075 - categorical_accuracy: 0.2912 - val_loss: 2.1353 - val_categorical_accuracy: 0.2087\n",
      "Epoch 12/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.9744 - categorical_accuracy: 0.2750Epoch 12: loss = 1.9669288396835327, val_loss = 1.9253292083740234\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 1.9669 - categorical_accuracy: 0.2797 - val_loss: 1.9253 - val_categorical_accuracy: 0.2727\n",
      "Epoch 13/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.9760 - categorical_accuracy: 0.2953Epoch 13: loss = 1.9831490516662598, val_loss = 2.208843946456909\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 1.9831 - categorical_accuracy: 0.2942 - val_loss: 2.2088 - val_categorical_accuracy: 0.2635\n",
      "Epoch 14/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 1.9693 - categorical_accuracy: 0.2928Epoch 14: loss = 1.9588061571121216, val_loss = 1.7881497144699097\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 1.9588 - categorical_accuracy: 0.2934 - val_loss: 1.7881 - val_categorical_accuracy: 0.3709\n",
      "Epoch 15/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.7732 - categorical_accuracy: 0.3478Epoch 15: loss = 1.7721149921417236, val_loss = 1.7621614933013916\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 1.7721 - categorical_accuracy: 0.3445 - val_loss: 1.7622 - val_categorical_accuracy: 0.3701\n",
      "Epoch 16/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.6966 - categorical_accuracy: 0.3782Epoch 16: loss = 1.68806791305542, val_loss = 1.7650537490844727\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 1.6881 - categorical_accuracy: 0.3803 - val_loss: 1.7651 - val_categorical_accuracy: 0.3572\n",
      "Epoch 17/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 2.3973 - categorical_accuracy: 0.2901Epoch 17: loss = 2.3985278606414795, val_loss = 2.5019850730895996\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 2.3985 - categorical_accuracy: 0.2812 - val_loss: 2.5020 - val_categorical_accuracy: 0.1272\n",
      "Epoch 18/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 2.2586 - categorical_accuracy: 0.1947Epoch 18: loss = 2.255814790725708, val_loss = 2.1150200366973877\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 2.2558 - categorical_accuracy: 0.1944 - val_loss: 2.1150 - val_categorical_accuracy: 0.2879\n",
      "Epoch 19/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 2.0542 - categorical_accuracy: 0.2878Epoch 19: loss = 2.0506772994995117, val_loss = 2.0063023567199707\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 2.0507 - categorical_accuracy: 0.2835 - val_loss: 2.0063 - val_categorical_accuracy: 0.2841\n",
      "Epoch 20/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.9034 - categorical_accuracy: 0.3141Epoch 20: loss = 1.9065181016921997, val_loss = 1.8690861463546753\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 1.9065 - categorical_accuracy: 0.3117 - val_loss: 1.8691 - val_categorical_accuracy: 0.3382\n",
      "Epoch 21/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 1.9028 - categorical_accuracy: 0.2895Epoch 21: loss = 1.8900644779205322, val_loss = 1.8688654899597168\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 1.8901 - categorical_accuracy: 0.2957 - val_loss: 1.8689 - val_categorical_accuracy: 0.3899\n",
      "Epoch 22/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 2.1122 - categorical_accuracy: 0.2755Epoch 22: loss = 2.133870840072632, val_loss = 2.4073405265808105\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 2.1339 - categorical_accuracy: 0.2729 - val_loss: 2.4073 - val_categorical_accuracy: 0.1736\n",
      "Epoch 23/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 2.2044 - categorical_accuracy: 0.2732Epoch 23: loss = 2.1946475505828857, val_loss = 2.011566638946533\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 2.1946 - categorical_accuracy: 0.2721 - val_loss: 2.0116 - val_categorical_accuracy: 0.2727\n",
      "Epoch 24/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.9424 - categorical_accuracy: 0.3269Epoch 24: loss = 1.9399669170379639, val_loss = 1.8083758354187012\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 1.9400 - categorical_accuracy: 0.3270 - val_loss: 1.8084 - val_categorical_accuracy: 0.3633\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.7067 - categorical_accuracy: 0.3620Epoch 25: loss = 1.7066999673843384, val_loss = 1.7333859205245972\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 1.7067 - categorical_accuracy: 0.3620 - val_loss: 1.7334 - val_categorical_accuracy: 0.3374\n",
      "Epoch 26/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.7217 - categorical_accuracy: 0.3414Epoch 26: loss = 1.7179851531982422, val_loss = 1.7272218465805054\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 1.7180 - categorical_accuracy: 0.3438 - val_loss: 1.7272 - val_categorical_accuracy: 0.3366\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.7888 - categorical_accuracy: 0.3460Epoch 27: loss = 1.7888063192367554, val_loss = 1.6472290754318237\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 1.7888 - categorical_accuracy: 0.3460 - val_loss: 1.6472 - val_categorical_accuracy: 0.3823\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.6859 - categorical_accuracy: 0.3849Epoch 28: loss = 1.685861349105835, val_loss = 1.5887905359268188\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 1.6859 - categorical_accuracy: 0.3849 - val_loss: 1.5888 - val_categorical_accuracy: 0.4296\n",
      "Epoch 29/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.5517 - categorical_accuracy: 0.4159Epoch 29: loss = 1.556449055671692, val_loss = 1.5665836334228516\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 1.5564 - categorical_accuracy: 0.4162 - val_loss: 1.5666 - val_categorical_accuracy: 0.4166\n",
      "Epoch 30/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.5131 - categorical_accuracy: 0.4375Epoch 30: loss = 1.5112676620483398, val_loss = 1.4664158821105957\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 1.5113 - categorical_accuracy: 0.4383 - val_loss: 1.4664 - val_categorical_accuracy: 0.4707\n",
      "Epoch 31/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.5149 - categorical_accuracy: 0.4313Epoch 31: loss = 1.5241934061050415, val_loss = 1.6442785263061523\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 1.5242 - categorical_accuracy: 0.4261 - val_loss: 1.6443 - val_categorical_accuracy: 0.3983\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.4688 - categorical_accuracy: 0.4604Epoch 32: loss = 1.468809723854065, val_loss = 1.5163335800170898\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 1.4688 - categorical_accuracy: 0.4604 - val_loss: 1.5163 - val_categorical_accuracy: 0.4364\n",
      "Epoch 33/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 1.4332 - categorical_accuracy: 0.4474Epoch 33: loss = 1.4279019832611084, val_loss = 1.3654742240905762\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 1.4279 - categorical_accuracy: 0.4482 - val_loss: 1.3655 - val_categorical_accuracy: 0.5187\n",
      "Epoch 34/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.3985 - categorical_accuracy: 0.4720Epoch 34: loss = 1.404340147972107, val_loss = 1.3159540891647339\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 1.4043 - categorical_accuracy: 0.4710 - val_loss: 1.3160 - val_categorical_accuracy: 0.5126\n",
      "Epoch 35/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.3620 - categorical_accuracy: 0.4864Epoch 35: loss = 1.3649787902832031, val_loss = 1.3781379461288452\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 1.3650 - categorical_accuracy: 0.4848 - val_loss: 1.3781 - val_categorical_accuracy: 0.4783\n",
      "Epoch 36/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.3506 - categorical_accuracy: 0.4953Epoch 36: loss = 1.3513864278793335, val_loss = 1.4005669355392456\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 1.3514 - categorical_accuracy: 0.4939 - val_loss: 1.4006 - val_categorical_accuracy: 0.4577\n",
      "Epoch 37/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.3209 - categorical_accuracy: 0.5180Epoch 37: loss = 1.323028802871704, val_loss = 1.2870985269546509\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 1.3230 - categorical_accuracy: 0.5145 - val_loss: 1.2871 - val_categorical_accuracy: 0.5156\n",
      "Epoch 38/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 1.2726 - categorical_accuracy: 0.5206Epoch 38: loss = 1.2711213827133179, val_loss = 1.2457966804504395\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 1.2711 - categorical_accuracy: 0.5221 - val_loss: 1.2458 - val_categorical_accuracy: 0.5529\n",
      "Epoch 39/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.2750 - categorical_accuracy: 0.5120Epoch 39: loss = 1.2809251546859741, val_loss = 1.2787894010543823\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 1.2809 - categorical_accuracy: 0.5099 - val_loss: 1.2788 - val_categorical_accuracy: 0.5369\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.3086 - categorical_accuracy: 0.5053Epoch 40: loss = 1.3085955381393433, val_loss = 1.220989465713501\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 1.3086 - categorical_accuracy: 0.5053 - val_loss: 1.2210 - val_categorical_accuracy: 0.5484\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2060 - categorical_accuracy: 0.5442Epoch 41: loss = 1.206039547920227, val_loss = 1.1523243188858032\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 1.2060 - categorical_accuracy: 0.5442 - val_loss: 1.1523 - val_categorical_accuracy: 0.5750\n",
      "Epoch 42/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.2191 - categorical_accuracy: 0.5500Epoch 42: loss = 1.2229067087173462, val_loss = 1.1689459085464478\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 1.2229 - categorical_accuracy: 0.5488 - val_loss: 1.1689 - val_categorical_accuracy: 0.5956\n",
      "Epoch 43/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.2510 - categorical_accuracy: 0.5586Epoch 43: loss = 1.25205397605896, val_loss = 1.1573219299316406\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 1.2521 - categorical_accuracy: 0.5579 - val_loss: 1.1573 - val_categorical_accuracy: 0.5933\n",
      "Epoch 44/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 1.1643 - categorical_accuracy: 0.5625Epoch 44: loss = 1.1666038036346436, val_loss = 1.2169758081436157\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 1.1666 - categorical_accuracy: 0.5633 - val_loss: 1.2170 - val_categorical_accuracy: 0.5415\n",
      "Epoch 45/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.1916 - categorical_accuracy: 0.5665Epoch 45: loss = 1.1859902143478394, val_loss = 1.1087779998779297\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 1.1860 - categorical_accuracy: 0.5686 - val_loss: 1.1088 - val_categorical_accuracy: 0.6184\n",
      "Epoch 46/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.1190 - categorical_accuracy: 0.5820Epoch 46: loss = 1.121218204498291, val_loss = 1.2298462390899658\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 1.1212 - categorical_accuracy: 0.5800 - val_loss: 1.2298 - val_categorical_accuracy: 0.5750\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2473 - categorical_accuracy: 0.5404Epoch 47: loss = 1.2473269701004028, val_loss = 1.1704479455947876\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 1.2473 - categorical_accuracy: 0.5404 - val_loss: 1.1704 - val_categorical_accuracy: 0.6093\n",
      "Epoch 48/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 1.1166 - categorical_accuracy: 0.5979Epoch 48: loss = 1.1137425899505615, val_loss = 1.0344209671020508\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 1.1137 - categorical_accuracy: 0.5998 - val_loss: 1.0344 - val_categorical_accuracy: 0.6382\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2305 - categorical_accuracy: 0.5373Epoch 49: loss = 1.2304966449737549, val_loss = 1.1609299182891846\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 1.2305 - categorical_accuracy: 0.5373 - val_loss: 1.1609 - val_categorical_accuracy: 0.5758\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0597 - categorical_accuracy: 0.6159Epoch 50: loss = 1.059721827507019, val_loss = 1.1295846700668335\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 1.0597 - categorical_accuracy: 0.6159 - val_loss: 1.1296 - val_categorical_accuracy: 0.5918\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 1.1296 - categorical_accuracy: 0.5918\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.2141 - categorical_accuracy: 0.0472Epoch 1: loss = 3.2140533924102783, val_loss = 3.183311700820923\n",
      "42/42 [==============================] - 6s 43ms/step - loss: 3.2141 - categorical_accuracy: 0.0472 - val_loss: 3.1833 - val_categorical_accuracy: 0.0884\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.1409 - categorical_accuracy: 0.0861Epoch 2: loss = 3.140901565551758, val_loss = 3.0080111026763916\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 3.1409 - categorical_accuracy: 0.0861 - val_loss: 3.0080 - val_categorical_accuracy: 0.0877\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.9789 - categorical_accuracy: 0.0883Epoch 3: loss = 2.978933572769165, val_loss = 2.7658636569976807\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 2.9789 - categorical_accuracy: 0.0883 - val_loss: 2.7659 - val_categorical_accuracy: 0.1113\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.7602 - categorical_accuracy: 0.1203Epoch 4: loss = 2.7601635456085205, val_loss = 2.571364164352417\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.7602 - categorical_accuracy: 0.1203 - val_loss: 2.5714 - val_categorical_accuracy: 0.0915\n",
      "Epoch 5/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.5666 - categorical_accuracy: 0.1288Epoch 5: loss = 2.5666441917419434, val_loss = 2.5591537952423096\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.5666 - categorical_accuracy: 0.1287 - val_loss: 2.5592 - val_categorical_accuracy: 0.1128\n",
      "Epoch 6/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.4970 - categorical_accuracy: 0.1578Epoch 6: loss = 2.491530656814575, val_loss = 2.300518274307251\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 2.4915 - categorical_accuracy: 0.1584 - val_loss: 2.3005 - val_categorical_accuracy: 0.2050\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.3869 - categorical_accuracy: 0.1973Epoch 7: loss = 2.3868887424468994, val_loss = 2.2796905040740967\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 2.3869 - categorical_accuracy: 0.1973 - val_loss: 2.2797 - val_categorical_accuracy: 0.2523\n",
      "Epoch 8/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.2919 - categorical_accuracy: 0.1969Epoch 8: loss = 2.2874464988708496, val_loss = 2.158665895462036\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2874 - categorical_accuracy: 0.1988 - val_loss: 2.1587 - val_categorical_accuracy: 0.2241\n",
      "Epoch 9/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.2690 - categorical_accuracy: 0.2242Epoch 9: loss = 2.2707269191741943, val_loss = 2.1164324283599854\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 2.2707 - categorical_accuracy: 0.2254 - val_loss: 2.1164 - val_categorical_accuracy: 0.2241\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.2244 - categorical_accuracy: 0.2186Epoch 10: loss = 2.224363327026367, val_loss = 2.1591665744781494\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2244 - categorical_accuracy: 0.2186 - val_loss: 2.1592 - val_categorical_accuracy: 0.2073\n",
      "Epoch 11/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.1788 - categorical_accuracy: 0.2660Epoch 11: loss = 2.1793131828308105, val_loss = 2.0712037086486816\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1793 - categorical_accuracy: 0.2658 - val_loss: 2.0712 - val_categorical_accuracy: 0.3056\n",
      "Epoch 12/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.1479 - categorical_accuracy: 0.2617Epoch 12: loss = 2.145456552505493, val_loss = 2.010974645614624\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 2.1455 - categorical_accuracy: 0.2628 - val_loss: 2.0110 - val_categorical_accuracy: 0.2866\n",
      "Epoch 13/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.1032 - categorical_accuracy: 0.2703Epoch 13: loss = 2.107374668121338, val_loss = 1.9713486433029175\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1074 - categorical_accuracy: 0.2688 - val_loss: 1.9713 - val_categorical_accuracy: 0.3018\n",
      "Epoch 14/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.0357 - categorical_accuracy: 0.2953Epoch 14: loss = 2.0371758937835693, val_loss = 1.8781561851501465\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.0372 - categorical_accuracy: 0.2963 - val_loss: 1.8782 - val_categorical_accuracy: 0.3483\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.9548 - categorical_accuracy: 0.3115Epoch 15: loss = 1.9548159837722778, val_loss = 1.7465834617614746\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.9548 - categorical_accuracy: 0.3115 - val_loss: 1.7466 - val_categorical_accuracy: 0.3773\n",
      "Epoch 16/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.1695 - categorical_accuracy: 0.2797Epoch 16: loss = 2.162705898284912, val_loss = 1.8366811275482178\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1627 - categorical_accuracy: 0.2818 - val_loss: 1.8367 - val_categorical_accuracy: 0.3468\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.8555 - categorical_accuracy: 0.3145Epoch 17: loss = 1.8555136919021606, val_loss = 1.8341015577316284\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.8555 - categorical_accuracy: 0.3145 - val_loss: 1.8341 - val_categorical_accuracy: 0.3338\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.8361 - categorical_accuracy: 0.3267Epoch 18: loss = 1.8361457586288452, val_loss = 1.646188497543335\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 1.8361 - categorical_accuracy: 0.3267 - val_loss: 1.6462 - val_categorical_accuracy: 0.4017\n",
      "Epoch 19/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.6768 - categorical_accuracy: 0.3609Epoch 19: loss = 1.6796860694885254, val_loss = 1.521741271018982\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.6797 - categorical_accuracy: 0.3587 - val_loss: 1.5217 - val_categorical_accuracy: 0.3979\n",
      "Epoch 20/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.6673 - categorical_accuracy: 0.3643Epoch 20: loss = 1.668013334274292, val_loss = 1.7236542701721191\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.6680 - categorical_accuracy: 0.3641 - val_loss: 1.7237 - val_categorical_accuracy: 0.3506\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6070 - categorical_accuracy: 0.3869Epoch 21: loss = 1.6070183515548706, val_loss = 1.4381773471832275\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 1.6070 - categorical_accuracy: 0.3869 - val_loss: 1.4382 - val_categorical_accuracy: 0.4291\n",
      "Epoch 22/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.6113 - categorical_accuracy: 0.3891Epoch 22: loss = 1.6107723712921143, val_loss = 1.3825736045837402\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.6108 - categorical_accuracy: 0.3854 - val_loss: 1.3826 - val_categorical_accuracy: 0.4322\n",
      "Epoch 23/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.5497 - categorical_accuracy: 0.4102Epoch 23: loss = 1.5460599660873413, val_loss = 1.4210209846496582\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.5461 - categorical_accuracy: 0.4097 - val_loss: 1.4210 - val_categorical_accuracy: 0.4512\n",
      "Epoch 24/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.7172 - categorical_accuracy: 0.3656Epoch 24: loss = 1.7045516967773438, val_loss = 1.5283408164978027\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.7046 - categorical_accuracy: 0.3717 - val_loss: 1.5283 - val_categorical_accuracy: 0.3979\n",
      "Epoch 25/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.5017 - categorical_accuracy: 0.4108Epoch 25: loss = 1.5023362636566162, val_loss = 1.5223215818405151\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.5023 - categorical_accuracy: 0.4105 - val_loss: 1.5223 - val_categorical_accuracy: 0.4497\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4478 - categorical_accuracy: 0.4692Epoch 26: loss = 1.4477689266204834, val_loss = 1.3446688652038574\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.4478 - categorical_accuracy: 0.4692 - val_loss: 1.3447 - val_categorical_accuracy: 0.4787\n",
      "Epoch 27/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.4304 - categorical_accuracy: 0.4734Epoch 27: loss = 1.4280579090118408, val_loss = 1.2092748880386353\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 1.4281 - categorical_accuracy: 0.4745 - val_loss: 1.2093 - val_categorical_accuracy: 0.5297\n",
      "Epoch 28/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.4169 - categorical_accuracy: 0.4672Epoch 28: loss = 1.413068175315857, val_loss = 1.2632644176483154\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4131 - categorical_accuracy: 0.4676 - val_loss: 1.2633 - val_categorical_accuracy: 0.5191\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3473 - categorical_accuracy: 0.4791Epoch 29: loss = 1.347293496131897, val_loss = 1.2481153011322021\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.3473 - categorical_accuracy: 0.4791 - val_loss: 1.2481 - val_categorical_accuracy: 0.5450\n",
      "Epoch 30/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.4043 - categorical_accuracy: 0.4825Epoch 30: loss = 1.4046791791915894, val_loss = 1.1995770931243896\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4047 - categorical_accuracy: 0.4821 - val_loss: 1.1996 - val_categorical_accuracy: 0.5457\n",
      "Epoch 31/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.4168 - categorical_accuracy: 0.4779Epoch 31: loss = 1.4172230958938599, val_loss = 1.187081217765808\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4172 - categorical_accuracy: 0.4775 - val_loss: 1.1871 - val_categorical_accuracy: 0.5511\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2546 - categorical_accuracy: 0.5057Epoch 32: loss = 1.2545806169509888, val_loss = 1.1131900548934937\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 1.2546 - categorical_accuracy: 0.5057 - val_loss: 1.1132 - val_categorical_accuracy: 0.5884\n",
      "Epoch 33/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.1888 - categorical_accuracy: 0.5477Epoch 33: loss = 1.1905186176300049, val_loss = 1.040730357170105\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1905 - categorical_accuracy: 0.5453 - val_loss: 1.0407 - val_categorical_accuracy: 0.6265\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2709 - categorical_accuracy: 0.5301Epoch 34: loss = 1.2708535194396973, val_loss = 1.1226567029953003\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2709 - categorical_accuracy: 0.5301 - val_loss: 1.1227 - val_categorical_accuracy: 0.5762\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1704 - categorical_accuracy: 0.5545Epoch 35: loss = 1.1704251766204834, val_loss = 1.1544044017791748\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1704 - categorical_accuracy: 0.5545 - val_loss: 1.1544 - val_categorical_accuracy: 0.5747\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2280 - categorical_accuracy: 0.5400Epoch 36: loss = 1.2279635667800903, val_loss = 0.9769542217254639\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.2280 - categorical_accuracy: 0.5400 - val_loss: 0.9770 - val_categorical_accuracy: 0.6547\n",
      "Epoch 37/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.1230 - categorical_accuracy: 0.5680Epoch 37: loss = 1.1248928308486938, val_loss = 1.02338445186615\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1249 - categorical_accuracy: 0.5659 - val_loss: 1.0234 - val_categorical_accuracy: 0.6486\n",
      "Epoch 38/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.1806 - categorical_accuracy: 0.5594Epoch 38: loss = 1.1914777755737305, val_loss = 1.079020380973816\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1915 - categorical_accuracy: 0.5529 - val_loss: 1.0790 - val_categorical_accuracy: 0.6242\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1251 - categorical_accuracy: 0.5804Epoch 39: loss = 1.125142216682434, val_loss = 0.9739600419998169\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.1251 - categorical_accuracy: 0.5804 - val_loss: 0.9740 - val_categorical_accuracy: 0.6441\n",
      "Epoch 40/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.1130 - categorical_accuracy: 0.5823Epoch 40: loss = 1.1131281852722168, val_loss = 1.0655949115753174\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1131 - categorical_accuracy: 0.5819 - val_loss: 1.0656 - val_categorical_accuracy: 0.5854\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0794 - categorical_accuracy: 0.5872Epoch 41: loss = 1.0793704986572266, val_loss = 1.0817774534225464\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0794 - categorical_accuracy: 0.5872 - val_loss: 1.0818 - val_categorical_accuracy: 0.6166\n",
      "Epoch 42/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.2171 - categorical_accuracy: 0.5578Epoch 42: loss = 1.2168502807617188, val_loss = 1.054265022277832\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 1.2169 - categorical_accuracy: 0.5567 - val_loss: 1.0543 - val_categorical_accuracy: 0.6433\n",
      "Epoch 43/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.1246 - categorical_accuracy: 0.5773Epoch 43: loss = 1.127493977546692, val_loss = 1.280395746231079\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1275 - categorical_accuracy: 0.5765 - val_loss: 1.2804 - val_categorical_accuracy: 0.5610\n",
      "Epoch 44/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.0734 - categorical_accuracy: 0.5869Epoch 44: loss = 1.0727379322052002, val_loss = 0.8939464092254639\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0727 - categorical_accuracy: 0.5872 - val_loss: 0.8939 - val_categorical_accuracy: 0.6745\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0584 - categorical_accuracy: 0.6101Epoch 45: loss = 1.0583946704864502, val_loss = 1.0143793821334839\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 1.0584 - categorical_accuracy: 0.6101 - val_loss: 1.0144 - val_categorical_accuracy: 0.6502\n",
      "Epoch 46/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.1224 - categorical_accuracy: 0.5823Epoch 46: loss = 1.1215242147445679, val_loss = 0.8716385960578918\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.1215 - categorical_accuracy: 0.5826 - val_loss: 0.8716 - val_categorical_accuracy: 0.6692\n",
      "Epoch 47/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.0028 - categorical_accuracy: 0.6265Epoch 47: loss = 1.0023118257522583, val_loss = 0.8732276558876038\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.0023 - categorical_accuracy: 0.6268 - val_loss: 0.8732 - val_categorical_accuracy: 0.7035\n",
      "Epoch 48/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.9533 - categorical_accuracy: 0.6395Epoch 48: loss = 0.9531186819076538, val_loss = 0.9642022252082825\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9531 - categorical_accuracy: 0.6390 - val_loss: 0.9642 - val_categorical_accuracy: 0.6570\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1103 - categorical_accuracy: 0.5903Epoch 49: loss = 1.1102941036224365, val_loss = 1.1491197347640991\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.1103 - categorical_accuracy: 0.5903 - val_loss: 1.1491 - val_categorical_accuracy: 0.5838\n",
      "Epoch 50/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.0872 - categorical_accuracy: 0.5960Epoch 50: loss = 1.0870262384414673, val_loss = 0.9822004437446594\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.0870 - categorical_accuracy: 0.5963 - val_loss: 0.9822 - val_categorical_accuracy: 0.6395\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.9822 - categorical_accuracy: 0.6395\n",
      "Epoch 1/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 3.1765 - categorical_accuracy: 0.0403Epoch 1: loss = 3.1736090183258057, val_loss = 3.104196548461914\n",
      "41/41 [==============================] - 5s 41ms/step - loss: 3.1736 - categorical_accuracy: 0.0381 - val_loss: 3.1042 - val_categorical_accuracy: 0.0388\n",
      "Epoch 2/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 3.0337 - categorical_accuracy: 0.0510Epoch 2: loss = 3.0316667556762695, val_loss = 2.872162103652954\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 3.0317 - categorical_accuracy: 0.0549 - val_loss: 2.8722 - val_categorical_accuracy: 0.0792\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.8705 - categorical_accuracy: 0.0968Epoch 3: loss = 2.8704802989959717, val_loss = 2.719388961791992\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 2.8705 - categorical_accuracy: 0.0968 - val_loss: 2.7194 - val_categorical_accuracy: 0.0823\n",
      "Epoch 4/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 2.7178 - categorical_accuracy: 0.1034Epoch 4: loss = 2.715186834335327, val_loss = 2.5973424911499023\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 2.7152 - categorical_accuracy: 0.1029 - val_loss: 2.5973 - val_categorical_accuracy: 0.0937\n",
      "Epoch 5/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.6010 - categorical_accuracy: 0.1125Epoch 5: loss = 2.5948684215545654, val_loss = 2.4545302391052246\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 2.5949 - categorical_accuracy: 0.1159 - val_loss: 2.4545 - val_categorical_accuracy: 0.1538\n",
      "Epoch 6/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 2.4962 - categorical_accuracy: 0.1747Epoch 6: loss = 2.493529796600342, val_loss = 2.34621524810791\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 2.4935 - categorical_accuracy: 0.1799 - val_loss: 2.3462 - val_categorical_accuracy: 0.1942\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3685 - categorical_accuracy: 0.1860Epoch 7: loss = 2.368478536605835, val_loss = 2.5053069591522217\n",
      "41/41 [==============================] - 1s 31ms/step - loss: 2.3685 - categorical_accuracy: 0.1860 - val_loss: 2.5053 - val_categorical_accuracy: 0.1584\n",
      "Epoch 8/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 2.3702 - categorical_accuracy: 0.2091Epoch 8: loss = 2.371896982192993, val_loss = 2.2519662380218506\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 2.3719 - categorical_accuracy: 0.2073 - val_loss: 2.2520 - val_categorical_accuracy: 0.1896\n",
      "Epoch 9/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.2796 - categorical_accuracy: 0.2070Epoch 9: loss = 2.2792892456054688, val_loss = 2.1390910148620605\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 2.2793 - categorical_accuracy: 0.2050 - val_loss: 2.1391 - val_categorical_accuracy: 0.2803\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.1414 - categorical_accuracy: 0.2500Epoch 10: loss = 2.1413817405700684, val_loss = 2.007908344268799\n",
      "41/41 [==============================] - 1s 31ms/step - loss: 2.1414 - categorical_accuracy: 0.2500 - val_loss: 2.0079 - val_categorical_accuracy: 0.2963\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.0727 - categorical_accuracy: 0.2614Epoch 11: loss = 2.072702646255493, val_loss = 2.090254068374634\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 2.0727 - categorical_accuracy: 0.2614 - val_loss: 2.0903 - val_categorical_accuracy: 0.2940\n",
      "Epoch 12/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.1092 - categorical_accuracy: 0.2430Epoch 12: loss = 2.110621213912964, val_loss = 1.9613300561904907\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 2.1106 - categorical_accuracy: 0.2416 - val_loss: 1.9613 - val_categorical_accuracy: 0.3085\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.0104 - categorical_accuracy: 0.2820Epoch 13: loss = 2.010448932647705, val_loss = 2.0023233890533447\n",
      "41/41 [==============================] - 1s 34ms/step - loss: 2.0104 - categorical_accuracy: 0.2820 - val_loss: 2.0023 - val_categorical_accuracy: 0.3123\n",
      "Epoch 14/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.0250 - categorical_accuracy: 0.2961Epoch 14: loss = 2.0214691162109375, val_loss = 1.9384362697601318\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 2.0215 - categorical_accuracy: 0.2965 - val_loss: 1.9384 - val_categorical_accuracy: 0.3199\n",
      "Epoch 15/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 1.9347 - categorical_accuracy: 0.3076Epoch 15: loss = 1.9297512769699097, val_loss = 1.8251131772994995\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 1.9298 - categorical_accuracy: 0.3087 - val_loss: 1.8251 - val_categorical_accuracy: 0.3831\n",
      "Epoch 16/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.9080 - categorical_accuracy: 0.3301Epoch 16: loss = 1.9145746231079102, val_loss = 1.9785504341125488\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 1.9146 - categorical_accuracy: 0.3316 - val_loss: 1.9786 - val_categorical_accuracy: 0.3206\n",
      "Epoch 17/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.9184 - categorical_accuracy: 0.3213Epoch 17: loss = 1.923279881477356, val_loss = 1.8682663440704346\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 1.9233 - categorical_accuracy: 0.3186 - val_loss: 1.8683 - val_categorical_accuracy: 0.3595\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.8382 - categorical_accuracy: 0.3559Epoch 18: loss = 1.8381532430648804, val_loss = 1.7696897983551025\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 1.8382 - categorical_accuracy: 0.3559 - val_loss: 1.7697 - val_categorical_accuracy: 0.4006\n",
      "Epoch 19/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.9556 - categorical_accuracy: 0.3117Epoch 19: loss = 1.9501475095748901, val_loss = 1.9800289869308472\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 1.9501 - categorical_accuracy: 0.3125 - val_loss: 1.9800 - val_categorical_accuracy: 0.3161\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.0039 - categorical_accuracy: 0.3270Epoch 20: loss = 2.0038845539093018, val_loss = 2.0569071769714355\n",
      "41/41 [==============================] - 1s 34ms/step - loss: 2.0039 - categorical_accuracy: 0.3270 - val_loss: 2.0569 - val_categorical_accuracy: 0.2666\n",
      "Epoch 21/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 2.1679 - categorical_accuracy: 0.2262Epoch 21: loss = 2.155838966369629, val_loss = 1.990738868713379\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 2.1558 - categorical_accuracy: 0.2287 - val_loss: 1.9907 - val_categorical_accuracy: 0.3077\n",
      "Epoch 22/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.0533 - categorical_accuracy: 0.2781Epoch 22: loss = 2.0444183349609375, val_loss = 1.9359033107757568\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 2.0444 - categorical_accuracy: 0.2774 - val_loss: 1.9359 - val_categorical_accuracy: 0.3214\n",
      "Epoch 23/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.9085 - categorical_accuracy: 0.3070Epoch 23: loss = 1.9099297523498535, val_loss = 1.8270859718322754\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 1.9099 - categorical_accuracy: 0.3072 - val_loss: 1.8271 - val_categorical_accuracy: 0.3793\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.8413 - categorical_accuracy: 0.3232Epoch 24: loss = 1.8412628173828125, val_loss = 1.7799835205078125\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 1.8413 - categorical_accuracy: 0.3232 - val_loss: 1.7800 - val_categorical_accuracy: 0.3648\n",
      "Epoch 25/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.8177 - categorical_accuracy: 0.3234Epoch 25: loss = 1.821124792098999, val_loss = 1.813190221786499\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 1.8211 - categorical_accuracy: 0.3232 - val_loss: 1.8132 - val_categorical_accuracy: 0.3488\n",
      "Epoch 26/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.7275 - categorical_accuracy: 0.3484Epoch 26: loss = 1.7299184799194336, val_loss = 1.620019555091858\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 1.7299 - categorical_accuracy: 0.3476 - val_loss: 1.6200 - val_categorical_accuracy: 0.3907\n",
      "Epoch 27/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.7641 - categorical_accuracy: 0.3695Epoch 27: loss = 1.7647353410720825, val_loss = 1.7015876770019531\n",
      "41/41 [==============================] - 1s 33ms/step - loss: 1.7647 - categorical_accuracy: 0.3720 - val_loss: 1.7016 - val_categorical_accuracy: 0.4136\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.6262 - categorical_accuracy: 0.3948Epoch 28: loss = 1.6262048482894897, val_loss = 1.5965100526809692\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 1.6262 - categorical_accuracy: 0.3948 - val_loss: 1.5965 - val_categorical_accuracy: 0.4044\n",
      "Epoch 29/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.6006 - categorical_accuracy: 0.3922Epoch 29: loss = 1.6075571775436401, val_loss = 1.545289158821106\n",
      "41/41 [==============================] - 1s 34ms/step - loss: 1.6076 - categorical_accuracy: 0.3895 - val_loss: 1.5453 - val_categorical_accuracy: 0.3991\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.6095 - categorical_accuracy: 0.4108Epoch 30: loss = 1.6095036268234253, val_loss = 1.453979730606079\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 1.6095 - categorical_accuracy: 0.4108 - val_loss: 1.4540 - val_categorical_accuracy: 0.4562\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.5020 - categorical_accuracy: 0.4390Epoch 31: loss = 1.5019749402999878, val_loss = 1.4476462602615356\n",
      "41/41 [==============================] - 1s 34ms/step - loss: 1.5020 - categorical_accuracy: 0.4390 - val_loss: 1.4476 - val_categorical_accuracy: 0.4494\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.5341 - categorical_accuracy: 0.4284Epoch 32: loss = 1.5340802669525146, val_loss = 1.4382256269454956\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 1.5341 - categorical_accuracy: 0.4284 - val_loss: 1.4382 - val_categorical_accuracy: 0.4920\n",
      "Epoch 33/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.4475 - categorical_accuracy: 0.4551Epoch 33: loss = 1.449906826019287, val_loss = 1.3963838815689087\n",
      "41/41 [==============================] - 1s 33ms/step - loss: 1.4499 - categorical_accuracy: 0.4535 - val_loss: 1.3964 - val_categorical_accuracy: 0.5057\n",
      "Epoch 34/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.4846 - categorical_accuracy: 0.4445Epoch 34: loss = 1.4848785400390625, val_loss = 1.4840991497039795\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 1.4849 - categorical_accuracy: 0.4444 - val_loss: 1.4841 - val_categorical_accuracy: 0.4593\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.4588 - categorical_accuracy: 0.4512Epoch 35: loss = 1.4588470458984375, val_loss = 1.4169286489486694\n",
      "41/41 [==============================] - 1s 34ms/step - loss: 1.4588 - categorical_accuracy: 0.4512 - val_loss: 1.4169 - val_categorical_accuracy: 0.4059\n",
      "Epoch 36/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.4184 - categorical_accuracy: 0.4615Epoch 36: loss = 1.4233845472335815, val_loss = 1.3935784101486206\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 1.4234 - categorical_accuracy: 0.4566 - val_loss: 1.3936 - val_categorical_accuracy: 0.4615\n",
      "Epoch 37/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.3344 - categorical_accuracy: 0.4977Epoch 37: loss = 1.3514207601547241, val_loss = 1.639673113822937\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 1.3514 - categorical_accuracy: 0.4947 - val_loss: 1.6397 - val_categorical_accuracy: 0.3762\n",
      "Epoch 38/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.8053 - categorical_accuracy: 0.3398Epoch 38: loss = 1.8007564544677734, val_loss = 1.64132821559906\n",
      "41/41 [==============================] - 1s 31ms/step - loss: 1.8008 - categorical_accuracy: 0.3415 - val_loss: 1.6413 - val_categorical_accuracy: 0.3800\n",
      "Epoch 39/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.5347 - categorical_accuracy: 0.4359Epoch 39: loss = 1.5336979627609253, val_loss = 1.4087694883346558\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 1.5337 - categorical_accuracy: 0.4352 - val_loss: 1.4088 - val_categorical_accuracy: 0.4912\n",
      "Epoch 40/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.4889 - categorical_accuracy: 0.4344Epoch 40: loss = 1.4891607761383057, val_loss = 1.299746036529541\n",
      "41/41 [==============================] - 1s 33ms/step - loss: 1.4892 - categorical_accuracy: 0.4322 - val_loss: 1.2997 - val_categorical_accuracy: 0.5209\n",
      "Epoch 41/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.4848 - categorical_accuracy: 0.4551Epoch 41: loss = 1.4659247398376465, val_loss = 1.3957797288894653\n",
      "41/41 [==============================] - 1s 31ms/step - loss: 1.4659 - categorical_accuracy: 0.4665 - val_loss: 1.3958 - val_categorical_accuracy: 0.4730\n",
      "Epoch 42/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.3100 - categorical_accuracy: 0.4859Epoch 42: loss = 1.302773118019104, val_loss = 1.146580696105957\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 1.3028 - categorical_accuracy: 0.4886 - val_loss: 1.1466 - val_categorical_accuracy: 0.5484\n",
      "Epoch 43/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.3936 - categorical_accuracy: 0.4727Epoch 43: loss = 1.3872121572494507, val_loss = 1.2280899286270142\n",
      "41/41 [==============================] - 1s 33ms/step - loss: 1.3872 - categorical_accuracy: 0.4779 - val_loss: 1.2281 - val_categorical_accuracy: 0.5804\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.3825 - categorical_accuracy: 0.4893Epoch 44: loss = 1.3825284242630005, val_loss = 1.4125356674194336\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 1.3825 - categorical_accuracy: 0.4893 - val_loss: 1.4125 - val_categorical_accuracy: 0.4714\n",
      "Epoch 45/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.3368 - categorical_accuracy: 0.4781Epoch 45: loss = 1.3341714143753052, val_loss = 1.243154764175415\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 1.3342 - categorical_accuracy: 0.4779 - val_loss: 1.2432 - val_categorical_accuracy: 0.4890\n",
      "Epoch 46/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.2802 - categorical_accuracy: 0.5055Epoch 46: loss = 1.279745101928711, val_loss = 1.1005803346633911\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 1.2797 - categorical_accuracy: 0.5069 - val_loss: 1.1006 - val_categorical_accuracy: 0.5918\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1986 - categorical_accuracy: 0.5427Epoch 47: loss = 1.198636531829834, val_loss = 1.3135250806808472\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 1.1986 - categorical_accuracy: 0.5427 - val_loss: 1.3135 - val_categorical_accuracy: 0.5126\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2554 - categorical_accuracy: 0.5091Epoch 48: loss = 1.255389928817749, val_loss = 1.0558712482452393\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 1.2554 - categorical_accuracy: 0.5091 - val_loss: 1.0559 - val_categorical_accuracy: 0.6093\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.3224 - categorical_accuracy: 0.5130Epoch 49: loss = 1.3224053382873535, val_loss = 1.6802748441696167\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 1.3224 - categorical_accuracy: 0.5130 - val_loss: 1.6803 - val_categorical_accuracy: 0.4067\n",
      "Epoch 50/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.5429 - categorical_accuracy: 0.4215Epoch 50: loss = 1.5279890298843384, val_loss = 1.301611065864563\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 1.5280 - categorical_accuracy: 0.4261 - val_loss: 1.3016 - val_categorical_accuracy: 0.5446\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1.3016 - categorical_accuracy: 0.5446\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.2001 - categorical_accuracy: 0.0465Epoch 1: loss = 3.2001023292541504, val_loss = 3.1300432682037354\n",
      "42/42 [==============================] - 9s 50ms/step - loss: 3.2001 - categorical_accuracy: 0.0465 - val_loss: 3.1300 - val_categorical_accuracy: 0.1159\n",
      "Epoch 2/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 3.0967 - categorical_accuracy: 0.0828Epoch 2: loss = 3.0953149795532227, val_loss = 2.991929531097412\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 3.0953 - categorical_accuracy: 0.0838 - val_loss: 2.9919 - val_categorical_accuracy: 0.0686\n",
      "Epoch 3/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.9483 - categorical_accuracy: 0.0883Epoch 3: loss = 2.9437592029571533, val_loss = 2.781752824783325\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 2.9438 - categorical_accuracy: 0.0868 - val_loss: 2.7818 - val_categorical_accuracy: 0.1265\n",
      "Epoch 4/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.7920 - categorical_accuracy: 0.1305Epoch 4: loss = 2.786339282989502, val_loss = 2.6266839504241943\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.7863 - categorical_accuracy: 0.1325 - val_loss: 2.6267 - val_categorical_accuracy: 0.1928\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.7509 - categorical_accuracy: 0.1386Epoch 5: loss = 2.7509031295776367, val_loss = 2.554347515106201\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 2.7509 - categorical_accuracy: 0.1386 - val_loss: 2.5543 - val_categorical_accuracy: 0.1890\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.6113 - categorical_accuracy: 0.1592Epoch 6: loss = 2.6112568378448486, val_loss = 2.4699366092681885\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 2.6113 - categorical_accuracy: 0.1592 - val_loss: 2.4699 - val_categorical_accuracy: 0.1890\n",
      "Epoch 7/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.4557 - categorical_accuracy: 0.1898Epoch 7: loss = 2.45624041557312, val_loss = 2.344151735305786\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 2.4562 - categorical_accuracy: 0.1896 - val_loss: 2.3442 - val_categorical_accuracy: 0.2134\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.4139 - categorical_accuracy: 0.2087Epoch 8: loss = 2.4139249324798584, val_loss = 2.2779040336608887\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.4139 - categorical_accuracy: 0.2087 - val_loss: 2.2779 - val_categorical_accuracy: 0.2812\n",
      "Epoch 9/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.5236 - categorical_accuracy: 0.2035Epoch 9: loss = 2.522857427597046, val_loss = 2.280092239379883\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.5229 - categorical_accuracy: 0.2041 - val_loss: 2.2801 - val_categorical_accuracy: 0.2119\n",
      "Epoch 10/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.3246 - categorical_accuracy: 0.2320Epoch 10: loss = 2.3222906589508057, val_loss = 2.095048189163208\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3223 - categorical_accuracy: 0.2315 - val_loss: 2.0950 - val_categorical_accuracy: 0.3003\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.2454 - categorical_accuracy: 0.2589Epoch 11: loss = 2.2453601360321045, val_loss = 2.019801616668701\n",
      "42/42 [==============================] - 2s 35ms/step - loss: 2.2454 - categorical_accuracy: 0.2589 - val_loss: 2.0198 - val_categorical_accuracy: 0.3079\n",
      "Epoch 12/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.1680 - categorical_accuracy: 0.2852Epoch 12: loss = 2.161410093307495, val_loss = 1.9804285764694214\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.1614 - categorical_accuracy: 0.2848 - val_loss: 1.9804 - val_categorical_accuracy: 0.3803\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.5394 - categorical_accuracy: 0.2239Epoch 13: loss = 2.5393903255462646, val_loss = 3.945291757583618\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.5394 - categorical_accuracy: 0.2239 - val_loss: 3.9453 - val_categorical_accuracy: 0.2767\n",
      "Epoch 14/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 3.1070 - categorical_accuracy: 0.1195Epoch 14: loss = 3.0983333587646484, val_loss = 2.710634469985962\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 3.0983 - categorical_accuracy: 0.1188 - val_loss: 2.7106 - val_categorical_accuracy: 0.0846\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.6476 - categorical_accuracy: 0.1272Epoch 15: loss = 2.647639274597168, val_loss = 2.5859804153442383\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.6476 - categorical_accuracy: 0.1272 - val_loss: 2.5860 - val_categorical_accuracy: 0.1105\n",
      "Epoch 16/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.4243 - categorical_accuracy: 0.1859Epoch 16: loss = 2.420220375061035, val_loss = 2.176893949508667\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 2.4202 - categorical_accuracy: 0.1874 - val_loss: 2.1769 - val_categorical_accuracy: 0.2614\n",
      "Epoch 17/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.2171 - categorical_accuracy: 0.2500Epoch 17: loss = 2.2164804935455322, val_loss = 2.015275716781616\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.2165 - categorical_accuracy: 0.2498 - val_loss: 2.0153 - val_categorical_accuracy: 0.3575\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.1190 - categorical_accuracy: 0.2727Epoch 18: loss = 2.1190178394317627, val_loss = 1.9472490549087524\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 2.1190 - categorical_accuracy: 0.2727 - val_loss: 1.9472 - val_categorical_accuracy: 0.3598\n",
      "Epoch 19/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.0161 - categorical_accuracy: 0.3186Epoch 19: loss = 2.0168001651763916, val_loss = 1.9433633089065552\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.0168 - categorical_accuracy: 0.3184 - val_loss: 1.9434 - val_categorical_accuracy: 0.3407\n",
      "Epoch 20/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.9862 - categorical_accuracy: 0.3430Epoch 20: loss = 1.9796924591064453, val_loss = 2.0086734294891357\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 1.9797 - categorical_accuracy: 0.3450 - val_loss: 2.0087 - val_categorical_accuracy: 0.3155\n",
      "Epoch 21/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.0425 - categorical_accuracy: 0.3172Epoch 21: loss = 2.0492353439331055, val_loss = 1.8391063213348389\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.0492 - categorical_accuracy: 0.3138 - val_loss: 1.8391 - val_categorical_accuracy: 0.4474\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.8700 - categorical_accuracy: 0.3732Epoch 22: loss = 1.8699671030044556, val_loss = 1.7189393043518066\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.8700 - categorical_accuracy: 0.3732 - val_loss: 1.7189 - val_categorical_accuracy: 0.4085\n",
      "Epoch 23/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.8714 - categorical_accuracy: 0.3704Epoch 23: loss = 1.8699591159820557, val_loss = 1.6842628717422485\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 1.8700 - categorical_accuracy: 0.3709 - val_loss: 1.6843 - val_categorical_accuracy: 0.4306\n",
      "Epoch 24/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.8065 - categorical_accuracy: 0.4078Epoch 24: loss = 1.8051472902297974, val_loss = 1.6638648509979248\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 1.8051 - categorical_accuracy: 0.4082 - val_loss: 1.6639 - val_categorical_accuracy: 0.4375\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.8048 - categorical_accuracy: 0.3854Epoch 25: loss = 1.8047819137573242, val_loss = 1.75153648853302\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.8048 - categorical_accuracy: 0.3854 - val_loss: 1.7515 - val_categorical_accuracy: 0.4497\n",
      "Epoch 26/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.7464 - categorical_accuracy: 0.4284Epoch 26: loss = 1.7470154762268066, val_loss = 1.5484492778778076\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.7470 - categorical_accuracy: 0.4280 - val_loss: 1.5484 - val_categorical_accuracy: 0.4733\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.7282 - categorical_accuracy: 0.4364Epoch 27: loss = 1.728184461593628, val_loss = 1.682992696762085\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.7282 - categorical_accuracy: 0.4364 - val_loss: 1.6830 - val_categorical_accuracy: 0.3864\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6921 - categorical_accuracy: 0.4318Epoch 28: loss = 1.6920666694641113, val_loss = 1.542431116104126\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 1.6921 - categorical_accuracy: 0.4318 - val_loss: 1.5424 - val_categorical_accuracy: 0.5084\n",
      "Epoch 29/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.5928 - categorical_accuracy: 0.4588Epoch 29: loss = 1.5937291383743286, val_loss = 1.4597606658935547\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.5937 - categorical_accuracy: 0.4585 - val_loss: 1.4598 - val_categorical_accuracy: 0.5061\n",
      "Epoch 30/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.6281 - categorical_accuracy: 0.4566Epoch 30: loss = 1.6283082962036133, val_loss = 1.7262351512908936\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 1.6283 - categorical_accuracy: 0.4562 - val_loss: 1.7262 - val_categorical_accuracy: 0.3979\n",
      "Epoch 31/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.6987 - categorical_accuracy: 0.4414Epoch 31: loss = 1.7036830186843872, val_loss = 1.3657475709915161\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.7037 - categorical_accuracy: 0.4402 - val_loss: 1.3657 - val_categorical_accuracy: 0.5480\n",
      "Epoch 32/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.5984 - categorical_accuracy: 0.4570Epoch 32: loss = 1.5973191261291504, val_loss = 1.36735999584198\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 1.5973 - categorical_accuracy: 0.4570 - val_loss: 1.3674 - val_categorical_accuracy: 0.5709\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5214 - categorical_accuracy: 0.4851Epoch 33: loss = 1.5214390754699707, val_loss = 1.3180385828018188\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.5214 - categorical_accuracy: 0.4851 - val_loss: 1.3180 - val_categorical_accuracy: 0.5648\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5006 - categorical_accuracy: 0.4798Epoch 34: loss = 1.5005764961242676, val_loss = 1.3364485502243042\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 1.5006 - categorical_accuracy: 0.4798 - val_loss: 1.3364 - val_categorical_accuracy: 0.5610\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4703 - categorical_accuracy: 0.4935Epoch 35: loss = 1.4702825546264648, val_loss = 1.397801160812378\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.4703 - categorical_accuracy: 0.4935 - val_loss: 1.3978 - val_categorical_accuracy: 0.5084\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4667 - categorical_accuracy: 0.4874Epoch 36: loss = 1.466733694076538, val_loss = 1.7317265272140503\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.4667 - categorical_accuracy: 0.4874 - val_loss: 1.7317 - val_categorical_accuracy: 0.4032\n",
      "Epoch 37/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.7203 - categorical_accuracy: 0.4031Epoch 37: loss = 1.7124110460281372, val_loss = 1.867057204246521\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 1.7124 - categorical_accuracy: 0.4059 - val_loss: 1.8671 - val_categorical_accuracy: 0.3834\n",
      "Epoch 38/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.7399 - categorical_accuracy: 0.3922Epoch 38: loss = 1.7344406843185425, val_loss = 1.5329629182815552\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 1.7344 - categorical_accuracy: 0.3945 - val_loss: 1.5330 - val_categorical_accuracy: 0.4878\n",
      "Epoch 39/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.4346 - categorical_accuracy: 0.5137Epoch 39: loss = 1.4335495233535767, val_loss = 1.2417867183685303\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 1.4335 - categorical_accuracy: 0.5141 - val_loss: 1.2418 - val_categorical_accuracy: 0.5800\n",
      "Epoch 40/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.4884 - categorical_accuracy: 0.4924Epoch 40: loss = 1.4885437488555908, val_loss = 1.4839808940887451\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.4885 - categorical_accuracy: 0.4920 - val_loss: 1.4840 - val_categorical_accuracy: 0.4688\n",
      "Epoch 41/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.6253 - categorical_accuracy: 0.4227Epoch 41: loss = 1.630258560180664, val_loss = 1.339013695716858\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.6303 - categorical_accuracy: 0.4250 - val_loss: 1.3390 - val_categorical_accuracy: 0.5640\n",
      "Epoch 42/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.3978 - categorical_accuracy: 0.5117Epoch 42: loss = 1.3942023515701294, val_loss = 1.5906623601913452\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 1.3942 - categorical_accuracy: 0.5118 - val_loss: 1.5907 - val_categorical_accuracy: 0.4535\n",
      "Epoch 43/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.5964 - categorical_accuracy: 0.4741Epoch 43: loss = 1.5952893495559692, val_loss = 1.3334112167358398\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.5953 - categorical_accuracy: 0.4745 - val_loss: 1.3334 - val_categorical_accuracy: 0.5518\n",
      "Epoch 44/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.3845 - categorical_accuracy: 0.5183Epoch 44: loss = 1.3854824304580688, val_loss = 1.2001047134399414\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.3855 - categorical_accuracy: 0.5179 - val_loss: 1.2001 - val_categorical_accuracy: 0.5877\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3196 - categorical_accuracy: 0.5133Epoch 45: loss = 1.319570541381836, val_loss = 1.199399471282959\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 1.3196 - categorical_accuracy: 0.5133 - val_loss: 1.1994 - val_categorical_accuracy: 0.6029\n",
      "Epoch 46/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.2463 - categorical_accuracy: 0.5578Epoch 46: loss = 1.24313223361969, val_loss = 1.1295099258422852\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.2431 - categorical_accuracy: 0.5590 - val_loss: 1.1295 - val_categorical_accuracy: 0.6341\n",
      "Epoch 47/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.3431 - categorical_accuracy: 0.5335Epoch 47: loss = 1.3421155214309692, val_loss = 1.2795047760009766\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.3421 - categorical_accuracy: 0.5339 - val_loss: 1.2795 - val_categorical_accuracy: 0.5655\n",
      "Epoch 48/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.4948 - categorical_accuracy: 0.4619Epoch 48: loss = 1.4954743385314941, val_loss = 1.7999012470245361\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.4955 - categorical_accuracy: 0.4615 - val_loss: 1.7999 - val_categorical_accuracy: 0.3598\n",
      "Epoch 49/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.4179 - categorical_accuracy: 0.5000Epoch 49: loss = 1.4191523790359497, val_loss = 1.1376285552978516\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 1.4192 - categorical_accuracy: 0.4996 - val_loss: 1.1376 - val_categorical_accuracy: 0.6280\n",
      "Epoch 50/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2864 - categorical_accuracy: 0.5194Epoch 50: loss = 1.28639554977417, val_loss = 1.0836358070373535\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.2864 - categorical_accuracy: 0.5194 - val_loss: 1.0836 - val_categorical_accuracy: 0.6441\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.0836 - categorical_accuracy: 0.6441\n",
      "Epoch 1/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 3.2428 - categorical_accuracy: 0.0393Epoch 1: loss = 3.2409143447875977, val_loss = 3.177959680557251\n",
      "41/41 [==============================] - 5s 45ms/step - loss: 3.2409 - categorical_accuracy: 0.0373 - val_loss: 3.1780 - val_categorical_accuracy: 0.0312\n",
      "Epoch 2/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 3.1387 - categorical_accuracy: 0.0617Epoch 2: loss = 3.135507345199585, val_loss = 3.058089017868042\n",
      "41/41 [==============================] - 1s 31ms/step - loss: 3.1355 - categorical_accuracy: 0.0625 - val_loss: 3.0581 - val_categorical_accuracy: 0.0845\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 3.0597 - categorical_accuracy: 0.0686Epoch 3: loss = 3.0597217082977295, val_loss = 2.9900691509246826\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 3.0597 - categorical_accuracy: 0.0686 - val_loss: 2.9901 - val_categorical_accuracy: 0.0990\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.9510 - categorical_accuracy: 0.0823Epoch 4: loss = 2.9509952068328857, val_loss = 2.90402889251709\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 2.9510 - categorical_accuracy: 0.0823 - val_loss: 2.9040 - val_categorical_accuracy: 0.2018\n",
      "Epoch 5/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.9952 - categorical_accuracy: 0.1055Epoch 5: loss = 2.9929189682006836, val_loss = 2.8960635662078857\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 2.9929 - categorical_accuracy: 0.1067 - val_loss: 2.8961 - val_categorical_accuracy: 0.1615\n",
      "Epoch 6/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 2.9018 - categorical_accuracy: 0.1546Epoch 6: loss = 2.9045581817626953, val_loss = 2.818655490875244\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 2.9046 - categorical_accuracy: 0.1517 - val_loss: 2.8187 - val_categorical_accuracy: 0.1767\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.8333 - categorical_accuracy: 0.1494Epoch 7: loss = 2.8332581520080566, val_loss = 2.6844305992126465\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 2.8333 - categorical_accuracy: 0.1494 - val_loss: 2.6844 - val_categorical_accuracy: 0.1523\n",
      "Epoch 8/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.6914 - categorical_accuracy: 0.1578Epoch 8: loss = 2.692417621612549, val_loss = 2.4321608543395996\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 2.6924 - categorical_accuracy: 0.1570 - val_loss: 2.4322 - val_categorical_accuracy: 0.2452\n",
      "Epoch 9/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 2.5105 - categorical_accuracy: 0.2027Epoch 9: loss = 2.5076348781585693, val_loss = 2.402796745300293\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 2.5076 - categorical_accuracy: 0.2012 - val_loss: 2.4028 - val_categorical_accuracy: 0.2338\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3966 - categorical_accuracy: 0.1959Epoch 10: loss = 2.3966283798217773, val_loss = 2.213895320892334\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 2.3966 - categorical_accuracy: 0.1959 - val_loss: 2.2139 - val_categorical_accuracy: 0.2072\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.2696 - categorical_accuracy: 0.2157Epoch 11: loss = 2.2696282863616943, val_loss = 2.0448055267333984\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 2.2696 - categorical_accuracy: 0.2157 - val_loss: 2.0448 - val_categorical_accuracy: 0.2749\n",
      "Epoch 12/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 2.1156 - categorical_accuracy: 0.2588Epoch 12: loss = 2.104585886001587, val_loss = 1.9546576738357544\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 2.1046 - categorical_accuracy: 0.2622 - val_loss: 1.9547 - val_categorical_accuracy: 0.2628\n",
      "Epoch 13/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.0560 - categorical_accuracy: 0.2594Epoch 13: loss = 2.0484275817871094, val_loss = 1.880676031112671\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 2.0484 - categorical_accuracy: 0.2630 - val_loss: 1.8807 - val_categorical_accuracy: 0.3389\n",
      "Epoch 14/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.9259 - categorical_accuracy: 0.3157Epoch 14: loss = 1.92026948928833, val_loss = 1.7605136632919312\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 1.9203 - categorical_accuracy: 0.3148 - val_loss: 1.7605 - val_categorical_accuracy: 0.3549\n",
      "Epoch 15/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 1.9349 - categorical_accuracy: 0.3150Epoch 15: loss = 1.9303408861160278, val_loss = 1.7679111957550049\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 1.9303 - categorical_accuracy: 0.3209 - val_loss: 1.7679 - val_categorical_accuracy: 0.3450\n",
      "Epoch 16/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.8048 - categorical_accuracy: 0.3454Epoch 16: loss = 1.8020398616790771, val_loss = 1.7110466957092285\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 1.8020 - categorical_accuracy: 0.3468 - val_loss: 1.7110 - val_categorical_accuracy: 0.3717\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.7527 - categorical_accuracy: 0.3598Epoch 17: loss = 1.7527027130126953, val_loss = 1.6019803285598755\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 1.7527 - categorical_accuracy: 0.3598 - val_loss: 1.6020 - val_categorical_accuracy: 0.3907\n",
      "Epoch 18/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.7245 - categorical_accuracy: 0.3646Epoch 18: loss = 1.7203432321548462, val_loss = 1.4951823949813843\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 1.7203 - categorical_accuracy: 0.3651 - val_loss: 1.4952 - val_categorical_accuracy: 0.4455\n",
      "Epoch 19/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.6859 - categorical_accuracy: 0.3638Epoch 19: loss = 1.6775709390640259, val_loss = 1.4926577806472778\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 1.6776 - categorical_accuracy: 0.3659 - val_loss: 1.4927 - val_categorical_accuracy: 0.4806\n",
      "Epoch 20/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.5901 - categorical_accuracy: 0.4187Epoch 20: loss = 1.5875951051712036, val_loss = 1.4402039051055908\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 1.5876 - categorical_accuracy: 0.4200 - val_loss: 1.4402 - val_categorical_accuracy: 0.4935\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.5799 - categorical_accuracy: 0.4154Epoch 21: loss = 1.5799251794815063, val_loss = 1.625075101852417\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 1.5799 - categorical_accuracy: 0.4154 - val_loss: 1.6251 - val_categorical_accuracy: 0.3648\n",
      "Epoch 22/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.6131 - categorical_accuracy: 0.4000Epoch 22: loss = 1.6136150360107422, val_loss = 1.381003737449646\n",
      "41/41 [==============================] - 1s 31ms/step - loss: 1.6136 - categorical_accuracy: 0.4017 - val_loss: 1.3810 - val_categorical_accuracy: 0.4890\n",
      "Epoch 23/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.5232 - categorical_accuracy: 0.4295Epoch 23: loss = 1.5234135389328003, val_loss = 1.3571361303329468\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 1.5234 - categorical_accuracy: 0.4314 - val_loss: 1.3571 - val_categorical_accuracy: 0.4448\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.4420 - categorical_accuracy: 0.4566Epoch 24: loss = 1.4420026540756226, val_loss = 1.2375245094299316\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 1.4420 - categorical_accuracy: 0.4566 - val_loss: 1.2375 - val_categorical_accuracy: 0.5057\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.4437 - categorical_accuracy: 0.4497Epoch 25: loss = 1.4437017440795898, val_loss = 1.290492296218872\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 1.4437 - categorical_accuracy: 0.4497 - val_loss: 1.2905 - val_categorical_accuracy: 0.5088\n",
      "Epoch 26/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.4341 - categorical_accuracy: 0.4523Epoch 26: loss = 1.4324618577957153, val_loss = 1.2241132259368896\n",
      "41/41 [==============================] - 1s 31ms/step - loss: 1.4325 - categorical_accuracy: 0.4520 - val_loss: 1.2241 - val_categorical_accuracy: 0.5232\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.4328 - categorical_accuracy: 0.4649Epoch 27: loss = 1.4328471422195435, val_loss = 1.3907617330551147\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 1.4328 - categorical_accuracy: 0.4649 - val_loss: 1.3908 - val_categorical_accuracy: 0.4684\n",
      "Epoch 28/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.3978 - categorical_accuracy: 0.4712Epoch 28: loss = 1.3966312408447266, val_loss = 1.241610050201416\n",
      "41/41 [==============================] - 1s 31ms/step - loss: 1.3966 - categorical_accuracy: 0.4710 - val_loss: 1.2416 - val_categorical_accuracy: 0.5126\n",
      "Epoch 29/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.3908 - categorical_accuracy: 0.4609Epoch 29: loss = 1.396278977394104, val_loss = 1.203848123550415\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 1.3963 - categorical_accuracy: 0.4588 - val_loss: 1.2038 - val_categorical_accuracy: 0.5308\n",
      "Epoch 30/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.3336 - categorical_accuracy: 0.4880Epoch 30: loss = 1.337512731552124, val_loss = 1.2591115236282349\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 1.3375 - categorical_accuracy: 0.4893 - val_loss: 1.2591 - val_categorical_accuracy: 0.4981\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.8251 - categorical_accuracy: 0.3712Epoch 31: loss = 1.8251200914382935, val_loss = 1.7199450731277466\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 1.8251 - categorical_accuracy: 0.3712 - val_loss: 1.7199 - val_categorical_accuracy: 0.3679\n",
      "Epoch 32/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 1.4412 - categorical_accuracy: 0.4564Epoch 32: loss = 1.4458963871002197, val_loss = 1.2041877508163452\n",
      "41/41 [==============================] - 1s 31ms/step - loss: 1.4459 - categorical_accuracy: 0.4550 - val_loss: 1.2042 - val_categorical_accuracy: 0.5659\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2932 - categorical_accuracy: 0.4878Epoch 33: loss = 1.2932028770446777, val_loss = 1.1599044799804688\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 1.2932 - categorical_accuracy: 0.4878 - val_loss: 1.1599 - val_categorical_accuracy: 0.5986\n",
      "Epoch 34/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.2641 - categorical_accuracy: 0.5133Epoch 34: loss = 1.2691377401351929, val_loss = 1.1504563093185425\n",
      "41/41 [==============================] - 1s 34ms/step - loss: 1.2691 - categorical_accuracy: 0.5137 - val_loss: 1.1505 - val_categorical_accuracy: 0.5598\n",
      "Epoch 35/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.2181 - categorical_accuracy: 0.5104Epoch 35: loss = 1.2280545234680176, val_loss = 1.0882853269577026\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 1.2281 - categorical_accuracy: 0.5084 - val_loss: 1.0883 - val_categorical_accuracy: 0.5811\n",
      "Epoch 36/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.2664 - categorical_accuracy: 0.5024Epoch 36: loss = 1.2492423057556152, val_loss = 1.0119179487228394\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 1.2492 - categorical_accuracy: 0.5091 - val_loss: 1.0119 - val_categorical_accuracy: 0.6055\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1811 - categorical_accuracy: 0.5290Epoch 37: loss = 1.1810616254806519, val_loss = 1.0278512239456177\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 1.1811 - categorical_accuracy: 0.5290 - val_loss: 1.0279 - val_categorical_accuracy: 0.6093\n",
      "Epoch 38/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.1661 - categorical_accuracy: 0.5337Epoch 38: loss = 1.158964991569519, val_loss = 1.18603515625\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 1.1590 - categorical_accuracy: 0.5366 - val_loss: 1.1860 - val_categorical_accuracy: 0.5628\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2439 - categorical_accuracy: 0.5130Epoch 39: loss = 1.2438788414001465, val_loss = 1.033691644668579\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 1.2439 - categorical_accuracy: 0.5130 - val_loss: 1.0337 - val_categorical_accuracy: 0.6253\n",
      "Epoch 40/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.2150 - categorical_accuracy: 0.5232Epoch 40: loss = 1.206792950630188, val_loss = 1.001773476600647\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 1.2068 - categorical_accuracy: 0.5297 - val_loss: 1.0018 - val_categorical_accuracy: 0.6253\n",
      "Epoch 41/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.2126 - categorical_accuracy: 0.4968Epoch 41: loss = 1.216331958770752, val_loss = 1.0627412796020508\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 1.2163 - categorical_accuracy: 0.4977 - val_loss: 1.0627 - val_categorical_accuracy: 0.5979\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1775 - categorical_accuracy: 0.5404Epoch 42: loss = 1.1775201559066772, val_loss = 1.0347574949264526\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 1.1775 - categorical_accuracy: 0.5404 - val_loss: 1.0348 - val_categorical_accuracy: 0.6276\n",
      "Epoch 43/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.1732 - categorical_accuracy: 0.5383Epoch 43: loss = 1.1789751052856445, val_loss = 0.9717555642127991\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 1.1790 - categorical_accuracy: 0.5373 - val_loss: 0.9718 - val_categorical_accuracy: 0.6458\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1025 - categorical_accuracy: 0.5579Epoch 44: loss = 1.1025208234786987, val_loss = 0.9638981223106384\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 1.1025 - categorical_accuracy: 0.5579 - val_loss: 0.9639 - val_categorical_accuracy: 0.6717\n",
      "Epoch 45/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.0995 - categorical_accuracy: 0.5721Epoch 45: loss = 1.0928677320480347, val_loss = 0.9177274107933044\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 1.0929 - categorical_accuracy: 0.5739 - val_loss: 0.9177 - val_categorical_accuracy: 0.6504\n",
      "Epoch 46/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.1360 - categorical_accuracy: 0.5577Epoch 46: loss = 1.1496623754501343, val_loss = 1.0183342695236206\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 1.1497 - categorical_accuracy: 0.5534 - val_loss: 1.0183 - val_categorical_accuracy: 0.5651\n",
      "Epoch 47/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.1547 - categorical_accuracy: 0.5547Epoch 47: loss = 1.1664419174194336, val_loss = 1.1129921674728394\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 1.1664 - categorical_accuracy: 0.5534 - val_loss: 1.1130 - val_categorical_accuracy: 0.5613\n",
      "Epoch 48/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.3254 - categorical_accuracy: 0.5023Epoch 48: loss = 1.3210389614105225, val_loss = 1.0237475633621216\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 1.3210 - categorical_accuracy: 0.5030 - val_loss: 1.0237 - val_categorical_accuracy: 0.6321\n",
      "Epoch 49/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.0687 - categorical_accuracy: 0.5721Epoch 49: loss = 1.0592255592346191, val_loss = 0.9414851665496826\n",
      "41/41 [==============================] - 1s 33ms/step - loss: 1.0592 - categorical_accuracy: 0.5747 - val_loss: 0.9415 - val_categorical_accuracy: 0.6687\n",
      "Epoch 50/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.0026 - categorical_accuracy: 0.6359Epoch 50: loss = 1.000360369682312, val_loss = 0.9013440608978271\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 1.0004 - categorical_accuracy: 0.6357 - val_loss: 0.9013 - val_categorical_accuracy: 0.6512\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.9013 - categorical_accuracy: 0.6512\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.2604 - categorical_accuracy: 0.0366Epoch 1: loss = 3.2603609561920166, val_loss = 3.2223658561706543\n",
      "42/42 [==============================] - 6s 48ms/step - loss: 3.2604 - categorical_accuracy: 0.0366 - val_loss: 3.2224 - val_categorical_accuracy: 0.0236\n",
      "Epoch 2/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 3.2197 - categorical_accuracy: 0.0473Epoch 2: loss = 3.21975040435791, val_loss = 3.212989330291748\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 3.2198 - categorical_accuracy: 0.0472 - val_loss: 3.2130 - val_categorical_accuracy: 0.0343\n",
      "Epoch 3/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 3.1981 - categorical_accuracy: 0.0562Epoch 3: loss = 3.1971487998962402, val_loss = 3.154393196105957\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 3.1971 - categorical_accuracy: 0.0556 - val_loss: 3.1544 - val_categorical_accuracy: 0.0732\n",
      "Epoch 4/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 3.0463 - categorical_accuracy: 0.0800Epoch 4: loss = 3.0463531017303467, val_loss = 2.9247987270355225\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 3.0464 - categorical_accuracy: 0.0800 - val_loss: 2.9248 - val_categorical_accuracy: 0.0915\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.8375 - categorical_accuracy: 0.0952Epoch 5: loss = 2.8374786376953125, val_loss = 2.657163381576538\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.8375 - categorical_accuracy: 0.0952 - val_loss: 2.6572 - val_categorical_accuracy: 0.0838\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.6089 - categorical_accuracy: 0.1394Epoch 6: loss = 2.608938694000244, val_loss = 2.6105613708496094\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 2.6089 - categorical_accuracy: 0.1394 - val_loss: 2.6106 - val_categorical_accuracy: 0.1303\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.6895 - categorical_accuracy: 0.1356Epoch 7: loss = 2.6895368099212646, val_loss = 2.5245518684387207\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 2.6895 - categorical_accuracy: 0.1356 - val_loss: 2.5246 - val_categorical_accuracy: 0.1692\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.5589 - categorical_accuracy: 0.1500Epoch 8: loss = 2.558939218521118, val_loss = 2.3677890300750732\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 2.5589 - categorical_accuracy: 0.1500 - val_loss: 2.3678 - val_categorical_accuracy: 0.1921\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.4371 - categorical_accuracy: 0.1676Epoch 9: loss = 2.437138557434082, val_loss = 2.2670369148254395\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 2.4371 - categorical_accuracy: 0.1676 - val_loss: 2.2670 - val_categorical_accuracy: 0.1905\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.3331 - categorical_accuracy: 0.1759Epoch 10: loss = 2.333127737045288, val_loss = 2.134974956512451\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 2.3331 - categorical_accuracy: 0.1759 - val_loss: 2.1350 - val_categorical_accuracy: 0.2485\n",
      "Epoch 11/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.4080 - categorical_accuracy: 0.1799Epoch 11: loss = 2.4084017276763916, val_loss = 2.3393280506134033\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.4084 - categorical_accuracy: 0.1797 - val_loss: 2.3393 - val_categorical_accuracy: 0.1791\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.3345 - categorical_accuracy: 0.1775Epoch 12: loss = 2.3345139026641846, val_loss = 2.132915496826172\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 2.3345 - categorical_accuracy: 0.1775 - val_loss: 2.1329 - val_categorical_accuracy: 0.2622\n",
      "Epoch 13/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.1737 - categorical_accuracy: 0.2317Epoch 13: loss = 2.1733808517456055, val_loss = 2.0212559700012207\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.1734 - categorical_accuracy: 0.2315 - val_loss: 2.0213 - val_categorical_accuracy: 0.2393\n",
      "Epoch 14/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.1355 - categorical_accuracy: 0.2133Epoch 14: loss = 2.134305953979492, val_loss = 1.943206548690796\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 2.1343 - categorical_accuracy: 0.2117 - val_loss: 1.9432 - val_categorical_accuracy: 0.2927\n",
      "Epoch 15/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.0549 - categorical_accuracy: 0.2348Epoch 15: loss = 2.054844856262207, val_loss = 2.32291316986084\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.0548 - categorical_accuracy: 0.2346 - val_loss: 2.3229 - val_categorical_accuracy: 0.1845\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.1718 - categorical_accuracy: 0.2239Epoch 16: loss = 2.1718037128448486, val_loss = 1.86724853515625\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.1718 - categorical_accuracy: 0.2239 - val_loss: 1.8672 - val_categorical_accuracy: 0.3049\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.0602 - categorical_accuracy: 0.2262Epoch 17: loss = 2.0602025985717773, val_loss = 1.8747080564498901\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 2.0602 - categorical_accuracy: 0.2262 - val_loss: 1.8747 - val_categorical_accuracy: 0.3079\n",
      "Epoch 18/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.1501 - categorical_accuracy: 0.2256Epoch 18: loss = 2.149991512298584, val_loss = 1.9470347166061401\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.1500 - categorical_accuracy: 0.2254 - val_loss: 1.9470 - val_categorical_accuracy: 0.2668\n",
      "Epoch 19/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.0677 - categorical_accuracy: 0.2248Epoch 19: loss = 2.0679562091827393, val_loss = 1.8503038883209229\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 2.0680 - categorical_accuracy: 0.2247 - val_loss: 1.8503 - val_categorical_accuracy: 0.3102\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.9314 - categorical_accuracy: 0.2430Epoch 20: loss = 1.9314405918121338, val_loss = 1.870042324066162\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 1.9314 - categorical_accuracy: 0.2430 - val_loss: 1.8700 - val_categorical_accuracy: 0.2668\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.0310 - categorical_accuracy: 0.2414Epoch 21: loss = 2.031038284301758, val_loss = 2.0036582946777344\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.0310 - categorical_accuracy: 0.2414 - val_loss: 2.0037 - val_categorical_accuracy: 0.1982\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.9107 - categorical_accuracy: 0.2643Epoch 22: loss = 1.9107341766357422, val_loss = 1.7103040218353271\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.9107 - categorical_accuracy: 0.2643 - val_loss: 1.7103 - val_categorical_accuracy: 0.3117\n",
      "Epoch 23/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.8389 - categorical_accuracy: 0.2664Epoch 23: loss = 1.8378101587295532, val_loss = 1.9403667449951172\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.8378 - categorical_accuracy: 0.2666 - val_loss: 1.9404 - val_categorical_accuracy: 0.2637\n",
      "Epoch 24/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.8679 - categorical_accuracy: 0.2961Epoch 24: loss = 1.8824105262756348, val_loss = 1.6357148885726929\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.8824 - categorical_accuracy: 0.2925 - val_loss: 1.6357 - val_categorical_accuracy: 0.3582\n",
      "Epoch 25/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.9586 - categorical_accuracy: 0.2752Epoch 25: loss = 1.9590598344802856, val_loss = 1.9013493061065674\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.9591 - categorical_accuracy: 0.2749 - val_loss: 1.9013 - val_categorical_accuracy: 0.2881\n",
      "Epoch 26/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.8774 - categorical_accuracy: 0.2790Epoch 26: loss = 1.8775501251220703, val_loss = 1.6700748205184937\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 1.8776 - categorical_accuracy: 0.2788 - val_loss: 1.6701 - val_categorical_accuracy: 0.3247\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.7523 - categorical_accuracy: 0.3229Epoch 27: loss = 1.7522794008255005, val_loss = 1.5995477437973022\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.7523 - categorical_accuracy: 0.3229 - val_loss: 1.5995 - val_categorical_accuracy: 0.3369\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.8844 - categorical_accuracy: 0.3039Epoch 28: loss = 1.8843697309494019, val_loss = 1.6560341119766235\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.8844 - categorical_accuracy: 0.3039 - val_loss: 1.6560 - val_categorical_accuracy: 0.3460\n",
      "Epoch 29/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.7890 - categorical_accuracy: 0.3289Epoch 29: loss = 1.794613003730774, val_loss = 1.5336079597473145\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.7946 - categorical_accuracy: 0.3252 - val_loss: 1.5336 - val_categorical_accuracy: 0.4390\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6599 - categorical_accuracy: 0.3610Epoch 30: loss = 1.659920334815979, val_loss = 1.4423741102218628\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.6599 - categorical_accuracy: 0.3610 - val_loss: 1.4424 - val_categorical_accuracy: 0.4695\n",
      "Epoch 31/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.6669 - categorical_accuracy: 0.3445Epoch 31: loss = 1.6656980514526367, val_loss = 1.4579672813415527\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 1.6657 - categorical_accuracy: 0.3450 - val_loss: 1.4580 - val_categorical_accuracy: 0.4306\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6079 - categorical_accuracy: 0.3663Epoch 32: loss = 1.607911467552185, val_loss = 1.861378788948059\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.6079 - categorical_accuracy: 0.3663 - val_loss: 1.8614 - val_categorical_accuracy: 0.3201\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.7981 - categorical_accuracy: 0.3161Epoch 33: loss = 1.798102617263794, val_loss = 1.481365442276001\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 1.7981 - categorical_accuracy: 0.3161 - val_loss: 1.4814 - val_categorical_accuracy: 0.4200\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6274 - categorical_accuracy: 0.3595Epoch 34: loss = 1.6274025440216064, val_loss = 1.4354052543640137\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.6274 - categorical_accuracy: 0.3595 - val_loss: 1.4354 - val_categorical_accuracy: 0.4802\n",
      "Epoch 35/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.5869 - categorical_accuracy: 0.3727Epoch 35: loss = 1.5858750343322754, val_loss = 1.3939846754074097\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.5859 - categorical_accuracy: 0.3732 - val_loss: 1.3940 - val_categorical_accuracy: 0.4611\n",
      "Epoch 36/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.7158 - categorical_accuracy: 0.3414Epoch 36: loss = 1.719734787940979, val_loss = 1.7997087240219116\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.7197 - categorical_accuracy: 0.3397 - val_loss: 1.7997 - val_categorical_accuracy: 0.2454\n",
      "Epoch 37/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.7572 - categorical_accuracy: 0.3056Epoch 37: loss = 1.756298542022705, val_loss = 1.5073931217193604\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.7563 - categorical_accuracy: 0.3062 - val_loss: 1.5074 - val_categorical_accuracy: 0.4070\n",
      "Epoch 38/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.6569 - categorical_accuracy: 0.3377Epoch 38: loss = 1.6561304330825806, val_loss = 1.5282355546951294\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.6561 - categorical_accuracy: 0.3382 - val_loss: 1.5282 - val_categorical_accuracy: 0.3956\n",
      "Epoch 39/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.6460 - categorical_accuracy: 0.3415Epoch 39: loss = 1.6456626653671265, val_loss = 1.4480998516082764\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.6457 - categorical_accuracy: 0.3420 - val_loss: 1.4481 - val_categorical_accuracy: 0.4390\n",
      "Epoch 40/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.9095 - categorical_accuracy: 0.2945Epoch 40: loss = 1.9008867740631104, val_loss = 1.974760890007019\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 1.9009 - categorical_accuracy: 0.2963 - val_loss: 1.9748 - val_categorical_accuracy: 0.2835\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.7811 - categorical_accuracy: 0.2917Epoch 41: loss = 1.7811317443847656, val_loss = 1.555958867073059\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.7811 - categorical_accuracy: 0.2917 - val_loss: 1.5560 - val_categorical_accuracy: 0.4017\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6691 - categorical_accuracy: 0.3085Epoch 42: loss = 1.669074535369873, val_loss = 1.458965539932251\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 1.6691 - categorical_accuracy: 0.3085 - val_loss: 1.4590 - val_categorical_accuracy: 0.4268\n",
      "Epoch 43/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.6416 - categorical_accuracy: 0.3277Epoch 43: loss = 1.6414872407913208, val_loss = 1.4671074151992798\n",
      "42/42 [==============================] - 2s 53ms/step - loss: 1.6415 - categorical_accuracy: 0.3275 - val_loss: 1.4671 - val_categorical_accuracy: 0.4093\n",
      "Epoch 44/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.7014 - categorical_accuracy: 0.3338Epoch 44: loss = 1.7005972862243652, val_loss = 1.9106167554855347\n",
      "42/42 [==============================] - 2s 53ms/step - loss: 1.7006 - categorical_accuracy: 0.3343 - val_loss: 1.9106 - val_categorical_accuracy: 0.3034\n",
      "Epoch 45/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.6186 - categorical_accuracy: 0.3750Restoring model weights from the end of the best epoch: 35.\n",
      "Epoch 45: loss = 1.6185935735702515, val_loss = 1.40028715133667\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 1.6186 - categorical_accuracy: 0.3755 - val_loss: 1.4003 - val_categorical_accuracy: 0.4314\n",
      "Epoch 45: early stopping\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.3940 - categorical_accuracy: 0.4611\n",
      "Epoch 1/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 3.2491 - categorical_accuracy: 0.0556Epoch 1: loss = 3.2490975856781006, val_loss = 3.208281993865967\n",
      "82/82 [==============================] - 9s 52ms/step - loss: 3.2491 - categorical_accuracy: 0.0556 - val_loss: 3.2083 - val_categorical_accuracy: 0.0434\n",
      "Epoch 2/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 3.1246 - categorical_accuracy: 0.0640Epoch 2: loss = 3.1246464252471924, val_loss = 3.0020077228546143\n",
      "82/82 [==============================] - 3s 41ms/step - loss: 3.1246 - categorical_accuracy: 0.0640 - val_loss: 3.0020 - val_categorical_accuracy: 0.0815\n",
      "Epoch 3/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.8735 - categorical_accuracy: 0.1562Epoch 3: loss = 2.873546838760376, val_loss = 2.914607286453247\n",
      "82/82 [==============================] - 3s 38ms/step - loss: 2.8735 - categorical_accuracy: 0.1562 - val_loss: 2.9146 - val_categorical_accuracy: 0.1150\n",
      "Epoch 4/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.6347 - categorical_accuracy: 0.1767Epoch 4: loss = 2.6326534748077393, val_loss = 2.659566879272461\n",
      "82/82 [==============================] - 3s 41ms/step - loss: 2.6327 - categorical_accuracy: 0.1761 - val_loss: 2.6596 - val_categorical_accuracy: 0.1021\n",
      "Epoch 5/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 3.2771 - categorical_accuracy: 0.1489Epoch 5: loss = 3.268627166748047, val_loss = 2.669340133666992\n",
      "82/82 [==============================] - 3s 43ms/step - loss: 3.2686 - categorical_accuracy: 0.1494 - val_loss: 2.6693 - val_categorical_accuracy: 0.1478\n",
      "Epoch 6/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.4318 - categorical_accuracy: 0.1713Epoch 6: loss = 2.4351398944854736, val_loss = 2.285726547241211\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 2.4351 - categorical_accuracy: 0.1700 - val_loss: 2.2857 - val_categorical_accuracy: 0.1714\n",
      "Epoch 7/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.2619 - categorical_accuracy: 0.2111Epoch 7: loss = 2.2618632316589355, val_loss = 2.2236595153808594\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 2.2619 - categorical_accuracy: 0.2111 - val_loss: 2.2237 - val_categorical_accuracy: 0.2216\n",
      "Epoch 8/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.1207 - categorical_accuracy: 0.2716Epoch 8: loss = 2.1185662746429443, val_loss = 2.072530746459961\n",
      "82/82 [==============================] - 4s 44ms/step - loss: 2.1186 - categorical_accuracy: 0.2721 - val_loss: 2.0725 - val_categorical_accuracy: 0.2597\n",
      "Epoch 9/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.1543 - categorical_accuracy: 0.2878Epoch 9: loss = 2.1588830947875977, val_loss = 2.384415626525879\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 2.1589 - categorical_accuracy: 0.2858 - val_loss: 2.3844 - val_categorical_accuracy: 0.1630\n",
      "Epoch 10/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.1135 - categorical_accuracy: 0.2685Epoch 10: loss = 2.113267183303833, val_loss = 1.905854344367981\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 2.1133 - categorical_accuracy: 0.2698 - val_loss: 1.9059 - val_categorical_accuracy: 0.3648\n",
      "Epoch 11/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.8408 - categorical_accuracy: 0.3565Epoch 11: loss = 1.8429105281829834, val_loss = 1.6637893915176392\n",
      "82/82 [==============================] - 4s 47ms/step - loss: 1.8429 - categorical_accuracy: 0.3567 - val_loss: 1.6638 - val_categorical_accuracy: 0.4448\n",
      "Epoch 12/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.7124 - categorical_accuracy: 0.4162Epoch 12: loss = 1.7124040126800537, val_loss = 1.5466612577438354\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 1.7124 - categorical_accuracy: 0.4162 - val_loss: 1.5467 - val_categorical_accuracy: 0.4486\n",
      "Epoch 13/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.5495 - categorical_accuracy: 0.4606Epoch 13: loss = 1.5472017526626587, val_loss = 1.4460511207580566\n",
      "82/82 [==============================] - 3s 38ms/step - loss: 1.5472 - categorical_accuracy: 0.4611 - val_loss: 1.4461 - val_categorical_accuracy: 0.4615\n",
      "Epoch 14/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.3791 - categorical_accuracy: 0.5100Epoch 14: loss = 1.3842554092407227, val_loss = 1.2811944484710693\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 1.3843 - categorical_accuracy: 0.5084 - val_loss: 1.2812 - val_categorical_accuracy: 0.5659\n",
      "Epoch 15/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.5250 - categorical_accuracy: 0.4812Epoch 15: loss = 1.5251466035842896, val_loss = 1.5814485549926758\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 1.5251 - categorical_accuracy: 0.4794 - val_loss: 1.5814 - val_categorical_accuracy: 0.4288\n",
      "Epoch 16/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.2396 - categorical_accuracy: 0.5586Epoch 16: loss = 1.237074851989746, val_loss = 1.170219898223877\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 1.2371 - categorical_accuracy: 0.5595 - val_loss: 1.1702 - val_categorical_accuracy: 0.5644\n",
      "Epoch 17/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.1067 - categorical_accuracy: 0.5983Epoch 17: loss = 1.1067074537277222, val_loss = 1.1136970520019531\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 1.1067 - categorical_accuracy: 0.5983 - val_loss: 1.1137 - val_categorical_accuracy: 0.6055\n",
      "Epoch 18/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.2288 - categorical_accuracy: 0.5517Epoch 18: loss = 1.2296797037124634, val_loss = 1.40790593624115\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 1.2297 - categorical_accuracy: 0.5518 - val_loss: 1.4079 - val_categorical_accuracy: 0.4730\n",
      "Epoch 19/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.1194 - categorical_accuracy: 0.5887Epoch 19: loss = 1.121114730834961, val_loss = 1.1199146509170532\n",
      "82/82 [==============================] - 3s 31ms/step - loss: 1.1211 - categorical_accuracy: 0.5892 - val_loss: 1.1199 - val_categorical_accuracy: 0.5864\n",
      "Epoch 20/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.0279 - categorical_accuracy: 0.6258Epoch 20: loss = 1.0338959693908691, val_loss = 0.9836325645446777\n",
      "82/82 [==============================] - 3s 31ms/step - loss: 1.0339 - categorical_accuracy: 0.6212 - val_loss: 0.9836 - val_categorical_accuracy: 0.6329\n",
      "Epoch 21/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.0263 - categorical_accuracy: 0.6151Epoch 21: loss = 1.0263047218322754, val_loss = 0.947533130645752\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 1.0263 - categorical_accuracy: 0.6151 - val_loss: 0.9475 - val_categorical_accuracy: 0.6466\n",
      "Epoch 22/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.1997 - categorical_accuracy: 0.5716Epoch 22: loss = 1.1996866464614868, val_loss = 1.7832828760147095\n",
      "82/82 [==============================] - 3s 37ms/step - loss: 1.1997 - categorical_accuracy: 0.5716 - val_loss: 1.7833 - val_categorical_accuracy: 0.4136\n",
      "Epoch 23/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.2225 - categorical_accuracy: 0.5414Epoch 23: loss = 1.2161879539489746, val_loss = 1.0574556589126587\n",
      "82/82 [==============================] - 3s 36ms/step - loss: 1.2162 - categorical_accuracy: 0.5457 - val_loss: 1.0575 - val_categorical_accuracy: 0.5834\n",
      "Epoch 24/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.1107 - categorical_accuracy: 0.5805Epoch 24: loss = 1.1204257011413574, val_loss = 1.541617751121521\n",
      "82/82 [==============================] - 3s 38ms/step - loss: 1.1204 - categorical_accuracy: 0.5793 - val_loss: 1.5416 - val_categorical_accuracy: 0.4661\n",
      "Epoch 25/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.1342 - categorical_accuracy: 0.6156Epoch 25: loss = 1.1347308158874512, val_loss = 1.5442012548446655\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 1.1347 - categorical_accuracy: 0.6128 - val_loss: 1.5442 - val_categorical_accuracy: 0.4128\n",
      "Epoch 26/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.2248 - categorical_accuracy: 0.5508Epoch 26: loss = 1.2210848331451416, val_loss = 0.9643415212631226\n",
      "82/82 [==============================] - 3s 41ms/step - loss: 1.2211 - categorical_accuracy: 0.5526 - val_loss: 0.9643 - val_categorical_accuracy: 0.6398\n",
      "Epoch 27/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.8607 - categorical_accuracy: 0.6728Epoch 27: loss = 0.8629153370857239, val_loss = 0.9616822600364685\n",
      "82/82 [==============================] - 4s 47ms/step - loss: 0.8629 - categorical_accuracy: 0.6715 - val_loss: 0.9617 - val_categorical_accuracy: 0.6413\n",
      "Epoch 28/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9212 - categorical_accuracy: 0.6616Epoch 28: loss = 0.9212359189987183, val_loss = 0.9399603605270386\n",
      "82/82 [==============================] - 4s 50ms/step - loss: 0.9212 - categorical_accuracy: 0.6616 - val_loss: 0.9400 - val_categorical_accuracy: 0.6497\n",
      "Epoch 29/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.9260 - categorical_accuracy: 0.6319Epoch 29: loss = 0.9290032982826233, val_loss = 0.9901794195175171\n",
      "82/82 [==============================] - 3s 41ms/step - loss: 0.9290 - categorical_accuracy: 0.6296 - val_loss: 0.9902 - val_categorical_accuracy: 0.6177\n",
      "Epoch 30/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8655 - categorical_accuracy: 0.6616Epoch 30: loss = 0.8655468225479126, val_loss = 0.9194093346595764\n",
      "82/82 [==============================] - 3s 39ms/step - loss: 0.8655 - categorical_accuracy: 0.6616 - val_loss: 0.9194 - val_categorical_accuracy: 0.6573\n",
      "Epoch 31/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.9251 - categorical_accuracy: 0.6516Epoch 31: loss = 0.9183290004730225, val_loss = 0.8697962760925293\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 0.9183 - categorical_accuracy: 0.6555 - val_loss: 0.8698 - val_categorical_accuracy: 0.6839\n",
      "Epoch 32/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.8442 - categorical_accuracy: 0.6852Epoch 32: loss = 0.8439324498176575, val_loss = 0.8396949172019958\n",
      "82/82 [==============================] - 3s 42ms/step - loss: 0.8439 - categorical_accuracy: 0.6867 - val_loss: 0.8397 - val_categorical_accuracy: 0.7060\n",
      "Epoch 33/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.9820 - categorical_accuracy: 0.6435Epoch 33: loss = 0.9819836616516113, val_loss = 0.8014297485351562\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 0.9820 - categorical_accuracy: 0.6441 - val_loss: 0.8014 - val_categorical_accuracy: 0.7037\n",
      "Epoch 34/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.7453 - categorical_accuracy: 0.7096Epoch 34: loss = 0.7452665567398071, val_loss = 0.8862813115119934\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 0.7453 - categorical_accuracy: 0.7096 - val_loss: 0.8863 - val_categorical_accuracy: 0.6778\n",
      "Epoch 35/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.7856 - categorical_accuracy: 0.7188Epoch 35: loss = 0.785603940486908, val_loss = 0.732235312461853\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 0.7856 - categorical_accuracy: 0.7188 - val_loss: 0.7322 - val_categorical_accuracy: 0.7304\n",
      "Epoch 36/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.7913 - categorical_accuracy: 0.7076Epoch 36: loss = 0.7938947081565857, val_loss = 0.8028260469436646\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 0.7939 - categorical_accuracy: 0.7058 - val_loss: 0.8028 - val_categorical_accuracy: 0.7045\n",
      "Epoch 37/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.7465 - categorical_accuracy: 0.7104Epoch 37: loss = 0.7464500069618225, val_loss = 0.9014471173286438\n",
      "82/82 [==============================] - 3s 36ms/step - loss: 0.7465 - categorical_accuracy: 0.7104 - val_loss: 0.9014 - val_categorical_accuracy: 0.6908\n",
      "Epoch 38/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.7863 - categorical_accuracy: 0.7020Epoch 38: loss = 0.7863124012947083, val_loss = 0.7621209621429443\n",
      "82/82 [==============================] - 3s 36ms/step - loss: 0.7863 - categorical_accuracy: 0.7020 - val_loss: 0.7621 - val_categorical_accuracy: 0.7273\n",
      "Epoch 39/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.6656 - categorical_accuracy: 0.7423Epoch 39: loss = 0.6601987481117249, val_loss = 0.7539337873458862\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 0.6602 - categorical_accuracy: 0.7447 - val_loss: 0.7539 - val_categorical_accuracy: 0.7296\n",
      "Epoch 40/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.7907 - categorical_accuracy: 0.7047Epoch 40: loss = 0.7954399585723877, val_loss = 0.8167279958724976\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 0.7954 - categorical_accuracy: 0.7012 - val_loss: 0.8167 - val_categorical_accuracy: 0.7228\n",
      "Epoch 41/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.6646 - categorical_accuracy: 0.7361Epoch 41: loss = 0.6688246726989746, val_loss = 1.1110037565231323\n",
      "82/82 [==============================] - 3s 40ms/step - loss: 0.6688 - categorical_accuracy: 0.7355 - val_loss: 1.1110 - val_categorical_accuracy: 0.6161\n",
      "Epoch 42/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.7243 - categorical_accuracy: 0.7016Epoch 42: loss = 0.7256629467010498, val_loss = 0.8109157681465149\n",
      "82/82 [==============================] - 3s 40ms/step - loss: 0.7257 - categorical_accuracy: 0.6982 - val_loss: 0.8109 - val_categorical_accuracy: 0.7159\n",
      "Epoch 43/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.7615 - categorical_accuracy: 0.7114Epoch 43: loss = 0.7610160112380981, val_loss = 1.201880693435669\n",
      "82/82 [==============================] - 4s 43ms/step - loss: 0.7610 - categorical_accuracy: 0.7104 - val_loss: 1.2019 - val_categorical_accuracy: 0.5446\n",
      "Epoch 44/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.9275 - categorical_accuracy: 0.6570Epoch 44: loss = 0.9249594807624817, val_loss = 1.0024434328079224\n",
      "82/82 [==============================] - 4s 51ms/step - loss: 0.9250 - categorical_accuracy: 0.6608 - val_loss: 1.0024 - val_categorical_accuracy: 0.6794\n",
      "Epoch 45/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8889 - categorical_accuracy: 0.6684Restoring model weights from the end of the best epoch: 35.\n",
      "Epoch 45: loss = 0.8889309763908386, val_loss = 0.7553130388259888\n",
      "82/82 [==============================] - 3s 42ms/step - loss: 0.8889 - categorical_accuracy: 0.6684 - val_loss: 0.7553 - val_categorical_accuracy: 0.7342\n",
      "Epoch 45: early stopping\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7322 - categorical_accuracy: 0.7304\n",
      "Epoch 1/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 3.0848 - categorical_accuracy: 0.0625Epoch 1: loss = 3.0848491191864014, val_loss = 3.1078367233276367\n",
      "83/83 [==============================] - 11s 57ms/step - loss: 3.0848 - categorical_accuracy: 0.0625 - val_loss: 3.1078 - val_categorical_accuracy: 0.0457\n",
      "Epoch 2/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.9483 - categorical_accuracy: 0.0701Epoch 2: loss = 2.9483401775360107, val_loss = 2.7372689247131348\n",
      "83/83 [==============================] - 4s 43ms/step - loss: 2.9483 - categorical_accuracy: 0.0701 - val_loss: 2.7373 - val_categorical_accuracy: 0.0915\n",
      "Epoch 3/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.6820 - categorical_accuracy: 0.0891Epoch 3: loss = 2.6819581985473633, val_loss = 2.641141414642334\n",
      "83/83 [==============================] - 4s 45ms/step - loss: 2.6820 - categorical_accuracy: 0.0891 - val_loss: 2.6411 - val_categorical_accuracy: 0.1349\n",
      "Epoch 4/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.5807 - categorical_accuracy: 0.1410Epoch 4: loss = 2.5807974338531494, val_loss = 2.532738208770752\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 2.5808 - categorical_accuracy: 0.1409 - val_loss: 2.5327 - val_categorical_accuracy: 0.1380\n",
      "Epoch 5/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.5394 - categorical_accuracy: 0.1485Epoch 5: loss = 2.539440155029297, val_loss = 2.403550624847412\n",
      "83/83 [==============================] - 4s 43ms/step - loss: 2.5394 - categorical_accuracy: 0.1485 - val_loss: 2.4036 - val_categorical_accuracy: 0.1738\n",
      "Epoch 6/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.4047 - categorical_accuracy: 0.1836Epoch 6: loss = 2.4031569957733154, val_loss = 2.34004282951355\n",
      "83/83 [==============================] - 4s 48ms/step - loss: 2.4032 - categorical_accuracy: 0.1835 - val_loss: 2.3400 - val_categorical_accuracy: 0.1875\n",
      "Epoch 7/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.1216 - categorical_accuracy: 0.2536Epoch 7: loss = 2.121589183807373, val_loss = 1.9064964056015015\n",
      "83/83 [==============================] - 4s 44ms/step - loss: 2.1216 - categorical_accuracy: 0.2536 - val_loss: 1.9065 - val_categorical_accuracy: 0.3018\n",
      "Epoch 8/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.9144 - categorical_accuracy: 0.3191Epoch 8: loss = 1.9143731594085693, val_loss = 2.5276072025299072\n",
      "83/83 [==============================] - 4s 49ms/step - loss: 1.9144 - categorical_accuracy: 0.3191 - val_loss: 2.5276 - val_categorical_accuracy: 0.2561\n",
      "Epoch 9/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.0698 - categorical_accuracy: 0.2752Epoch 9: loss = 2.0693633556365967, val_loss = 1.9035561084747314\n",
      "83/83 [==============================] - 4s 49ms/step - loss: 2.0694 - categorical_accuracy: 0.2749 - val_loss: 1.9036 - val_categorical_accuracy: 0.2912\n",
      "Epoch 10/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.8210 - categorical_accuracy: 0.3384Epoch 10: loss = 1.8211418390274048, val_loss = 1.59968900680542\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.8211 - categorical_accuracy: 0.3382 - val_loss: 1.5997 - val_categorical_accuracy: 0.4367\n",
      "Epoch 11/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.6801 - categorical_accuracy: 0.3778Epoch 11: loss = 1.6801478862762451, val_loss = 2.1040661334991455\n",
      "83/83 [==============================] - 4s 45ms/step - loss: 1.6801 - categorical_accuracy: 0.3778 - val_loss: 2.1041 - val_categorical_accuracy: 0.3887\n",
      "Epoch 12/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.2507 - categorical_accuracy: 0.3399Epoch 12: loss = 2.24979829788208, val_loss = 1.9267786741256714\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 2.2498 - categorical_accuracy: 0.3404 - val_loss: 1.9268 - val_categorical_accuracy: 0.2988\n",
      "Epoch 13/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.6293 - categorical_accuracy: 0.3920Epoch 13: loss = 1.6369978189468384, val_loss = 1.4416139125823975\n",
      "83/83 [==============================] - 4s 49ms/step - loss: 1.6370 - categorical_accuracy: 0.3915 - val_loss: 1.4416 - val_categorical_accuracy: 0.4741\n",
      "Epoch 14/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.5385 - categorical_accuracy: 0.4265Epoch 14: loss = 1.5384889841079712, val_loss = 1.7850466966629028\n",
      "83/83 [==============================] - 4s 46ms/step - loss: 1.5385 - categorical_accuracy: 0.4265 - val_loss: 1.7850 - val_categorical_accuracy: 0.4367\n",
      "Epoch 15/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.4717 - categorical_accuracy: 0.4649Epoch 15: loss = 1.472318172454834, val_loss = 1.2731783390045166\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 1.4723 - categorical_accuracy: 0.4646 - val_loss: 1.2732 - val_categorical_accuracy: 0.5373\n",
      "Epoch 16/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.3579 - categorical_accuracy: 0.4970Epoch 16: loss = 1.3581584692001343, val_loss = 1.6727509498596191\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 1.3582 - categorical_accuracy: 0.4966 - val_loss: 1.6728 - val_categorical_accuracy: 0.4291\n",
      "Epoch 17/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.5782 - categorical_accuracy: 0.4512Epoch 17: loss = 1.5783824920654297, val_loss = 1.2956693172454834\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 1.5784 - categorical_accuracy: 0.4509 - val_loss: 1.2957 - val_categorical_accuracy: 0.5808\n",
      "Epoch 18/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.4797 - categorical_accuracy: 0.4604Epoch 18: loss = 1.4802451133728027, val_loss = 1.2003154754638672\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 1.4802 - categorical_accuracy: 0.4600 - val_loss: 1.2003 - val_categorical_accuracy: 0.5694\n",
      "Epoch 19/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.2641 - categorical_accuracy: 0.5369Epoch 19: loss = 1.2641161680221558, val_loss = 1.3475521802902222\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 1.2641 - categorical_accuracy: 0.5369 - val_loss: 1.3476 - val_categorical_accuracy: 0.5503\n",
      "Epoch 20/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.2184 - categorical_accuracy: 0.5549Epoch 20: loss = 1.2176016569137573, val_loss = 1.0121724605560303\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 1.2176 - categorical_accuracy: 0.5552 - val_loss: 1.0122 - val_categorical_accuracy: 0.6441\n",
      "Epoch 21/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.0245 - categorical_accuracy: 0.6080Epoch 21: loss = 1.02460777759552, val_loss = 0.9644103646278381\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 1.0246 - categorical_accuracy: 0.6085 - val_loss: 0.9644 - val_categorical_accuracy: 0.6601\n",
      "Epoch 22/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.1007 - categorical_accuracy: 0.5938Epoch 22: loss = 1.100125789642334, val_loss = 1.1056960821151733\n",
      "83/83 [==============================] - 3s 41ms/step - loss: 1.1001 - categorical_accuracy: 0.5941 - val_loss: 1.1057 - val_categorical_accuracy: 0.5808\n",
      "Epoch 23/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.9810 - categorical_accuracy: 0.6235Epoch 23: loss = 0.9806588888168335, val_loss = 0.9743263721466064\n",
      "83/83 [==============================] - 4s 43ms/step - loss: 0.9807 - categorical_accuracy: 0.6238 - val_loss: 0.9743 - val_categorical_accuracy: 0.6242\n",
      "Epoch 24/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.1250 - categorical_accuracy: 0.5934Epoch 24: loss = 1.1231647729873657, val_loss = 0.9729388952255249\n",
      "83/83 [==============================] - 3s 41ms/step - loss: 1.1232 - categorical_accuracy: 0.5933 - val_loss: 0.9729 - val_categorical_accuracy: 0.6532\n",
      "Epoch 25/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.0193 - categorical_accuracy: 0.6265Epoch 25: loss = 1.0158114433288574, val_loss = 0.8089944124221802\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 1.0158 - categorical_accuracy: 0.6276 - val_loss: 0.8090 - val_categorical_accuracy: 0.7012\n",
      "Epoch 26/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.9237 - categorical_accuracy: 0.6512Epoch 26: loss = 0.9332250952720642, val_loss = 1.2713491916656494\n",
      "83/83 [==============================] - 3s 41ms/step - loss: 0.9332 - categorical_accuracy: 0.6489 - val_loss: 1.2713 - val_categorical_accuracy: 0.5099\n",
      "Epoch 27/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.9895 - categorical_accuracy: 0.6358Epoch 27: loss = 0.9891412258148193, val_loss = 0.8422166705131531\n",
      "83/83 [==============================] - 4s 45ms/step - loss: 0.9891 - categorical_accuracy: 0.6367 - val_loss: 0.8422 - val_categorical_accuracy: 0.7332\n",
      "Epoch 28/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.8576 - categorical_accuracy: 0.6837Epoch 28: loss = 0.8577083945274353, val_loss = 0.8287879228591919\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.8577 - categorical_accuracy: 0.6832 - val_loss: 0.8288 - val_categorical_accuracy: 0.7226\n",
      "Epoch 29/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.8213 - categorical_accuracy: 0.6852Epoch 29: loss = 0.8180210590362549, val_loss = 0.7076727151870728\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.8180 - categorical_accuracy: 0.6870 - val_loss: 0.7077 - val_categorical_accuracy: 0.7530\n",
      "Epoch 30/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.7671 - categorical_accuracy: 0.7096Epoch 30: loss = 0.7670962810516357, val_loss = 0.7716151475906372\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 0.7671 - categorical_accuracy: 0.7098 - val_loss: 0.7716 - val_categorical_accuracy: 0.7332\n",
      "Epoch 31/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.8371 - categorical_accuracy: 0.7007Epoch 31: loss = 0.8370665311813354, val_loss = 0.7094739079475403\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.8371 - categorical_accuracy: 0.7007 - val_loss: 0.7095 - val_categorical_accuracy: 0.7591\n",
      "Epoch 32/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.7403 - categorical_accuracy: 0.7241Epoch 32: loss = 0.7397369146347046, val_loss = 0.6957085728645325\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 0.7397 - categorical_accuracy: 0.7243 - val_loss: 0.6957 - val_categorical_accuracy: 0.7462\n",
      "Epoch 33/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.9370 - categorical_accuracy: 0.6542Epoch 33: loss = 0.9369505643844604, val_loss = 0.9377484917640686\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 0.9370 - categorical_accuracy: 0.6542 - val_loss: 0.9377 - val_categorical_accuracy: 0.7073\n",
      "Epoch 34/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.7162 - categorical_accuracy: 0.7258Epoch 34: loss = 0.7162198424339294, val_loss = 0.6303684115409851\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 0.7162 - categorical_accuracy: 0.7258 - val_loss: 0.6304 - val_categorical_accuracy: 0.7774\n",
      "Epoch 35/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.7446 - categorical_accuracy: 0.7226Epoch 35: loss = 0.7440638542175293, val_loss = 0.6139444708824158\n",
      "83/83 [==============================] - 4s 43ms/step - loss: 0.7441 - categorical_accuracy: 0.7228 - val_loss: 0.6139 - val_categorical_accuracy: 0.8125\n",
      "Epoch 36/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.6552 - categorical_accuracy: 0.7662Epoch 36: loss = 0.6559260487556458, val_loss = 0.7311879396438599\n",
      "83/83 [==============================] - 4s 48ms/step - loss: 0.6559 - categorical_accuracy: 0.7654 - val_loss: 0.7312 - val_categorical_accuracy: 0.7119\n",
      "Epoch 37/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.8715 - categorical_accuracy: 0.6837Epoch 37: loss = 0.871432363986969, val_loss = 0.6731393933296204\n",
      "83/83 [==============================] - 4s 46ms/step - loss: 0.8714 - categorical_accuracy: 0.6832 - val_loss: 0.6731 - val_categorical_accuracy: 0.7630\n",
      "Epoch 38/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.7156 - categorical_accuracy: 0.7348Epoch 38: loss = 0.7152469754219055, val_loss = 0.6511670351028442\n",
      "83/83 [==============================] - 4s 44ms/step - loss: 0.7152 - categorical_accuracy: 0.7350 - val_loss: 0.6512 - val_categorical_accuracy: 0.7439\n",
      "Epoch 39/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.6707 - categorical_accuracy: 0.7378Epoch 39: loss = 0.6702154278755188, val_loss = 0.7542229294776917\n",
      "83/83 [==============================] - 4s 45ms/step - loss: 0.6702 - categorical_accuracy: 0.7380 - val_loss: 0.7542 - val_categorical_accuracy: 0.7431\n",
      "Epoch 40/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.6476 - categorical_accuracy: 0.7562Epoch 40: loss = 0.6443738341331482, val_loss = 0.8815823197364807\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.6444 - categorical_accuracy: 0.7570 - val_loss: 0.8816 - val_categorical_accuracy: 0.6829\n",
      "Epoch 41/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.6090 - categorical_accuracy: 0.7660Epoch 41: loss = 0.6085644960403442, val_loss = 0.6428225636482239\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.6086 - categorical_accuracy: 0.7662 - val_loss: 0.6428 - val_categorical_accuracy: 0.7706\n",
      "Epoch 42/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.6224 - categorical_accuracy: 0.7723Epoch 42: loss = 0.6224149465560913, val_loss = 0.7029138803482056\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.6224 - categorical_accuracy: 0.7723 - val_loss: 0.7029 - val_categorical_accuracy: 0.7576\n",
      "Epoch 43/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.6357 - categorical_accuracy: 0.7449Epoch 43: loss = 0.6357285380363464, val_loss = 0.6863062977790833\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.6357 - categorical_accuracy: 0.7449 - val_loss: 0.6863 - val_categorical_accuracy: 0.7866\n",
      "Epoch 44/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.6597 - categorical_accuracy: 0.7540Epoch 44: loss = 0.6596678495407104, val_loss = 0.6446125507354736\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.6597 - categorical_accuracy: 0.7540 - val_loss: 0.6446 - val_categorical_accuracy: 0.7912\n",
      "Epoch 45/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.5773 - categorical_accuracy: 0.7820Epoch 45: loss = 0.5768940448760986, val_loss = 0.5515343546867371\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.5769 - categorical_accuracy: 0.7822 - val_loss: 0.5515 - val_categorical_accuracy: 0.7965\n",
      "Epoch 46/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.5918 - categorical_accuracy: 0.7790Epoch 46: loss = 0.5913326144218445, val_loss = 0.8378884792327881\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 0.5913 - categorical_accuracy: 0.7791 - val_loss: 0.8379 - val_categorical_accuracy: 0.6921\n",
      "Epoch 47/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.6662 - categorical_accuracy: 0.7523Epoch 47: loss = 0.6656601428985596, val_loss = 0.6149908304214478\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.6657 - categorical_accuracy: 0.7525 - val_loss: 0.6150 - val_categorical_accuracy: 0.7774\n",
      "Epoch 48/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.5907 - categorical_accuracy: 0.7753Epoch 48: loss = 0.5907479524612427, val_loss = 0.7301092147827148\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.5907 - categorical_accuracy: 0.7753 - val_loss: 0.7301 - val_categorical_accuracy: 0.7553\n",
      "Epoch 49/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.5784 - categorical_accuracy: 0.7875Epoch 49: loss = 0.5783936381340027, val_loss = 0.6223294138908386\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 0.5784 - categorical_accuracy: 0.7875 - val_loss: 0.6223 - val_categorical_accuracy: 0.7691\n",
      "Epoch 50/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.6559 - categorical_accuracy: 0.7675Epoch 50: loss = 0.6558541655540466, val_loss = 0.5915572047233582\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 0.6559 - categorical_accuracy: 0.7677 - val_loss: 0.5916 - val_categorical_accuracy: 0.8003\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.5915 - categorical_accuracy: 0.8003\n",
      "Epoch 1/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 3.1972 - categorical_accuracy: 0.0633Epoch 1: loss = 3.1972310543060303, val_loss = 3.115896463394165\n",
      "82/82 [==============================] - 7s 43ms/step - loss: 3.1972 - categorical_accuracy: 0.0633 - val_loss: 3.1159 - val_categorical_accuracy: 0.1516\n",
      "Epoch 2/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 2.9727 - categorical_accuracy: 0.0984Epoch 2: loss = 2.964371919631958, val_loss = 2.888962745666504\n",
      "82/82 [==============================] - 3s 36ms/step - loss: 2.9644 - categorical_accuracy: 0.1006 - val_loss: 2.8890 - val_categorical_accuracy: 0.0564\n",
      "Epoch 3/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.7122 - categorical_accuracy: 0.1197Epoch 3: loss = 2.7121939659118652, val_loss = 2.60622501373291\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 2.7122 - categorical_accuracy: 0.1197 - val_loss: 2.6062 - val_categorical_accuracy: 0.1021\n",
      "Epoch 4/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.5362 - categorical_accuracy: 0.1349Epoch 4: loss = 2.5361955165863037, val_loss = 2.7162978649139404\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 2.5362 - categorical_accuracy: 0.1349 - val_loss: 2.7163 - val_categorical_accuracy: 0.0883\n",
      "Epoch 5/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.5502 - categorical_accuracy: 0.1273Epoch 5: loss = 2.550198554992676, val_loss = 2.443819284439087\n",
      "82/82 [==============================] - 3s 31ms/step - loss: 2.5502 - categorical_accuracy: 0.1273 - val_loss: 2.4438 - val_categorical_accuracy: 0.1660\n",
      "Epoch 6/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.3603 - categorical_accuracy: 0.2050Epoch 6: loss = 2.360306739807129, val_loss = 2.2522621154785156\n",
      "82/82 [==============================] - 3s 31ms/step - loss: 2.3603 - categorical_accuracy: 0.2050 - val_loss: 2.2523 - val_categorical_accuracy: 0.2521\n",
      "Epoch 7/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 2.3581 - categorical_accuracy: 0.2125Epoch 7: loss = 2.358036756515503, val_loss = 2.5226082801818848\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 2.3580 - categorical_accuracy: 0.2127 - val_loss: 2.5226 - val_categorical_accuracy: 0.1622\n",
      "Epoch 8/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.2127 - categorical_accuracy: 0.2346Epoch 8: loss = 2.213209390640259, val_loss = 2.2597579956054688\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 2.2132 - categorical_accuracy: 0.2340 - val_loss: 2.2598 - val_categorical_accuracy: 0.2178\n",
      "Epoch 9/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.9350 - categorical_accuracy: 0.2820Epoch 9: loss = 1.9312127828598022, val_loss = 1.7544002532958984\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 1.9312 - categorical_accuracy: 0.2835 - val_loss: 1.7544 - val_categorical_accuracy: 0.3435\n",
      "Epoch 10/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.8104 - categorical_accuracy: 0.3503Epoch 10: loss = 1.8065403699874878, val_loss = 1.7049033641815186\n",
      "82/82 [==============================] - 3s 37ms/step - loss: 1.8065 - categorical_accuracy: 0.3506 - val_loss: 1.7049 - val_categorical_accuracy: 0.3998\n",
      "Epoch 11/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.6726 - categorical_accuracy: 0.3780Epoch 11: loss = 1.6726399660110474, val_loss = 1.5298579931259155\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.6726 - categorical_accuracy: 0.3780 - val_loss: 1.5299 - val_categorical_accuracy: 0.3960\n",
      "Epoch 12/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.5059 - categorical_accuracy: 0.4352Epoch 12: loss = 1.505948781967163, val_loss = 1.4405609369277954\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 1.5059 - categorical_accuracy: 0.4352 - val_loss: 1.4406 - val_categorical_accuracy: 0.4478\n",
      "Epoch 13/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.4207 - categorical_accuracy: 0.4838Epoch 13: loss = 1.4240037202835083, val_loss = 1.4396557807922363\n",
      "82/82 [==============================] - 3s 31ms/step - loss: 1.4240 - categorical_accuracy: 0.4817 - val_loss: 1.4397 - val_categorical_accuracy: 0.4867\n",
      "Epoch 14/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.3199 - categorical_accuracy: 0.4915Epoch 14: loss = 1.3192505836486816, val_loss = 1.2623224258422852\n",
      "82/82 [==============================] - 3s 31ms/step - loss: 1.3193 - categorical_accuracy: 0.4924 - val_loss: 1.2623 - val_categorical_accuracy: 0.5133\n",
      "Epoch 15/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.8561 - categorical_accuracy: 0.3891Epoch 15: loss = 1.858524203300476, val_loss = 1.6842697858810425\n",
      "82/82 [==============================] - 2s 30ms/step - loss: 1.8585 - categorical_accuracy: 0.3872 - val_loss: 1.6843 - val_categorical_accuracy: 0.3732\n",
      "Epoch 16/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.7518 - categorical_accuracy: 0.3586Epoch 16: loss = 1.7458224296569824, val_loss = 1.4423754215240479\n",
      "82/82 [==============================] - 3s 31ms/step - loss: 1.7458 - categorical_accuracy: 0.3605 - val_loss: 1.4424 - val_categorical_accuracy: 0.4463\n",
      "Epoch 17/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.5348 - categorical_accuracy: 0.4236Epoch 17: loss = 1.5324138402938843, val_loss = 1.422129511833191\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 1.5324 - categorical_accuracy: 0.4238 - val_loss: 1.4221 - val_categorical_accuracy: 0.4440\n",
      "Epoch 18/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.3817 - categorical_accuracy: 0.4766Epoch 18: loss = 1.3869167566299438, val_loss = 1.4409575462341309\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 1.3869 - categorical_accuracy: 0.4771 - val_loss: 1.4410 - val_categorical_accuracy: 0.4494\n",
      "Epoch 19/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.3160 - categorical_accuracy: 0.4820Epoch 19: loss = 1.327647089958191, val_loss = 1.262804388999939\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.3276 - categorical_accuracy: 0.4787 - val_loss: 1.2628 - val_categorical_accuracy: 0.4570\n",
      "Epoch 20/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.2689 - categorical_accuracy: 0.5131Epoch 20: loss = 1.2660707235336304, val_loss = 1.3268609046936035\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.2661 - categorical_accuracy: 0.5152 - val_loss: 1.3269 - val_categorical_accuracy: 0.5392\n",
      "Epoch 21/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 8.6895 - categorical_accuracy: 0.4062Epoch 21: loss = 8.537900924682617, val_loss = 2.5345633029937744\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 8.5379 - categorical_accuracy: 0.4024 - val_loss: 2.5346 - val_categorical_accuracy: 0.1500\n",
      "Epoch 22/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.3059 - categorical_accuracy: 0.1651Epoch 22: loss = 2.3084821701049805, val_loss = 1.9901750087738037\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 2.3085 - categorical_accuracy: 0.1631 - val_loss: 1.9902 - val_categorical_accuracy: 0.2559\n",
      "Epoch 23/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.9033 - categorical_accuracy: 0.2945Epoch 23: loss = 1.9005930423736572, val_loss = 1.5988222360610962\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 1.9006 - categorical_accuracy: 0.2934 - val_loss: 1.5988 - val_categorical_accuracy: 0.4212\n",
      "Epoch 24/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.6210 - categorical_accuracy: 0.4055Restoring model weights from the end of the best epoch: 14.\n",
      "Epoch 24: loss = 1.6210308074951172, val_loss = 1.614830493927002\n",
      "82/82 [==============================] - 3s 31ms/step - loss: 1.6210 - categorical_accuracy: 0.4055 - val_loss: 1.6148 - val_categorical_accuracy: 0.3610\n",
      "Epoch 24: early stopping\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1.2623 - categorical_accuracy: 0.5133\n",
      "Epoch 1/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 3.2139 - categorical_accuracy: 0.0795Epoch 1: loss = 3.213315010070801, val_loss = 3.16784405708313\n",
      "83/83 [==============================] - 8s 44ms/step - loss: 3.2133 - categorical_accuracy: 0.0823 - val_loss: 3.1678 - val_categorical_accuracy: 0.1090\n",
      "Epoch 2/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.9370 - categorical_accuracy: 0.1059Epoch 2: loss = 2.937303304672241, val_loss = 2.5917482376098633\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 2.9373 - categorical_accuracy: 0.1059 - val_loss: 2.5917 - val_categorical_accuracy: 0.1433\n",
      "Epoch 3/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.7072 - categorical_accuracy: 0.1257Epoch 3: loss = 2.7072086334228516, val_loss = 2.50840163230896\n",
      "83/83 [==============================] - 3s 36ms/step - loss: 2.7072 - categorical_accuracy: 0.1257 - val_loss: 2.5084 - val_categorical_accuracy: 0.2180\n",
      "Epoch 4/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.4325 - categorical_accuracy: 0.1813Epoch 4: loss = 2.431448459625244, val_loss = 2.11069655418396\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 2.4314 - categorical_accuracy: 0.1805 - val_loss: 2.1107 - val_categorical_accuracy: 0.2767\n",
      "Epoch 5/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.2190 - categorical_accuracy: 0.2431Epoch 5: loss = 2.217449903488159, val_loss = 2.328936815261841\n",
      "83/83 [==============================] - 3s 41ms/step - loss: 2.2174 - categorical_accuracy: 0.2422 - val_loss: 2.3289 - val_categorical_accuracy: 0.2325\n",
      "Epoch 6/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.9941 - categorical_accuracy: 0.3244Epoch 6: loss = 1.9940742254257202, val_loss = 1.7118710279464722\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 1.9941 - categorical_accuracy: 0.3244 - val_loss: 1.7119 - val_categorical_accuracy: 0.3735\n",
      "Epoch 7/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.9543 - categorical_accuracy: 0.3110Epoch 7: loss = 1.9540096521377563, val_loss = 1.6910895109176636\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 1.9540 - categorical_accuracy: 0.3115 - val_loss: 1.6911 - val_categorical_accuracy: 0.4314\n",
      "Epoch 8/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.8024 - categorical_accuracy: 0.3328Epoch 8: loss = 1.8023842573165894, val_loss = 1.4975335597991943\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 1.8024 - categorical_accuracy: 0.3328 - val_loss: 1.4975 - val_categorical_accuracy: 0.4726\n",
      "Epoch 9/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.6739 - categorical_accuracy: 0.3873Epoch 9: loss = 1.6749398708343506, val_loss = 1.419221043586731\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 1.6749 - categorical_accuracy: 0.3899 - val_loss: 1.4192 - val_categorical_accuracy: 0.4855\n",
      "Epoch 10/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.8279 - categorical_accuracy: 0.3918Epoch 10: loss = 1.8276582956314087, val_loss = 1.8893917798995972\n",
      "83/83 [==============================] - 4s 44ms/step - loss: 1.8277 - categorical_accuracy: 0.3915 - val_loss: 1.8894 - val_categorical_accuracy: 0.3651\n",
      "Epoch 11/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.7788 - categorical_accuracy: 0.3460Epoch 11: loss = 1.7775071859359741, val_loss = 1.485505223274231\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.7775 - categorical_accuracy: 0.3465 - val_loss: 1.4855 - val_categorical_accuracy: 0.4787\n",
      "Epoch 12/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.5695 - categorical_accuracy: 0.4044Epoch 12: loss = 1.569512963294983, val_loss = 1.4753917455673218\n",
      "83/83 [==============================] - 3s 42ms/step - loss: 1.5695 - categorical_accuracy: 0.4044 - val_loss: 1.4754 - val_categorical_accuracy: 0.4436\n",
      "Epoch 13/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.5065 - categorical_accuracy: 0.4421Epoch 13: loss = 1.509779930114746, val_loss = 1.186554193496704\n",
      "83/83 [==============================] - 5s 60ms/step - loss: 1.5098 - categorical_accuracy: 0.4395 - val_loss: 1.1866 - val_categorical_accuracy: 0.5823\n",
      "Epoch 14/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.4810 - categorical_accuracy: 0.4668Epoch 14: loss = 1.4826014041900635, val_loss = 1.6322840452194214\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 1.4826 - categorical_accuracy: 0.4669 - val_loss: 1.6323 - val_categorical_accuracy: 0.4428\n",
      "Epoch 15/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.3943 - categorical_accuracy: 0.4939Epoch 15: loss = 1.3941141366958618, val_loss = 1.0732768774032593\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 1.3941 - categorical_accuracy: 0.4935 - val_loss: 1.0733 - val_categorical_accuracy: 0.6181\n",
      "Epoch 16/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.2674 - categorical_accuracy: 0.5198Epoch 16: loss = 1.2684612274169922, val_loss = 1.0293586254119873\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 1.2685 - categorical_accuracy: 0.5194 - val_loss: 1.0294 - val_categorical_accuracy: 0.6608\n",
      "Epoch 17/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.2173 - categorical_accuracy: 0.5434Epoch 17: loss = 1.2167145013809204, val_loss = 1.2623445987701416\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 1.2167 - categorical_accuracy: 0.5438 - val_loss: 1.2623 - val_categorical_accuracy: 0.5587\n",
      "Epoch 18/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.1348 - categorical_accuracy: 0.5678Epoch 18: loss = 1.1340316534042358, val_loss = 1.0608068704605103\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 1.1340 - categorical_accuracy: 0.5682 - val_loss: 1.0608 - val_categorical_accuracy: 0.6021\n",
      "Epoch 19/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.1978 - categorical_accuracy: 0.5417Epoch 19: loss = 1.197688102722168, val_loss = 1.0750508308410645\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 1.1977 - categorical_accuracy: 0.5423 - val_loss: 1.0751 - val_categorical_accuracy: 0.6418\n",
      "Epoch 20/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.2413 - categorical_accuracy: 0.5522Epoch 20: loss = 1.241257667541504, val_loss = 1.4164959192276\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 1.2413 - categorical_accuracy: 0.5522 - val_loss: 1.4165 - val_categorical_accuracy: 0.4657\n",
      "Epoch 21/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.1050 - categorical_accuracy: 0.5948Epoch 21: loss = 1.104981541633606, val_loss = 0.7983676791191101\n",
      "83/83 [==============================] - 3s 36ms/step - loss: 1.1050 - categorical_accuracy: 0.5948 - val_loss: 0.7984 - val_categorical_accuracy: 0.7309\n",
      "Epoch 22/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.0424 - categorical_accuracy: 0.6034Epoch 22: loss = 1.0431818962097168, val_loss = 0.9584269523620605\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 1.0432 - categorical_accuracy: 0.6047 - val_loss: 0.9584 - val_categorical_accuracy: 0.6730\n",
      "Epoch 23/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.1643 - categorical_accuracy: 0.6211Epoch 23: loss = 1.159954309463501, val_loss = 1.5010253190994263\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 1.1600 - categorical_accuracy: 0.6215 - val_loss: 1.5010 - val_categorical_accuracy: 0.4726\n",
      "Epoch 24/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.0769 - categorical_accuracy: 0.5948Epoch 24: loss = 1.0768522024154663, val_loss = 1.2367545366287231\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 1.0769 - categorical_accuracy: 0.5948 - val_loss: 1.2368 - val_categorical_accuracy: 0.5762\n",
      "Epoch 25/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.4620 - categorical_accuracy: 0.4966Epoch 25: loss = 1.4619812965393066, val_loss = 0.8864376544952393\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 1.4620 - categorical_accuracy: 0.4966 - val_loss: 0.8864 - val_categorical_accuracy: 0.6730\n",
      "Epoch 26/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.0224 - categorical_accuracy: 0.6062Epoch 26: loss = 1.0223923921585083, val_loss = 0.8706921935081482\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 1.0224 - categorical_accuracy: 0.6062 - val_loss: 0.8707 - val_categorical_accuracy: 0.6928\n",
      "Epoch 27/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.9782 - categorical_accuracy: 0.6334Epoch 27: loss = 0.9775699973106384, val_loss = 0.8191031217575073\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.9776 - categorical_accuracy: 0.6337 - val_loss: 0.8191 - val_categorical_accuracy: 0.6997\n",
      "Epoch 28/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.3311 - categorical_accuracy: 0.5198Epoch 28: loss = 1.3301515579223633, val_loss = 0.9615145325660706\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 1.3302 - categorical_accuracy: 0.5202 - val_loss: 0.9615 - val_categorical_accuracy: 0.6273\n",
      "Epoch 29/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.9841 - categorical_accuracy: 0.6197Epoch 29: loss = 0.9838229417800903, val_loss = 0.7547194361686707\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.9838 - categorical_accuracy: 0.6200 - val_loss: 0.7547 - val_categorical_accuracy: 0.7218\n",
      "Epoch 30/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.9318 - categorical_accuracy: 0.6601Epoch 30: loss = 0.9322360157966614, val_loss = 0.9353435039520264\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.9322 - categorical_accuracy: 0.6596 - val_loss: 0.9353 - val_categorical_accuracy: 0.6547\n",
      "Epoch 31/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.8909 - categorical_accuracy: 0.6463Epoch 31: loss = 0.8902286887168884, val_loss = 0.8523930907249451\n",
      "83/83 [==============================] - 3s 41ms/step - loss: 0.8902 - categorical_accuracy: 0.6466 - val_loss: 0.8524 - val_categorical_accuracy: 0.6860\n",
      "Epoch 32/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.8342 - categorical_accuracy: 0.6806Epoch 32: loss = 0.8338592648506165, val_loss = 1.1912513971328735\n",
      "83/83 [==============================] - 3s 42ms/step - loss: 0.8339 - categorical_accuracy: 0.6809 - val_loss: 1.1913 - val_categorical_accuracy: 0.5922\n",
      "Epoch 33/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.1149 - categorical_accuracy: 0.6220Epoch 33: loss = 1.1149532794952393, val_loss = 0.8464327454566956\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 1.1150 - categorical_accuracy: 0.6222 - val_loss: 0.8464 - val_categorical_accuracy: 0.6898\n",
      "Epoch 34/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.8771 - categorical_accuracy: 0.6717Epoch 34: loss = 0.8771396279335022, val_loss = 0.7956107258796692\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.8771 - categorical_accuracy: 0.6717 - val_loss: 0.7956 - val_categorical_accuracy: 0.6905\n",
      "Epoch 35/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.7574 - categorical_accuracy: 0.6938Epoch 35: loss = 0.7574290633201599, val_loss = 0.6797365546226501\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.7574 - categorical_accuracy: 0.6938 - val_loss: 0.6797 - val_categorical_accuracy: 0.7584\n",
      "Epoch 36/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.7960 - categorical_accuracy: 0.6913Epoch 36: loss = 0.7967393398284912, val_loss = 0.9221406579017639\n",
      "83/83 [==============================] - 4s 48ms/step - loss: 0.7967 - categorical_accuracy: 0.6908 - val_loss: 0.9221 - val_categorical_accuracy: 0.6669\n",
      "Epoch 37/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.7516 - categorical_accuracy: 0.7014Epoch 37: loss = 0.7515561580657959, val_loss = 1.226536750793457\n",
      "83/83 [==============================] - 6s 68ms/step - loss: 0.7516 - categorical_accuracy: 0.7014 - val_loss: 1.2265 - val_categorical_accuracy: 0.6532\n",
      "Epoch 38/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.8052 - categorical_accuracy: 0.6976Epoch 38: loss = 0.8051949143409729, val_loss = 0.8941890597343445\n",
      "83/83 [==============================] - 4s 44ms/step - loss: 0.8052 - categorical_accuracy: 0.6976 - val_loss: 0.8942 - val_categorical_accuracy: 0.6761\n",
      "Epoch 39/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.8403 - categorical_accuracy: 0.6806Epoch 39: loss = 0.839040219783783, val_loss = 0.6682019829750061\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 0.8390 - categorical_accuracy: 0.6794 - val_loss: 0.6682 - val_categorical_accuracy: 0.7744\n",
      "Epoch 40/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.7082 - categorical_accuracy: 0.7180Epoch 40: loss = 0.7076920866966248, val_loss = 0.6001766324043274\n",
      "83/83 [==============================] - 3s 41ms/step - loss: 0.7077 - categorical_accuracy: 0.7182 - val_loss: 0.6002 - val_categorical_accuracy: 0.7805\n",
      "Epoch 41/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.8846 - categorical_accuracy: 0.6759Epoch 41: loss = 0.8819641470909119, val_loss = 1.1986124515533447\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.8820 - categorical_accuracy: 0.6763 - val_loss: 1.1986 - val_categorical_accuracy: 0.5694\n",
      "Epoch 42/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.2406 - categorical_accuracy: 0.5922Epoch 42: loss = 1.2407398223876953, val_loss = 0.9853652119636536\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 1.2407 - categorical_accuracy: 0.5918 - val_loss: 0.9854 - val_categorical_accuracy: 0.6593\n",
      "Epoch 43/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.8677 - categorical_accuracy: 0.6829Epoch 43: loss = 0.8666592240333557, val_loss = 0.8594957590103149\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 0.8667 - categorical_accuracy: 0.6832 - val_loss: 0.8595 - val_categorical_accuracy: 0.6928\n",
      "Epoch 44/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.7491 - categorical_accuracy: 0.7136Epoch 44: loss = 0.7490831017494202, val_loss = 0.8488744497299194\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.7491 - categorical_accuracy: 0.7136 - val_loss: 0.8489 - val_categorical_accuracy: 0.6989\n",
      "Epoch 45/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.6811 - categorical_accuracy: 0.7346Epoch 45: loss = 0.6841191649436951, val_loss = 0.6000475883483887\n",
      "83/83 [==============================] - 3s 41ms/step - loss: 0.6841 - categorical_accuracy: 0.7342 - val_loss: 0.6000 - val_categorical_accuracy: 0.7835\n",
      "Epoch 46/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.5825 - categorical_accuracy: 0.7677Epoch 46: loss = 0.5848326683044434, val_loss = 0.6800663471221924\n",
      "83/83 [==============================] - 4s 45ms/step - loss: 0.5848 - categorical_accuracy: 0.7639 - val_loss: 0.6801 - val_categorical_accuracy: 0.7973\n",
      "Epoch 47/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.6048 - categorical_accuracy: 0.7713Epoch 47: loss = 0.6043851971626282, val_loss = 0.5831552147865295\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.6044 - categorical_accuracy: 0.7715 - val_loss: 0.5832 - val_categorical_accuracy: 0.7942\n",
      "Epoch 48/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.6004 - categorical_accuracy: 0.7622Epoch 48: loss = 0.5999331474304199, val_loss = 0.6499273777008057\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.5999 - categorical_accuracy: 0.7624 - val_loss: 0.6499 - val_categorical_accuracy: 0.7752\n",
      "Epoch 49/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.6797 - categorical_accuracy: 0.7363Epoch 49: loss = 0.679141640663147, val_loss = 0.7394064664840698\n",
      "83/83 [==============================] - 3s 35ms/step - loss: 0.6791 - categorical_accuracy: 0.7365 - val_loss: 0.7394 - val_categorical_accuracy: 0.7165\n",
      "Epoch 50/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.5932 - categorical_accuracy: 0.7677Epoch 50: loss = 0.593248188495636, val_loss = 0.6170485615730286\n",
      "83/83 [==============================] - 3s 32ms/step - loss: 0.5932 - categorical_accuracy: 0.7677 - val_loss: 0.6170 - val_categorical_accuracy: 0.7866\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 0.6170 - categorical_accuracy: 0.7866\n",
      "Epoch 1/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 3.1612 - categorical_accuracy: 0.0755Epoch 1: loss = 3.16115665435791, val_loss = 3.000763177871704\n",
      "82/82 [==============================] - 9s 48ms/step - loss: 3.1612 - categorical_accuracy: 0.0755 - val_loss: 3.0008 - val_categorical_accuracy: 0.1074\n",
      "Epoch 2/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.8234 - categorical_accuracy: 0.1157Epoch 2: loss = 2.823697328567505, val_loss = 2.7317419052124023\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 2.8237 - categorical_accuracy: 0.1166 - val_loss: 2.7317 - val_categorical_accuracy: 0.1295\n",
      "Epoch 3/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.6096 - categorical_accuracy: 0.1319Epoch 3: loss = 2.613340139389038, val_loss = 2.618420124053955\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 2.6133 - categorical_accuracy: 0.1311 - val_loss: 2.6184 - val_categorical_accuracy: 0.0792\n",
      "Epoch 4/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.5555 - categorical_accuracy: 0.1197Epoch 4: loss = 2.555482864379883, val_loss = 2.8755195140838623\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 2.5555 - categorical_accuracy: 0.1197 - val_loss: 2.8755 - val_categorical_accuracy: 0.0716\n",
      "Epoch 5/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.5182 - categorical_accuracy: 0.1597Epoch 5: loss = 2.5176849365234375, val_loss = 2.362485408782959\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 2.5177 - categorical_accuracy: 0.1601 - val_loss: 2.3625 - val_categorical_accuracy: 0.1485\n",
      "Epoch 6/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 2.2611 - categorical_accuracy: 0.2156Epoch 6: loss = 2.2647037506103516, val_loss = 2.0551981925964355\n",
      "82/82 [==============================] - 3s 36ms/step - loss: 2.2647 - categorical_accuracy: 0.2157 - val_loss: 2.0552 - val_categorical_accuracy: 0.2650\n",
      "Epoch 7/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.9880 - categorical_accuracy: 0.2812Epoch 7: loss = 1.9880017042160034, val_loss = 1.787596344947815\n",
      "82/82 [==============================] - 2s 30ms/step - loss: 1.9880 - categorical_accuracy: 0.2812 - val_loss: 1.7876 - val_categorical_accuracy: 0.3420\n",
      "Epoch 8/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.9020 - categorical_accuracy: 0.3218Epoch 8: loss = 1.9033461809158325, val_loss = 2.008955717086792\n",
      "82/82 [==============================] - 4s 44ms/step - loss: 1.9033 - categorical_accuracy: 0.3216 - val_loss: 2.0090 - val_categorical_accuracy: 0.2757\n",
      "Epoch 9/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.8006 - categorical_accuracy: 0.3326Epoch 9: loss = 1.8025765419006348, val_loss = 1.5081101655960083\n",
      "82/82 [==============================] - 3s 36ms/step - loss: 1.8026 - categorical_accuracy: 0.3308 - val_loss: 1.5081 - val_categorical_accuracy: 0.4570\n",
      "Epoch 10/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.2566 - categorical_accuracy: 0.2523Epoch 10: loss = 2.25658917427063, val_loss = 2.3897383213043213\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 2.2566 - categorical_accuracy: 0.2523 - val_loss: 2.3897 - val_categorical_accuracy: 0.1523\n",
      "Epoch 11/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.4280 - categorical_accuracy: 0.2083Epoch 11: loss = 2.4271280765533447, val_loss = 2.452362298965454\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 2.4271 - categorical_accuracy: 0.2096 - val_loss: 2.4524 - val_categorical_accuracy: 0.2094\n",
      "Epoch 12/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 2.4206 - categorical_accuracy: 0.1953Epoch 12: loss = 2.4172680377960205, val_loss = 2.305861473083496\n",
      "82/82 [==============================] - 3s 36ms/step - loss: 2.4173 - categorical_accuracy: 0.1982 - val_loss: 2.3059 - val_categorical_accuracy: 0.2308\n",
      "Epoch 13/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.2274 - categorical_accuracy: 0.2462Epoch 13: loss = 2.2273948192596436, val_loss = 2.173344135284424\n",
      "82/82 [==============================] - 3s 31ms/step - loss: 2.2274 - categorical_accuracy: 0.2462 - val_loss: 2.1733 - val_categorical_accuracy: 0.2635\n",
      "Epoch 14/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 2.2100 - categorical_accuracy: 0.2406Epoch 14: loss = 2.2040085792541504, val_loss = 2.136833906173706\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 2.2040 - categorical_accuracy: 0.2424 - val_loss: 2.1368 - val_categorical_accuracy: 0.2567\n",
      "Epoch 15/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.1239 - categorical_accuracy: 0.2677Epoch 15: loss = 2.1274192333221436, val_loss = 2.106092691421509\n",
      "82/82 [==============================] - 3s 31ms/step - loss: 2.1274 - categorical_accuracy: 0.2668 - val_loss: 2.1061 - val_categorical_accuracy: 0.2315\n",
      "Epoch 16/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.1231 - categorical_accuracy: 0.2713Epoch 16: loss = 2.1230528354644775, val_loss = 2.045180559158325\n",
      "82/82 [==============================] - 3s 41ms/step - loss: 2.1231 - categorical_accuracy: 0.2713 - val_loss: 2.0452 - val_categorical_accuracy: 0.2970\n",
      "Epoch 17/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.0330 - categorical_accuracy: 0.2843Epoch 17: loss = 2.032978057861328, val_loss = 1.9393625259399414\n",
      "82/82 [==============================] - 3s 39ms/step - loss: 2.0330 - categorical_accuracy: 0.2843 - val_loss: 1.9394 - val_categorical_accuracy: 0.3046\n",
      "Epoch 18/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.9543 - categorical_accuracy: 0.3187Epoch 18: loss = 1.9562945365905762, val_loss = 1.943644404411316\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 1.9563 - categorical_accuracy: 0.3186 - val_loss: 1.9436 - val_categorical_accuracy: 0.3153\n",
      "Epoch 19/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.9433 - categorical_accuracy: 0.3148Restoring model weights from the end of the best epoch: 9.\n",
      "Epoch 19: loss = 1.9433387517929077, val_loss = 1.79622220993042\n",
      "82/82 [==============================] - 3s 38ms/step - loss: 1.9433 - categorical_accuracy: 0.3148 - val_loss: 1.7962 - val_categorical_accuracy: 0.3260\n",
      "Epoch 19: early stopping\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 1.5081 - categorical_accuracy: 0.4570\n",
      "Epoch 1/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 3.1832 - categorical_accuracy: 0.0655Epoch 1: loss = 3.1832199096679688, val_loss = 3.0352532863616943\n",
      "83/83 [==============================] - 9s 42ms/step - loss: 3.1832 - categorical_accuracy: 0.0655 - val_loss: 3.0353 - val_categorical_accuracy: 0.0816\n",
      "Epoch 2/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.9121 - categorical_accuracy: 0.0972Epoch 2: loss = 2.9094600677490234, val_loss = 2.762366533279419\n",
      "83/83 [==============================] - 3s 35ms/step - loss: 2.9095 - categorical_accuracy: 0.0982 - val_loss: 2.7624 - val_categorical_accuracy: 0.0648\n",
      "Epoch 3/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.7006 - categorical_accuracy: 0.1281Epoch 3: loss = 2.7000041007995605, val_loss = 2.6702816486358643\n",
      "83/83 [==============================] - 3s 36ms/step - loss: 2.7000 - categorical_accuracy: 0.1287 - val_loss: 2.6703 - val_categorical_accuracy: 0.1730\n",
      "Epoch 4/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.5153 - categorical_accuracy: 0.1516Epoch 4: loss = 2.515260696411133, val_loss = 2.437635898590088\n",
      "83/83 [==============================] - 3s 34ms/step - loss: 2.5153 - categorical_accuracy: 0.1516 - val_loss: 2.4376 - val_categorical_accuracy: 0.1479\n",
      "Epoch 5/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.4225 - categorical_accuracy: 0.1813Epoch 5: loss = 2.4224905967712402, val_loss = 2.322673797607422\n",
      "83/83 [==============================] - 3s 35ms/step - loss: 2.4225 - categorical_accuracy: 0.1813 - val_loss: 2.3227 - val_categorical_accuracy: 0.2409\n",
      "Epoch 6/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.3032 - categorical_accuracy: 0.2064Epoch 6: loss = 2.303178310394287, val_loss = 2.113797903060913\n",
      "83/83 [==============================] - 3s 41ms/step - loss: 2.3032 - categorical_accuracy: 0.2064 - val_loss: 2.1138 - val_categorical_accuracy: 0.2614\n",
      "Epoch 7/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 29.5140 - categorical_accuracy: 0.1166Epoch 7: loss = 29.517478942871094, val_loss = 6.893057346343994\n",
      "83/83 [==============================] - 3s 35ms/step - loss: 29.5175 - categorical_accuracy: 0.1165 - val_loss: 6.8931 - val_categorical_accuracy: 0.0221\n",
      "Epoch 8/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 5.9833 - categorical_accuracy: 0.0595Epoch 8: loss = 5.980687618255615, val_loss = 2.9988696575164795\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 5.9807 - categorical_accuracy: 0.0594 - val_loss: 2.9989 - val_categorical_accuracy: 0.0953\n",
      "Epoch 9/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.8855 - categorical_accuracy: 0.0777Epoch 9: loss = 2.885100841522217, val_loss = 2.679514169692993\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 2.8851 - categorical_accuracy: 0.0777 - val_loss: 2.6795 - val_categorical_accuracy: 0.1075\n",
      "Epoch 10/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.7375 - categorical_accuracy: 0.0998Epoch 10: loss = 2.7370429039001465, val_loss = 2.5839555263519287\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 2.7370 - categorical_accuracy: 0.0998 - val_loss: 2.5840 - val_categorical_accuracy: 0.1204\n",
      "Epoch 11/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.5806 - categorical_accuracy: 0.1197Epoch 11: loss = 2.5804569721221924, val_loss = 2.4818153381347656\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 2.5805 - categorical_accuracy: 0.1196 - val_loss: 2.4818 - val_categorical_accuracy: 0.1791\n",
      "Epoch 12/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.5968 - categorical_accuracy: 0.1387Epoch 12: loss = 2.5967705249786377, val_loss = 2.48593807220459\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 2.5968 - categorical_accuracy: 0.1386 - val_loss: 2.4859 - val_categorical_accuracy: 0.1570\n",
      "Epoch 13/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.5079 - categorical_accuracy: 0.1397Epoch 13: loss = 2.5090343952178955, val_loss = 2.326413154602051\n",
      "83/83 [==============================] - 3s 41ms/step - loss: 2.5090 - categorical_accuracy: 0.1386 - val_loss: 2.3264 - val_categorical_accuracy: 0.1867\n",
      "Epoch 14/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.4417 - categorical_accuracy: 0.1433Epoch 14: loss = 2.442251443862915, val_loss = 2.2570278644561768\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 2.4423 - categorical_accuracy: 0.1432 - val_loss: 2.2570 - val_categorical_accuracy: 0.1814\n",
      "Epoch 15/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.3303 - categorical_accuracy: 0.1753Epoch 15: loss = 2.331118583679199, val_loss = 2.115630626678467\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 2.3311 - categorical_accuracy: 0.1752 - val_loss: 2.1156 - val_categorical_accuracy: 0.2828\n",
      "Epoch 16/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.2851 - categorical_accuracy: 0.1919Epoch 16: loss = 2.285054922103882, val_loss = 2.072551965713501\n",
      "83/83 [==============================] - 3s 36ms/step - loss: 2.2851 - categorical_accuracy: 0.1919 - val_loss: 2.0726 - val_categorical_accuracy: 0.2721\n",
      "Epoch 17/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.2065 - categorical_accuracy: 0.2114Epoch 17: loss = 2.1990325450897217, val_loss = 2.065781831741333\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 2.1990 - categorical_accuracy: 0.2140 - val_loss: 2.0658 - val_categorical_accuracy: 0.2713\n",
      "Epoch 18/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.1581 - categorical_accuracy: 0.2207Epoch 18: loss = 2.161949396133423, val_loss = 4.478812217712402\n",
      "83/83 [==============================] - 3s 36ms/step - loss: 2.1619 - categorical_accuracy: 0.2186 - val_loss: 4.4788 - val_categorical_accuracy: 0.2995\n",
      "Epoch 19/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.2234 - categorical_accuracy: 0.2238Epoch 19: loss = 2.2230536937713623, val_loss = 5.146224021911621\n",
      "83/83 [==============================] - 3s 35ms/step - loss: 2.2231 - categorical_accuracy: 0.2254 - val_loss: 5.1462 - val_categorical_accuracy: 0.2812\n",
      "Epoch 20/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 3.0572 - categorical_accuracy: 0.1775Epoch 20: loss = 3.054152488708496, val_loss = 2.5961053371429443\n",
      "83/83 [==============================] - 3s 35ms/step - loss: 3.0542 - categorical_accuracy: 0.1752 - val_loss: 2.5961 - val_categorical_accuracy: 0.1860\n",
      "Epoch 21/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.4855 - categorical_accuracy: 0.1867Epoch 21: loss = 2.4848949909210205, val_loss = 2.2653684616088867\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 2.4849 - categorical_accuracy: 0.1858 - val_loss: 2.2654 - val_categorical_accuracy: 0.2134\n",
      "Epoch 22/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.3345 - categorical_accuracy: 0.2106Epoch 22: loss = 2.3358802795410156, val_loss = 2.298011064529419\n",
      "83/83 [==============================] - 3s 35ms/step - loss: 2.3359 - categorical_accuracy: 0.2094 - val_loss: 2.2980 - val_categorical_accuracy: 0.3003\n",
      "Epoch 23/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.3475 - categorical_accuracy: 0.1960Epoch 23: loss = 2.348615884780884, val_loss = 2.2769553661346436\n",
      "83/83 [==============================] - 3s 35ms/step - loss: 2.3486 - categorical_accuracy: 0.1950 - val_loss: 2.2770 - val_categorical_accuracy: 0.2630\n",
      "Epoch 24/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.5994 - categorical_accuracy: 0.1936Epoch 24: loss = 2.599454879760742, val_loss = 3.1694090366363525\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 2.5995 - categorical_accuracy: 0.1935 - val_loss: 3.1694 - val_categorical_accuracy: 0.2066\n",
      "Epoch 25/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.7735 - categorical_accuracy: 0.2087Epoch 25: loss = 2.773465871810913, val_loss = 2.053872585296631\n",
      "83/83 [==============================] - 3s 34ms/step - loss: 2.7735 - categorical_accuracy: 0.2087 - val_loss: 2.0539 - val_categorical_accuracy: 0.2492\n",
      "Epoch 26/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.1872 - categorical_accuracy: 0.2232Epoch 26: loss = 2.1871559619903564, val_loss = 1.951345682144165\n",
      "83/83 [==============================] - 3s 41ms/step - loss: 2.1872 - categorical_accuracy: 0.2232 - val_loss: 1.9513 - val_categorical_accuracy: 0.2584\n",
      "Epoch 27/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.2703 - categorical_accuracy: 0.2338Epoch 27: loss = 2.3026282787323, val_loss = 3.7652409076690674\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 2.3026 - categorical_accuracy: 0.2315 - val_loss: 3.7652 - val_categorical_accuracy: 0.1319\n",
      "Epoch 28/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 3.1055 - categorical_accuracy: 0.1037Epoch 28: loss = 3.1046621799468994, val_loss = 2.4368982315063477\n",
      "83/83 [==============================] - 3s 36ms/step - loss: 3.1047 - categorical_accuracy: 0.1036 - val_loss: 2.4369 - val_categorical_accuracy: 0.1463\n",
      "Epoch 29/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.6373 - categorical_accuracy: 0.1860Epoch 29: loss = 2.6371026039123535, val_loss = 2.7451298236846924\n",
      "83/83 [==============================] - 3s 42ms/step - loss: 2.6371 - categorical_accuracy: 0.1858 - val_loss: 2.7451 - val_categorical_accuracy: 0.1288\n",
      "Epoch 30/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.4403 - categorical_accuracy: 0.1883Epoch 30: loss = 2.4426095485687256, val_loss = 2.5533335208892822\n",
      "83/83 [==============================] - 3s 34ms/step - loss: 2.4426 - categorical_accuracy: 0.1881 - val_loss: 2.5533 - val_categorical_accuracy: 0.2066\n",
      "Epoch 31/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.4541 - categorical_accuracy: 0.1822Epoch 31: loss = 2.453747272491455, val_loss = 2.126157283782959\n",
      "83/83 [==============================] - 3s 36ms/step - loss: 2.4537 - categorical_accuracy: 0.1820 - val_loss: 2.1262 - val_categorical_accuracy: 0.2279\n",
      "Epoch 32/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.1710 - categorical_accuracy: 0.2308Epoch 32: loss = 2.1709611415863037, val_loss = 2.0743355751037598\n",
      "83/83 [==============================] - 3s 36ms/step - loss: 2.1710 - categorical_accuracy: 0.2308 - val_loss: 2.0743 - val_categorical_accuracy: 0.2744\n",
      "Epoch 33/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.1026 - categorical_accuracy: 0.2460Epoch 33: loss = 2.1026079654693604, val_loss = 1.959090232849121\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 2.1026 - categorical_accuracy: 0.2460 - val_loss: 1.9591 - val_categorical_accuracy: 0.3277\n",
      "Epoch 34/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.2284 - categorical_accuracy: 0.2752Epoch 34: loss = 2.22818660736084, val_loss = 1.9667344093322754\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 2.2282 - categorical_accuracy: 0.2749 - val_loss: 1.9667 - val_categorical_accuracy: 0.3026\n",
      "Epoch 35/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.1156 - categorical_accuracy: 0.2909Epoch 35: loss = 2.113917827606201, val_loss = 2.0611186027526855\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 2.1139 - categorical_accuracy: 0.2917 - val_loss: 2.0611 - val_categorical_accuracy: 0.2797\n",
      "Epoch 36/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.5305 - categorical_accuracy: 0.2142Restoring model weights from the end of the best epoch: 26.\n",
      "Epoch 36: loss = 2.530048370361328, val_loss = 2.3539257049560547\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 2.5300 - categorical_accuracy: 0.2140 - val_loss: 2.3539 - val_categorical_accuracy: 0.2058\n",
      "Epoch 36: early stopping\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 1.9513 - categorical_accuracy: 0.2584\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 3.1222 - categorical_accuracy: 0.0564Epoch 1: loss = 3.1221776008605957, val_loss = 3.0281877517700195\n",
      "41/41 [==============================] - 6s 62ms/step - loss: 3.1222 - categorical_accuracy: 0.0564 - val_loss: 3.0282 - val_categorical_accuracy: 0.0883\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.7707 - categorical_accuracy: 0.1159Epoch 2: loss = 2.7706711292266846, val_loss = 2.6769042015075684\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 2.7707 - categorical_accuracy: 0.1159 - val_loss: 2.6769 - val_categorical_accuracy: 0.1005\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.5708 - categorical_accuracy: 0.1654Epoch 3: loss = 2.570775270462036, val_loss = 2.370330572128296\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 2.5708 - categorical_accuracy: 0.1654 - val_loss: 2.3703 - val_categorical_accuracy: 0.1980\n",
      "Epoch 4/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.2526 - categorical_accuracy: 0.2180Epoch 4: loss = 2.2405946254730225, val_loss = 1.8283452987670898\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 2.2406 - categorical_accuracy: 0.2203 - val_loss: 1.8283 - val_categorical_accuracy: 0.3473\n",
      "Epoch 5/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.9506 - categorical_accuracy: 0.3086Epoch 5: loss = 1.9512416124343872, val_loss = 1.7985897064208984\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 1.9512 - categorical_accuracy: 0.3095 - val_loss: 1.7986 - val_categorical_accuracy: 0.3191\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.7657 - categorical_accuracy: 0.3780Epoch 6: loss = 1.7656840085983276, val_loss = 1.5866214036941528\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 1.7657 - categorical_accuracy: 0.3780 - val_loss: 1.5866 - val_categorical_accuracy: 0.4379\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.7142 - categorical_accuracy: 0.3933Epoch 7: loss = 1.7142353057861328, val_loss = 1.5636651515960693\n",
      "41/41 [==============================] - 2s 49ms/step - loss: 1.7142 - categorical_accuracy: 0.3933 - val_loss: 1.5637 - val_categorical_accuracy: 0.4280\n",
      "Epoch 8/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.5195 - categorical_accuracy: 0.4383Epoch 8: loss = 1.5175117254257202, val_loss = 1.496902585029602\n",
      "41/41 [==============================] - 2s 49ms/step - loss: 1.5175 - categorical_accuracy: 0.4405 - val_loss: 1.4969 - val_categorical_accuracy: 0.4364\n",
      "Epoch 9/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.3988 - categorical_accuracy: 0.4960Epoch 9: loss = 1.3949849605560303, val_loss = 1.270824670791626\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 1.3950 - categorical_accuracy: 0.5000 - val_loss: 1.2708 - val_categorical_accuracy: 0.5834\n",
      "Epoch 10/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.3112 - categorical_accuracy: 0.5273Epoch 10: loss = 1.313103199005127, val_loss = 1.220306396484375\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 1.3131 - categorical_accuracy: 0.5259 - val_loss: 1.2203 - val_categorical_accuracy: 0.5659\n",
      "Epoch 11/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.2288 - categorical_accuracy: 0.5489Epoch 11: loss = 1.2243924140930176, val_loss = 1.10686194896698\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 1.2244 - categorical_accuracy: 0.5526 - val_loss: 1.1069 - val_categorical_accuracy: 0.6245\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1754 - categorical_accuracy: 0.5518Epoch 12: loss = 1.1754138469696045, val_loss = 1.0728428363800049\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 1.1754 - categorical_accuracy: 0.5518 - val_loss: 1.0728 - val_categorical_accuracy: 0.5986\n",
      "Epoch 13/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.0850 - categorical_accuracy: 0.6047Epoch 13: loss = 1.1034237146377563, val_loss = 1.162471055984497\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 1.1034 - categorical_accuracy: 0.5998 - val_loss: 1.1625 - val_categorical_accuracy: 0.5910\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.9597 - categorical_accuracy: 0.6418Epoch 14: loss = 0.9596515893936157, val_loss = 1.0041953325271606\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 0.9597 - categorical_accuracy: 0.6418 - val_loss: 1.0042 - val_categorical_accuracy: 0.6816\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0096 - categorical_accuracy: 0.6372Epoch 15: loss = 1.0096369981765747, val_loss = 1.0819156169891357\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 1.0096 - categorical_accuracy: 0.6372 - val_loss: 1.0819 - val_categorical_accuracy: 0.5933\n",
      "Epoch 16/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.9643 - categorical_accuracy: 0.6352Epoch 16: loss = 0.9646563529968262, val_loss = 1.0107403993606567\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.9647 - categorical_accuracy: 0.6341 - val_loss: 1.0107 - val_categorical_accuracy: 0.6740\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.9440 - categorical_accuracy: 0.6677Epoch 17: loss = 0.9440147876739502, val_loss = 0.9161179661750793\n",
      "41/41 [==============================] - 2s 43ms/step - loss: 0.9440 - categorical_accuracy: 0.6677 - val_loss: 0.9161 - val_categorical_accuracy: 0.6778\n",
      "Epoch 18/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.9007 - categorical_accuracy: 0.6820Epoch 18: loss = 0.8963202238082886, val_loss = 1.0583711862564087\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 0.8963 - categorical_accuracy: 0.6829 - val_loss: 1.0584 - val_categorical_accuracy: 0.6969\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.8487 - categorical_accuracy: 0.6829Epoch 19: loss = 0.8487012982368469, val_loss = 0.8087877631187439\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 0.8487 - categorical_accuracy: 0.6829 - val_loss: 0.8088 - val_categorical_accuracy: 0.7388\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.7132 - categorical_accuracy: 0.7256Epoch 20: loss = 0.7131640911102295, val_loss = 0.8588523864746094\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 0.7132 - categorical_accuracy: 0.7256 - val_loss: 0.8589 - val_categorical_accuracy: 0.6893\n",
      "Epoch 21/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.7585 - categorical_accuracy: 0.7141Epoch 21: loss = 0.7538000345230103, val_loss = 0.8041849136352539\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.7538 - categorical_accuracy: 0.7149 - val_loss: 0.8042 - val_categorical_accuracy: 0.7266\n",
      "Epoch 22/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.7763 - categorical_accuracy: 0.7258Epoch 22: loss = 0.7741868495941162, val_loss = 0.933278501033783\n",
      "41/41 [==============================] - 2s 43ms/step - loss: 0.7742 - categorical_accuracy: 0.7271 - val_loss: 0.9333 - val_categorical_accuracy: 0.6695\n",
      "Epoch 23/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.6916 - categorical_accuracy: 0.7388Epoch 23: loss = 0.691851794719696, val_loss = 0.7419850826263428\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.6919 - categorical_accuracy: 0.7409 - val_loss: 0.7420 - val_categorical_accuracy: 0.7647\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6511 - categorical_accuracy: 0.7591Epoch 24: loss = 0.6511430740356445, val_loss = 0.7758309245109558\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 0.6511 - categorical_accuracy: 0.7591 - val_loss: 0.7758 - val_categorical_accuracy: 0.7464\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6677 - categorical_accuracy: 0.7409Epoch 25: loss = 0.667652428150177, val_loss = 0.822800874710083\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.6677 - categorical_accuracy: 0.7409 - val_loss: 0.8228 - val_categorical_accuracy: 0.7136\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.7117 - categorical_accuracy: 0.7439Epoch 26: loss = 0.7117236852645874, val_loss = 0.8259149193763733\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 0.7117 - categorical_accuracy: 0.7439 - val_loss: 0.8259 - val_categorical_accuracy: 0.7113\n",
      "Epoch 27/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.7366 - categorical_accuracy: 0.7234Epoch 27: loss = 0.7318770885467529, val_loss = 0.7380788326263428\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.7319 - categorical_accuracy: 0.7248 - val_loss: 0.7381 - val_categorical_accuracy: 0.7609\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6078 - categorical_accuracy: 0.7774Epoch 28: loss = 0.6077572703361511, val_loss = 0.6446242928504944\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.6078 - categorical_accuracy: 0.7774 - val_loss: 0.6446 - val_categorical_accuracy: 0.7982\n",
      "Epoch 29/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.5406 - categorical_accuracy: 0.7869Epoch 29: loss = 0.5386221408843994, val_loss = 0.7349817752838135\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.5386 - categorical_accuracy: 0.7866 - val_loss: 0.7350 - val_categorical_accuracy: 0.7639\n",
      "Epoch 30/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.5481 - categorical_accuracy: 0.8000Epoch 30: loss = 0.5418426394462585, val_loss = 0.6023504137992859\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 0.5418 - categorical_accuracy: 0.8026 - val_loss: 0.6024 - val_categorical_accuracy: 0.8020\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.5665 - categorical_accuracy: 0.7919Epoch 31: loss = 0.5664600133895874, val_loss = 0.7326040267944336\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.5665 - categorical_accuracy: 0.7919 - val_loss: 0.7326 - val_categorical_accuracy: 0.7647\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6267 - categorical_accuracy: 0.7569Epoch 32: loss = 0.6266577839851379, val_loss = 0.6523796319961548\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.6267 - categorical_accuracy: 0.7569 - val_loss: 0.6524 - val_categorical_accuracy: 0.8020\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6468 - categorical_accuracy: 0.7538Epoch 33: loss = 0.6467759013175964, val_loss = 0.6607221364974976\n",
      "41/41 [==============================] - 2s 43ms/step - loss: 0.6468 - categorical_accuracy: 0.7538 - val_loss: 0.6607 - val_categorical_accuracy: 0.7768\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.5638 - categorical_accuracy: 0.7904Epoch 34: loss = 0.5637683272361755, val_loss = 0.6878488063812256\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 0.5638 - categorical_accuracy: 0.7904 - val_loss: 0.6878 - val_categorical_accuracy: 0.7609\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.5154 - categorical_accuracy: 0.7912Epoch 35: loss = 0.5154314041137695, val_loss = 0.5650611519813538\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.5154 - categorical_accuracy: 0.7912 - val_loss: 0.5651 - val_categorical_accuracy: 0.7974\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4909 - categorical_accuracy: 0.8186Epoch 36: loss = 0.49092432856559753, val_loss = 0.6245526075363159\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.4909 - categorical_accuracy: 0.8186 - val_loss: 0.6246 - val_categorical_accuracy: 0.7784\n",
      "Epoch 37/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.4560 - categorical_accuracy: 0.8281Epoch 37: loss = 0.4595544934272766, val_loss = 0.6758655309677124\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.4596 - categorical_accuracy: 0.8262 - val_loss: 0.6759 - val_categorical_accuracy: 0.7746\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6367 - categorical_accuracy: 0.7630Epoch 38: loss = 0.6367110013961792, val_loss = 0.6448730230331421\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 0.6367 - categorical_accuracy: 0.7630 - val_loss: 0.6449 - val_categorical_accuracy: 0.7624\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4461 - categorical_accuracy: 0.8331Epoch 39: loss = 0.4461146593093872, val_loss = 0.5774167776107788\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.4461 - categorical_accuracy: 0.8331 - val_loss: 0.5774 - val_categorical_accuracy: 0.8294\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.7111 - categorical_accuracy: 0.7576Epoch 40: loss = 0.7111332416534424, val_loss = 0.920453667640686\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.7111 - categorical_accuracy: 0.7576 - val_loss: 0.9205 - val_categorical_accuracy: 0.7030\n",
      "Epoch 41/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.6913 - categorical_accuracy: 0.7484Epoch 41: loss = 0.6904872059822083, val_loss = 0.6253551244735718\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 0.6905 - categorical_accuracy: 0.7477 - val_loss: 0.6254 - val_categorical_accuracy: 0.7829\n",
      "Epoch 42/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.7764 - categorical_accuracy: 0.7227Epoch 42: loss = 0.7720310091972351, val_loss = 0.6841769814491272\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 0.7720 - categorical_accuracy: 0.7241 - val_loss: 0.6842 - val_categorical_accuracy: 0.7647\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.5610 - categorical_accuracy: 0.8018Epoch 43: loss = 0.5609924793243408, val_loss = 0.5973207354545593\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.5610 - categorical_accuracy: 0.8018 - val_loss: 0.5973 - val_categorical_accuracy: 0.8050\n",
      "Epoch 44/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.5033 - categorical_accuracy: 0.8180Epoch 44: loss = 0.5016238689422607, val_loss = 0.87193363904953\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 0.5016 - categorical_accuracy: 0.8178 - val_loss: 0.8719 - val_categorical_accuracy: 0.6839\n",
      "Epoch 45/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.5918 - categorical_accuracy: 0.7750Restoring model weights from the end of the best epoch: 35.\n",
      "Epoch 45: loss = 0.5843066573143005, val_loss = 0.717455267906189\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.5843 - categorical_accuracy: 0.7767 - val_loss: 0.7175 - val_categorical_accuracy: 0.7951\n",
      "Epoch 45: early stopping\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.5651 - categorical_accuracy: 0.7974\n",
      "Epoch 1/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 3.1866 - categorical_accuracy: 0.0785Epoch 1: loss = 3.186614513397217, val_loss = 3.023432493209839\n",
      "42/42 [==============================] - 6s 58ms/step - loss: 3.1866 - categorical_accuracy: 0.0784 - val_loss: 3.0234 - val_categorical_accuracy: 0.1860\n",
      "Epoch 2/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.9138 - categorical_accuracy: 0.1448Epoch 2: loss = 2.9140188694000244, val_loss = 2.6772983074188232\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.9140 - categorical_accuracy: 0.1447 - val_loss: 2.6773 - val_categorical_accuracy: 0.1486\n",
      "Epoch 3/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.6635 - categorical_accuracy: 0.1471Epoch 3: loss = 2.663677930831909, val_loss = 2.6251893043518066\n",
      "42/42 [==============================] - 2s 54ms/step - loss: 2.6637 - categorical_accuracy: 0.1470 - val_loss: 2.6252 - val_categorical_accuracy: 0.1319\n",
      "Epoch 4/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.4312 - categorical_accuracy: 0.1977Epoch 4: loss = 2.431607246398926, val_loss = 2.3907837867736816\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.4316 - categorical_accuracy: 0.2003 - val_loss: 2.3908 - val_categorical_accuracy: 0.1845\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.1567 - categorical_accuracy: 0.2688Epoch 5: loss = 2.156724452972412, val_loss = 2.102363109588623\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.1567 - categorical_accuracy: 0.2688 - val_loss: 2.1024 - val_categorical_accuracy: 0.2614\n",
      "Epoch 6/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.0823 - categorical_accuracy: 0.2691Epoch 6: loss = 2.0809640884399414, val_loss = 1.7896997928619385\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 2.0810 - categorical_accuracy: 0.2696 - val_loss: 1.7897 - val_categorical_accuracy: 0.3072\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.8302 - categorical_accuracy: 0.3138Epoch 7: loss = 1.8301746845245361, val_loss = 1.7776576280593872\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 1.8302 - categorical_accuracy: 0.3138 - val_loss: 1.7777 - val_categorical_accuracy: 0.3079\n",
      "Epoch 8/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.7696 - categorical_accuracy: 0.3422Epoch 8: loss = 1.7699555158615112, val_loss = 1.6843827962875366\n",
      "42/42 [==============================] - 2s 52ms/step - loss: 1.7700 - categorical_accuracy: 0.3420 - val_loss: 1.6844 - val_categorical_accuracy: 0.3727\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.7054 - categorical_accuracy: 0.3633Epoch 9: loss = 1.7054471969604492, val_loss = 1.6733900308609009\n",
      "42/42 [==============================] - 2s 54ms/step - loss: 1.7054 - categorical_accuracy: 0.3633 - val_loss: 1.6734 - val_categorical_accuracy: 0.3636\n",
      "Epoch 10/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.6782 - categorical_accuracy: 0.3880Epoch 10: loss = 1.6787053346633911, val_loss = 1.7768216133117676\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 1.6787 - categorical_accuracy: 0.3877 - val_loss: 1.7768 - val_categorical_accuracy: 0.3453\n",
      "Epoch 11/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.6938 - categorical_accuracy: 0.3695Epoch 11: loss = 1.6891751289367676, val_loss = 1.5352561473846436\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 1.6892 - categorical_accuracy: 0.3694 - val_loss: 1.5353 - val_categorical_accuracy: 0.3902\n",
      "Epoch 12/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.6095 - categorical_accuracy: 0.3887Epoch 12: loss = 1.6082748174667358, val_loss = 1.3773777484893799\n",
      "42/42 [==============================] - 2s 55ms/step - loss: 1.6083 - categorical_accuracy: 0.3892 - val_loss: 1.3774 - val_categorical_accuracy: 0.4581\n",
      "Epoch 13/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.4617 - categorical_accuracy: 0.4314Epoch 13: loss = 1.4606339931488037, val_loss = 1.709820032119751\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 1.4606 - categorical_accuracy: 0.4318 - val_loss: 1.7098 - val_categorical_accuracy: 0.4017\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5879 - categorical_accuracy: 0.4189Epoch 14: loss = 1.5879437923431396, val_loss = 1.4302644729614258\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 1.5879 - categorical_accuracy: 0.4189 - val_loss: 1.4303 - val_categorical_accuracy: 0.4009\n",
      "Epoch 15/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.4858 - categorical_accuracy: 0.4398Epoch 15: loss = 1.484654188156128, val_loss = 1.1974976062774658\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 1.4847 - categorical_accuracy: 0.4402 - val_loss: 1.1975 - val_categorical_accuracy: 0.5373\n",
      "Epoch 16/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.4817 - categorical_accuracy: 0.4461Epoch 16: loss = 1.4812548160552979, val_loss = 1.5733203887939453\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.4813 - categorical_accuracy: 0.4448 - val_loss: 1.5733 - val_categorical_accuracy: 0.4070\n",
      "Epoch 17/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.3673 - categorical_accuracy: 0.4787Epoch 17: loss = 1.3677183389663696, val_loss = 1.4262057542800903\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.3677 - categorical_accuracy: 0.4783 - val_loss: 1.4262 - val_categorical_accuracy: 0.4489\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5473 - categorical_accuracy: 0.4273Epoch 18: loss = 1.5473170280456543, val_loss = 1.2263410091400146\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 1.5473 - categorical_accuracy: 0.4273 - val_loss: 1.2263 - val_categorical_accuracy: 0.5236\n",
      "Epoch 19/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.2848 - categorical_accuracy: 0.5016Epoch 19: loss = 1.2783268690109253, val_loss = 1.4028421640396118\n",
      "42/42 [==============================] - 2s 52ms/step - loss: 1.2783 - categorical_accuracy: 0.5050 - val_loss: 1.4028 - val_categorical_accuracy: 0.4970\n",
      "Epoch 20/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.2595 - categorical_accuracy: 0.5114Epoch 20: loss = 1.259263515472412, val_loss = 1.1664565801620483\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.2593 - categorical_accuracy: 0.5110 - val_loss: 1.1665 - val_categorical_accuracy: 0.5427\n",
      "Epoch 21/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.1934 - categorical_accuracy: 0.5495Epoch 21: loss = 1.193529725074768, val_loss = 1.1647905111312866\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.1935 - categorical_accuracy: 0.5491 - val_loss: 1.1648 - val_categorical_accuracy: 0.5191\n",
      "Epoch 22/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.2118 - categorical_accuracy: 0.5328Epoch 22: loss = 1.2052719593048096, val_loss = 1.1880651712417603\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.2053 - categorical_accuracy: 0.5354 - val_loss: 1.1881 - val_categorical_accuracy: 0.5358\n",
      "Epoch 23/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.3394 - categorical_accuracy: 0.5198Epoch 23: loss = 1.3388570547103882, val_loss = 1.1713470220565796\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.3389 - categorical_accuracy: 0.5202 - val_loss: 1.1713 - val_categorical_accuracy: 0.5976\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1630 - categorical_accuracy: 0.5796Epoch 24: loss = 1.1629971265792847, val_loss = 1.1491259336471558\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 1.1630 - categorical_accuracy: 0.5796 - val_loss: 1.1491 - val_categorical_accuracy: 0.5747\n",
      "Epoch 25/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.0513 - categorical_accuracy: 0.5915Epoch 25: loss = 1.053080677986145, val_loss = 0.9280503392219543\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 1.0531 - categorical_accuracy: 0.5910 - val_loss: 0.9281 - val_categorical_accuracy: 0.6562\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0362 - categorical_accuracy: 0.6009Epoch 26: loss = 1.0362086296081543, val_loss = 0.912621021270752\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.0362 - categorical_accuracy: 0.6009 - val_loss: 0.9126 - val_categorical_accuracy: 0.6883\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.9612 - categorical_accuracy: 0.6200Epoch 27: loss = 0.961161732673645, val_loss = 2.8559274673461914\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 0.9612 - categorical_accuracy: 0.6200 - val_loss: 2.8559 - val_categorical_accuracy: 0.4085\n",
      "Epoch 28/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.9769 - categorical_accuracy: 0.3575Epoch 28: loss = 1.9755035638809204, val_loss = 1.2056397199630737\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 1.9755 - categorical_accuracy: 0.3580 - val_loss: 1.2056 - val_categorical_accuracy: 0.5655\n",
      "Epoch 29/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.1428 - categorical_accuracy: 0.5610Epoch 29: loss = 1.1419570446014404, val_loss = 1.1711512804031372\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.1420 - categorical_accuracy: 0.5613 - val_loss: 1.1712 - val_categorical_accuracy: 0.5846\n",
      "Epoch 30/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.9894 - categorical_accuracy: 0.6029Epoch 30: loss = 0.9891617894172668, val_loss = 1.3469985723495483\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.9892 - categorical_accuracy: 0.6032 - val_loss: 1.3470 - val_categorical_accuracy: 0.5389\n",
      "Epoch 31/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.1002 - categorical_accuracy: 0.5655Epoch 31: loss = 1.1004277467727661, val_loss = 1.14255690574646\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 1.1004 - categorical_accuracy: 0.5651 - val_loss: 1.1426 - val_categorical_accuracy: 0.5518\n",
      "Epoch 32/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.0605 - categorical_accuracy: 0.5930Epoch 32: loss = 1.0597366094589233, val_loss = 0.9247149229049683\n",
      "42/42 [==============================] - 2s 53ms/step - loss: 1.0597 - categorical_accuracy: 0.5933 - val_loss: 0.9247 - val_categorical_accuracy: 0.6441\n",
      "Epoch 33/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.0388 - categorical_accuracy: 0.6021Epoch 33: loss = 1.0397634506225586, val_loss = 0.8739950656890869\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.0398 - categorical_accuracy: 0.6017 - val_loss: 0.8740 - val_categorical_accuracy: 0.6951\n",
      "Epoch 34/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.9938 - categorical_accuracy: 0.6075Epoch 34: loss = 0.9932051301002502, val_loss = 0.9892101883888245\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.9932 - categorical_accuracy: 0.6078 - val_loss: 0.9892 - val_categorical_accuracy: 0.6319\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.8810 - categorical_accuracy: 0.6344Epoch 35: loss = 0.8810306191444397, val_loss = 1.0311353206634521\n",
      "42/42 [==============================] - 2s 52ms/step - loss: 0.8810 - categorical_accuracy: 0.6344 - val_loss: 1.0311 - val_categorical_accuracy: 0.6113\n",
      "Epoch 36/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.8876 - categorical_accuracy: 0.6608Epoch 36: loss = 0.8882327079772949, val_loss = 0.8809849619865417\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.8882 - categorical_accuracy: 0.6603 - val_loss: 0.8810 - val_categorical_accuracy: 0.6578\n",
      "Epoch 37/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.9717 - categorical_accuracy: 0.6380Epoch 37: loss = 0.9725931286811829, val_loss = 1.3767982721328735\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.9726 - categorical_accuracy: 0.6375 - val_loss: 1.3768 - val_categorical_accuracy: 0.5099\n",
      "Epoch 38/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.2237 - categorical_accuracy: 0.5343Epoch 38: loss = 1.2230514287948608, val_loss = 1.018937110900879\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 1.2231 - categorical_accuracy: 0.5347 - val_loss: 1.0189 - val_categorical_accuracy: 0.6235\n",
      "Epoch 39/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.8576 - categorical_accuracy: 0.6641Epoch 39: loss = 0.8538338541984558, val_loss = 0.9616757035255432\n",
      "42/42 [==============================] - 2s 55ms/step - loss: 0.8538 - categorical_accuracy: 0.6649 - val_loss: 0.9617 - val_categorical_accuracy: 0.6380\n",
      "Epoch 40/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.8020 - categorical_accuracy: 0.6860Epoch 40: loss = 0.801439106464386, val_loss = 0.7372472286224365\n",
      "42/42 [==============================] - 2s 52ms/step - loss: 0.8014 - categorical_accuracy: 0.6862 - val_loss: 0.7372 - val_categorical_accuracy: 0.7294\n",
      "Epoch 41/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.7098 - categorical_accuracy: 0.7081Epoch 41: loss = 0.7099597454071045, val_loss = 0.9039189219474792\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.7100 - categorical_accuracy: 0.7075 - val_loss: 0.9039 - val_categorical_accuracy: 0.6745\n",
      "Epoch 42/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.8778 - categorical_accuracy: 0.6711Epoch 42: loss = 0.8761796951293945, val_loss = 0.7813450694084167\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.8762 - categorical_accuracy: 0.6725 - val_loss: 0.7813 - val_categorical_accuracy: 0.7188\n",
      "Epoch 43/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.7429 - categorical_accuracy: 0.7027Epoch 43: loss = 0.7439178824424744, val_loss = 0.8739207983016968\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.7439 - categorical_accuracy: 0.7022 - val_loss: 0.8739 - val_categorical_accuracy: 0.7157\n",
      "Epoch 44/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.3540 - categorical_accuracy: 0.5389Epoch 44: loss = 1.3543306589126587, val_loss = 1.9745970964431763\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.3543 - categorical_accuracy: 0.5385 - val_loss: 1.9746 - val_categorical_accuracy: 0.4192\n",
      "Epoch 45/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.2900 - categorical_accuracy: 0.5290Epoch 45: loss = 1.2905447483062744, val_loss = 0.9505088329315186\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.2905 - categorical_accuracy: 0.5286 - val_loss: 0.9505 - val_categorical_accuracy: 0.6395\n",
      "Epoch 46/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.8404 - categorical_accuracy: 0.6555Epoch 46: loss = 0.839911162853241, val_loss = 0.7732716202735901\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.8399 - categorical_accuracy: 0.6558 - val_loss: 0.7733 - val_categorical_accuracy: 0.7104\n",
      "Epoch 47/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.7135 - categorical_accuracy: 0.7119Epoch 47: loss = 0.7136855125427246, val_loss = 0.6705582141876221\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.7137 - categorical_accuracy: 0.7113 - val_loss: 0.6706 - val_categorical_accuracy: 0.7515\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.6726 - categorical_accuracy: 0.7159Epoch 48: loss = 0.6726192235946655, val_loss = 0.7433242201805115\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.6726 - categorical_accuracy: 0.7159 - val_loss: 0.7433 - val_categorical_accuracy: 0.7081\n",
      "Epoch 49/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.6720 - categorical_accuracy: 0.7156Epoch 49: loss = 0.6673362851142883, val_loss = 0.7169432640075684\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.6673 - categorical_accuracy: 0.7174 - val_loss: 0.7169 - val_categorical_accuracy: 0.7447\n",
      "Epoch 50/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.6061 - categorical_accuracy: 0.7517Epoch 50: loss = 0.6060975790023804, val_loss = 1.529313087463379\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.6061 - categorical_accuracy: 0.7517 - val_loss: 1.5293 - val_categorical_accuracy: 0.5861\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 1.5293 - categorical_accuracy: 0.5861\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 3.1832 - categorical_accuracy: 0.0579Epoch 1: loss = 3.183229684829712, val_loss = 3.0387730598449707\n",
      "41/41 [==============================] - 7s 67ms/step - loss: 3.1832 - categorical_accuracy: 0.0579 - val_loss: 3.0388 - val_categorical_accuracy: 0.1051\n",
      "Epoch 2/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.9130 - categorical_accuracy: 0.1180Epoch 2: loss = 2.9165472984313965, val_loss = 2.6375386714935303\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 2.9165 - categorical_accuracy: 0.1166 - val_loss: 2.6375 - val_categorical_accuracy: 0.1790\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.6587 - categorical_accuracy: 0.1852Epoch 3: loss = 2.6586568355560303, val_loss = 2.371112823486328\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 2.6587 - categorical_accuracy: 0.1852 - val_loss: 2.3711 - val_categorical_accuracy: 0.2628\n",
      "Epoch 4/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.3384 - categorical_accuracy: 0.2438Epoch 4: loss = 2.3357808589935303, val_loss = 2.1879122257232666\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 2.3358 - categorical_accuracy: 0.2439 - val_loss: 2.1879 - val_categorical_accuracy: 0.2734\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.1583 - categorical_accuracy: 0.2881Epoch 5: loss = 2.158294439315796, val_loss = 2.1594014167785645\n",
      "41/41 [==============================] - 2s 50ms/step - loss: 2.1583 - categorical_accuracy: 0.2881 - val_loss: 2.1594 - val_categorical_accuracy: 0.2605\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.1454 - categorical_accuracy: 0.2851Epoch 6: loss = 2.1453633308410645, val_loss = 2.071359872817993\n",
      "41/41 [==============================] - 2s 54ms/step - loss: 2.1454 - categorical_accuracy: 0.2851 - val_loss: 2.0714 - val_categorical_accuracy: 0.2818\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.9707 - categorical_accuracy: 0.3239Epoch 7: loss = 1.9707478284835815, val_loss = 1.8898663520812988\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 1.9707 - categorical_accuracy: 0.3239 - val_loss: 1.8899 - val_categorical_accuracy: 0.3382\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.8290 - categorical_accuracy: 0.3659Epoch 8: loss = 1.8289934396743774, val_loss = 1.5473662614822388\n",
      "41/41 [==============================] - 2s 56ms/step - loss: 1.8290 - categorical_accuracy: 0.3659 - val_loss: 1.5474 - val_categorical_accuracy: 0.4539\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.5998 - categorical_accuracy: 0.4291Epoch 9: loss = 1.5998269319534302, val_loss = 1.6261472702026367\n",
      "41/41 [==============================] - 2s 55ms/step - loss: 1.5998 - categorical_accuracy: 0.4291 - val_loss: 1.6261 - val_categorical_accuracy: 0.3785\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.5584 - categorical_accuracy: 0.4230Epoch 10: loss = 1.5584214925765991, val_loss = 1.3930861949920654\n",
      "41/41 [==============================] - 2s 48ms/step - loss: 1.5584 - categorical_accuracy: 0.4230 - val_loss: 1.3931 - val_categorical_accuracy: 0.4783\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.5945 - categorical_accuracy: 0.4360Epoch 11: loss = 1.5945215225219727, val_loss = 1.7411943674087524\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 1.5945 - categorical_accuracy: 0.4360 - val_loss: 1.7412 - val_categorical_accuracy: 0.3915\n",
      "Epoch 12/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.5472 - categorical_accuracy: 0.4266Epoch 12: loss = 1.5510084629058838, val_loss = 1.8061776161193848\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 1.5510 - categorical_accuracy: 0.4253 - val_loss: 1.8062 - val_categorical_accuracy: 0.2986\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.5647 - categorical_accuracy: 0.4306Epoch 13: loss = 1.564736008644104, val_loss = 1.403301477432251\n",
      "41/41 [==============================] - 2s 50ms/step - loss: 1.5647 - categorical_accuracy: 0.4306 - val_loss: 1.4033 - val_categorical_accuracy: 0.4836\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.5215 - categorical_accuracy: 0.4306Epoch 14: loss = 1.5215349197387695, val_loss = 1.5975233316421509\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 1.5215 - categorical_accuracy: 0.4306 - val_loss: 1.5975 - val_categorical_accuracy: 0.3564\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.4111 - categorical_accuracy: 0.4611Epoch 15: loss = 1.4111371040344238, val_loss = 1.4870307445526123\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 1.4111 - categorical_accuracy: 0.4611 - val_loss: 1.4870 - val_categorical_accuracy: 0.4166\n",
      "Epoch 16/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.4600 - categorical_accuracy: 0.4453Epoch 16: loss = 1.4551513195037842, val_loss = 1.3773225545883179\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 1.4552 - categorical_accuracy: 0.4497 - val_loss: 1.3773 - val_categorical_accuracy: 0.5385\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.4211 - categorical_accuracy: 0.4764Epoch 17: loss = 1.4210536479949951, val_loss = 1.2496871948242188\n",
      "41/41 [==============================] - 2s 60ms/step - loss: 1.4211 - categorical_accuracy: 0.4764 - val_loss: 1.2497 - val_categorical_accuracy: 0.5476\n",
      "Epoch 18/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.2845 - categorical_accuracy: 0.4992Epoch 18: loss = 1.2795090675354004, val_loss = 1.1596107482910156\n",
      "41/41 [==============================] - 3s 71ms/step - loss: 1.2795 - categorical_accuracy: 0.5015 - val_loss: 1.1596 - val_categorical_accuracy: 0.5925\n",
      "Epoch 19/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.1461 - categorical_accuracy: 0.5891Epoch 19: loss = 1.1509637832641602, val_loss = 1.0585254430770874\n",
      "41/41 [==============================] - 2s 48ms/step - loss: 1.1510 - categorical_accuracy: 0.5884 - val_loss: 1.0585 - val_categorical_accuracy: 0.6420\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2803 - categorical_accuracy: 0.5495Epoch 20: loss = 1.2803354263305664, val_loss = 1.256089687347412\n",
      "41/41 [==============================] - 2s 50ms/step - loss: 1.2803 - categorical_accuracy: 0.5495 - val_loss: 1.2561 - val_categorical_accuracy: 0.6093\n",
      "Epoch 21/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.1194 - categorical_accuracy: 0.6016Epoch 21: loss = 1.1162306070327759, val_loss = 1.040451169013977\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 1.1162 - categorical_accuracy: 0.6052 - val_loss: 1.0405 - val_categorical_accuracy: 0.5918\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1206 - categorical_accuracy: 0.5770Epoch 22: loss = 1.1205573081970215, val_loss = 1.0523172616958618\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 1.1206 - categorical_accuracy: 0.5770 - val_loss: 1.0523 - val_categorical_accuracy: 0.6154\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1029 - categorical_accuracy: 0.5915Epoch 23: loss = 1.102878451347351, val_loss = 1.0935707092285156\n",
      "41/41 [==============================] - 2s 48ms/step - loss: 1.1029 - categorical_accuracy: 0.5915 - val_loss: 1.0936 - val_categorical_accuracy: 0.6047\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.9504 - categorical_accuracy: 0.6471Epoch 24: loss = 0.9504363536834717, val_loss = 0.9828033447265625\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.9504 - categorical_accuracy: 0.6471 - val_loss: 0.9828 - val_categorical_accuracy: 0.6367\n",
      "Epoch 25/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.0356 - categorical_accuracy: 0.6195Epoch 25: loss = 1.0358142852783203, val_loss = 1.0643243789672852\n",
      "41/41 [==============================] - 2s 54ms/step - loss: 1.0358 - categorical_accuracy: 0.6181 - val_loss: 1.0643 - val_categorical_accuracy: 0.6276\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0294 - categorical_accuracy: 0.6197Epoch 26: loss = 1.0294157266616821, val_loss = 0.9299245476722717\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 1.0294 - categorical_accuracy: 0.6197 - val_loss: 0.9299 - val_categorical_accuracy: 0.6436\n",
      "Epoch 27/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.0179 - categorical_accuracy: 0.6273Epoch 27: loss = 1.0105620622634888, val_loss = 0.863013744354248\n",
      "41/41 [==============================] - 2s 49ms/step - loss: 1.0106 - categorical_accuracy: 0.6296 - val_loss: 0.8630 - val_categorical_accuracy: 0.6710\n",
      "Epoch 28/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.9135 - categorical_accuracy: 0.6547Epoch 28: loss = 0.9101991653442383, val_loss = 0.8726619482040405\n",
      "41/41 [==============================] - 2s 53ms/step - loss: 0.9102 - categorical_accuracy: 0.6593 - val_loss: 0.8727 - val_categorical_accuracy: 0.6748\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.8630 - categorical_accuracy: 0.6738Epoch 29: loss = 0.8630266785621643, val_loss = 0.8013957738876343\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.8630 - categorical_accuracy: 0.6738 - val_loss: 0.8014 - val_categorical_accuracy: 0.7060\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.9052 - categorical_accuracy: 0.6654Epoch 30: loss = 0.9052060842514038, val_loss = 1.0613188743591309\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 0.9052 - categorical_accuracy: 0.6654 - val_loss: 1.0613 - val_categorical_accuracy: 0.5864\n",
      "Epoch 31/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.8815 - categorical_accuracy: 0.6609Epoch 31: loss = 0.8813564777374268, val_loss = 0.7410055994987488\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.8814 - categorical_accuracy: 0.6608 - val_loss: 0.7410 - val_categorical_accuracy: 0.7411\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.7882 - categorical_accuracy: 0.7157Epoch 32: loss = 0.7882336974143982, val_loss = 0.7672736644744873\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 0.7882 - categorical_accuracy: 0.7157 - val_loss: 0.7673 - val_categorical_accuracy: 0.6969\n",
      "Epoch 33/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.8888 - categorical_accuracy: 0.6828Epoch 33: loss = 0.8864611983299255, val_loss = 0.718233048915863\n",
      "41/41 [==============================] - 2s 50ms/step - loss: 0.8865 - categorical_accuracy: 0.6822 - val_loss: 0.7182 - val_categorical_accuracy: 0.7228\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.8752 - categorical_accuracy: 0.6761Epoch 34: loss = 0.8751533031463623, val_loss = 0.9106347560882568\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 0.8752 - categorical_accuracy: 0.6761 - val_loss: 0.9106 - val_categorical_accuracy: 0.6565\n",
      "Epoch 35/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.8746 - categorical_accuracy: 0.6955Epoch 35: loss = 0.8756047487258911, val_loss = 0.790095865726471\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 0.8756 - categorical_accuracy: 0.6944 - val_loss: 0.7901 - val_categorical_accuracy: 0.6999\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6984 - categorical_accuracy: 0.7386Epoch 36: loss = 0.6984412670135498, val_loss = 0.7522648572921753\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.6984 - categorical_accuracy: 0.7386 - val_loss: 0.7523 - val_categorical_accuracy: 0.7022\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.7301 - categorical_accuracy: 0.7279Epoch 37: loss = 0.730144202709198, val_loss = 0.6885089874267578\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.7301 - categorical_accuracy: 0.7279 - val_loss: 0.6885 - val_categorical_accuracy: 0.7449\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.7591 - categorical_accuracy: 0.7317Epoch 38: loss = 0.7591431736946106, val_loss = 0.7739154100418091\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.7591 - categorical_accuracy: 0.7317 - val_loss: 0.7739 - val_categorical_accuracy: 0.7289\n",
      "Epoch 39/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.7323 - categorical_accuracy: 0.7383Epoch 39: loss = 0.7311885356903076, val_loss = 0.6294069886207581\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 0.7312 - categorical_accuracy: 0.7363 - val_loss: 0.6294 - val_categorical_accuracy: 0.7669\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.7560 - categorical_accuracy: 0.7149Epoch 40: loss = 0.7559539079666138, val_loss = 0.6752341389656067\n",
      "41/41 [==============================] - 2s 43ms/step - loss: 0.7560 - categorical_accuracy: 0.7149 - val_loss: 0.6752 - val_categorical_accuracy: 0.7532\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6815 - categorical_accuracy: 0.7492Epoch 41: loss = 0.6815309524536133, val_loss = 0.6420876979827881\n",
      "41/41 [==============================] - 2s 49ms/step - loss: 0.6815 - categorical_accuracy: 0.7492 - val_loss: 0.6421 - val_categorical_accuracy: 0.7563\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6515 - categorical_accuracy: 0.7607Epoch 42: loss = 0.6515471339225769, val_loss = 0.5784256458282471\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.6515 - categorical_accuracy: 0.7607 - val_loss: 0.5784 - val_categorical_accuracy: 0.7921\n",
      "Epoch 43/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.6146 - categorical_accuracy: 0.7845Epoch 43: loss = 0.6294079422950745, val_loss = 0.6811224222183228\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.6294 - categorical_accuracy: 0.7782 - val_loss: 0.6811 - val_categorical_accuracy: 0.7403\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6249 - categorical_accuracy: 0.7630Epoch 44: loss = 0.624923586845398, val_loss = 0.8437832593917847\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.6249 - categorical_accuracy: 0.7630 - val_loss: 0.8438 - val_categorical_accuracy: 0.6740\n",
      "Epoch 45/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.6455 - categorical_accuracy: 0.7764Epoch 45: loss = 0.6452342867851257, val_loss = 0.554114818572998\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.6452 - categorical_accuracy: 0.7744 - val_loss: 0.5541 - val_categorical_accuracy: 0.8081\n",
      "Epoch 46/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.5489 - categorical_accuracy: 0.7922Epoch 46: loss = 0.5531041622161865, val_loss = 0.705661952495575\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.5531 - categorical_accuracy: 0.7896 - val_loss: 0.7057 - val_categorical_accuracy: 0.7350\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6229 - categorical_accuracy: 0.7683Epoch 47: loss = 0.6229236125946045, val_loss = 0.670159637928009\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.6229 - categorical_accuracy: 0.7683 - val_loss: 0.6702 - val_categorical_accuracy: 0.7456\n",
      "Epoch 48/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.5913 - categorical_accuracy: 0.7930Epoch 48: loss = 0.5862953662872314, val_loss = 0.7020589113235474\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 0.5863 - categorical_accuracy: 0.7957 - val_loss: 0.7021 - val_categorical_accuracy: 0.7212\n",
      "Epoch 49/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.5389 - categorical_accuracy: 0.8008Epoch 49: loss = 0.5396704077720642, val_loss = 0.5255171656608582\n",
      "41/41 [==============================] - 2s 58ms/step - loss: 0.5397 - categorical_accuracy: 0.8003 - val_loss: 0.5255 - val_categorical_accuracy: 0.7974\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 5.9753 - categorical_accuracy: 0.2119Epoch 50: loss = 5.9752960205078125, val_loss = 2.7056405544281006\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 5.9753 - categorical_accuracy: 0.2119 - val_loss: 2.7056 - val_categorical_accuracy: 0.1386\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 2.7056 - categorical_accuracy: 0.1386\n",
      "Epoch 1/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 3.1314 - categorical_accuracy: 0.0570Epoch 1: loss = 3.1346426010131836, val_loss = 3.0376033782958984\n",
      "42/42 [==============================] - 8s 84ms/step - loss: 3.1346 - categorical_accuracy: 0.0579 - val_loss: 3.0376 - val_categorical_accuracy: 0.0587\n",
      "Epoch 2/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 3.0189 - categorical_accuracy: 0.0828Epoch 2: loss = 3.0213818550109863, val_loss = 2.971919536590576\n",
      "42/42 [==============================] - 2s 52ms/step - loss: 3.0214 - categorical_accuracy: 0.0838 - val_loss: 2.9719 - val_categorical_accuracy: 0.0587\n",
      "Epoch 3/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.7524 - categorical_accuracy: 0.1235Epoch 3: loss = 2.7511119842529297, val_loss = 2.492589235305786\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 2.7511 - categorical_accuracy: 0.1241 - val_loss: 2.4926 - val_categorical_accuracy: 0.1875\n",
      "Epoch 4/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.8512 - categorical_accuracy: 0.1311Epoch 4: loss = 2.8514060974121094, val_loss = 2.4295971393585205\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.8514 - categorical_accuracy: 0.1310 - val_loss: 2.4296 - val_categorical_accuracy: 0.1936\n",
      "Epoch 5/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.4978 - categorical_accuracy: 0.1860Epoch 5: loss = 2.4982831478118896, val_loss = 2.169020652770996\n",
      "42/42 [==============================] - 2s 53ms/step - loss: 2.4983 - categorical_accuracy: 0.1858 - val_loss: 2.1690 - val_categorical_accuracy: 0.3026\n",
      "Epoch 6/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.2790 - categorical_accuracy: 0.2142Epoch 6: loss = 2.278064012527466, val_loss = 2.06701922416687\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.2781 - categorical_accuracy: 0.2140 - val_loss: 2.0670 - val_categorical_accuracy: 0.3072\n",
      "Epoch 7/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.7524 - categorical_accuracy: 0.1616Epoch 7: loss = 2.751885175704956, val_loss = 2.545797348022461\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.7519 - categorical_accuracy: 0.1615 - val_loss: 2.5458 - val_categorical_accuracy: 0.1532\n",
      "Epoch 8/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.3814 - categorical_accuracy: 0.2000Epoch 8: loss = 2.3794498443603516, val_loss = 2.113553285598755\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.3794 - categorical_accuracy: 0.1980 - val_loss: 2.1136 - val_categorical_accuracy: 0.2546\n",
      "Epoch 9/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.3144 - categorical_accuracy: 0.2279Epoch 9: loss = 2.3146727085113525, val_loss = 2.2754201889038086\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.3147 - categorical_accuracy: 0.2277 - val_loss: 2.2754 - val_categorical_accuracy: 0.2355\n",
      "Epoch 10/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.2621 - categorical_accuracy: 0.2125Epoch 10: loss = 2.2585208415985107, val_loss = 2.011725902557373\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.2585 - categorical_accuracy: 0.2133 - val_loss: 2.0117 - val_categorical_accuracy: 0.2973\n",
      "Epoch 11/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.2851 - categorical_accuracy: 0.2302Epoch 11: loss = 2.28525972366333, val_loss = 2.048569917678833\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 2.2853 - categorical_accuracy: 0.2300 - val_loss: 2.0486 - val_categorical_accuracy: 0.2881\n",
      "Epoch 12/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.0754 - categorical_accuracy: 0.2668Epoch 12: loss = 2.0743775367736816, val_loss = 2.016324043273926\n",
      "42/42 [==============================] - 3s 72ms/step - loss: 2.0744 - categorical_accuracy: 0.2666 - val_loss: 2.0163 - val_categorical_accuracy: 0.2043\n",
      "Epoch 13/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.0537 - categorical_accuracy: 0.2706Epoch 13: loss = 2.05317759513855, val_loss = 1.843234896659851\n",
      "42/42 [==============================] - 2s 54ms/step - loss: 2.0532 - categorical_accuracy: 0.2704 - val_loss: 1.8432 - val_categorical_accuracy: 0.2927\n",
      "Epoch 14/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.9615 - categorical_accuracy: 0.2706Epoch 14: loss = 1.9606794118881226, val_loss = 1.9781076908111572\n",
      "42/42 [==============================] - 2s 53ms/step - loss: 1.9607 - categorical_accuracy: 0.2704 - val_loss: 1.9781 - val_categorical_accuracy: 0.2698\n",
      "Epoch 15/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.0193 - categorical_accuracy: 0.2584Epoch 15: loss = 2.0193276405334473, val_loss = 1.8808302879333496\n",
      "42/42 [==============================] - 2s 53ms/step - loss: 2.0193 - categorical_accuracy: 0.2582 - val_loss: 1.8808 - val_categorical_accuracy: 0.2889\n",
      "Epoch 16/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.8341 - categorical_accuracy: 0.3171Epoch 16: loss = 1.8347902297973633, val_loss = 2.1759021282196045\n",
      "42/42 [==============================] - 2s 55ms/step - loss: 1.8348 - categorical_accuracy: 0.3168 - val_loss: 2.1759 - val_categorical_accuracy: 0.2081\n",
      "Epoch 17/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.9259 - categorical_accuracy: 0.2995Epoch 17: loss = 1.9256808757781982, val_loss = 1.778370976448059\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 1.9257 - categorical_accuracy: 0.3001 - val_loss: 1.7784 - val_categorical_accuracy: 0.3514\n",
      "Epoch 18/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.8641 - categorical_accuracy: 0.3171Epoch 18: loss = 1.8629144430160522, val_loss = 1.5788919925689697\n",
      "42/42 [==============================] - 3s 65ms/step - loss: 1.8629 - categorical_accuracy: 0.3176 - val_loss: 1.5789 - val_categorical_accuracy: 0.4223\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6224 - categorical_accuracy: 0.3884Epoch 19: loss = 1.6224486827850342, val_loss = 1.5409307479858398\n",
      "42/42 [==============================] - 2s 55ms/step - loss: 1.6224 - categorical_accuracy: 0.3884 - val_loss: 1.5409 - val_categorical_accuracy: 0.4893\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5589 - categorical_accuracy: 0.4257Epoch 20: loss = 1.5588685274124146, val_loss = 1.6182516813278198\n",
      "42/42 [==============================] - 2s 55ms/step - loss: 1.5589 - categorical_accuracy: 0.4257 - val_loss: 1.6183 - val_categorical_accuracy: 0.4261\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6453 - categorical_accuracy: 0.3877Epoch 21: loss = 1.6453230381011963, val_loss = 1.3910969495773315\n",
      "42/42 [==============================] - 2s 54ms/step - loss: 1.6453 - categorical_accuracy: 0.3877 - val_loss: 1.3911 - val_categorical_accuracy: 0.5168\n",
      "Epoch 22/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.4931 - categorical_accuracy: 0.4649Epoch 22: loss = 1.4935929775238037, val_loss = 1.608654499053955\n",
      "42/42 [==============================] - 2s 55ms/step - loss: 1.4936 - categorical_accuracy: 0.4646 - val_loss: 1.6087 - val_categorical_accuracy: 0.4078\n",
      "Epoch 23/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.5633 - categorical_accuracy: 0.4328Epoch 23: loss = 1.5590771436691284, val_loss = 1.3546390533447266\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 1.5591 - categorical_accuracy: 0.4341 - val_loss: 1.3546 - val_categorical_accuracy: 0.5526\n",
      "Epoch 24/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.4658 - categorical_accuracy: 0.4578Epoch 24: loss = 1.4857946634292603, val_loss = 1.441213846206665\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 1.4858 - categorical_accuracy: 0.4570 - val_loss: 1.4412 - val_categorical_accuracy: 0.4848\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4078 - categorical_accuracy: 0.4775Epoch 25: loss = 1.4077632427215576, val_loss = 1.264175295829773\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 1.4078 - categorical_accuracy: 0.4775 - val_loss: 1.2642 - val_categorical_accuracy: 0.5579\n",
      "Epoch 26/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.4587 - categorical_accuracy: 0.4710Epoch 26: loss = 1.4576245546340942, val_loss = 1.3545665740966797\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 1.4576 - categorical_accuracy: 0.4714 - val_loss: 1.3546 - val_categorical_accuracy: 0.5008\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3451 - categorical_accuracy: 0.5034Epoch 27: loss = 1.3451186418533325, val_loss = 1.3330186605453491\n",
      "42/42 [==============================] - 2s 52ms/step - loss: 1.3451 - categorical_accuracy: 0.5034 - val_loss: 1.3330 - val_categorical_accuracy: 0.5046\n",
      "Epoch 28/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.5411 - categorical_accuracy: 0.4329Epoch 28: loss = 1.540674090385437, val_loss = 1.3674973249435425\n",
      "42/42 [==============================] - 2s 53ms/step - loss: 1.5407 - categorical_accuracy: 0.4326 - val_loss: 1.3675 - val_categorical_accuracy: 0.5457\n",
      "Epoch 29/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.2726 - categorical_accuracy: 0.5477Epoch 29: loss = 1.2658885717391968, val_loss = 1.108176589012146\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 1.2659 - categorical_accuracy: 0.5491 - val_loss: 1.1082 - val_categorical_accuracy: 0.6463\n",
      "Epoch 30/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.1961 - categorical_accuracy: 0.5526Epoch 30: loss = 1.1952115297317505, val_loss = 1.2107203006744385\n",
      "42/42 [==============================] - 2s 55ms/step - loss: 1.1952 - categorical_accuracy: 0.5529 - val_loss: 1.2107 - val_categorical_accuracy: 0.5724\n",
      "Epoch 31/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.1060 - categorical_accuracy: 0.5961Epoch 31: loss = 1.1134892702102661, val_loss = 1.260765790939331\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 1.1135 - categorical_accuracy: 0.5933 - val_loss: 1.2608 - val_categorical_accuracy: 0.5404\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4319 - categorical_accuracy: 0.4912Epoch 32: loss = 1.4319016933441162, val_loss = 1.1545062065124512\n",
      "42/42 [==============================] - 2s 52ms/step - loss: 1.4319 - categorical_accuracy: 0.4912 - val_loss: 1.1545 - val_categorical_accuracy: 0.6303\n",
      "Epoch 33/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.1392 - categorical_accuracy: 0.5816Epoch 33: loss = 1.1383626461029053, val_loss = 1.1277391910552979\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.1384 - categorical_accuracy: 0.5819 - val_loss: 1.1277 - val_categorical_accuracy: 0.6181\n",
      "Epoch 34/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.1760 - categorical_accuracy: 0.5820Epoch 34: loss = 1.172552227973938, val_loss = 0.9203184247016907\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 1.1726 - categorical_accuracy: 0.5826 - val_loss: 0.9203 - val_categorical_accuracy: 0.6860\n",
      "Epoch 35/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.1821 - categorical_accuracy: 0.5724Epoch 35: loss = 1.1814645528793335, val_loss = 1.097078800201416\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 1.1815 - categorical_accuracy: 0.5727 - val_loss: 1.0971 - val_categorical_accuracy: 0.6235\n",
      "Epoch 36/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.1627 - categorical_accuracy: 0.5813Epoch 36: loss = 1.159519910812378, val_loss = 1.681875467300415\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 1.1595 - categorical_accuracy: 0.5842 - val_loss: 1.6819 - val_categorical_accuracy: 0.5450\n",
      "Epoch 37/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.2797 - categorical_accuracy: 0.5366Epoch 37: loss = 1.2787830829620361, val_loss = 1.001879096031189\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 1.2788 - categorical_accuracy: 0.5369 - val_loss: 1.0019 - val_categorical_accuracy: 0.6502\n",
      "Epoch 38/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.0027 - categorical_accuracy: 0.6235Epoch 38: loss = 1.0019590854644775, val_loss = 0.948628842830658\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 1.0020 - categorical_accuracy: 0.6238 - val_loss: 0.9486 - val_categorical_accuracy: 0.6738\n",
      "Epoch 39/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.9560 - categorical_accuracy: 0.6418Epoch 39: loss = 0.9553079605102539, val_loss = 1.0143405199050903\n",
      "42/42 [==============================] - 2s 54ms/step - loss: 0.9553 - categorical_accuracy: 0.6420 - val_loss: 1.0143 - val_categorical_accuracy: 0.6471\n",
      "Epoch 40/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.9956 - categorical_accuracy: 0.6288Epoch 40: loss = 0.99546879529953, val_loss = 0.9179380536079407\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.9955 - categorical_accuracy: 0.6291 - val_loss: 0.9179 - val_categorical_accuracy: 0.6616\n",
      "Epoch 41/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.9588 - categorical_accuracy: 0.6578Epoch 41: loss = 0.9555382132530212, val_loss = 0.9580255150794983\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.9555 - categorical_accuracy: 0.6618 - val_loss: 0.9580 - val_categorical_accuracy: 0.6562\n",
      "Epoch 42/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.9353 - categorical_accuracy: 0.6479Epoch 42: loss = 0.9346000552177429, val_loss = 0.8669317960739136\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 0.9346 - categorical_accuracy: 0.6481 - val_loss: 0.8669 - val_categorical_accuracy: 0.6806\n",
      "Epoch 43/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.8826 - categorical_accuracy: 0.6648Epoch 43: loss = 0.8832659125328064, val_loss = 1.016745924949646\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.8833 - categorical_accuracy: 0.6611 - val_loss: 1.0167 - val_categorical_accuracy: 0.6357\n",
      "Epoch 44/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.9615 - categorical_accuracy: 0.6509Epoch 44: loss = 0.9624279141426086, val_loss = 1.1678115129470825\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 0.9624 - categorical_accuracy: 0.6504 - val_loss: 1.1678 - val_categorical_accuracy: 0.6128\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0291 - categorical_accuracy: 0.6276Epoch 45: loss = 1.0290783643722534, val_loss = 0.8695204854011536\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.0291 - categorical_accuracy: 0.6276 - val_loss: 0.8695 - val_categorical_accuracy: 0.6867\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.9246 - categorical_accuracy: 0.6497Epoch 46: loss = 0.9245952367782593, val_loss = 0.8401005268096924\n",
      "42/42 [==============================] - 2s 54ms/step - loss: 0.9246 - categorical_accuracy: 0.6497 - val_loss: 0.8401 - val_categorical_accuracy: 0.7172\n",
      "Epoch 47/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.8842 - categorical_accuracy: 0.6734Epoch 47: loss = 0.8887115716934204, val_loss = 0.8643956780433655\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.8887 - categorical_accuracy: 0.6733 - val_loss: 0.8644 - val_categorical_accuracy: 0.7027\n",
      "Epoch 48/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.8300 - categorical_accuracy: 0.6860Epoch 48: loss = 0.8297487497329712, val_loss = 0.8501064777374268\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 0.8297 - categorical_accuracy: 0.6862 - val_loss: 0.8501 - val_categorical_accuracy: 0.6997\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.8268 - categorical_accuracy: 0.6961Epoch 49: loss = 0.8268351554870605, val_loss = 0.7324387431144714\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.8268 - categorical_accuracy: 0.6961 - val_loss: 0.7324 - val_categorical_accuracy: 0.7683\n",
      "Epoch 50/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.7830 - categorical_accuracy: 0.7014Epoch 50: loss = 0.7829785943031311, val_loss = 0.8458786010742188\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.7830 - categorical_accuracy: 0.7014 - val_loss: 0.8459 - val_categorical_accuracy: 0.6928\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.8459 - categorical_accuracy: 0.6928\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 3.1917 - categorical_accuracy: 0.0686Epoch 1: loss = 3.19173002243042, val_loss = 3.1501638889312744\n",
      "41/41 [==============================] - 6s 63ms/step - loss: 3.1917 - categorical_accuracy: 0.0686 - val_loss: 3.1502 - val_categorical_accuracy: 0.0693\n",
      "Epoch 2/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 3.0872 - categorical_accuracy: 0.0781Epoch 2: loss = 3.0836591720581055, val_loss = 3.010885238647461\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 3.0837 - categorical_accuracy: 0.0777 - val_loss: 3.0109 - val_categorical_accuracy: 0.0952\n",
      "Epoch 3/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.9322 - categorical_accuracy: 0.1086Epoch 3: loss = 2.9311764240264893, val_loss = 2.763909101486206\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 2.9312 - categorical_accuracy: 0.1075 - val_loss: 2.7639 - val_categorical_accuracy: 0.1325\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.7841 - categorical_accuracy: 0.1380Epoch 4: loss = 2.7841415405273438, val_loss = 2.6326029300689697\n",
      "41/41 [==============================] - 2s 43ms/step - loss: 2.7841 - categorical_accuracy: 0.1380 - val_loss: 2.6326 - val_categorical_accuracy: 0.1219\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.7265 - categorical_accuracy: 0.1441Epoch 5: loss = 2.7265493869781494, val_loss = 2.677232265472412\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 2.7265 - categorical_accuracy: 0.1441 - val_loss: 2.6772 - val_categorical_accuracy: 0.1462\n",
      "Epoch 6/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.6464 - categorical_accuracy: 0.1398Epoch 6: loss = 2.6423938274383545, val_loss = 2.517426013946533\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 2.6424 - categorical_accuracy: 0.1395 - val_loss: 2.5174 - val_categorical_accuracy: 0.1295\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.6820 - categorical_accuracy: 0.1669Epoch 7: loss = 2.681994915008545, val_loss = 2.7418062686920166\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 2.6820 - categorical_accuracy: 0.1669 - val_loss: 2.7418 - val_categorical_accuracy: 0.1356\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.8423 - categorical_accuracy: 0.1303Epoch 8: loss = 2.8422765731811523, val_loss = 2.481898546218872\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 2.8423 - categorical_accuracy: 0.1303 - val_loss: 2.4819 - val_categorical_accuracy: 0.1721\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.4608 - categorical_accuracy: 0.1814Epoch 9: loss = 2.4608073234558105, val_loss = 2.4159739017486572\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 2.4608 - categorical_accuracy: 0.1814 - val_loss: 2.4160 - val_categorical_accuracy: 0.2026\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.9608 - categorical_accuracy: 0.1608Epoch 10: loss = 2.9608347415924072, val_loss = 2.369626045227051\n",
      "41/41 [==============================] - 2s 48ms/step - loss: 2.9608 - categorical_accuracy: 0.1608 - val_loss: 2.3696 - val_categorical_accuracy: 0.1866\n",
      "Epoch 11/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.3783 - categorical_accuracy: 0.1828Epoch 11: loss = 2.3739030361175537, val_loss = 2.1664748191833496\n",
      "41/41 [==============================] - 3s 61ms/step - loss: 2.3739 - categorical_accuracy: 0.1829 - val_loss: 2.1665 - val_categorical_accuracy: 0.2445\n",
      "Epoch 12/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.2688 - categorical_accuracy: 0.2219Epoch 12: loss = 2.2649354934692383, val_loss = 2.099532127380371\n",
      "41/41 [==============================] - 2s 51ms/step - loss: 2.2649 - categorical_accuracy: 0.2233 - val_loss: 2.0995 - val_categorical_accuracy: 0.2254\n",
      "Epoch 13/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.1477 - categorical_accuracy: 0.2500Epoch 13: loss = 2.1461474895477295, val_loss = 1.936173439025879\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 2.1461 - categorical_accuracy: 0.2492 - val_loss: 1.9362 - val_categorical_accuracy: 0.2879\n",
      "Epoch 14/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.1150 - categorical_accuracy: 0.2734Epoch 14: loss = 2.118659257888794, val_loss = 2.063878297805786\n",
      "41/41 [==============================] - 2s 60ms/step - loss: 2.1187 - categorical_accuracy: 0.2721 - val_loss: 2.0639 - val_categorical_accuracy: 0.2574\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.0300 - categorical_accuracy: 0.2683Epoch 15: loss = 2.029961109161377, val_loss = 1.7907658815383911\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 2.0300 - categorical_accuracy: 0.2683 - val_loss: 1.7908 - val_categorical_accuracy: 0.3427\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.9845 - categorical_accuracy: 0.2965Epoch 16: loss = 1.9844645261764526, val_loss = 1.7813931703567505\n",
      "41/41 [==============================] - 2s 49ms/step - loss: 1.9845 - categorical_accuracy: 0.2965 - val_loss: 1.7814 - val_categorical_accuracy: 0.3077\n",
      "Epoch 17/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.8583 - categorical_accuracy: 0.3141Epoch 17: loss = 1.8530724048614502, val_loss = 1.6556215286254883\n",
      "41/41 [==============================] - 2s 50ms/step - loss: 1.8531 - categorical_accuracy: 0.3155 - val_loss: 1.6556 - val_categorical_accuracy: 0.3793\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.7909 - categorical_accuracy: 0.3460Epoch 18: loss = 1.79086172580719, val_loss = 1.6563154458999634\n",
      "41/41 [==============================] - 2s 50ms/step - loss: 1.7909 - categorical_accuracy: 0.3460 - val_loss: 1.6563 - val_categorical_accuracy: 0.3481\n",
      "Epoch 19/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.8177 - categorical_accuracy: 0.3352Epoch 19: loss = 1.8188878297805786, val_loss = 1.618890404701233\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 1.8189 - categorical_accuracy: 0.3354 - val_loss: 1.6189 - val_categorical_accuracy: 0.3785\n",
      "Epoch 20/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.6879 - categorical_accuracy: 0.3641Epoch 20: loss = 1.6861518621444702, val_loss = 1.577201247215271\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 1.6862 - categorical_accuracy: 0.3674 - val_loss: 1.5772 - val_categorical_accuracy: 0.3915\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.6555 - categorical_accuracy: 0.3963Epoch 21: loss = 1.6555049419403076, val_loss = 1.3857578039169312\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 1.6555 - categorical_accuracy: 0.3963 - val_loss: 1.3858 - val_categorical_accuracy: 0.5027\n",
      "Epoch 22/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.6333 - categorical_accuracy: 0.4016Epoch 22: loss = 1.632041573524475, val_loss = 1.4767955541610718\n",
      "41/41 [==============================] - 2s 48ms/step - loss: 1.6320 - categorical_accuracy: 0.4032 - val_loss: 1.4768 - val_categorical_accuracy: 0.4516\n",
      "Epoch 23/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.5002 - categorical_accuracy: 0.4508Epoch 23: loss = 1.501328945159912, val_loss = 1.3184435367584229\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 1.5013 - categorical_accuracy: 0.4535 - val_loss: 1.3184 - val_categorical_accuracy: 0.4920\n",
      "Epoch 24/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.5066 - categorical_accuracy: 0.4383Epoch 24: loss = 1.5069547891616821, val_loss = 1.3887004852294922\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 1.5070 - categorical_accuracy: 0.4375 - val_loss: 1.3887 - val_categorical_accuracy: 0.4623\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.4856 - categorical_accuracy: 0.4367Epoch 25: loss = 1.4855564832687378, val_loss = 1.3132990598678589\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 1.4856 - categorical_accuracy: 0.4367 - val_loss: 1.3133 - val_categorical_accuracy: 0.5011\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.6080 - categorical_accuracy: 0.4405Epoch 26: loss = 1.6080189943313599, val_loss = 1.6596473455429077\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 1.6080 - categorical_accuracy: 0.4405 - val_loss: 1.6596 - val_categorical_accuracy: 0.3663\n",
      "Epoch 27/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.5830 - categorical_accuracy: 0.4344Epoch 27: loss = 1.5775222778320312, val_loss = 1.2288111448287964\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 1.5775 - categorical_accuracy: 0.4345 - val_loss: 1.2288 - val_categorical_accuracy: 0.5225\n",
      "Epoch 28/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.4268 - categorical_accuracy: 0.4563Epoch 28: loss = 1.428002119064331, val_loss = 1.215492606163025\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 1.4280 - categorical_accuracy: 0.4581 - val_loss: 1.2155 - val_categorical_accuracy: 0.5187\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.3412 - categorical_accuracy: 0.5015Epoch 29: loss = 1.3411715030670166, val_loss = 1.145263433456421\n",
      "41/41 [==============================] - 2s 43ms/step - loss: 1.3412 - categorical_accuracy: 0.5015 - val_loss: 1.1453 - val_categorical_accuracy: 0.5324\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.3421 - categorical_accuracy: 0.4939Epoch 30: loss = 1.3420807123184204, val_loss = 1.1633347272872925\n",
      "41/41 [==============================] - 2s 43ms/step - loss: 1.3421 - categorical_accuracy: 0.4939 - val_loss: 1.1633 - val_categorical_accuracy: 0.5750\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.3014 - categorical_accuracy: 0.4947Epoch 31: loss = 1.3014036417007446, val_loss = 1.1408700942993164\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 1.3014 - categorical_accuracy: 0.4947 - val_loss: 1.1409 - val_categorical_accuracy: 0.5567\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2793 - categorical_accuracy: 0.5053Epoch 32: loss = 1.2792916297912598, val_loss = 1.0673363208770752\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 1.2793 - categorical_accuracy: 0.5053 - val_loss: 1.0673 - val_categorical_accuracy: 0.5819\n",
      "Epoch 33/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.2863 - categorical_accuracy: 0.5047Epoch 33: loss = 1.2772210836410522, val_loss = 1.0570006370544434\n",
      "41/41 [==============================] - 2s 60ms/step - loss: 1.2772 - categorical_accuracy: 0.5084 - val_loss: 1.0570 - val_categorical_accuracy: 0.6085\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.3033 - categorical_accuracy: 0.5229Epoch 34: loss = 1.3032792806625366, val_loss = 1.1854397058486938\n",
      "41/41 [==============================] - 2s 53ms/step - loss: 1.3033 - categorical_accuracy: 0.5229 - val_loss: 1.1854 - val_categorical_accuracy: 0.5072\n",
      "Epoch 35/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.5216 - categorical_accuracy: 0.4391Epoch 35: loss = 1.5223852396011353, val_loss = 1.0749032497406006\n",
      "41/41 [==============================] - 3s 65ms/step - loss: 1.5224 - categorical_accuracy: 0.4375 - val_loss: 1.0749 - val_categorical_accuracy: 0.5979\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2307 - categorical_accuracy: 0.5297Epoch 36: loss = 1.2307173013687134, val_loss = 1.0291386842727661\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 1.2307 - categorical_accuracy: 0.5297 - val_loss: 1.0291 - val_categorical_accuracy: 0.5903\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1416 - categorical_accuracy: 0.5640Epoch 37: loss = 1.1415683031082153, val_loss = 1.11180579662323\n",
      "41/41 [==============================] - 2s 54ms/step - loss: 1.1416 - categorical_accuracy: 0.5640 - val_loss: 1.1118 - val_categorical_accuracy: 0.5613\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1612 - categorical_accuracy: 0.5366Epoch 38: loss = 1.1611982583999634, val_loss = 1.1441669464111328\n",
      "41/41 [==============================] - 2s 59ms/step - loss: 1.1612 - categorical_accuracy: 0.5366 - val_loss: 1.1442 - val_categorical_accuracy: 0.5095\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0914 - categorical_accuracy: 0.5648Epoch 39: loss = 1.0914080142974854, val_loss = 1.061913251876831\n",
      "41/41 [==============================] - 3s 78ms/step - loss: 1.0914 - categorical_accuracy: 0.5648 - val_loss: 1.0619 - val_categorical_accuracy: 0.5392\n",
      "Epoch 40/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.0555 - categorical_accuracy: 0.5820Epoch 40: loss = 1.0615893602371216, val_loss = 0.9385637044906616\n",
      "41/41 [==============================] - 3s 65ms/step - loss: 1.0616 - categorical_accuracy: 0.5793 - val_loss: 0.9386 - val_categorical_accuracy: 0.6725\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1271 - categorical_accuracy: 0.5564Epoch 41: loss = 1.1270962953567505, val_loss = 0.9084932804107666\n",
      "41/41 [==============================] - 3s 64ms/step - loss: 1.1271 - categorical_accuracy: 0.5564 - val_loss: 0.9085 - val_categorical_accuracy: 0.6359\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0041 - categorical_accuracy: 0.6128Epoch 42: loss = 1.0041122436523438, val_loss = 1.0564799308776855\n",
      "41/41 [==============================] - 3s 68ms/step - loss: 1.0041 - categorical_accuracy: 0.6128 - val_loss: 1.0565 - val_categorical_accuracy: 0.5651\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.4094 - categorical_accuracy: 0.4954Epoch 43: loss = 1.4093986749649048, val_loss = 1.0902832746505737\n",
      "41/41 [==============================] - 2s 54ms/step - loss: 1.4094 - categorical_accuracy: 0.4954 - val_loss: 1.0903 - val_categorical_accuracy: 0.5720\n",
      "Epoch 44/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.1787 - categorical_accuracy: 0.5555Epoch 44: loss = 1.1795603036880493, val_loss = 0.9735817909240723\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 1.1796 - categorical_accuracy: 0.5541 - val_loss: 0.9736 - val_categorical_accuracy: 0.6253\n",
      "Epoch 45/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.1707 - categorical_accuracy: 0.5547Epoch 45: loss = 1.1698455810546875, val_loss = 1.4304450750350952\n",
      "41/41 [==============================] - 2s 43ms/step - loss: 1.1698 - categorical_accuracy: 0.5518 - val_loss: 1.4304 - val_categorical_accuracy: 0.4798\n",
      "Epoch 46/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.2607 - categorical_accuracy: 0.5144Epoch 46: loss = 1.2428922653198242, val_loss = 1.0270241498947144\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 1.2429 - categorical_accuracy: 0.5252 - val_loss: 1.0270 - val_categorical_accuracy: 0.5720\n",
      "Epoch 47/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.0013 - categorical_accuracy: 0.6203Epoch 47: loss = 0.9980384111404419, val_loss = 0.9056409597396851\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 0.9980 - categorical_accuracy: 0.6220 - val_loss: 0.9056 - val_categorical_accuracy: 0.6519\n",
      "Epoch 48/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.1705 - categorical_accuracy: 0.5906Epoch 48: loss = 1.1652741432189941, val_loss = 1.1087607145309448\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 1.1653 - categorical_accuracy: 0.5930 - val_loss: 1.1088 - val_categorical_accuracy: 0.5644\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1248 - categorical_accuracy: 0.5854Epoch 49: loss = 1.124820351600647, val_loss = 0.9282073974609375\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 1.1248 - categorical_accuracy: 0.5854 - val_loss: 0.9282 - val_categorical_accuracy: 0.6657\n",
      "Epoch 50/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.9937 - categorical_accuracy: 0.6242Epoch 50: loss = 0.9860389232635498, val_loss = 0.921403706073761\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.9860 - categorical_accuracy: 0.6250 - val_loss: 0.9214 - val_categorical_accuracy: 0.6161\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.9214 - categorical_accuracy: 0.6161\n",
      "Epoch 1/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 3.1804 - categorical_accuracy: 0.0648Epoch 1: loss = 3.1800615787506104, val_loss = 3.060842275619507\n",
      "42/42 [==============================] - 7s 68ms/step - loss: 3.1801 - categorical_accuracy: 0.0647 - val_loss: 3.0608 - val_categorical_accuracy: 0.0816\n",
      "Epoch 2/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.9705 - categorical_accuracy: 0.0793Epoch 2: loss = 2.970247507095337, val_loss = 2.854583740234375\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.9702 - categorical_accuracy: 0.0792 - val_loss: 2.8546 - val_categorical_accuracy: 0.1242\n",
      "Epoch 3/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.8070 - categorical_accuracy: 0.0976Epoch 3: loss = 2.807077169418335, val_loss = 2.612358808517456\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.8071 - categorical_accuracy: 0.0975 - val_loss: 2.6124 - val_categorical_accuracy: 0.1479\n",
      "Epoch 4/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.6526 - categorical_accuracy: 0.1189Epoch 4: loss = 2.6519742012023926, val_loss = 2.6535708904266357\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.6520 - categorical_accuracy: 0.1188 - val_loss: 2.6536 - val_categorical_accuracy: 0.1090\n",
      "Epoch 5/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.5385 - categorical_accuracy: 0.1463Epoch 5: loss = 2.538259983062744, val_loss = 2.279385566711426\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.5383 - categorical_accuracy: 0.1462 - val_loss: 2.2794 - val_categorical_accuracy: 0.2134\n",
      "Epoch 6/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.4943 - categorical_accuracy: 0.1695Epoch 6: loss = 2.4951093196868896, val_loss = 2.159073829650879\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.4951 - categorical_accuracy: 0.1683 - val_loss: 2.1591 - val_categorical_accuracy: 0.3133\n",
      "Epoch 7/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.3245 - categorical_accuracy: 0.2058Epoch 7: loss = 2.3249905109405518, val_loss = 2.3914639949798584\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.3250 - categorical_accuracy: 0.2056 - val_loss: 2.3915 - val_categorical_accuracy: 0.1296\n",
      "Epoch 8/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.2184 - categorical_accuracy: 0.2447Epoch 8: loss = 2.2188057899475098, val_loss = 2.1273486614227295\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.2188 - categorical_accuracy: 0.2445 - val_loss: 2.1273 - val_categorical_accuracy: 0.2058\n",
      "Epoch 9/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.1277 - categorical_accuracy: 0.2271Epoch 9: loss = 2.127864122390747, val_loss = 1.7934826612472534\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.1279 - categorical_accuracy: 0.2270 - val_loss: 1.7935 - val_categorical_accuracy: 0.3384\n",
      "Epoch 10/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.0118 - categorical_accuracy: 0.2719Epoch 10: loss = 2.3312439918518066, val_loss = 4.022075176239014\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.3312 - categorical_accuracy: 0.2704 - val_loss: 4.0221 - val_categorical_accuracy: 0.3438\n",
      "Epoch 11/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.9302 - categorical_accuracy: 0.3087Epoch 11: loss = 1.930748701095581, val_loss = 1.7554268836975098\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.9307 - categorical_accuracy: 0.3085 - val_loss: 1.7554 - val_categorical_accuracy: 0.3803\n",
      "Epoch 12/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.8350 - categorical_accuracy: 0.3262Epoch 12: loss = 1.83454167842865, val_loss = 1.8564304113388062\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.8345 - categorical_accuracy: 0.3260 - val_loss: 1.8564 - val_categorical_accuracy: 0.3186\n",
      "Epoch 13/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.0413 - categorical_accuracy: 0.2797Epoch 13: loss = 2.0414047241210938, val_loss = 1.8470213413238525\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.0414 - categorical_accuracy: 0.2795 - val_loss: 1.8470 - val_categorical_accuracy: 0.3438\n",
      "Epoch 14/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.8230 - categorical_accuracy: 0.3216Epoch 14: loss = 1.8225497007369995, val_loss = 2.0324935913085938\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.8225 - categorical_accuracy: 0.3222 - val_loss: 2.0325 - val_categorical_accuracy: 0.3140\n",
      "Epoch 15/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.8482 - categorical_accuracy: 0.3384Epoch 15: loss = 1.8485686779022217, val_loss = 1.494802474975586\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.8486 - categorical_accuracy: 0.3382 - val_loss: 1.4948 - val_categorical_accuracy: 0.5046\n",
      "Epoch 16/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.6946 - categorical_accuracy: 0.3666Epoch 16: loss = 1.695672631263733, val_loss = 1.5478602647781372\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.6957 - categorical_accuracy: 0.3663 - val_loss: 1.5479 - val_categorical_accuracy: 0.4543\n",
      "Epoch 17/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.5543 - categorical_accuracy: 0.4146Epoch 17: loss = 1.5539886951446533, val_loss = 1.5575754642486572\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.5540 - categorical_accuracy: 0.4151 - val_loss: 1.5576 - val_categorical_accuracy: 0.4787\n",
      "Epoch 18/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.5091 - categorical_accuracy: 0.4588Epoch 18: loss = 1.5090055465698242, val_loss = 1.297877311706543\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.5090 - categorical_accuracy: 0.4585 - val_loss: 1.2979 - val_categorical_accuracy: 0.5396\n",
      "Epoch 19/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.4190 - categorical_accuracy: 0.4649Epoch 19: loss = 1.418727993965149, val_loss = 1.3022518157958984\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.4187 - categorical_accuracy: 0.4646 - val_loss: 1.3023 - val_categorical_accuracy: 0.5152\n",
      "Epoch 20/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.3997 - categorical_accuracy: 0.4688Epoch 20: loss = 1.4080018997192383, val_loss = 1.4934178590774536\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.4080 - categorical_accuracy: 0.4676 - val_loss: 1.4934 - val_categorical_accuracy: 0.4566\n",
      "Epoch 21/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.4682 - categorical_accuracy: 0.4581Epoch 21: loss = 1.4684619903564453, val_loss = 1.2771679162979126\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.4685 - categorical_accuracy: 0.4577 - val_loss: 1.2772 - val_categorical_accuracy: 0.5633\n",
      "Epoch 22/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.3807 - categorical_accuracy: 0.4947Epoch 22: loss = 1.3800292015075684, val_loss = 1.1128098964691162\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.3800 - categorical_accuracy: 0.4950 - val_loss: 1.1128 - val_categorical_accuracy: 0.6059\n",
      "Epoch 23/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.2341 - categorical_accuracy: 0.5419Epoch 23: loss = 1.2334314584732056, val_loss = 1.0087106227874756\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.2334 - categorical_accuracy: 0.5423 - val_loss: 1.0087 - val_categorical_accuracy: 0.6418\n",
      "Epoch 24/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.2259 - categorical_accuracy: 0.5289Epoch 24: loss = 1.2241243124008179, val_loss = 0.9470881223678589\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.2241 - categorical_accuracy: 0.5301 - val_loss: 0.9471 - val_categorical_accuracy: 0.6608\n",
      "Epoch 25/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.1745 - categorical_accuracy: 0.5453Epoch 25: loss = 1.1744240522384644, val_loss = 1.7057517766952515\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.1744 - categorical_accuracy: 0.5461 - val_loss: 1.7058 - val_categorical_accuracy: 0.5351\n",
      "Epoch 26/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.3159 - categorical_accuracy: 0.5141Epoch 26: loss = 1.3068791627883911, val_loss = 1.000380039215088\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.3069 - categorical_accuracy: 0.5187 - val_loss: 1.0004 - val_categorical_accuracy: 0.6387\n",
      "Epoch 27/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.1278 - categorical_accuracy: 0.5719Epoch 27: loss = 1.1297757625579834, val_loss = 0.9393700361251831\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.1298 - categorical_accuracy: 0.5720 - val_loss: 0.9394 - val_categorical_accuracy: 0.6776\n",
      "Epoch 28/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.0740 - categorical_accuracy: 0.5838Epoch 28: loss = 1.0733989477157593, val_loss = 0.8891922831535339\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.0734 - categorical_accuracy: 0.5842 - val_loss: 0.8892 - val_categorical_accuracy: 0.6860\n",
      "Epoch 29/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.9733 - categorical_accuracy: 0.6136Epoch 29: loss = 0.9729819297790527, val_loss = 0.9432791471481323\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.9730 - categorical_accuracy: 0.6139 - val_loss: 0.9433 - val_categorical_accuracy: 0.6662\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5728 - categorical_accuracy: 0.4623Epoch 30: loss = 1.572752594947815, val_loss = 10.669349670410156\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 1.5728 - categorical_accuracy: 0.4623 - val_loss: 10.6693 - val_categorical_accuracy: 0.2424\n",
      "Epoch 31/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.0700 - categorical_accuracy: 0.3477Epoch 31: loss = 2.05791974067688, val_loss = 1.2806097269058228\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.0579 - categorical_accuracy: 0.3481 - val_loss: 1.2806 - val_categorical_accuracy: 0.5442\n",
      "Epoch 32/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.3479 - categorical_accuracy: 0.5109Epoch 32: loss = 1.3491058349609375, val_loss = 1.7650477886199951\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.3491 - categorical_accuracy: 0.5118 - val_loss: 1.7650 - val_categorical_accuracy: 0.4535\n",
      "Epoch 33/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.2922 - categorical_accuracy: 0.5030Epoch 33: loss = 1.2913789749145508, val_loss = 0.904715359210968\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.2914 - categorical_accuracy: 0.5034 - val_loss: 0.9047 - val_categorical_accuracy: 0.6829\n",
      "Epoch 34/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.0672 - categorical_accuracy: 0.5914Epoch 34: loss = 1.0695139169692993, val_loss = 0.8679947257041931\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.0695 - categorical_accuracy: 0.5910 - val_loss: 0.8680 - val_categorical_accuracy: 0.6425\n",
      "Epoch 35/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.0215 - categorical_accuracy: 0.6052Epoch 35: loss = 1.022174596786499, val_loss = 0.90040522813797\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.0222 - categorical_accuracy: 0.6047 - val_loss: 0.9004 - val_categorical_accuracy: 0.6730\n",
      "Epoch 36/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.0361 - categorical_accuracy: 0.6113Epoch 36: loss = 1.0355104207992554, val_loss = 1.0553638935089111\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.0355 - categorical_accuracy: 0.6116 - val_loss: 1.0554 - val_categorical_accuracy: 0.5960\n",
      "Epoch 37/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.0049 - categorical_accuracy: 0.6197Epoch 37: loss = 1.0047043561935425, val_loss = 0.8230151534080505\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 1.0047 - categorical_accuracy: 0.6200 - val_loss: 0.8230 - val_categorical_accuracy: 0.7119\n",
      "Epoch 38/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.1977 - categorical_accuracy: 0.5526Epoch 38: loss = 1.1973176002502441, val_loss = 1.0022298097610474\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.1973 - categorical_accuracy: 0.5529 - val_loss: 1.0022 - val_categorical_accuracy: 0.6402\n",
      "Epoch 39/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.1013 - categorical_accuracy: 0.6006Epoch 39: loss = 1.101961374282837, val_loss = 0.8550998568534851\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.1020 - categorical_accuracy: 0.6009 - val_loss: 0.8551 - val_categorical_accuracy: 0.7248\n",
      "Epoch 40/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.9016 - categorical_accuracy: 0.6593Epoch 40: loss = 0.9024253487586975, val_loss = 0.7864211201667786\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 0.9024 - categorical_accuracy: 0.6588 - val_loss: 0.7864 - val_categorical_accuracy: 0.7157\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0287 - categorical_accuracy: 0.6017Epoch 41: loss = 1.028727650642395, val_loss = 1.0078527927398682\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 1.0287 - categorical_accuracy: 0.6017 - val_loss: 1.0079 - val_categorical_accuracy: 0.5953\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0519 - categorical_accuracy: 0.5941Epoch 42: loss = 1.0518691539764404, val_loss = 0.825986921787262\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 1.0519 - categorical_accuracy: 0.5941 - val_loss: 0.8260 - val_categorical_accuracy: 0.7241\n",
      "Epoch 43/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.8865 - categorical_accuracy: 0.6578Epoch 43: loss = 0.8858497738838196, val_loss = 0.7820051908493042\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.8858 - categorical_accuracy: 0.6580 - val_loss: 0.7820 - val_categorical_accuracy: 0.7409\n",
      "Epoch 44/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.8460 - categorical_accuracy: 0.6753Epoch 44: loss = 0.8471568822860718, val_loss = 1.2745287418365479\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.8472 - categorical_accuracy: 0.6748 - val_loss: 1.2745 - val_categorical_accuracy: 0.6265\n",
      "Epoch 45/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.0106 - categorical_accuracy: 0.6281Epoch 45: loss = 1.0119121074676514, val_loss = 0.8852734565734863\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 1.0119 - categorical_accuracy: 0.6291 - val_loss: 0.8853 - val_categorical_accuracy: 0.6799\n",
      "Epoch 46/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.8740 - categorical_accuracy: 0.6578Epoch 46: loss = 0.8732292652130127, val_loss = 0.6701698303222656\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.8732 - categorical_accuracy: 0.6573 - val_loss: 0.6702 - val_categorical_accuracy: 0.7614\n",
      "Epoch 47/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.7877 - categorical_accuracy: 0.6812Epoch 47: loss = 0.7957655191421509, val_loss = 1.4398144483566284\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.7958 - categorical_accuracy: 0.6778 - val_loss: 1.4398 - val_categorical_accuracy: 0.5259\n",
      "Epoch 48/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.8635 - categorical_accuracy: 0.4116Epoch 48: loss = 1.8633233308792114, val_loss = 1.2800445556640625\n",
      "42/42 [==============================] - 2s 53ms/step - loss: 1.8633 - categorical_accuracy: 0.4113 - val_loss: 1.2800 - val_categorical_accuracy: 0.5282\n",
      "Epoch 49/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.2224 - categorical_accuracy: 0.5404Epoch 49: loss = 1.2228291034698486, val_loss = 1.0925298929214478\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 1.2228 - categorical_accuracy: 0.5400 - val_loss: 1.0925 - val_categorical_accuracy: 0.6212\n",
      "Epoch 50/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1123 - categorical_accuracy: 0.5880Epoch 50: loss = 1.1123031377792358, val_loss = 1.9257421493530273\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 1.1123 - categorical_accuracy: 0.5880 - val_loss: 1.9257 - val_categorical_accuracy: 0.3742\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 1.9257 - categorical_accuracy: 0.3742\n",
      "Epoch 1/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 3.1612 - categorical_accuracy: 0.0772Epoch 1: loss = 3.158430576324463, val_loss = 2.973609447479248\n",
      "82/82 [==============================] - 10s 77ms/step - loss: 3.1584 - categorical_accuracy: 0.0777 - val_loss: 2.9736 - val_categorical_accuracy: 0.0625\n",
      "Epoch 2/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 3.5114 - categorical_accuracy: 0.1044Epoch 2: loss = 3.5113537311553955, val_loss = 3.3370606899261475\n",
      "82/82 [==============================] - 7s 82ms/step - loss: 3.5114 - categorical_accuracy: 0.1044 - val_loss: 3.3371 - val_categorical_accuracy: 0.1234\n",
      "Epoch 3/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.9458 - categorical_accuracy: 0.1326Epoch 3: loss = 2.9457693099975586, val_loss = 2.511383056640625\n",
      "82/82 [==============================] - 6s 76ms/step - loss: 2.9458 - categorical_accuracy: 0.1326 - val_loss: 2.5114 - val_categorical_accuracy: 0.1127\n",
      "Epoch 4/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.4624 - categorical_accuracy: 0.1728Epoch 4: loss = 2.462555408477783, val_loss = 2.453875780105591\n",
      "82/82 [==============================] - 7s 80ms/step - loss: 2.4626 - categorical_accuracy: 0.1738 - val_loss: 2.4539 - val_categorical_accuracy: 0.1577\n",
      "Epoch 5/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.4051 - categorical_accuracy: 0.1983Epoch 5: loss = 2.399681568145752, val_loss = 2.3215179443359375\n",
      "82/82 [==============================] - 5s 60ms/step - loss: 2.3997 - categorical_accuracy: 0.2012 - val_loss: 2.3215 - val_categorical_accuracy: 0.1447\n",
      "Epoch 6/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.3781 - categorical_accuracy: 0.2052Epoch 6: loss = 2.3812878131866455, val_loss = 2.401954412460327\n",
      "82/82 [==============================] - 5s 64ms/step - loss: 2.3813 - categorical_accuracy: 0.2043 - val_loss: 2.4020 - val_categorical_accuracy: 0.1592\n",
      "Epoch 7/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.4126 - categorical_accuracy: 0.1806Epoch 7: loss = 2.4125566482543945, val_loss = 2.2188239097595215\n",
      "82/82 [==============================] - 5s 62ms/step - loss: 2.4126 - categorical_accuracy: 0.1806 - val_loss: 2.2188 - val_categorical_accuracy: 0.2117\n",
      "Epoch 8/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.0881 - categorical_accuracy: 0.2685Epoch 8: loss = 2.082939386367798, val_loss = 2.102811574935913\n",
      "82/82 [==============================] - 5s 61ms/step - loss: 2.0829 - categorical_accuracy: 0.2691 - val_loss: 2.1028 - val_categorical_accuracy: 0.2567\n",
      "Epoch 9/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.9174 - categorical_accuracy: 0.3148Epoch 9: loss = 1.9172370433807373, val_loss = 2.087733745574951\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 1.9172 - categorical_accuracy: 0.3140 - val_loss: 2.0877 - val_categorical_accuracy: 0.2110\n",
      "Epoch 10/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.7480 - categorical_accuracy: 0.3613Epoch 10: loss = 1.7479615211486816, val_loss = 1.571313738822937\n",
      "82/82 [==============================] - 5s 62ms/step - loss: 1.7480 - categorical_accuracy: 0.3613 - val_loss: 1.5713 - val_categorical_accuracy: 0.4280\n",
      "Epoch 11/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.6132 - categorical_accuracy: 0.3963Epoch 11: loss = 1.6131954193115234, val_loss = 1.446280837059021\n",
      "82/82 [==============================] - 5s 57ms/step - loss: 1.6132 - categorical_accuracy: 0.3963 - val_loss: 1.4463 - val_categorical_accuracy: 0.4752\n",
      "Epoch 12/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.5759 - categorical_accuracy: 0.4131Epoch 12: loss = 1.5759029388427734, val_loss = 1.4501953125\n",
      "82/82 [==============================] - 4s 55ms/step - loss: 1.5759 - categorical_accuracy: 0.4131 - val_loss: 1.4502 - val_categorical_accuracy: 0.4646\n",
      "Epoch 13/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.5127 - categorical_accuracy: 0.4352Epoch 13: loss = 1.5127378702163696, val_loss = 1.429777979850769\n",
      "82/82 [==============================] - 4s 55ms/step - loss: 1.5127 - categorical_accuracy: 0.4352 - val_loss: 1.4298 - val_categorical_accuracy: 0.4547\n",
      "Epoch 14/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.4437 - categorical_accuracy: 0.4665Epoch 14: loss = 1.443699836730957, val_loss = 1.6381926536560059\n",
      "82/82 [==============================] - 5s 56ms/step - loss: 1.4437 - categorical_accuracy: 0.4665 - val_loss: 1.6382 - val_categorical_accuracy: 0.3442\n",
      "Epoch 15/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.3356 - categorical_accuracy: 0.4977Epoch 15: loss = 1.3355884552001953, val_loss = 1.2814781665802002\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 1.3356 - categorical_accuracy: 0.4977 - val_loss: 1.2815 - val_categorical_accuracy: 0.5202\n",
      "Epoch 16/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.1949 - categorical_accuracy: 0.5335Epoch 16: loss = 1.1949089765548706, val_loss = 1.3394465446472168\n",
      "82/82 [==============================] - 5s 61ms/step - loss: 1.1949 - categorical_accuracy: 0.5335 - val_loss: 1.3394 - val_categorical_accuracy: 0.4829\n",
      "Epoch 17/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.1995 - categorical_accuracy: 0.5378Epoch 17: loss = 1.2027573585510254, val_loss = 1.22304105758667\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.2028 - categorical_accuracy: 0.5373 - val_loss: 1.2230 - val_categorical_accuracy: 0.5179\n",
      "Epoch 18/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.3749 - categorical_accuracy: 0.5091Epoch 18: loss = 1.3748610019683838, val_loss = 1.1565779447555542\n",
      "82/82 [==============================] - 5s 59ms/step - loss: 1.3749 - categorical_accuracy: 0.5091 - val_loss: 1.1566 - val_categorical_accuracy: 0.5575\n",
      "Epoch 19/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.1548 - categorical_accuracy: 0.4799Epoch 19: loss = 2.1466610431671143, val_loss = 1.3693289756774902\n",
      "82/82 [==============================] - 5s 59ms/step - loss: 2.1467 - categorical_accuracy: 0.4764 - val_loss: 1.3693 - val_categorical_accuracy: 0.4836\n",
      "Epoch 20/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.3320 - categorical_accuracy: 0.5091Epoch 20: loss = 1.3319848775863647, val_loss = 1.1802587509155273\n",
      "82/82 [==============================] - 5s 59ms/step - loss: 1.3320 - categorical_accuracy: 0.5091 - val_loss: 1.1803 - val_categorical_accuracy: 0.5179\n",
      "Epoch 21/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.1286 - categorical_accuracy: 0.5755Epoch 21: loss = 1.1286474466323853, val_loss = 1.1831177473068237\n",
      "82/82 [==============================] - 5s 58ms/step - loss: 1.1286 - categorical_accuracy: 0.5755 - val_loss: 1.1831 - val_categorical_accuracy: 0.5826\n",
      "Epoch 22/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.0558 - categorical_accuracy: 0.5980Epoch 22: loss = 1.0542986392974854, val_loss = 1.0196330547332764\n",
      "82/82 [==============================] - 4s 55ms/step - loss: 1.0543 - categorical_accuracy: 0.5991 - val_loss: 1.0196 - val_categorical_accuracy: 0.5925\n",
      "Epoch 23/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9446 - categorical_accuracy: 0.6502Epoch 23: loss = 0.9445866942405701, val_loss = 0.9687601327896118\n",
      "82/82 [==============================] - 5s 58ms/step - loss: 0.9446 - categorical_accuracy: 0.6502 - val_loss: 0.9688 - val_categorical_accuracy: 0.6603\n",
      "Epoch 24/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.9028 - categorical_accuracy: 0.6535Epoch 24: loss = 0.9130092859268188, val_loss = 0.972499668598175\n",
      "82/82 [==============================] - 4s 54ms/step - loss: 0.9130 - categorical_accuracy: 0.6494 - val_loss: 0.9725 - val_categorical_accuracy: 0.6352\n",
      "Epoch 25/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.1579 - categorical_accuracy: 0.5934Epoch 25: loss = 1.1573307514190674, val_loss = 1.117581844329834\n",
      "82/82 [==============================] - 5s 56ms/step - loss: 1.1573 - categorical_accuracy: 0.5915 - val_loss: 1.1176 - val_categorical_accuracy: 0.5842\n",
      "Epoch 26/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.0207 - categorical_accuracy: 0.6119Epoch 26: loss = 1.0190049409866333, val_loss = 1.0298389196395874\n",
      "82/82 [==============================] - 5s 56ms/step - loss: 1.0190 - categorical_accuracy: 0.6120 - val_loss: 1.0298 - val_categorical_accuracy: 0.6184\n",
      "Epoch 27/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9207 - categorical_accuracy: 0.6395Epoch 27: loss = 0.9206597805023193, val_loss = 0.8784936666488647\n",
      "82/82 [==============================] - 5s 57ms/step - loss: 0.9207 - categorical_accuracy: 0.6395 - val_loss: 0.8785 - val_categorical_accuracy: 0.6877\n",
      "Epoch 28/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.9507 - categorical_accuracy: 0.6597Epoch 28: loss = 0.950699508190155, val_loss = 1.069164752960205\n",
      "82/82 [==============================] - 4s 54ms/step - loss: 0.9507 - categorical_accuracy: 0.6616 - val_loss: 1.0692 - val_categorical_accuracy: 0.5842\n",
      "Epoch 29/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.8958 - categorical_accuracy: 0.6682Epoch 29: loss = 0.8904343843460083, val_loss = 0.7864161133766174\n",
      "82/82 [==============================] - 4s 55ms/step - loss: 0.8904 - categorical_accuracy: 0.6715 - val_loss: 0.7864 - val_categorical_accuracy: 0.7304\n",
      "Epoch 30/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.7979 - categorical_accuracy: 0.7005Epoch 30: loss = 0.7979047894477844, val_loss = 0.946506142616272\n",
      "82/82 [==============================] - 4s 55ms/step - loss: 0.7979 - categorical_accuracy: 0.7005 - val_loss: 0.9465 - val_categorical_accuracy: 0.6679\n",
      "Epoch 31/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.7626 - categorical_accuracy: 0.7111Epoch 31: loss = 0.7625905871391296, val_loss = 1.5480636358261108\n",
      "82/82 [==============================] - 5s 56ms/step - loss: 0.7626 - categorical_accuracy: 0.7111 - val_loss: 1.5481 - val_categorical_accuracy: 0.5270\n",
      "Epoch 32/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9604 - categorical_accuracy: 0.6471Epoch 32: loss = 0.9603598117828369, val_loss = 0.8564911484718323\n",
      "82/82 [==============================] - 5s 57ms/step - loss: 0.9604 - categorical_accuracy: 0.6471 - val_loss: 0.8565 - val_categorical_accuracy: 0.6938\n",
      "Epoch 33/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.7226 - categorical_accuracy: 0.7361Epoch 33: loss = 0.7267341017723083, val_loss = 0.7491354942321777\n",
      "82/82 [==============================] - 4s 54ms/step - loss: 0.7267 - categorical_accuracy: 0.7340 - val_loss: 0.7491 - val_categorical_accuracy: 0.7251\n",
      "Epoch 34/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.7329 - categorical_accuracy: 0.7446Epoch 34: loss = 0.735520601272583, val_loss = 0.9159443974494934\n",
      "82/82 [==============================] - 5s 57ms/step - loss: 0.7355 - categorical_accuracy: 0.7447 - val_loss: 0.9159 - val_categorical_accuracy: 0.6824\n",
      "Epoch 35/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8095 - categorical_accuracy: 0.7073Epoch 35: loss = 0.8094648122787476, val_loss = 0.8739811182022095\n",
      "82/82 [==============================] - 5s 62ms/step - loss: 0.8095 - categorical_accuracy: 0.7073 - val_loss: 0.8740 - val_categorical_accuracy: 0.6725\n",
      "Epoch 36/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.8230 - categorical_accuracy: 0.7199Epoch 36: loss = 0.8206864595413208, val_loss = 1.3349677324295044\n",
      "82/82 [==============================] - 5s 60ms/step - loss: 0.8207 - categorical_accuracy: 0.7195 - val_loss: 1.3350 - val_categorical_accuracy: 0.5385\n",
      "Epoch 37/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.7706 - categorical_accuracy: 0.6921Epoch 37: loss = 0.7705739736557007, val_loss = 0.7195785641670227\n",
      "82/82 [==============================] - 6s 70ms/step - loss: 0.7706 - categorical_accuracy: 0.6921 - val_loss: 0.7196 - val_categorical_accuracy: 0.7319\n",
      "Epoch 38/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6732 - categorical_accuracy: 0.7553Epoch 38: loss = 0.6731794476509094, val_loss = 0.7369664311408997\n",
      "82/82 [==============================] - 6s 68ms/step - loss: 0.6732 - categorical_accuracy: 0.7553 - val_loss: 0.7370 - val_categorical_accuracy: 0.7327\n",
      "Epoch 39/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6101 - categorical_accuracy: 0.7797Epoch 39: loss = 0.6101400256156921, val_loss = 0.6603508591651917\n",
      "82/82 [==============================] - 6s 77ms/step - loss: 0.6101 - categorical_accuracy: 0.7797 - val_loss: 0.6604 - val_categorical_accuracy: 0.7327\n",
      "Epoch 40/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.6461 - categorical_accuracy: 0.7515Epoch 40: loss = 0.6464590430259705, val_loss = 0.6999514698982239\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 0.6465 - categorical_accuracy: 0.7508 - val_loss: 0.7000 - val_categorical_accuracy: 0.7357\n",
      "Epoch 41/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6466 - categorical_accuracy: 0.7530Epoch 41: loss = 0.6466078162193298, val_loss = 0.6881179213523865\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 0.6466 - categorical_accuracy: 0.7530 - val_loss: 0.6881 - val_categorical_accuracy: 0.7517\n",
      "Epoch 42/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.6523 - categorical_accuracy: 0.7647Epoch 42: loss = 0.649408757686615, val_loss = 0.7945520281791687\n",
      "82/82 [==============================] - 5s 64ms/step - loss: 0.6494 - categorical_accuracy: 0.7652 - val_loss: 0.7946 - val_categorical_accuracy: 0.7258\n",
      "Epoch 43/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.6098 - categorical_accuracy: 0.7793Epoch 43: loss = 0.6098414063453674, val_loss = 0.6801719069480896\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 0.6098 - categorical_accuracy: 0.7805 - val_loss: 0.6802 - val_categorical_accuracy: 0.7601\n",
      "Epoch 44/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5465 - categorical_accuracy: 0.8011Epoch 44: loss = 0.5464927554130554, val_loss = 0.6514943838119507\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 0.5465 - categorical_accuracy: 0.8011 - val_loss: 0.6515 - val_categorical_accuracy: 0.7746\n",
      "Epoch 45/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5346 - categorical_accuracy: 0.8018Epoch 45: loss = 0.5346094369888306, val_loss = 0.6426912546157837\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 0.5346 - categorical_accuracy: 0.8018 - val_loss: 0.6427 - val_categorical_accuracy: 0.7669\n",
      "Epoch 46/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.5775 - categorical_accuracy: 0.7870Epoch 46: loss = 0.5753609538078308, val_loss = 0.6139853596687317\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 0.5754 - categorical_accuracy: 0.7889 - val_loss: 0.6140 - val_categorical_accuracy: 0.7906\n",
      "Epoch 47/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.5482 - categorical_accuracy: 0.7994Epoch 47: loss = 0.5474057793617249, val_loss = 0.5252372622489929\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 0.5474 - categorical_accuracy: 0.8003 - val_loss: 0.5252 - val_categorical_accuracy: 0.8271\n",
      "Epoch 48/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4873 - categorical_accuracy: 0.8178Epoch 48: loss = 0.48732253909111023, val_loss = 0.6531248092651367\n",
      "82/82 [==============================] - 6s 70ms/step - loss: 0.4873 - categorical_accuracy: 0.8178 - val_loss: 0.6531 - val_categorical_accuracy: 0.7730\n",
      "Epoch 49/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4564 - categorical_accuracy: 0.8316Epoch 49: loss = 0.45643240213394165, val_loss = 0.6740939021110535\n",
      "82/82 [==============================] - 6s 70ms/step - loss: 0.4564 - categorical_accuracy: 0.8316 - val_loss: 0.6741 - val_categorical_accuracy: 0.7616\n",
      "Epoch 50/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.7442 - categorical_accuracy: 0.7485Epoch 50: loss = 0.7432215809822083, val_loss = 0.8175492286682129\n",
      "82/82 [==============================] - 6s 70ms/step - loss: 0.7432 - categorical_accuracy: 0.7477 - val_loss: 0.8175 - val_categorical_accuracy: 0.7281\n",
      "42/42 [==============================] - 2s 35ms/step - loss: 0.8175 - categorical_accuracy: 0.7281\n",
      "Epoch 1/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 3.0726 - categorical_accuracy: 0.0808Epoch 1: loss = 3.072495460510254, val_loss = 2.934678316116333\n",
      "83/83 [==============================] - 10s 74ms/step - loss: 3.0725 - categorical_accuracy: 0.0807 - val_loss: 2.9347 - val_categorical_accuracy: 0.0838\n",
      "Epoch 2/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.7471 - categorical_accuracy: 0.0930Epoch 2: loss = 2.7470128536224365, val_loss = 2.567598581314087\n",
      "83/83 [==============================] - 6s 69ms/step - loss: 2.7470 - categorical_accuracy: 0.0929 - val_loss: 2.5676 - val_categorical_accuracy: 0.1067\n",
      "Epoch 3/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.6068 - categorical_accuracy: 0.1136Epoch 3: loss = 2.6066324710845947, val_loss = 2.9033656120300293\n",
      "83/83 [==============================] - 6s 68ms/step - loss: 2.6066 - categorical_accuracy: 0.1135 - val_loss: 2.9034 - val_categorical_accuracy: 0.1098\n",
      "Epoch 4/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.5040 - categorical_accuracy: 0.1410Epoch 4: loss = 2.5027315616607666, val_loss = 3.302016496658325\n",
      "83/83 [==============================] - 8s 91ms/step - loss: 2.5027 - categorical_accuracy: 0.1417 - val_loss: 3.3020 - val_categorical_accuracy: 0.1174\n",
      "Epoch 5/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.3187 - categorical_accuracy: 0.2087Epoch 5: loss = 2.318673610687256, val_loss = 2.275346517562866\n",
      "83/83 [==============================] - 6s 71ms/step - loss: 2.3187 - categorical_accuracy: 0.2087 - val_loss: 2.2753 - val_categorical_accuracy: 0.2325\n",
      "Epoch 6/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.4053 - categorical_accuracy: 0.1959Epoch 6: loss = 2.40555477142334, val_loss = 2.1102795600891113\n",
      "83/83 [==============================] - 6s 78ms/step - loss: 2.4056 - categorical_accuracy: 0.1957 - val_loss: 2.1103 - val_categorical_accuracy: 0.2302\n",
      "Epoch 7/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.0071 - categorical_accuracy: 0.2797Epoch 7: loss = 2.0071511268615723, val_loss = 1.7241237163543701\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 2.0072 - categorical_accuracy: 0.2795 - val_loss: 1.7241 - val_categorical_accuracy: 0.3209\n",
      "Epoch 8/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.8719 - categorical_accuracy: 0.2848Epoch 8: loss = 1.871924877166748, val_loss = 1.7252014875411987\n",
      "83/83 [==============================] - 6s 67ms/step - loss: 1.8719 - categorical_accuracy: 0.2848 - val_loss: 1.7252 - val_categorical_accuracy: 0.3651\n",
      "Epoch 9/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.8925 - categorical_accuracy: 0.2917Epoch 9: loss = 1.8925204277038574, val_loss = 1.7312947511672974\n",
      "83/83 [==============================] - 5s 65ms/step - loss: 1.8925 - categorical_accuracy: 0.2917 - val_loss: 1.7313 - val_categorical_accuracy: 0.3933\n",
      "Epoch 10/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.6560 - categorical_accuracy: 0.3681Epoch 10: loss = 1.6568419933319092, val_loss = 1.755214810371399\n",
      "83/83 [==============================] - 5s 66ms/step - loss: 1.6568 - categorical_accuracy: 0.3679 - val_loss: 1.7552 - val_categorical_accuracy: 0.3605\n",
      "Epoch 11/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.5174 - categorical_accuracy: 0.4455Epoch 11: loss = 1.5174270868301392, val_loss = 1.3285820484161377\n",
      "83/83 [==============================] - 6s 67ms/step - loss: 1.5174 - categorical_accuracy: 0.4455 - val_loss: 1.3286 - val_categorical_accuracy: 0.4474\n",
      "Epoch 12/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.5389 - categorical_accuracy: 0.4280Epoch 12: loss = 1.5388842821121216, val_loss = 1.4482873678207397\n",
      "83/83 [==============================] - 6s 67ms/step - loss: 1.5389 - categorical_accuracy: 0.4280 - val_loss: 1.4483 - val_categorical_accuracy: 0.4566\n",
      "Epoch 13/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.4069 - categorical_accuracy: 0.4497Epoch 13: loss = 1.4065784215927124, val_loss = 1.2261780500411987\n",
      "83/83 [==============================] - 5s 65ms/step - loss: 1.4066 - categorical_accuracy: 0.4501 - val_loss: 1.2262 - val_categorical_accuracy: 0.5511\n",
      "Epoch 14/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.2179 - categorical_accuracy: 0.5232Epoch 14: loss = 1.2179454565048218, val_loss = 1.433519959449768\n",
      "83/83 [==============================] - 6s 75ms/step - loss: 1.2179 - categorical_accuracy: 0.5232 - val_loss: 1.4335 - val_categorical_accuracy: 0.4093\n",
      "Epoch 15/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.1498 - categorical_accuracy: 0.5457Epoch 15: loss = 1.149092197418213, val_loss = 1.0835741758346558\n",
      "83/83 [==============================] - 6s 71ms/step - loss: 1.1491 - categorical_accuracy: 0.5461 - val_loss: 1.0836 - val_categorical_accuracy: 0.5564\n",
      "Epoch 16/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.1232 - categorical_accuracy: 0.5579Epoch 16: loss = 1.123118281364441, val_loss = 0.9184167385101318\n",
      "83/83 [==============================] - 6s 73ms/step - loss: 1.1231 - categorical_accuracy: 0.5575 - val_loss: 0.9184 - val_categorical_accuracy: 0.6319\n",
      "Epoch 17/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.1368 - categorical_accuracy: 0.5655Epoch 17: loss = 1.1359798908233643, val_loss = 0.9299764633178711\n",
      "83/83 [==============================] - 6s 74ms/step - loss: 1.1360 - categorical_accuracy: 0.5659 - val_loss: 0.9300 - val_categorical_accuracy: 0.6593\n",
      "Epoch 18/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.0873 - categorical_accuracy: 0.5808Epoch 18: loss = 1.087070107460022, val_loss = 1.1170432567596436\n",
      "83/83 [==============================] - 7s 82ms/step - loss: 1.0871 - categorical_accuracy: 0.5811 - val_loss: 1.1170 - val_categorical_accuracy: 0.5976\n",
      "Epoch 19/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.1273 - categorical_accuracy: 0.5986Epoch 19: loss = 1.1273157596588135, val_loss = 1.329357624053955\n",
      "83/83 [==============================] - 7s 80ms/step - loss: 1.1273 - categorical_accuracy: 0.5986 - val_loss: 1.3294 - val_categorical_accuracy: 0.6311\n",
      "Epoch 20/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.9247 - categorical_accuracy: 0.6291Epoch 20: loss = 0.9247068166732788, val_loss = 0.8826082944869995\n",
      "83/83 [==============================] - 7s 81ms/step - loss: 0.9247 - categorical_accuracy: 0.6291 - val_loss: 0.8826 - val_categorical_accuracy: 0.6814\n",
      "Epoch 21/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.8986 - categorical_accuracy: 0.6441Epoch 21: loss = 0.8981104493141174, val_loss = 0.7822179198265076\n",
      "83/83 [==============================] - 7s 86ms/step - loss: 0.8981 - categorical_accuracy: 0.6443 - val_loss: 0.7822 - val_categorical_accuracy: 0.6829\n",
      "Epoch 22/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.8633 - categorical_accuracy: 0.5076Epoch 22: loss = 1.863257646560669, val_loss = 3.38366961479187\n",
      "83/83 [==============================] - 7s 91ms/step - loss: 1.8633 - categorical_accuracy: 0.5072 - val_loss: 3.3837 - val_categorical_accuracy: 0.1067\n",
      "Epoch 23/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.8870 - categorical_accuracy: 0.3529Epoch 23: loss = 1.8870618343353271, val_loss = 1.1573786735534668\n",
      "83/83 [==============================] - 7s 80ms/step - loss: 1.8871 - categorical_accuracy: 0.3526 - val_loss: 1.1574 - val_categorical_accuracy: 0.5686\n",
      "Epoch 24/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.0137 - categorical_accuracy: 0.4108Epoch 24: loss = 2.01446270942688, val_loss = 1.457846999168396\n",
      "83/83 [==============================] - 8s 91ms/step - loss: 2.0145 - categorical_accuracy: 0.4105 - val_loss: 1.4578 - val_categorical_accuracy: 0.4680\n",
      "Epoch 25/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.2813 - categorical_accuracy: 0.5473Epoch 25: loss = 1.2833837270736694, val_loss = 1.1951631307601929\n",
      "83/83 [==============================] - 8s 92ms/step - loss: 1.2834 - categorical_accuracy: 0.5468 - val_loss: 1.1952 - val_categorical_accuracy: 0.5640\n",
      "Epoch 26/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.1500 - categorical_accuracy: 0.5811Epoch 26: loss = 1.149969458580017, val_loss = 0.9979923367500305\n",
      "83/83 [==============================] - 6s 75ms/step - loss: 1.1500 - categorical_accuracy: 0.5811 - val_loss: 0.9980 - val_categorical_accuracy: 0.6486\n",
      "Epoch 27/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.9188 - categorical_accuracy: 0.6715Epoch 27: loss = 0.9184166789054871, val_loss = 0.9105167984962463\n",
      "83/83 [==============================] - 7s 79ms/step - loss: 0.9184 - categorical_accuracy: 0.6717 - val_loss: 0.9105 - val_categorical_accuracy: 0.6837\n",
      "Epoch 28/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.8984 - categorical_accuracy: 0.6441Epoch 28: loss = 0.9009556174278259, val_loss = 0.727806806564331\n",
      "83/83 [==============================] - 7s 84ms/step - loss: 0.9010 - categorical_accuracy: 0.6436 - val_loss: 0.7278 - val_categorical_accuracy: 0.7165\n",
      "Epoch 29/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.8355 - categorical_accuracy: 0.6921Epoch 29: loss = 0.8351990580558777, val_loss = 0.8107932209968567\n",
      "83/83 [==============================] - 7s 79ms/step - loss: 0.8352 - categorical_accuracy: 0.6923 - val_loss: 0.8108 - val_categorical_accuracy: 0.6905\n",
      "Epoch 30/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.7755 - categorical_accuracy: 0.7012Epoch 30: loss = 0.7749550342559814, val_loss = 0.7193771004676819\n",
      "83/83 [==============================] - 6s 71ms/step - loss: 0.7750 - categorical_accuracy: 0.7014 - val_loss: 0.7194 - val_categorical_accuracy: 0.7210\n",
      "Epoch 31/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 5.7861 - categorical_accuracy: 0.4527Epoch 31: loss = 5.783625602722168, val_loss = 2.5906882286071777\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 5.7836 - categorical_accuracy: 0.4524 - val_loss: 2.5907 - val_categorical_accuracy: 0.1258\n",
      "Epoch 32/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.6151 - categorical_accuracy: 0.1500Epoch 32: loss = 2.6151485443115234, val_loss = 2.6008965969085693\n",
      "83/83 [==============================] - 6s 68ms/step - loss: 2.6151 - categorical_accuracy: 0.1500 - val_loss: 2.6009 - val_categorical_accuracy: 0.1151\n",
      "Epoch 33/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.3346 - categorical_accuracy: 0.2262Epoch 33: loss = 2.334599018096924, val_loss = 2.071634292602539\n",
      "83/83 [==============================] - 6s 69ms/step - loss: 2.3346 - categorical_accuracy: 0.2262 - val_loss: 2.0716 - val_categorical_accuracy: 0.3079\n",
      "Epoch 34/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.0686 - categorical_accuracy: 0.2530Epoch 34: loss = 2.068279981613159, val_loss = 2.1947526931762695\n",
      "83/83 [==============================] - 5s 65ms/step - loss: 2.0683 - categorical_accuracy: 0.2529 - val_loss: 2.1948 - val_categorical_accuracy: 0.1951\n",
      "Epoch 35/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.4005 - categorical_accuracy: 0.1997Epoch 35: loss = 2.4000813961029053, val_loss = 2.064894914627075\n",
      "83/83 [==============================] - 6s 68ms/step - loss: 2.4001 - categorical_accuracy: 0.2003 - val_loss: 2.0649 - val_categorical_accuracy: 0.2843\n",
      "Epoch 36/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.0153 - categorical_accuracy: 0.2812Epoch 36: loss = 2.015470027923584, val_loss = 1.8032965660095215\n",
      "83/83 [==============================] - 5s 64ms/step - loss: 2.0155 - categorical_accuracy: 0.2810 - val_loss: 1.8033 - val_categorical_accuracy: 0.3628\n",
      "Epoch 37/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.8806 - categorical_accuracy: 0.3316Epoch 37: loss = 1.8810949325561523, val_loss = 1.643401861190796\n",
      "83/83 [==============================] - 5s 65ms/step - loss: 1.8811 - categorical_accuracy: 0.3313 - val_loss: 1.6434 - val_categorical_accuracy: 0.4085\n",
      "Epoch 38/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.8241 - categorical_accuracy: 0.3460Epoch 38: loss = 1.8239679336547852, val_loss = 1.6728575229644775\n",
      "83/83 [==============================] - 6s 74ms/step - loss: 1.8240 - categorical_accuracy: 0.3465 - val_loss: 1.6729 - val_categorical_accuracy: 0.4436\n",
      "Epoch 39/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.6770 - categorical_accuracy: 0.4146Epoch 39: loss = 1.6775257587432861, val_loss = 1.3634198904037476\n",
      "83/83 [==============================] - 6s 74ms/step - loss: 1.6775 - categorical_accuracy: 0.4143 - val_loss: 1.3634 - val_categorical_accuracy: 0.5503\n",
      "Epoch 40/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.5827 - categorical_accuracy: 0.4398Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 40: loss = 1.5821754932403564, val_loss = 1.2795530557632446\n",
      "83/83 [==============================] - 6s 74ms/step - loss: 1.5822 - categorical_accuracy: 0.4402 - val_loss: 1.2796 - val_categorical_accuracy: 0.5465\n",
      "Epoch 40: early stopping\n",
      "41/41 [==============================] - 2s 34ms/step - loss: 0.7194 - categorical_accuracy: 0.7210\n",
      "Epoch 1/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 3.1444 - categorical_accuracy: 0.0640Epoch 1: loss = 3.1443674564361572, val_loss = 3.044358015060425\n",
      "82/82 [==============================] - 9s 69ms/step - loss: 3.1444 - categorical_accuracy: 0.0640 - val_loss: 3.0444 - val_categorical_accuracy: 0.1028\n",
      "Epoch 2/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.8662 - categorical_accuracy: 0.1166Epoch 2: loss = 2.8662102222442627, val_loss = 2.517054557800293\n",
      "82/82 [==============================] - 5s 62ms/step - loss: 2.8662 - categorical_accuracy: 0.1166 - val_loss: 2.5171 - val_categorical_accuracy: 0.1165\n",
      "Epoch 3/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.5267 - categorical_accuracy: 0.1636Epoch 3: loss = 2.525029182434082, val_loss = 2.371565103530884\n",
      "82/82 [==============================] - 5s 59ms/step - loss: 2.5250 - categorical_accuracy: 0.1639 - val_loss: 2.3716 - val_categorical_accuracy: 0.1523\n",
      "Epoch 4/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.3754 - categorical_accuracy: 0.2027Epoch 4: loss = 2.375365734100342, val_loss = 2.294908046722412\n",
      "82/82 [==============================] - 5s 58ms/step - loss: 2.3754 - categorical_accuracy: 0.2027 - val_loss: 2.2949 - val_categorical_accuracy: 0.1485\n",
      "Epoch 5/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.2198 - categorical_accuracy: 0.2253Epoch 5: loss = 2.217349052429199, val_loss = 2.390470266342163\n",
      "82/82 [==============================] - 5s 60ms/step - loss: 2.2173 - categorical_accuracy: 0.2264 - val_loss: 2.3905 - val_categorical_accuracy: 0.1904\n",
      "Epoch 6/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.4997 - categorical_accuracy: 0.2346Epoch 6: loss = 2.498595952987671, val_loss = 2.116889715194702\n",
      "82/82 [==============================] - 5s 59ms/step - loss: 2.4986 - categorical_accuracy: 0.2332 - val_loss: 2.1169 - val_categorical_accuracy: 0.2178\n",
      "Epoch 7/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.0040 - categorical_accuracy: 0.2858Epoch 7: loss = 2.004033088684082, val_loss = 1.827298879623413\n",
      "82/82 [==============================] - 5s 58ms/step - loss: 2.0040 - categorical_accuracy: 0.2858 - val_loss: 1.8273 - val_categorical_accuracy: 0.3031\n",
      "Epoch 8/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.8258 - categorical_accuracy: 0.3270Epoch 8: loss = 1.8257927894592285, val_loss = 1.670580506324768\n",
      "82/82 [==============================] - 5s 58ms/step - loss: 1.8258 - categorical_accuracy: 0.3270 - val_loss: 1.6706 - val_categorical_accuracy: 0.3854\n",
      "Epoch 9/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.5891 - categorical_accuracy: 0.3994Epoch 9: loss = 1.58913254737854, val_loss = 1.5575388669967651\n",
      "82/82 [==============================] - 5s 58ms/step - loss: 1.5891 - categorical_accuracy: 0.3994 - val_loss: 1.5575 - val_categorical_accuracy: 0.4120\n",
      "Epoch 10/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.5304 - categorical_accuracy: 0.4405Epoch 10: loss = 1.5304337739944458, val_loss = 1.7266125679016113\n",
      "82/82 [==============================] - 5s 59ms/step - loss: 1.5304 - categorical_accuracy: 0.4405 - val_loss: 1.7266 - val_categorical_accuracy: 0.3618\n",
      "Epoch 11/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.5302 - categorical_accuracy: 0.4352Epoch 11: loss = 1.5288808345794678, val_loss = 1.5070890188217163\n",
      "82/82 [==============================] - 5s 57ms/step - loss: 1.5289 - categorical_accuracy: 0.4360 - val_loss: 1.5071 - val_categorical_accuracy: 0.4699\n",
      "Epoch 12/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.4326 - categorical_accuracy: 0.4815Epoch 12: loss = 1.4303656816482544, val_loss = 1.338447093963623\n",
      "82/82 [==============================] - 5s 58ms/step - loss: 1.4304 - categorical_accuracy: 0.4794 - val_loss: 1.3384 - val_categorical_accuracy: 0.4912\n",
      "Epoch 13/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.1850 - categorical_accuracy: 0.5756Epoch 13: loss = 1.1901988983154297, val_loss = 1.1979395151138306\n",
      "82/82 [==============================] - 5s 57ms/step - loss: 1.1902 - categorical_accuracy: 0.5732 - val_loss: 1.1979 - val_categorical_accuracy: 0.5461\n",
      "Epoch 14/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.3274 - categorical_accuracy: 0.5340Epoch 14: loss = 1.3220964670181274, val_loss = 1.1956491470336914\n",
      "82/82 [==============================] - 5s 58ms/step - loss: 1.3221 - categorical_accuracy: 0.5366 - val_loss: 1.1956 - val_categorical_accuracy: 0.6268\n",
      "Epoch 15/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.2222 - categorical_accuracy: 0.5610Epoch 15: loss = 1.2220381498336792, val_loss = 1.1341395378112793\n",
      "82/82 [==============================] - 5s 60ms/step - loss: 1.2220 - categorical_accuracy: 0.5602 - val_loss: 1.1341 - val_categorical_accuracy: 0.5918\n",
      "Epoch 16/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.2494 - categorical_accuracy: 0.5363Epoch 16: loss = 1.2424330711364746, val_loss = 1.1225824356079102\n",
      "82/82 [==============================] - 5s 58ms/step - loss: 1.2424 - categorical_accuracy: 0.5404 - val_loss: 1.1226 - val_categorical_accuracy: 0.5918\n",
      "Epoch 17/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.0650 - categorical_accuracy: 0.6082Epoch 17: loss = 1.0649806261062622, val_loss = 0.9295446872711182\n",
      "82/82 [==============================] - 5s 59ms/step - loss: 1.0650 - categorical_accuracy: 0.6082 - val_loss: 0.9295 - val_categorical_accuracy: 0.6573\n",
      "Epoch 18/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.0047 - categorical_accuracy: 0.6327Epoch 18: loss = 1.0139505863189697, val_loss = 0.9221265912055969\n",
      "82/82 [==============================] - 5s 57ms/step - loss: 1.0140 - categorical_accuracy: 0.6311 - val_loss: 0.9221 - val_categorical_accuracy: 0.6611\n",
      "Epoch 19/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.0049 - categorical_accuracy: 0.6387Epoch 19: loss = 1.0049309730529785, val_loss = 0.9137493968009949\n",
      "82/82 [==============================] - 5s 58ms/step - loss: 1.0049 - categorical_accuracy: 0.6387 - val_loss: 0.9137 - val_categorical_accuracy: 0.6756\n",
      "Epoch 20/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9271 - categorical_accuracy: 0.6608Epoch 20: loss = 0.9270968437194824, val_loss = 1.1353179216384888\n",
      "82/82 [==============================] - 5s 60ms/step - loss: 0.9271 - categorical_accuracy: 0.6608 - val_loss: 1.1353 - val_categorical_accuracy: 0.6085\n",
      "Epoch 21/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.3189 - categorical_accuracy: 0.5903Epoch 21: loss = 1.3255455493927002, val_loss = 1.8951119184494019\n",
      "82/82 [==============================] - 5s 59ms/step - loss: 1.3255 - categorical_accuracy: 0.5854 - val_loss: 1.8951 - val_categorical_accuracy: 0.3054\n",
      "Epoch 22/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.7409 - categorical_accuracy: 0.3651Epoch 22: loss = 1.7409368753433228, val_loss = 1.6644864082336426\n",
      "82/82 [==============================] - 5s 59ms/step - loss: 1.7409 - categorical_accuracy: 0.3651 - val_loss: 1.6645 - val_categorical_accuracy: 0.3420\n",
      "Epoch 23/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.6686 - categorical_accuracy: 0.3681Epoch 23: loss = 1.6661138534545898, val_loss = 1.5880590677261353\n",
      "82/82 [==============================] - 5s 58ms/step - loss: 1.6661 - categorical_accuracy: 0.3689 - val_loss: 1.5881 - val_categorical_accuracy: 0.3831\n",
      "Epoch 24/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.5597 - categorical_accuracy: 0.4108Epoch 24: loss = 1.5597234964370728, val_loss = 1.4983341693878174\n",
      "82/82 [==============================] - 5s 59ms/step - loss: 1.5597 - categorical_accuracy: 0.4108 - val_loss: 1.4983 - val_categorical_accuracy: 0.4242\n",
      "Epoch 25/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.4496 - categorical_accuracy: 0.4437Epoch 25: loss = 1.452219009399414, val_loss = 1.3440567255020142\n",
      "82/82 [==============================] - 5s 59ms/step - loss: 1.4522 - categorical_accuracy: 0.4421 - val_loss: 1.3441 - val_categorical_accuracy: 0.4874\n",
      "Epoch 26/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.3995 - categorical_accuracy: 0.4588Epoch 26: loss = 1.3994598388671875, val_loss = 1.3782587051391602\n",
      "82/82 [==============================] - 5s 59ms/step - loss: 1.3995 - categorical_accuracy: 0.4588 - val_loss: 1.3783 - val_categorical_accuracy: 0.4585\n",
      "Epoch 27/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.2824 - categorical_accuracy: 0.5123Epoch 27: loss = 1.2826619148254395, val_loss = 1.2313281297683716\n",
      "82/82 [==============================] - 5s 60ms/step - loss: 1.2827 - categorical_accuracy: 0.5122 - val_loss: 1.2313 - val_categorical_accuracy: 0.5339\n",
      "Epoch 28/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.2655 - categorical_accuracy: 0.5053Epoch 28: loss = 1.2655192613601685, val_loss = 1.1991459131240845\n",
      "82/82 [==============================] - 5s 58ms/step - loss: 1.2655 - categorical_accuracy: 0.5053 - val_loss: 1.1991 - val_categorical_accuracy: 0.5659\n",
      "Epoch 29/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.2080 - categorical_accuracy: 0.5183Restoring model weights from the end of the best epoch: 19.\n",
      "Epoch 29: loss = 1.2080118656158447, val_loss = 1.3388242721557617\n",
      "82/82 [==============================] - 5s 58ms/step - loss: 1.2080 - categorical_accuracy: 0.5183 - val_loss: 1.3388 - val_categorical_accuracy: 0.4821\n",
      "Epoch 29: early stopping\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.9137 - categorical_accuracy: 0.6756\n",
      "Epoch 1/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 3.1379 - categorical_accuracy: 0.0610Epoch 1: loss = 3.138195753097534, val_loss = 2.946937322616577\n",
      "83/83 [==============================] - 11s 84ms/step - loss: 3.1382 - categorical_accuracy: 0.0609 - val_loss: 2.9469 - val_categorical_accuracy: 0.0747\n",
      "Epoch 2/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.7161 - categorical_accuracy: 0.1090Epoch 2: loss = 2.716233015060425, val_loss = 2.4802193641662598\n",
      "83/83 [==============================] - 7s 86ms/step - loss: 2.7162 - categorical_accuracy: 0.1089 - val_loss: 2.4802 - val_categorical_accuracy: 0.1204\n",
      "Epoch 3/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.5687 - categorical_accuracy: 0.1235Epoch 3: loss = 2.568608522415161, val_loss = 2.400078058242798\n",
      "83/83 [==============================] - 8s 94ms/step - loss: 2.5686 - categorical_accuracy: 0.1234 - val_loss: 2.4001 - val_categorical_accuracy: 0.1509\n",
      "Epoch 4/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.5097 - categorical_accuracy: 0.1349Epoch 4: loss = 2.5093770027160645, val_loss = 2.144087553024292\n",
      "83/83 [==============================] - 7s 80ms/step - loss: 2.5094 - categorical_accuracy: 0.1348 - val_loss: 2.1441 - val_categorical_accuracy: 0.1951\n",
      "Epoch 5/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.2501 - categorical_accuracy: 0.1973Epoch 5: loss = 2.2501094341278076, val_loss = 2.2954859733581543\n",
      "83/83 [==============================] - 6s 74ms/step - loss: 2.2501 - categorical_accuracy: 0.1973 - val_loss: 2.2955 - val_categorical_accuracy: 0.1608\n",
      "Epoch 6/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 3.5380 - categorical_accuracy: 0.1889Epoch 6: loss = 3.5379908084869385, val_loss = 2.384502410888672\n",
      "83/83 [==============================] - 6s 67ms/step - loss: 3.5380 - categorical_accuracy: 0.1889 - val_loss: 2.3845 - val_categorical_accuracy: 0.1524\n",
      "Epoch 7/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.2130 - categorical_accuracy: 0.1982Epoch 7: loss = 2.212970018386841, val_loss = 1.9645094871520996\n",
      "83/83 [==============================] - 6s 68ms/step - loss: 2.2130 - categorical_accuracy: 0.1980 - val_loss: 1.9645 - val_categorical_accuracy: 0.2309\n",
      "Epoch 8/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.9401 - categorical_accuracy: 0.2752Epoch 8: loss = 1.9402437210083008, val_loss = 2.731738328933716\n",
      "83/83 [==============================] - 6s 67ms/step - loss: 1.9402 - categorical_accuracy: 0.2749 - val_loss: 2.7317 - val_categorical_accuracy: 0.1006\n",
      "Epoch 9/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.0098 - categorical_accuracy: 0.2848Epoch 9: loss = 2.0098047256469727, val_loss = 1.88589608669281\n",
      "83/83 [==============================] - 6s 69ms/step - loss: 2.0098 - categorical_accuracy: 0.2848 - val_loss: 1.8859 - val_categorical_accuracy: 0.2950\n",
      "Epoch 10/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.2785 - categorical_accuracy: 0.2119Epoch 10: loss = 2.28096866607666, val_loss = 2.8748250007629395\n",
      "83/83 [==============================] - 6s 68ms/step - loss: 2.2810 - categorical_accuracy: 0.2117 - val_loss: 2.8748 - val_categorical_accuracy: 0.2271\n",
      "Epoch 11/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.9856 - categorical_accuracy: 0.2607Epoch 11: loss = 1.9858417510986328, val_loss = 1.7953569889068604\n",
      "83/83 [==============================] - 6s 68ms/step - loss: 1.9858 - categorical_accuracy: 0.2605 - val_loss: 1.7954 - val_categorical_accuracy: 0.2851\n",
      "Epoch 12/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.8895 - categorical_accuracy: 0.2843Epoch 12: loss = 1.889469027519226, val_loss = 1.8766320943832397\n",
      "83/83 [==============================] - 6s 70ms/step - loss: 1.8895 - categorical_accuracy: 0.2841 - val_loss: 1.8766 - val_categorical_accuracy: 0.2409\n",
      "Epoch 13/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.7017 - categorical_accuracy: 0.3526Epoch 13: loss = 1.701716661453247, val_loss = 1.467894434928894\n",
      "83/83 [==============================] - 6s 68ms/step - loss: 1.7017 - categorical_accuracy: 0.3526 - val_loss: 1.4679 - val_categorical_accuracy: 0.4428\n",
      "Epoch 14/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.5217 - categorical_accuracy: 0.4417Epoch 14: loss = 1.5217421054840088, val_loss = 1.7707135677337646\n",
      "83/83 [==============================] - 6s 69ms/step - loss: 1.5217 - categorical_accuracy: 0.4417 - val_loss: 1.7707 - val_categorical_accuracy: 0.3255\n",
      "Epoch 15/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.4938 - categorical_accuracy: 0.4444Epoch 15: loss = 1.492655634880066, val_loss = 1.2711615562438965\n",
      "83/83 [==============================] - 6s 67ms/step - loss: 1.4927 - categorical_accuracy: 0.4448 - val_loss: 1.2712 - val_categorical_accuracy: 0.5450\n",
      "Epoch 16/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.4246 - categorical_accuracy: 0.4444Epoch 16: loss = 1.4248154163360596, val_loss = 1.3828809261322021\n",
      "83/83 [==============================] - 6s 69ms/step - loss: 1.4248 - categorical_accuracy: 0.4440 - val_loss: 1.3829 - val_categorical_accuracy: 0.4733\n",
      "Epoch 17/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.2592 - categorical_accuracy: 0.5099Epoch 17: loss = 1.2599290609359741, val_loss = 1.6744384765625\n",
      "83/83 [==============================] - 7s 79ms/step - loss: 1.2599 - categorical_accuracy: 0.5095 - val_loss: 1.6744 - val_categorical_accuracy: 0.3529\n",
      "Epoch 18/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.4100 - categorical_accuracy: 0.4886Epoch 18: loss = 1.410544753074646, val_loss = 1.2156580686569214\n",
      "83/83 [==============================] - 7s 80ms/step - loss: 1.4105 - categorical_accuracy: 0.4882 - val_loss: 1.2157 - val_categorical_accuracy: 0.5488\n",
      "Epoch 19/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.1492 - categorical_accuracy: 0.5522Epoch 19: loss = 1.1492146253585815, val_loss = 0.9454730749130249\n",
      "83/83 [==============================] - 6s 69ms/step - loss: 1.1492 - categorical_accuracy: 0.5522 - val_loss: 0.9455 - val_categorical_accuracy: 0.6463\n",
      "Epoch 20/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.1712 - categorical_accuracy: 0.5587Epoch 20: loss = 1.1718295812606812, val_loss = 1.0694427490234375\n",
      "83/83 [==============================] - 6s 69ms/step - loss: 1.1718 - categorical_accuracy: 0.5590 - val_loss: 1.0694 - val_categorical_accuracy: 0.5884\n",
      "Epoch 21/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.1099 - categorical_accuracy: 0.5610Epoch 21: loss = 1.110456943511963, val_loss = 1.0324645042419434\n",
      "83/83 [==============================] - 6s 69ms/step - loss: 1.1105 - categorical_accuracy: 0.5605 - val_loss: 1.0325 - val_categorical_accuracy: 0.6082\n",
      "Epoch 22/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.0953 - categorical_accuracy: 0.6037Epoch 22: loss = 1.0946210622787476, val_loss = 0.9935453534126282\n",
      "83/83 [==============================] - 8s 94ms/step - loss: 1.0946 - categorical_accuracy: 0.6040 - val_loss: 0.9935 - val_categorical_accuracy: 0.6364\n",
      "Epoch 23/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.0010 - categorical_accuracy: 0.6319Epoch 23: loss = 1.0017518997192383, val_loss = 0.9638365507125854\n",
      "83/83 [==============================] - 7s 79ms/step - loss: 1.0018 - categorical_accuracy: 0.6314 - val_loss: 0.9638 - val_categorical_accuracy: 0.6326\n",
      "Epoch 24/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.0092 - categorical_accuracy: 0.6075Epoch 24: loss = 1.0084336996078491, val_loss = 0.9391298294067383\n",
      "83/83 [==============================] - 6s 70ms/step - loss: 1.0084 - categorical_accuracy: 0.6078 - val_loss: 0.9391 - val_categorical_accuracy: 0.6341\n",
      "Epoch 25/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.9892 - categorical_accuracy: 0.6220Epoch 25: loss = 0.9885210990905762, val_loss = 0.8151835203170776\n",
      "83/83 [==============================] - 6s 71ms/step - loss: 0.9885 - categorical_accuracy: 0.6222 - val_loss: 0.8152 - val_categorical_accuracy: 0.6928\n",
      "Epoch 26/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.9124 - categorical_accuracy: 0.6352Epoch 26: loss = 0.9123536944389343, val_loss = 0.8223456144332886\n",
      "83/83 [==============================] - 6s 70ms/step - loss: 0.9124 - categorical_accuracy: 0.6352 - val_loss: 0.8223 - val_categorical_accuracy: 0.7020\n",
      "Epoch 27/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.8855 - categorical_accuracy: 0.6608Epoch 27: loss = 0.8848675489425659, val_loss = 0.9273205399513245\n",
      "83/83 [==============================] - 6s 71ms/step - loss: 0.8849 - categorical_accuracy: 0.6611 - val_loss: 0.9273 - val_categorical_accuracy: 0.6402\n",
      "Epoch 28/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.8756 - categorical_accuracy: 0.6806Epoch 28: loss = 0.8751883506774902, val_loss = 0.9268922805786133\n",
      "83/83 [==============================] - 6s 71ms/step - loss: 0.8752 - categorical_accuracy: 0.6809 - val_loss: 0.9269 - val_categorical_accuracy: 0.6692\n",
      "Epoch 29/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.8909 - categorical_accuracy: 0.6443Epoch 29: loss = 0.8909422159194946, val_loss = 0.7894158959388733\n",
      "83/83 [==============================] - 6s 77ms/step - loss: 0.8909 - categorical_accuracy: 0.6443 - val_loss: 0.7894 - val_categorical_accuracy: 0.7241\n",
      "Epoch 30/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.7696 - categorical_accuracy: 0.6944Epoch 30: loss = 0.7706255316734314, val_loss = 0.8981921672821045\n",
      "83/83 [==============================] - 6s 73ms/step - loss: 0.7706 - categorical_accuracy: 0.6938 - val_loss: 0.8982 - val_categorical_accuracy: 0.6944\n",
      "Epoch 31/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.3262 - categorical_accuracy: 0.5755Epoch 31: loss = 1.3258037567138672, val_loss = 1.3465585708618164\n",
      "83/83 [==============================] - 6s 69ms/step - loss: 1.3258 - categorical_accuracy: 0.5758 - val_loss: 1.3466 - val_categorical_accuracy: 0.5396\n",
      "Epoch 32/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.0810 - categorical_accuracy: 0.6037Epoch 32: loss = 1.0802699327468872, val_loss = 0.8338168263435364\n",
      "83/83 [==============================] - 6s 77ms/step - loss: 1.0803 - categorical_accuracy: 0.6040 - val_loss: 0.8338 - val_categorical_accuracy: 0.6944\n",
      "Epoch 33/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.9217 - categorical_accuracy: 0.6524Epoch 33: loss = 0.9210216403007507, val_loss = 0.7708190679550171\n",
      "83/83 [==============================] - 6s 75ms/step - loss: 0.9210 - categorical_accuracy: 0.6527 - val_loss: 0.7708 - val_categorical_accuracy: 0.7104\n",
      "Epoch 34/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.7794 - categorical_accuracy: 0.7119Epoch 34: loss = 0.778769850730896, val_loss = 0.7694728374481201\n",
      "83/83 [==============================] - 6s 69ms/step - loss: 0.7788 - categorical_accuracy: 0.7121 - val_loss: 0.7695 - val_categorical_accuracy: 0.7348\n",
      "Epoch 35/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.7165 - categorical_accuracy: 0.7289Epoch 35: loss = 0.7164873480796814, val_loss = 0.8384118676185608\n",
      "83/83 [==============================] - 5s 62ms/step - loss: 0.7165 - categorical_accuracy: 0.7289 - val_loss: 0.8384 - val_categorical_accuracy: 0.6852\n",
      "Epoch 36/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.7212 - categorical_accuracy: 0.7241Epoch 36: loss = 0.7223227620124817, val_loss = 0.8075554966926575\n",
      "83/83 [==============================] - 5s 62ms/step - loss: 0.7223 - categorical_accuracy: 0.7235 - val_loss: 0.8076 - val_categorical_accuracy: 0.7584\n",
      "Epoch 37/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.6587 - categorical_accuracy: 0.4631Epoch 37: loss = 1.6587401628494263, val_loss = 1.0933712720870972\n",
      "83/83 [==============================] - 5s 63ms/step - loss: 1.6587 - categorical_accuracy: 0.4631 - val_loss: 1.0934 - val_categorical_accuracy: 0.6479\n",
      "Epoch 38/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.1376 - categorical_accuracy: 0.5895Epoch 38: loss = 1.1376458406448364, val_loss = 1.2033729553222656\n",
      "83/83 [==============================] - 5s 62ms/step - loss: 1.1376 - categorical_accuracy: 0.5895 - val_loss: 1.2034 - val_categorical_accuracy: 0.5640\n",
      "Epoch 39/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.8271 - categorical_accuracy: 0.6824Epoch 39: loss = 0.8271180391311646, val_loss = 0.7637052536010742\n",
      "83/83 [==============================] - 5s 59ms/step - loss: 0.8271 - categorical_accuracy: 0.6824 - val_loss: 0.7637 - val_categorical_accuracy: 0.7233\n",
      "Epoch 40/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.7574 - categorical_accuracy: 0.6984Epoch 40: loss = 0.7573691010475159, val_loss = 0.6557947993278503\n",
      "83/83 [==============================] - 5s 59ms/step - loss: 0.7574 - categorical_accuracy: 0.6984 - val_loss: 0.6558 - val_categorical_accuracy: 0.7584\n",
      "Epoch 41/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.6807 - categorical_accuracy: 0.7409Epoch 41: loss = 0.6802158951759338, val_loss = 0.6392961144447327\n",
      "83/83 [==============================] - 5s 59ms/step - loss: 0.6802 - categorical_accuracy: 0.7411 - val_loss: 0.6393 - val_categorical_accuracy: 0.7713\n",
      "Epoch 42/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.6804 - categorical_accuracy: 0.7289Epoch 42: loss = 0.6803902387619019, val_loss = 0.7157877683639526\n",
      "83/83 [==============================] - 5s 59ms/step - loss: 0.6804 - categorical_accuracy: 0.7289 - val_loss: 0.7158 - val_categorical_accuracy: 0.7340\n",
      "Epoch 43/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.6218 - categorical_accuracy: 0.7508Epoch 43: loss = 0.6213732361793518, val_loss = 0.7032285332679749\n",
      "83/83 [==============================] - 5s 58ms/step - loss: 0.6214 - categorical_accuracy: 0.7510 - val_loss: 0.7032 - val_categorical_accuracy: 0.7332\n",
      "Epoch 44/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.6540 - categorical_accuracy: 0.7464Epoch 44: loss = 0.6540151834487915, val_loss = 0.6052730083465576\n",
      "83/83 [==============================] - 6s 67ms/step - loss: 0.6540 - categorical_accuracy: 0.7464 - val_loss: 0.6053 - val_categorical_accuracy: 0.7736\n",
      "Epoch 45/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.6925 - categorical_accuracy: 0.7334Epoch 45: loss = 0.6924792528152466, val_loss = 0.6567547917366028\n",
      "83/83 [==============================] - 5s 59ms/step - loss: 0.6925 - categorical_accuracy: 0.7334 - val_loss: 0.6568 - val_categorical_accuracy: 0.7569\n",
      "Epoch 46/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.6172 - categorical_accuracy: 0.7713Epoch 46: loss = 0.6168755292892456, val_loss = 0.6212313175201416\n",
      "83/83 [==============================] - 5s 59ms/step - loss: 0.6169 - categorical_accuracy: 0.7715 - val_loss: 0.6212 - val_categorical_accuracy: 0.7637\n",
      "Epoch 47/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.6384 - categorical_accuracy: 0.7525Epoch 47: loss = 0.6383528709411621, val_loss = 1.057202696800232\n",
      "83/83 [==============================] - 5s 58ms/step - loss: 0.6384 - categorical_accuracy: 0.7525 - val_loss: 1.0572 - val_categorical_accuracy: 0.6540\n",
      "Epoch 48/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.6279 - categorical_accuracy: 0.7494Epoch 48: loss = 0.627907931804657, val_loss = 0.566288411617279\n",
      "83/83 [==============================] - 5s 59ms/step - loss: 0.6279 - categorical_accuracy: 0.7494 - val_loss: 0.5663 - val_categorical_accuracy: 0.7995\n",
      "Epoch 49/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.5811 - categorical_accuracy: 0.7630Epoch 49: loss = 0.5813137292861938, val_loss = 0.7100035548210144\n",
      "83/83 [==============================] - 5s 59ms/step - loss: 0.5813 - categorical_accuracy: 0.7624 - val_loss: 0.7100 - val_categorical_accuracy: 0.7538\n",
      "Epoch 50/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.5851 - categorical_accuracy: 0.7677Epoch 50: loss = 0.5851210951805115, val_loss = 0.6327025890350342\n",
      "83/83 [==============================] - 5s 59ms/step - loss: 0.5851 - categorical_accuracy: 0.7677 - val_loss: 0.6327 - val_categorical_accuracy: 0.7729\n",
      "41/41 [==============================] - 2s 26ms/step - loss: 0.6327 - categorical_accuracy: 0.7729\n",
      "Epoch 1/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 3.1041 - categorical_accuracy: 0.0664Epoch 1: loss = 3.1002185344696045, val_loss = 2.7624411582946777\n",
      "82/82 [==============================] - 8s 61ms/step - loss: 3.1002 - categorical_accuracy: 0.0678 - val_loss: 2.7624 - val_categorical_accuracy: 0.0792\n",
      "Epoch 2/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.7705 - categorical_accuracy: 0.1105Epoch 2: loss = 2.7705488204956055, val_loss = 2.6547064781188965\n",
      "82/82 [==============================] - 5s 61ms/step - loss: 2.7705 - categorical_accuracy: 0.1105 - val_loss: 2.6547 - val_categorical_accuracy: 0.0701\n",
      "Epoch 3/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.7130 - categorical_accuracy: 0.1113Epoch 3: loss = 2.7129604816436768, val_loss = 2.5409979820251465\n",
      "82/82 [==============================] - 4s 54ms/step - loss: 2.7130 - categorical_accuracy: 0.1113 - val_loss: 2.5410 - val_categorical_accuracy: 0.1142\n",
      "Epoch 4/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.6439 - categorical_accuracy: 0.1289Epoch 4: loss = 2.639254570007324, val_loss = 2.506256103515625\n",
      "82/82 [==============================] - 5s 56ms/step - loss: 2.6393 - categorical_accuracy: 0.1296 - val_loss: 2.5063 - val_categorical_accuracy: 0.1112\n",
      "Epoch 5/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.4790 - categorical_accuracy: 0.1593Epoch 5: loss = 2.4789679050445557, val_loss = 2.4289097785949707\n",
      "82/82 [==============================] - 5s 60ms/step - loss: 2.4790 - categorical_accuracy: 0.1593 - val_loss: 2.4289 - val_categorical_accuracy: 0.1660\n",
      "Epoch 6/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.3790 - categorical_accuracy: 0.1667Epoch 6: loss = 2.379040002822876, val_loss = 2.3773860931396484\n",
      "82/82 [==============================] - 4s 54ms/step - loss: 2.3790 - categorical_accuracy: 0.1669 - val_loss: 2.3774 - val_categorical_accuracy: 0.1394\n",
      "Epoch 7/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.4250 - categorical_accuracy: 0.1867Epoch 7: loss = 2.425004005432129, val_loss = 2.39095401763916\n",
      "82/82 [==============================] - 4s 55ms/step - loss: 2.4250 - categorical_accuracy: 0.1867 - val_loss: 2.3910 - val_categorical_accuracy: 0.1264\n",
      "Epoch 8/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.3008 - categorical_accuracy: 0.2119Epoch 8: loss = 2.3008248805999756, val_loss = 2.2121036052703857\n",
      "82/82 [==============================] - 4s 54ms/step - loss: 2.3008 - categorical_accuracy: 0.2119 - val_loss: 2.2121 - val_categorical_accuracy: 0.2262\n",
      "Epoch 9/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.2287 - categorical_accuracy: 0.2279Epoch 9: loss = 2.2287423610687256, val_loss = 2.2267987728118896\n",
      "82/82 [==============================] - 5s 59ms/step - loss: 2.2287 - categorical_accuracy: 0.2279 - val_loss: 2.2268 - val_categorical_accuracy: 0.2056\n",
      "Epoch 10/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.1827 - categorical_accuracy: 0.2315Epoch 10: loss = 2.181269884109497, val_loss = 2.1731886863708496\n",
      "82/82 [==============================] - 4s 53ms/step - loss: 2.1813 - categorical_accuracy: 0.2317 - val_loss: 2.1732 - val_categorical_accuracy: 0.2673\n",
      "Epoch 11/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.0421 - categorical_accuracy: 0.2932Epoch 11: loss = 2.0416603088378906, val_loss = 1.8910242319107056\n",
      "82/82 [==============================] - 5s 55ms/step - loss: 2.0417 - categorical_accuracy: 0.2927 - val_loss: 1.8910 - val_categorical_accuracy: 0.3382\n",
      "Epoch 12/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.1725 - categorical_accuracy: 0.2889Epoch 12: loss = 2.1725354194641113, val_loss = 2.2301106452941895\n",
      "82/82 [==============================] - 4s 54ms/step - loss: 2.1725 - categorical_accuracy: 0.2889 - val_loss: 2.2301 - val_categorical_accuracy: 0.2209\n",
      "Epoch 13/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.0940 - categorical_accuracy: 0.2755Epoch 13: loss = 2.091057300567627, val_loss = 1.9539262056350708\n",
      "82/82 [==============================] - 4s 54ms/step - loss: 2.0911 - categorical_accuracy: 0.2767 - val_loss: 1.9539 - val_categorical_accuracy: 0.2833\n",
      "Epoch 14/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.9473 - categorical_accuracy: 0.3178Epoch 14: loss = 1.9473216533660889, val_loss = 1.8442778587341309\n",
      "82/82 [==============================] - 4s 53ms/step - loss: 1.9473 - categorical_accuracy: 0.3178 - val_loss: 1.8443 - val_categorical_accuracy: 0.3663\n",
      "Epoch 15/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.8708 - categorical_accuracy: 0.3460Epoch 15: loss = 1.8708158731460571, val_loss = 1.9630542993545532\n",
      "82/82 [==============================] - 5s 61ms/step - loss: 1.8708 - categorical_accuracy: 0.3460 - val_loss: 1.9631 - val_categorical_accuracy: 0.2925\n",
      "Epoch 16/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.7887 - categorical_accuracy: 0.3552Epoch 16: loss = 1.7887474298477173, val_loss = 1.6177518367767334\n",
      "82/82 [==============================] - 5s 56ms/step - loss: 1.7887 - categorical_accuracy: 0.3552 - val_loss: 1.6178 - val_categorical_accuracy: 0.4402\n",
      "Epoch 17/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.7350 - categorical_accuracy: 0.3826Epoch 17: loss = 1.7349708080291748, val_loss = 1.6474971771240234\n",
      "82/82 [==============================] - 5s 56ms/step - loss: 1.7350 - categorical_accuracy: 0.3826 - val_loss: 1.6475 - val_categorical_accuracy: 0.3907\n",
      "Epoch 18/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.7141 - categorical_accuracy: 0.3659Epoch 18: loss = 1.7140979766845703, val_loss = 1.431065320968628\n",
      "82/82 [==============================] - 5s 58ms/step - loss: 1.7141 - categorical_accuracy: 0.3659 - val_loss: 1.4311 - val_categorical_accuracy: 0.4859\n",
      "Epoch 19/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.4376 - categorical_accuracy: 0.4707Epoch 19: loss = 1.4432532787322998, val_loss = 1.3797903060913086\n",
      "82/82 [==============================] - 5s 58ms/step - loss: 1.4433 - categorical_accuracy: 0.4695 - val_loss: 1.3798 - val_categorical_accuracy: 0.4905\n",
      "Epoch 20/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.4359 - categorical_accuracy: 0.4576Epoch 20: loss = 1.4314212799072266, val_loss = 1.3882472515106201\n",
      "82/82 [==============================] - 4s 52ms/step - loss: 1.4314 - categorical_accuracy: 0.4604 - val_loss: 1.3882 - val_categorical_accuracy: 0.4775\n",
      "Epoch 21/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.3165 - categorical_accuracy: 0.5170Epoch 21: loss = 1.3250139951705933, val_loss = 1.2073062658309937\n",
      "82/82 [==============================] - 4s 52ms/step - loss: 1.3250 - categorical_accuracy: 0.5145 - val_loss: 1.2073 - val_categorical_accuracy: 0.5727\n",
      "Epoch 22/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.2646 - categorical_accuracy: 0.5285Epoch 22: loss = 1.2676010131835938, val_loss = 1.319689393043518\n",
      "82/82 [==============================] - 4s 53ms/step - loss: 1.2676 - categorical_accuracy: 0.5274 - val_loss: 1.3197 - val_categorical_accuracy: 0.4920\n",
      "Epoch 23/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.3488 - categorical_accuracy: 0.4909Epoch 23: loss = 1.3488458395004272, val_loss = 1.28199303150177\n",
      "82/82 [==============================] - 4s 55ms/step - loss: 1.3488 - categorical_accuracy: 0.4909 - val_loss: 1.2820 - val_categorical_accuracy: 0.5331\n",
      "Epoch 24/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.2744 - categorical_accuracy: 0.5424Epoch 24: loss = 1.2700533866882324, val_loss = 1.3091175556182861\n",
      "82/82 [==============================] - 4s 54ms/step - loss: 1.2701 - categorical_accuracy: 0.5442 - val_loss: 1.3091 - val_categorical_accuracy: 0.5263\n",
      "Epoch 25/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.2154 - categorical_accuracy: 0.5409Epoch 25: loss = 1.2133203744888306, val_loss = 1.1075081825256348\n",
      "82/82 [==============================] - 4s 53ms/step - loss: 1.2133 - categorical_accuracy: 0.5412 - val_loss: 1.1075 - val_categorical_accuracy: 0.5925\n",
      "Epoch 26/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.2716 - categorical_accuracy: 0.5229Epoch 26: loss = 1.2715767621994019, val_loss = 1.110978603363037\n",
      "82/82 [==============================] - 5s 58ms/step - loss: 1.2716 - categorical_accuracy: 0.5229 - val_loss: 1.1110 - val_categorical_accuracy: 0.5864\n",
      "Epoch 27/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.0871 - categorical_accuracy: 0.5884Epoch 27: loss = 1.0870537757873535, val_loss = 1.0395046472549438\n",
      "82/82 [==============================] - 5s 61ms/step - loss: 1.0871 - categorical_accuracy: 0.5884 - val_loss: 1.0395 - val_categorical_accuracy: 0.6169\n",
      "Epoch 28/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.0496 - categorical_accuracy: 0.5960Epoch 28: loss = 1.0496023893356323, val_loss = 1.2258878946304321\n",
      "82/82 [==============================] - 5s 64ms/step - loss: 1.0496 - categorical_accuracy: 0.5960 - val_loss: 1.2259 - val_categorical_accuracy: 0.5697\n",
      "Epoch 29/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.0323 - categorical_accuracy: 0.5945Epoch 29: loss = 1.0323102474212646, val_loss = 0.992927074432373\n",
      "82/82 [==============================] - 5s 62ms/step - loss: 1.0323 - categorical_accuracy: 0.5945 - val_loss: 0.9929 - val_categorical_accuracy: 0.6040\n",
      "Epoch 30/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9473 - categorical_accuracy: 0.6402Epoch 30: loss = 0.9473198652267456, val_loss = 0.9698590636253357\n",
      "82/82 [==============================] - 5s 61ms/step - loss: 0.9473 - categorical_accuracy: 0.6402 - val_loss: 0.9699 - val_categorical_accuracy: 0.6565\n",
      "Epoch 31/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.0748 - categorical_accuracy: 0.5957Epoch 31: loss = 1.0727003812789917, val_loss = 0.9696212410926819\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.0727 - categorical_accuracy: 0.5960 - val_loss: 0.9696 - val_categorical_accuracy: 0.6337\n",
      "Epoch 32/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9403 - categorical_accuracy: 0.6341Epoch 32: loss = 0.9402939677238464, val_loss = 1.3199528455734253\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 0.9403 - categorical_accuracy: 0.6341 - val_loss: 1.3200 - val_categorical_accuracy: 0.5575\n",
      "Epoch 33/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.8779 - categorical_accuracy: 0.6590Epoch 33: loss = 0.8751142621040344, val_loss = 0.834032416343689\n",
      "82/82 [==============================] - 5s 61ms/step - loss: 0.8751 - categorical_accuracy: 0.6601 - val_loss: 0.8340 - val_categorical_accuracy: 0.6672\n",
      "Epoch 34/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9067 - categorical_accuracy: 0.6463Epoch 34: loss = 0.9066598415374756, val_loss = 0.8824666738510132\n",
      "82/82 [==============================] - 5s 57ms/step - loss: 0.9067 - categorical_accuracy: 0.6463 - val_loss: 0.8825 - val_categorical_accuracy: 0.6657\n",
      "Epoch 35/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8453 - categorical_accuracy: 0.6829Epoch 35: loss = 0.8452826738357544, val_loss = 0.8469406366348267\n",
      "82/82 [==============================] - 4s 53ms/step - loss: 0.8453 - categorical_accuracy: 0.6829 - val_loss: 0.8469 - val_categorical_accuracy: 0.6657\n",
      "Epoch 36/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.8262 - categorical_accuracy: 0.6767Epoch 36: loss = 0.8235554695129395, val_loss = 0.7732211351394653\n",
      "82/82 [==============================] - 4s 53ms/step - loss: 0.8236 - categorical_accuracy: 0.6768 - val_loss: 0.7732 - val_categorical_accuracy: 0.7136\n",
      "Epoch 37/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.0106 - categorical_accuracy: 0.6103Epoch 37: loss = 1.0042675733566284, val_loss = 0.8829955458641052\n",
      "82/82 [==============================] - 4s 54ms/step - loss: 1.0043 - categorical_accuracy: 0.6128 - val_loss: 0.8830 - val_categorical_accuracy: 0.6748\n",
      "Epoch 38/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.9380 - categorical_accuracy: 0.6543Epoch 38: loss = 0.9340775609016418, val_loss = 0.9434651732444763\n",
      "82/82 [==============================] - 4s 53ms/step - loss: 0.9341 - categorical_accuracy: 0.6547 - val_loss: 0.9435 - val_categorical_accuracy: 0.6207\n",
      "Epoch 39/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.2466 - categorical_accuracy: 0.5625Epoch 39: loss = 1.2466166019439697, val_loss = 0.977855920791626\n",
      "82/82 [==============================] - 5s 57ms/step - loss: 1.2466 - categorical_accuracy: 0.5625 - val_loss: 0.9779 - val_categorical_accuracy: 0.6337\n",
      "Epoch 40/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8576 - categorical_accuracy: 0.6623Epoch 40: loss = 0.8575678467750549, val_loss = 0.7649369239807129\n",
      "82/82 [==============================] - 5s 61ms/step - loss: 0.8576 - categorical_accuracy: 0.6623 - val_loss: 0.7649 - val_categorical_accuracy: 0.7060\n",
      "Epoch 41/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8746 - categorical_accuracy: 0.6509Epoch 41: loss = 0.8745830059051514, val_loss = 0.897464394569397\n",
      "82/82 [==============================] - 5s 63ms/step - loss: 0.8746 - categorical_accuracy: 0.6509 - val_loss: 0.8975 - val_categorical_accuracy: 0.6634\n",
      "Epoch 42/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 9.9300 - categorical_accuracy: 0.2988 Epoch 42: loss = 9.930047035217285, val_loss = 1.7155383825302124\n",
      "82/82 [==============================] - 5s 60ms/step - loss: 9.9300 - categorical_accuracy: 0.2988 - val_loss: 1.7155 - val_categorical_accuracy: 0.4090\n",
      "Epoch 43/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.6038 - categorical_accuracy: 0.4282Epoch 43: loss = 1.6066615581512451, val_loss = 1.3319886922836304\n",
      "82/82 [==============================] - 5s 60ms/step - loss: 1.6067 - categorical_accuracy: 0.4276 - val_loss: 1.3320 - val_categorical_accuracy: 0.4912\n",
      "Epoch 44/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.4357 - categorical_accuracy: 0.4715Epoch 44: loss = 1.431695818901062, val_loss = 1.0710817575454712\n",
      "82/82 [==============================] - 5s 61ms/step - loss: 1.4317 - categorical_accuracy: 0.4733 - val_loss: 1.0711 - val_categorical_accuracy: 0.5727\n",
      "Epoch 45/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.1385 - categorical_accuracy: 0.5755Epoch 45: loss = 1.1384780406951904, val_loss = 1.002066969871521\n",
      "82/82 [==============================] - 5s 57ms/step - loss: 1.1385 - categorical_accuracy: 0.5755 - val_loss: 1.0021 - val_categorical_accuracy: 0.6535\n",
      "Epoch 46/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.3325 - categorical_accuracy: 0.5221Epoch 46: loss = 1.3324908018112183, val_loss = 1.4618885517120361\n",
      "82/82 [==============================] - 5s 57ms/step - loss: 1.3325 - categorical_accuracy: 0.5221 - val_loss: 1.4619 - val_categorical_accuracy: 0.5286\n",
      "Epoch 47/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.2171 - categorical_accuracy: 0.5526Epoch 47: loss = 1.2170891761779785, val_loss = 0.9510853290557861\n",
      "82/82 [==============================] - 5s 59ms/step - loss: 1.2171 - categorical_accuracy: 0.5526 - val_loss: 0.9511 - val_categorical_accuracy: 0.6398\n",
      "Epoch 48/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.0048 - categorical_accuracy: 0.6281Epoch 48: loss = 1.002921462059021, val_loss = 1.0957269668579102\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.0029 - categorical_accuracy: 0.6296 - val_loss: 1.0957 - val_categorical_accuracy: 0.5605\n",
      "Epoch 49/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.9192 - categorical_accuracy: 0.6551Epoch 49: loss = 0.9169092774391174, val_loss = 0.9854090213775635\n",
      "82/82 [==============================] - 5s 60ms/step - loss: 0.9169 - categorical_accuracy: 0.6555 - val_loss: 0.9854 - val_categorical_accuracy: 0.6108\n",
      "Epoch 50/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.8915 - categorical_accuracy: 0.6582Restoring model weights from the end of the best epoch: 40.\n",
      "Epoch 50: loss = 0.8896817564964294, val_loss = 0.8115938305854797\n",
      "82/82 [==============================] - 5s 62ms/step - loss: 0.8897 - categorical_accuracy: 0.6578 - val_loss: 0.8116 - val_categorical_accuracy: 0.6687\n",
      "Epoch 50: early stopping\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.7649 - categorical_accuracy: 0.7060\n",
      "Epoch 1/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 3.0535 - categorical_accuracy: 0.0816Epoch 1: loss = 3.0531227588653564, val_loss = 2.769768476486206\n",
      "83/83 [==============================] - 10s 74ms/step - loss: 3.0531 - categorical_accuracy: 0.0815 - val_loss: 2.7698 - val_categorical_accuracy: 0.0816\n",
      "Epoch 2/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.7496 - categorical_accuracy: 0.1136Epoch 2: loss = 2.74965500831604, val_loss = 2.4950175285339355\n",
      "83/83 [==============================] - 5s 66ms/step - loss: 2.7497 - categorical_accuracy: 0.1135 - val_loss: 2.4950 - val_categorical_accuracy: 0.1509\n",
      "Epoch 3/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.6717 - categorical_accuracy: 0.1264Epoch 3: loss = 2.6716578006744385, val_loss = 2.46498966217041\n",
      "83/83 [==============================] - 5s 63ms/step - loss: 2.6717 - categorical_accuracy: 0.1264 - val_loss: 2.4650 - val_categorical_accuracy: 0.1997\n",
      "Epoch 4/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.3907 - categorical_accuracy: 0.1745Epoch 4: loss = 2.39032244682312, val_loss = 2.171651601791382\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 2.3903 - categorical_accuracy: 0.1744 - val_loss: 2.1717 - val_categorical_accuracy: 0.2218\n",
      "Epoch 5/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.3045 - categorical_accuracy: 0.1890Epoch 5: loss = 2.3037264347076416, val_loss = 2.418694257736206\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 2.3037 - categorical_accuracy: 0.1889 - val_loss: 2.4187 - val_categorical_accuracy: 0.1608\n",
      "Epoch 6/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.1689 - categorical_accuracy: 0.2270Epoch 6: loss = 2.1688578128814697, val_loss = 1.8857697248458862\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 2.1689 - categorical_accuracy: 0.2270 - val_loss: 1.8858 - val_categorical_accuracy: 0.3018\n",
      "Epoch 7/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.1971 - categorical_accuracy: 0.2072Epoch 7: loss = 2.1971070766448975, val_loss = 2.083516836166382\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 2.1971 - categorical_accuracy: 0.2072 - val_loss: 2.0835 - val_categorical_accuracy: 0.2073\n",
      "Epoch 8/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.9544 - categorical_accuracy: 0.2986Epoch 8: loss = 1.9544005393981934, val_loss = 2.226243257522583\n",
      "83/83 [==============================] - 5s 58ms/step - loss: 1.9544 - categorical_accuracy: 0.2986 - val_loss: 2.2262 - val_categorical_accuracy: 0.2797\n",
      "Epoch 9/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.9047 - categorical_accuracy: 0.2826Epoch 9: loss = 1.904732346534729, val_loss = 1.6295908689498901\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.9047 - categorical_accuracy: 0.2826 - val_loss: 1.6296 - val_categorical_accuracy: 0.4261\n",
      "Epoch 10/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.7915 - categorical_accuracy: 0.3679Epoch 10: loss = 1.7914618253707886, val_loss = 1.750374436378479\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.7915 - categorical_accuracy: 0.3679 - val_loss: 1.7504 - val_categorical_accuracy: 0.3864\n",
      "Epoch 11/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.5965 - categorical_accuracy: 0.3732Epoch 11: loss = 1.596539855003357, val_loss = 1.756584882736206\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 1.5965 - categorical_accuracy: 0.3732 - val_loss: 1.7566 - val_categorical_accuracy: 0.3491\n",
      "Epoch 12/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.5130 - categorical_accuracy: 0.4181Epoch 12: loss = 1.513044834136963, val_loss = 1.6235569715499878\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.5130 - categorical_accuracy: 0.4181 - val_loss: 1.6236 - val_categorical_accuracy: 0.3323\n",
      "Epoch 13/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.6472 - categorical_accuracy: 0.4116Epoch 13: loss = 1.6468796730041504, val_loss = 1.85013747215271\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.6469 - categorical_accuracy: 0.4120 - val_loss: 1.8501 - val_categorical_accuracy: 0.3841\n",
      "Epoch 14/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.4810 - categorical_accuracy: 0.4486Epoch 14: loss = 1.4809585809707642, val_loss = 1.5308023691177368\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 1.4810 - categorical_accuracy: 0.4486 - val_loss: 1.5308 - val_categorical_accuracy: 0.4817\n",
      "Epoch 15/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.4828 - categorical_accuracy: 0.4352Epoch 15: loss = 1.4828368425369263, val_loss = 1.2060812711715698\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.4828 - categorical_accuracy: 0.4349 - val_loss: 1.2061 - val_categorical_accuracy: 0.5396\n",
      "Epoch 16/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.3019 - categorical_accuracy: 0.4931Epoch 16: loss = 1.301438808441162, val_loss = 1.1511343717575073\n",
      "83/83 [==============================] - 5s 62ms/step - loss: 1.3014 - categorical_accuracy: 0.4935 - val_loss: 1.1511 - val_categorical_accuracy: 0.5442\n",
      "Epoch 17/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.2530 - categorical_accuracy: 0.5091Epoch 17: loss = 1.2537128925323486, val_loss = 1.1400997638702393\n",
      "83/83 [==============================] - 5s 56ms/step - loss: 1.2537 - categorical_accuracy: 0.5088 - val_loss: 1.1401 - val_categorical_accuracy: 0.5343\n",
      "Epoch 18/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.1727 - categorical_accuracy: 0.2932Epoch 18: loss = 2.1726863384246826, val_loss = 1.6450111865997314\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 2.1727 - categorical_accuracy: 0.2932 - val_loss: 1.6450 - val_categorical_accuracy: 0.3925\n",
      "Epoch 19/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.7851 - categorical_accuracy: 0.3701Epoch 19: loss = 1.7851231098175049, val_loss = 1.6336939334869385\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.7851 - categorical_accuracy: 0.3701 - val_loss: 1.6337 - val_categorical_accuracy: 0.3910\n",
      "Epoch 20/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.7312 - categorical_accuracy: 0.3625Epoch 20: loss = 1.7311716079711914, val_loss = 1.7120888233184814\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.7312 - categorical_accuracy: 0.3625 - val_loss: 1.7121 - val_categorical_accuracy: 0.3559\n",
      "Epoch 21/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.5411 - categorical_accuracy: 0.4181Epoch 21: loss = 1.5410754680633545, val_loss = 1.385071039199829\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.5411 - categorical_accuracy: 0.4181 - val_loss: 1.3851 - val_categorical_accuracy: 0.4352\n",
      "Epoch 22/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.3692 - categorical_accuracy: 0.4802Epoch 22: loss = 1.3687981367111206, val_loss = 1.313860297203064\n",
      "83/83 [==============================] - 5s 61ms/step - loss: 1.3688 - categorical_accuracy: 0.4806 - val_loss: 1.3139 - val_categorical_accuracy: 0.5015\n",
      "Epoch 23/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.1548 - categorical_accuracy: 0.5648Epoch 23: loss = 1.1577574014663696, val_loss = 1.2951017618179321\n",
      "83/83 [==============================] - 5s 59ms/step - loss: 1.1578 - categorical_accuracy: 0.5644 - val_loss: 1.2951 - val_categorical_accuracy: 0.4985\n",
      "Epoch 24/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.4495 - categorical_accuracy: 0.4573Epoch 24: loss = 1.4484049081802368, val_loss = 1.198454737663269\n",
      "83/83 [==============================] - 5s 65ms/step - loss: 1.4484 - categorical_accuracy: 0.4577 - val_loss: 1.1985 - val_categorical_accuracy: 0.5305\n",
      "Epoch 25/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.1958 - categorical_accuracy: 0.5404Epoch 25: loss = 1.1964033842086792, val_loss = 1.1202178001403809\n",
      "83/83 [==============================] - 5s 57ms/step - loss: 1.1964 - categorical_accuracy: 0.5400 - val_loss: 1.1202 - val_categorical_accuracy: 0.5602\n",
      "Epoch 26/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.1759 - categorical_accuracy: 0.5473Epoch 26: loss = 1.1750577688217163, val_loss = 1.040713906288147\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 1.1751 - categorical_accuracy: 0.5476 - val_loss: 1.0407 - val_categorical_accuracy: 0.6585\n",
      "Epoch 27/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.0728 - categorical_accuracy: 0.5910Epoch 27: loss = 1.0728124380111694, val_loss = 0.9591061472892761\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 1.0728 - categorical_accuracy: 0.5910 - val_loss: 0.9591 - val_categorical_accuracy: 0.6334\n",
      "Epoch 28/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.9497 - categorical_accuracy: 0.6289Epoch 28: loss = 0.9515442252159119, val_loss = 1.4776605367660522\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 0.9515 - categorical_accuracy: 0.6291 - val_loss: 1.4777 - val_categorical_accuracy: 0.4832\n",
      "Epoch 29/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.3555 - categorical_accuracy: 0.5122Epoch 29: loss = 1.355883002281189, val_loss = 1.2446101903915405\n",
      "83/83 [==============================] - 5s 56ms/step - loss: 1.3559 - categorical_accuracy: 0.5126 - val_loss: 1.2446 - val_categorical_accuracy: 0.5145\n",
      "Epoch 30/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.1208 - categorical_accuracy: 0.5583Epoch 30: loss = 1.1208076477050781, val_loss = 1.071946144104004\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 1.1208 - categorical_accuracy: 0.5583 - val_loss: 1.0719 - val_categorical_accuracy: 0.6082\n",
      "Epoch 31/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.0084 - categorical_accuracy: 0.6032Epoch 31: loss = 1.0084176063537598, val_loss = 0.9483431577682495\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 1.0084 - categorical_accuracy: 0.6032 - val_loss: 0.9483 - val_categorical_accuracy: 0.6547\n",
      "Epoch 32/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.8890 - categorical_accuracy: 0.6527Epoch 32: loss = 0.888975977897644, val_loss = 0.8033218383789062\n",
      "83/83 [==============================] - 5s 60ms/step - loss: 0.8890 - categorical_accuracy: 0.6527 - val_loss: 0.8033 - val_categorical_accuracy: 0.6944\n",
      "Epoch 33/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.2757 - categorical_accuracy: 0.5762Epoch 33: loss = 1.2763597965240479, val_loss = 1.0951073169708252\n",
      "83/83 [==============================] - 5s 57ms/step - loss: 1.2764 - categorical_accuracy: 0.5758 - val_loss: 1.0951 - val_categorical_accuracy: 0.5777\n",
      "Epoch 34/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.0275 - categorical_accuracy: 0.6029Epoch 34: loss = 1.026776671409607, val_loss = 0.8813574314117432\n",
      "83/83 [==============================] - 5s 59ms/step - loss: 1.0268 - categorical_accuracy: 0.6032 - val_loss: 0.8814 - val_categorical_accuracy: 0.6791\n",
      "Epoch 35/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.5010 - categorical_accuracy: 0.6136Epoch 35: loss = 1.5017777681350708, val_loss = 1.6933740377426147\n",
      "83/83 [==============================] - 5s 57ms/step - loss: 1.5018 - categorical_accuracy: 0.6131 - val_loss: 1.6934 - val_categorical_accuracy: 0.5297\n",
      "Epoch 36/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.3417 - categorical_accuracy: 0.5274Epoch 36: loss = 1.3425571918487549, val_loss = 0.9603285193443298\n",
      "83/83 [==============================] - 5s 66ms/step - loss: 1.3426 - categorical_accuracy: 0.5270 - val_loss: 0.9603 - val_categorical_accuracy: 0.6402\n",
      "Epoch 37/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.0982 - categorical_accuracy: 0.5918Epoch 37: loss = 1.0982195138931274, val_loss = 1.4905061721801758\n",
      "83/83 [==============================] - 6s 69ms/step - loss: 1.0982 - categorical_accuracy: 0.5918 - val_loss: 1.4905 - val_categorical_accuracy: 0.4886\n",
      "Epoch 38/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.0228 - categorical_accuracy: 0.6105Epoch 38: loss = 1.0220723152160645, val_loss = 0.8406960368156433\n",
      "83/83 [==============================] - 5s 64ms/step - loss: 1.0221 - categorical_accuracy: 0.6108 - val_loss: 0.8407 - val_categorical_accuracy: 0.7066\n",
      "Epoch 39/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.8975 - categorical_accuracy: 0.6463Epoch 39: loss = 0.8968971371650696, val_loss = 0.9567936062812805\n",
      "83/83 [==============================] - 6s 71ms/step - loss: 0.8969 - categorical_accuracy: 0.6466 - val_loss: 0.9568 - val_categorical_accuracy: 0.6517\n",
      "Epoch 40/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.9064 - categorical_accuracy: 0.6562Epoch 40: loss = 0.9070475101470947, val_loss = 0.9266555309295654\n",
      "83/83 [==============================] - 5s 65ms/step - loss: 0.9070 - categorical_accuracy: 0.6558 - val_loss: 0.9267 - val_categorical_accuracy: 0.6402\n",
      "Epoch 41/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.7814 - categorical_accuracy: 0.6966Epoch 41: loss = 0.7822387218475342, val_loss = 0.7008230090141296\n",
      "83/83 [==============================] - 5s 63ms/step - loss: 0.7822 - categorical_accuracy: 0.6961 - val_loss: 0.7008 - val_categorical_accuracy: 0.7439\n",
      "Epoch 42/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.9180 - categorical_accuracy: 0.6540Epoch 42: loss = 0.9180493354797363, val_loss = 0.7449106574058533\n",
      "83/83 [==============================] - 5s 56ms/step - loss: 0.9180 - categorical_accuracy: 0.6542 - val_loss: 0.7449 - val_categorical_accuracy: 0.7378\n",
      "Epoch 43/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.7934 - categorical_accuracy: 0.7088Epoch 43: loss = 0.7929444909095764, val_loss = 0.7700024247169495\n",
      "83/83 [==============================] - 5s 56ms/step - loss: 0.7929 - categorical_accuracy: 0.7091 - val_loss: 0.7700 - val_categorical_accuracy: 0.7012\n",
      "Epoch 44/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.7189 - categorical_accuracy: 0.7226Epoch 44: loss = 0.7192911505699158, val_loss = 0.7404339909553528\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 0.7193 - categorical_accuracy: 0.7228 - val_loss: 0.7404 - val_categorical_accuracy: 0.7401\n",
      "Epoch 45/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.7336 - categorical_accuracy: 0.7157Epoch 45: loss = 0.7330414056777954, val_loss = 0.6860101819038391\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 0.7330 - categorical_accuracy: 0.7159 - val_loss: 0.6860 - val_categorical_accuracy: 0.7599\n",
      "Epoch 46/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.7015 - categorical_accuracy: 0.7197Epoch 46: loss = 0.7015316486358643, val_loss = 0.7368916273117065\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 0.7015 - categorical_accuracy: 0.7197 - val_loss: 0.7369 - val_categorical_accuracy: 0.7157\n",
      "Epoch 47/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.8210 - categorical_accuracy: 0.6890Epoch 47: loss = 0.8211184740066528, val_loss = 0.6687431931495667\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 0.8211 - categorical_accuracy: 0.6893 - val_loss: 0.6687 - val_categorical_accuracy: 0.7622\n",
      "Epoch 48/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.7138 - categorical_accuracy: 0.7228Epoch 48: loss = 0.7138133645057678, val_loss = 0.8281541466712952\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 0.7138 - categorical_accuracy: 0.7228 - val_loss: 0.8282 - val_categorical_accuracy: 0.6890\n",
      "Epoch 49/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.7804 - categorical_accuracy: 0.7076Epoch 49: loss = 0.7792717218399048, val_loss = 0.7012749910354614\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 0.7793 - categorical_accuracy: 0.7083 - val_loss: 0.7013 - val_categorical_accuracy: 0.7409\n",
      "Epoch 50/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.7179 - categorical_accuracy: 0.7235Epoch 50: loss = 0.7179035544395447, val_loss = 0.7848984599113464\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 0.7179 - categorical_accuracy: 0.7235 - val_loss: 0.7849 - val_categorical_accuracy: 0.7127\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.7849 - categorical_accuracy: 0.7127\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 3.0572 - categorical_accuracy: 0.0945Epoch 1: loss = 3.057162046432495, val_loss = 2.830533742904663\n",
      "41/41 [==============================] - 8s 113ms/step - loss: 3.0572 - categorical_accuracy: 0.0945 - val_loss: 2.8305 - val_categorical_accuracy: 0.1074\n",
      "Epoch 2/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.7565 - categorical_accuracy: 0.1125Epoch 2: loss = 2.754748821258545, val_loss = 2.6285078525543213\n",
      "41/41 [==============================] - 3s 84ms/step - loss: 2.7547 - categorical_accuracy: 0.1120 - val_loss: 2.6285 - val_categorical_accuracy: 0.0899\n",
      "Epoch 3/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.4242 - categorical_accuracy: 0.1852Epoch 3: loss = 2.4162774085998535, val_loss = 2.20957350730896\n",
      "41/41 [==============================] - 3s 81ms/step - loss: 2.4163 - categorical_accuracy: 0.1875 - val_loss: 2.2096 - val_categorical_accuracy: 0.2201\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.4022 - categorical_accuracy: 0.1890Epoch 4: loss = 2.4021899700164795, val_loss = 2.1518659591674805\n",
      "41/41 [==============================] - 3s 81ms/step - loss: 2.4022 - categorical_accuracy: 0.1890 - val_loss: 2.1519 - val_categorical_accuracy: 0.1797\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.2377 - categorical_accuracy: 0.2127Epoch 5: loss = 2.237748861312866, val_loss = 1.9924890995025635\n",
      "41/41 [==============================] - 4s 87ms/step - loss: 2.2377 - categorical_accuracy: 0.2127 - val_loss: 1.9925 - val_categorical_accuracy: 0.2361\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.9592 - categorical_accuracy: 0.2812Epoch 6: loss = 1.959246039390564, val_loss = 1.84395170211792\n",
      "41/41 [==============================] - 3s 84ms/step - loss: 1.9592 - categorical_accuracy: 0.2812 - val_loss: 1.8440 - val_categorical_accuracy: 0.2986\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.2902 - categorical_accuracy: 0.2248Epoch 7: loss = 2.2901570796966553, val_loss = 2.1273622512817383\n",
      "41/41 [==============================] - 4s 89ms/step - loss: 2.2902 - categorical_accuracy: 0.2248 - val_loss: 2.1274 - val_categorical_accuracy: 0.2117\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.9361 - categorical_accuracy: 0.2774Epoch 8: loss = 1.9360826015472412, val_loss = 1.9024726152420044\n",
      "41/41 [==============================] - 4s 87ms/step - loss: 1.9361 - categorical_accuracy: 0.2774 - val_loss: 1.9025 - val_categorical_accuracy: 0.3709\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.7031 - categorical_accuracy: 0.3864Epoch 9: loss = 1.7031337022781372, val_loss = 1.6218767166137695\n",
      "41/41 [==============================] - 3s 81ms/step - loss: 1.7031 - categorical_accuracy: 0.3864 - val_loss: 1.6219 - val_categorical_accuracy: 0.4143\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.6066 - categorical_accuracy: 0.4108Epoch 10: loss = 1.6066021919250488, val_loss = 1.5130541324615479\n",
      "41/41 [==============================] - 3s 81ms/step - loss: 1.6066 - categorical_accuracy: 0.4108 - val_loss: 1.5131 - val_categorical_accuracy: 0.4494\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.6091 - categorical_accuracy: 0.4032Epoch 11: loss = 1.6091089248657227, val_loss = 1.8117454051971436\n",
      "41/41 [==============================] - 3s 82ms/step - loss: 1.6091 - categorical_accuracy: 0.4032 - val_loss: 1.8117 - val_categorical_accuracy: 0.3054\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.6238 - categorical_accuracy: 0.4238Epoch 12: loss = 1.6237988471984863, val_loss = 1.5099432468414307\n",
      "41/41 [==============================] - 3s 82ms/step - loss: 1.6238 - categorical_accuracy: 0.4238 - val_loss: 1.5099 - val_categorical_accuracy: 0.4158\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.3051 - categorical_accuracy: 0.5259Epoch 13: loss = 1.3051177263259888, val_loss = 1.1777620315551758\n",
      "41/41 [==============================] - 3s 83ms/step - loss: 1.3051 - categorical_accuracy: 0.5259 - val_loss: 1.1778 - val_categorical_accuracy: 0.5826\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2435 - categorical_accuracy: 0.5290Epoch 14: loss = 1.2435122728347778, val_loss = 1.356716275215149\n",
      "41/41 [==============================] - 3s 82ms/step - loss: 1.2435 - categorical_accuracy: 0.5290 - val_loss: 1.3567 - val_categorical_accuracy: 0.4958\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1445 - categorical_accuracy: 0.5556Epoch 15: loss = 1.1445002555847168, val_loss = 1.0572528839111328\n",
      "41/41 [==============================] - 3s 81ms/step - loss: 1.1445 - categorical_accuracy: 0.5556 - val_loss: 1.0573 - val_categorical_accuracy: 0.6040\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0593 - categorical_accuracy: 0.5991Epoch 16: loss = 1.0592588186264038, val_loss = 1.1447798013687134\n",
      "41/41 [==============================] - 3s 83ms/step - loss: 1.0593 - categorical_accuracy: 0.5991 - val_loss: 1.1448 - val_categorical_accuracy: 0.5529\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1260 - categorical_accuracy: 0.5930Epoch 17: loss = 1.1259523630142212, val_loss = 1.0557204484939575\n",
      "41/41 [==============================] - 3s 81ms/step - loss: 1.1260 - categorical_accuracy: 0.5930 - val_loss: 1.0557 - val_categorical_accuracy: 0.6314\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.9708 - categorical_accuracy: 0.6204Epoch 18: loss = 0.9708462357521057, val_loss = 1.0831246376037598\n",
      "41/41 [==============================] - 3s 81ms/step - loss: 0.9708 - categorical_accuracy: 0.6204 - val_loss: 1.0831 - val_categorical_accuracy: 0.5986\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0185 - categorical_accuracy: 0.6311Epoch 19: loss = 1.0185171365737915, val_loss = 1.4231997728347778\n",
      "41/41 [==============================] - 3s 82ms/step - loss: 1.0185 - categorical_accuracy: 0.6311 - val_loss: 1.4232 - val_categorical_accuracy: 0.5141\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.9936 - categorical_accuracy: 0.6578Epoch 20: loss = 0.9936490058898926, val_loss = 1.0754072666168213\n",
      "41/41 [==============================] - 3s 82ms/step - loss: 0.9936 - categorical_accuracy: 0.6578 - val_loss: 1.0754 - val_categorical_accuracy: 0.6032\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.9057 - categorical_accuracy: 0.6738Epoch 21: loss = 0.9056706428527832, val_loss = 0.7914668917655945\n",
      "41/41 [==============================] - 3s 85ms/step - loss: 0.9057 - categorical_accuracy: 0.6738 - val_loss: 0.7915 - val_categorical_accuracy: 0.7144\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.7426 - categorical_accuracy: 0.7248Epoch 22: loss = 0.742607831954956, val_loss = 0.7471805810928345\n",
      "41/41 [==============================] - 3s 82ms/step - loss: 0.7426 - categorical_accuracy: 0.7248 - val_loss: 0.7472 - val_categorical_accuracy: 0.7205\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.8542 - categorical_accuracy: 0.6875Epoch 23: loss = 0.8542276620864868, val_loss = 0.8129261136054993\n",
      "41/41 [==============================] - 3s 82ms/step - loss: 0.8542 - categorical_accuracy: 0.6875 - val_loss: 0.8129 - val_categorical_accuracy: 0.7060\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.8707 - categorical_accuracy: 0.6791Epoch 24: loss = 0.8707358837127686, val_loss = 0.7940358519554138\n",
      "41/41 [==============================] - 3s 82ms/step - loss: 0.8707 - categorical_accuracy: 0.6791 - val_loss: 0.7940 - val_categorical_accuracy: 0.7037\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.8059 - categorical_accuracy: 0.6966Epoch 25: loss = 0.8059390783309937, val_loss = 0.7649886608123779\n",
      "41/41 [==============================] - 3s 84ms/step - loss: 0.8059 - categorical_accuracy: 0.6966 - val_loss: 0.7650 - val_categorical_accuracy: 0.7281\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6998 - categorical_accuracy: 0.7348Epoch 26: loss = 0.6997780203819275, val_loss = 0.8373990654945374\n",
      "41/41 [==============================] - 3s 82ms/step - loss: 0.6998 - categorical_accuracy: 0.7348 - val_loss: 0.8374 - val_categorical_accuracy: 0.6862\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6520 - categorical_accuracy: 0.7591Epoch 27: loss = 0.6519790887832642, val_loss = 0.6439051628112793\n",
      "41/41 [==============================] - 3s 81ms/step - loss: 0.6520 - categorical_accuracy: 0.7591 - val_loss: 0.6439 - val_categorical_accuracy: 0.7829\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.7311 - categorical_accuracy: 0.7081Epoch 28: loss = 0.7310749292373657, val_loss = 3.032797336578369\n",
      "41/41 [==============================] - 3s 82ms/step - loss: 0.7311 - categorical_accuracy: 0.7081 - val_loss: 3.0328 - val_categorical_accuracy: 0.5491\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.9723 - categorical_accuracy: 0.6486Epoch 29: loss = 0.9722650051116943, val_loss = 1.0117945671081543\n",
      "41/41 [==============================] - 3s 83ms/step - loss: 0.9723 - categorical_accuracy: 0.6486 - val_loss: 1.0118 - val_categorical_accuracy: 0.6443\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6960 - categorical_accuracy: 0.7424Epoch 30: loss = 0.6960116028785706, val_loss = 0.8339963555335999\n",
      "41/41 [==============================] - 3s 83ms/step - loss: 0.6960 - categorical_accuracy: 0.7424 - val_loss: 0.8340 - val_categorical_accuracy: 0.6885\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.9074 - categorical_accuracy: 0.6898Epoch 31: loss = 0.9073727130889893, val_loss = 0.9640514254570007\n",
      "41/41 [==============================] - 3s 84ms/step - loss: 0.9074 - categorical_accuracy: 0.6898 - val_loss: 0.9641 - val_categorical_accuracy: 0.6603\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6985 - categorical_accuracy: 0.7409Epoch 32: loss = 0.6984650492668152, val_loss = 0.6705438494682312\n",
      "41/41 [==============================] - 3s 83ms/step - loss: 0.6985 - categorical_accuracy: 0.7409 - val_loss: 0.6705 - val_categorical_accuracy: 0.7586\n",
      "Epoch 33/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.6847 - categorical_accuracy: 0.7430Epoch 33: loss = 0.6854258179664612, val_loss = 0.7572256326675415\n",
      "41/41 [==============================] - 3s 83ms/step - loss: 0.6854 - categorical_accuracy: 0.7431 - val_loss: 0.7572 - val_categorical_accuracy: 0.7053\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.8042 - categorical_accuracy: 0.7104Epoch 34: loss = 0.8041619062423706, val_loss = 0.8957887887954712\n",
      "41/41 [==============================] - 3s 81ms/step - loss: 0.8042 - categorical_accuracy: 0.7104 - val_loss: 0.8958 - val_categorical_accuracy: 0.6801\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.7068 - categorical_accuracy: 0.7279Epoch 35: loss = 0.7067736387252808, val_loss = 0.6733750104904175\n",
      "41/41 [==============================] - 3s 83ms/step - loss: 0.7068 - categorical_accuracy: 0.7279 - val_loss: 0.6734 - val_categorical_accuracy: 0.7677\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.5844 - categorical_accuracy: 0.7774Epoch 36: loss = 0.5844194889068604, val_loss = 0.6184881925582886\n",
      "41/41 [==============================] - 4s 100ms/step - loss: 0.5844 - categorical_accuracy: 0.7774 - val_loss: 0.6185 - val_categorical_accuracy: 0.7685\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6884 - categorical_accuracy: 0.7569Epoch 37: loss = 0.6883950233459473, val_loss = 0.909691572189331\n",
      "41/41 [==============================] - 4s 99ms/step - loss: 0.6884 - categorical_accuracy: 0.7569 - val_loss: 0.9097 - val_categorical_accuracy: 0.6710\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6745 - categorical_accuracy: 0.7774Epoch 38: loss = 0.6744762659072876, val_loss = 0.6306795477867126\n",
      "41/41 [==============================] - 4s 98ms/step - loss: 0.6745 - categorical_accuracy: 0.7774 - val_loss: 0.6307 - val_categorical_accuracy: 0.7898\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.6067 - categorical_accuracy: 0.7401Epoch 39: loss = 1.6067007780075073, val_loss = 1.3799476623535156\n",
      "41/41 [==============================] - 4s 94ms/step - loss: 1.6067 - categorical_accuracy: 0.7401 - val_loss: 1.3799 - val_categorical_accuracy: 0.5605\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0666 - categorical_accuracy: 0.6593Epoch 40: loss = 1.066602349281311, val_loss = 0.7878186702728271\n",
      "41/41 [==============================] - 4s 97ms/step - loss: 1.0666 - categorical_accuracy: 0.6593 - val_loss: 0.7878 - val_categorical_accuracy: 0.7106\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6510 - categorical_accuracy: 0.7553Epoch 41: loss = 0.6509614586830139, val_loss = 0.6743346452713013\n",
      "41/41 [==============================] - 4s 100ms/step - loss: 0.6510 - categorical_accuracy: 0.7553 - val_loss: 0.6743 - val_categorical_accuracy: 0.7624\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.5925 - categorical_accuracy: 0.7843Epoch 42: loss = 0.5924770832061768, val_loss = 0.6243718862533569\n",
      "41/41 [==============================] - 4s 100ms/step - loss: 0.5925 - categorical_accuracy: 0.7843 - val_loss: 0.6244 - val_categorical_accuracy: 0.7898\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6012 - categorical_accuracy: 0.7828Epoch 43: loss = 0.6011786460876465, val_loss = 0.8200885057449341\n",
      "41/41 [==============================] - 4s 93ms/step - loss: 0.6012 - categorical_accuracy: 0.7828 - val_loss: 0.8201 - val_categorical_accuracy: 0.6954\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6856 - categorical_accuracy: 0.7515Epoch 44: loss = 0.6856340765953064, val_loss = 0.759377121925354\n",
      "41/41 [==============================] - 4s 93ms/step - loss: 0.6856 - categorical_accuracy: 0.7515 - val_loss: 0.7594 - val_categorical_accuracy: 0.7220\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.5797 - categorical_accuracy: 0.7759Epoch 45: loss = 0.5797221660614014, val_loss = 0.6064241528511047\n",
      "41/41 [==============================] - 4s 90ms/step - loss: 0.5797 - categorical_accuracy: 0.7759 - val_loss: 0.6064 - val_categorical_accuracy: 0.7791\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.5534 - categorical_accuracy: 0.7820Epoch 46: loss = 0.5534458756446838, val_loss = 0.6163846254348755\n",
      "41/41 [==============================] - 4s 94ms/step - loss: 0.5534 - categorical_accuracy: 0.7820 - val_loss: 0.6164 - val_categorical_accuracy: 0.7814\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.5343 - categorical_accuracy: 0.7896Epoch 47: loss = 0.534309446811676, val_loss = 0.5954720377922058\n",
      "41/41 [==============================] - 3s 83ms/step - loss: 0.5343 - categorical_accuracy: 0.7896 - val_loss: 0.5955 - val_categorical_accuracy: 0.7921\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4851 - categorical_accuracy: 0.8194Epoch 48: loss = 0.48506996035575867, val_loss = 0.6750860810279846\n",
      "41/41 [==============================] - 3s 84ms/step - loss: 0.4851 - categorical_accuracy: 0.8194 - val_loss: 0.6751 - val_categorical_accuracy: 0.7601\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4860 - categorical_accuracy: 0.8117Epoch 49: loss = 0.4860409200191498, val_loss = 0.6403244137763977\n",
      "41/41 [==============================] - 3s 82ms/step - loss: 0.4860 - categorical_accuracy: 0.8117 - val_loss: 0.6403 - val_categorical_accuracy: 0.7845\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6182 - categorical_accuracy: 0.7683Epoch 50: loss = 0.6181512475013733, val_loss = 0.6315724849700928\n",
      "41/41 [==============================] - 3s 82ms/step - loss: 0.6182 - categorical_accuracy: 0.7683 - val_loss: 0.6316 - val_categorical_accuracy: 0.7555\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.6316 - categorical_accuracy: 0.7555\n",
      "Epoch 1/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 3.0952 - categorical_accuracy: 0.0701Epoch 1: loss = 3.0951836109161377, val_loss = 3.0433855056762695\n",
      "42/42 [==============================] - 8s 95ms/step - loss: 3.0952 - categorical_accuracy: 0.0701 - val_loss: 3.0434 - val_categorical_accuracy: 0.0915\n",
      "Epoch 2/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.8027 - categorical_accuracy: 0.1075Epoch 2: loss = 2.8029401302337646, val_loss = 2.651951789855957\n",
      "42/42 [==============================] - 4s 85ms/step - loss: 2.8029 - categorical_accuracy: 0.1074 - val_loss: 2.6520 - val_categorical_accuracy: 0.1372\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.5652 - categorical_accuracy: 0.1363Epoch 3: loss = 2.565182685852051, val_loss = 2.447409152984619\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 2.5652 - categorical_accuracy: 0.1363 - val_loss: 2.4474 - val_categorical_accuracy: 0.1189\n",
      "Epoch 4/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.3424 - categorical_accuracy: 0.1768Epoch 4: loss = 2.341475248336792, val_loss = 2.287360191345215\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 2.3415 - categorical_accuracy: 0.1767 - val_loss: 2.2874 - val_categorical_accuracy: 0.1928\n",
      "Epoch 5/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.1832 - categorical_accuracy: 0.2180Epoch 5: loss = 2.1829657554626465, val_loss = 1.9820915460586548\n",
      "42/42 [==============================] - 3s 83ms/step - loss: 2.1830 - categorical_accuracy: 0.2178 - val_loss: 1.9821 - val_categorical_accuracy: 0.2447\n",
      "Epoch 6/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.0277 - categorical_accuracy: 0.2447Epoch 6: loss = 2.0277531147003174, val_loss = 1.8030834197998047\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 2.0278 - categorical_accuracy: 0.2445 - val_loss: 1.8031 - val_categorical_accuracy: 0.3239\n",
      "Epoch 7/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.7869 - categorical_accuracy: 0.3224Epoch 7: loss = 1.788642406463623, val_loss = 2.617492914199829\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 1.7886 - categorical_accuracy: 0.3222 - val_loss: 2.6175 - val_categorical_accuracy: 0.1951\n",
      "Epoch 8/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.4306 - categorical_accuracy: 0.2241Epoch 8: loss = 2.4309937953948975, val_loss = 2.1941444873809814\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 2.4310 - categorical_accuracy: 0.2239 - val_loss: 2.1941 - val_categorical_accuracy: 0.2332\n",
      "Epoch 9/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.9833 - categorical_accuracy: 0.3476Epoch 9: loss = 1.9832167625427246, val_loss = 3.7250709533691406\n",
      "42/42 [==============================] - 3s 82ms/step - loss: 1.9832 - categorical_accuracy: 0.3473 - val_loss: 3.7251 - val_categorical_accuracy: 0.2454\n",
      "Epoch 10/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.3464 - categorical_accuracy: 0.2477Epoch 10: loss = 2.3464601039886475, val_loss = 1.8238162994384766\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 2.3465 - categorical_accuracy: 0.2475 - val_loss: 1.8238 - val_categorical_accuracy: 0.3285\n",
      "Epoch 11/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.6951 - categorical_accuracy: 0.3712Epoch 11: loss = 1.69548761844635, val_loss = 1.7308160066604614\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 1.6955 - categorical_accuracy: 0.3709 - val_loss: 1.7308 - val_categorical_accuracy: 0.3720\n",
      "Epoch 12/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.6439 - categorical_accuracy: 0.3895Epoch 12: loss = 1.642778754234314, val_loss = 1.5401654243469238\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 1.6428 - categorical_accuracy: 0.3899 - val_loss: 1.5402 - val_categorical_accuracy: 0.4055\n",
      "Epoch 13/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.5943 - categorical_accuracy: 0.4352Epoch 13: loss = 1.594552755355835, val_loss = 1.7744953632354736\n",
      "42/42 [==============================] - 3s 79ms/step - loss: 1.5946 - categorical_accuracy: 0.4349 - val_loss: 1.7745 - val_categorical_accuracy: 0.3399\n",
      "Epoch 14/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.6935 - categorical_accuracy: 0.3963Epoch 14: loss = 1.6943930387496948, val_loss = 1.5297363996505737\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 1.6944 - categorical_accuracy: 0.3960 - val_loss: 1.5297 - val_categorical_accuracy: 0.4367\n",
      "Epoch 15/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 10.6834 - categorical_accuracy: 0.4215Epoch 15: loss = 10.677748680114746, val_loss = 2.2083380222320557\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 10.6777 - categorical_accuracy: 0.4212 - val_loss: 2.2083 - val_categorical_accuracy: 0.3346\n",
      "Epoch 16/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.0315 - categorical_accuracy: 0.3209Epoch 16: loss = 2.032148599624634, val_loss = 1.9353762865066528\n",
      "42/42 [==============================] - 3s 84ms/step - loss: 2.0321 - categorical_accuracy: 0.3206 - val_loss: 1.9354 - val_categorical_accuracy: 0.2980\n",
      "Epoch 17/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.6204 - categorical_accuracy: 0.3925Epoch 17: loss = 1.6220052242279053, val_loss = 1.6775531768798828\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 1.6220 - categorical_accuracy: 0.3922 - val_loss: 1.6776 - val_categorical_accuracy: 0.4649\n",
      "Epoch 18/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.7915 - categorical_accuracy: 0.2409Epoch 18: loss = 2.7914607524871826, val_loss = 2.2296650409698486\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 2.7915 - categorical_accuracy: 0.2407 - val_loss: 2.2297 - val_categorical_accuracy: 0.3430\n",
      "Epoch 19/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.4153 - categorical_accuracy: 0.2744Epoch 19: loss = 2.4142568111419678, val_loss = 1.828411340713501\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 2.4143 - categorical_accuracy: 0.2742 - val_loss: 1.8284 - val_categorical_accuracy: 0.3247\n",
      "Epoch 20/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.8351 - categorical_accuracy: 0.3544Epoch 20: loss = 1.8350173234939575, val_loss = 1.6477605104446411\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 1.8350 - categorical_accuracy: 0.3549 - val_loss: 1.6478 - val_categorical_accuracy: 0.4040\n",
      "Epoch 21/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.5514 - categorical_accuracy: 0.4489Epoch 21: loss = 1.5509936809539795, val_loss = 1.4507578611373901\n",
      "42/42 [==============================] - 3s 83ms/step - loss: 1.5510 - categorical_accuracy: 0.4494 - val_loss: 1.4508 - val_categorical_accuracy: 0.5358\n",
      "Epoch 22/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.4833 - categorical_accuracy: 0.4962Epoch 22: loss = 1.483345866203308, val_loss = 2.3311338424682617\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 1.4833 - categorical_accuracy: 0.4958 - val_loss: 2.3311 - val_categorical_accuracy: 0.4512\n",
      "Epoch 23/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.7453 - categorical_accuracy: 0.4268Epoch 23: loss = 1.7449331283569336, val_loss = 1.3712482452392578\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 1.7449 - categorical_accuracy: 0.4273 - val_loss: 1.3712 - val_categorical_accuracy: 0.4931\n",
      "Epoch 24/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.3830 - categorical_accuracy: 0.4787Epoch 24: loss = 1.383588194847107, val_loss = 1.3051023483276367\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 1.3836 - categorical_accuracy: 0.4783 - val_loss: 1.3051 - val_categorical_accuracy: 0.5381\n",
      "Epoch 25/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.2571 - categorical_accuracy: 0.5290Epoch 25: loss = 1.2577390670776367, val_loss = 1.4606057405471802\n",
      "42/42 [==============================] - 3s 83ms/step - loss: 1.2577 - categorical_accuracy: 0.5286 - val_loss: 1.4606 - val_categorical_accuracy: 0.5168\n",
      "Epoch 26/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.4013 - categorical_accuracy: 0.5175Epoch 26: loss = 1.4007071256637573, val_loss = 1.2170395851135254\n",
      "42/42 [==============================] - 3s 83ms/step - loss: 1.4007 - categorical_accuracy: 0.5179 - val_loss: 1.2170 - val_categorical_accuracy: 0.5396\n",
      "Epoch 27/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.1889 - categorical_accuracy: 0.5549Epoch 27: loss = 1.1895439624786377, val_loss = 1.132420301437378\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 1.1895 - categorical_accuracy: 0.5545 - val_loss: 1.1324 - val_categorical_accuracy: 0.5960\n",
      "Epoch 28/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.1359 - categorical_accuracy: 0.5808Epoch 28: loss = 1.1350767612457275, val_loss = 0.9798640608787537\n",
      "42/42 [==============================] - 4s 89ms/step - loss: 1.1351 - categorical_accuracy: 0.5811 - val_loss: 0.9799 - val_categorical_accuracy: 0.6280\n",
      "Epoch 29/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.0718 - categorical_accuracy: 0.5823Epoch 29: loss = 1.0724812746047974, val_loss = 0.9304732084274292\n",
      "42/42 [==============================] - 4s 84ms/step - loss: 1.0725 - categorical_accuracy: 0.5819 - val_loss: 0.9305 - val_categorical_accuracy: 0.6425\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.9723 - categorical_accuracy: 0.6207Epoch 30: loss = 0.9722916483879089, val_loss = 0.9198796153068542\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 0.9723 - categorical_accuracy: 0.6207 - val_loss: 0.9199 - val_categorical_accuracy: 0.6715\n",
      "Epoch 31/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.0771 - categorical_accuracy: 0.6105Epoch 31: loss = 1.0763224363327026, val_loss = 0.8744151592254639\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 1.0763 - categorical_accuracy: 0.6108 - val_loss: 0.8744 - val_categorical_accuracy: 0.6837\n",
      "Epoch 32/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.8683 - categorical_accuracy: 0.6623Epoch 32: loss = 0.8679096102714539, val_loss = 0.9528809785842896\n",
      "42/42 [==============================] - 3s 82ms/step - loss: 0.8679 - categorical_accuracy: 0.6626 - val_loss: 0.9529 - val_categorical_accuracy: 0.6319\n",
      "Epoch 33/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.0381 - categorical_accuracy: 0.6143Epoch 33: loss = 1.037735104560852, val_loss = 6.10241174697876\n",
      "42/42 [==============================] - 3s 83ms/step - loss: 1.0377 - categorical_accuracy: 0.6146 - val_loss: 6.1024 - val_categorical_accuracy: 0.6860\n",
      "Epoch 34/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 3.8797 - categorical_accuracy: 0.2645Epoch 34: loss = 3.8784046173095703, val_loss = 2.225670099258423\n",
      "42/42 [==============================] - 3s 79ms/step - loss: 3.8784 - categorical_accuracy: 0.2643 - val_loss: 2.2257 - val_categorical_accuracy: 0.2134\n",
      "Epoch 35/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.1840 - categorical_accuracy: 0.2645Epoch 35: loss = 2.1844773292541504, val_loss = 1.907940149307251\n",
      "42/42 [==============================] - 4s 87ms/step - loss: 2.1845 - categorical_accuracy: 0.2643 - val_loss: 1.9079 - val_categorical_accuracy: 0.3941\n",
      "Epoch 36/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.0807 - categorical_accuracy: 0.3125Epoch 36: loss = 2.0810272693634033, val_loss = 2.160876750946045\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 2.0810 - categorical_accuracy: 0.3123 - val_loss: 2.1609 - val_categorical_accuracy: 0.2134\n",
      "Epoch 37/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.9931 - categorical_accuracy: 0.2950Epoch 37: loss = 1.993103265762329, val_loss = 1.777719259262085\n",
      "42/42 [==============================] - 3s 79ms/step - loss: 1.9931 - categorical_accuracy: 0.2955 - val_loss: 1.7777 - val_categorical_accuracy: 0.3788\n",
      "Epoch 38/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.7200 - categorical_accuracy: 0.3918Epoch 38: loss = 1.7187706232070923, val_loss = 1.5674206018447876\n",
      "42/42 [==============================] - 4s 91ms/step - loss: 1.7188 - categorical_accuracy: 0.3922 - val_loss: 1.5674 - val_categorical_accuracy: 0.4360\n",
      "Epoch 39/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.5377 - categorical_accuracy: 0.4345Epoch 39: loss = 1.5391850471496582, val_loss = 1.4250601530075073\n",
      "42/42 [==============================] - 5s 109ms/step - loss: 1.5392 - categorical_accuracy: 0.4341 - val_loss: 1.4251 - val_categorical_accuracy: 0.4741\n",
      "Epoch 40/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.3923 - categorical_accuracy: 0.4954Epoch 40: loss = 1.391758918762207, val_loss = 1.3030422925949097\n",
      "42/42 [==============================] - 4s 102ms/step - loss: 1.3918 - categorical_accuracy: 0.4958 - val_loss: 1.3030 - val_categorical_accuracy: 0.5518\n",
      "Epoch 41/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.3854 - categorical_accuracy: 0.4840Restoring model weights from the end of the best epoch: 31.\n",
      "Epoch 41: loss = 1.3851406574249268, val_loss = 1.2750216722488403\n",
      "42/42 [==============================] - 4s 97ms/step - loss: 1.3851 - categorical_accuracy: 0.4844 - val_loss: 1.2750 - val_categorical_accuracy: 0.4916\n",
      "Epoch 41: early stopping\n",
      "41/41 [==============================] - 1s 34ms/step - loss: 0.8744 - categorical_accuracy: 0.6837\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 3.1172 - categorical_accuracy: 0.0747Epoch 1: loss = 3.1172218322753906, val_loss = 2.962761640548706\n",
      "41/41 [==============================] - 7s 107ms/step - loss: 3.1172 - categorical_accuracy: 0.0747 - val_loss: 2.9628 - val_categorical_accuracy: 0.0685\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.8150 - categorical_accuracy: 0.1113Epoch 2: loss = 2.815049648284912, val_loss = 2.644949197769165\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 2.8150 - categorical_accuracy: 0.1113 - val_loss: 2.6449 - val_categorical_accuracy: 0.1280\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.5243 - categorical_accuracy: 0.1616Epoch 3: loss = 2.524258613586426, val_loss = 2.376837968826294\n",
      "41/41 [==============================] - 4s 89ms/step - loss: 2.5243 - categorical_accuracy: 0.1616 - val_loss: 2.3768 - val_categorical_accuracy: 0.1874\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.4781 - categorical_accuracy: 0.1730Epoch 4: loss = 2.4780678749084473, val_loss = 2.3279354572296143\n",
      "41/41 [==============================] - 4s 90ms/step - loss: 2.4781 - categorical_accuracy: 0.1730 - val_loss: 2.3279 - val_categorical_accuracy: 0.1813\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3202 - categorical_accuracy: 0.2256Epoch 5: loss = 2.320223331451416, val_loss = 2.412881374359131\n",
      "41/41 [==============================] - 4s 90ms/step - loss: 2.3202 - categorical_accuracy: 0.2256 - val_loss: 2.4129 - val_categorical_accuracy: 0.2399\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.1706 - categorical_accuracy: 0.2599Epoch 6: loss = 2.1706087589263916, val_loss = 2.067075729370117\n",
      "41/41 [==============================] - 4s 88ms/step - loss: 2.1706 - categorical_accuracy: 0.2599 - val_loss: 2.0671 - val_categorical_accuracy: 0.2788\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.9288 - categorical_accuracy: 0.3369Epoch 7: loss = 1.9287524223327637, val_loss = 1.7362866401672363\n",
      "41/41 [==============================] - 4s 90ms/step - loss: 1.9288 - categorical_accuracy: 0.3369 - val_loss: 1.7363 - val_categorical_accuracy: 0.2940\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.9359 - categorical_accuracy: 0.3468Epoch 8: loss = 1.9358689785003662, val_loss = 1.7864665985107422\n",
      "41/41 [==============================] - 4s 92ms/step - loss: 1.9359 - categorical_accuracy: 0.3468 - val_loss: 1.7865 - val_categorical_accuracy: 0.3252\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.9834 - categorical_accuracy: 0.3155Epoch 9: loss = 1.9834033250808716, val_loss = 1.8034768104553223\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 1.9834 - categorical_accuracy: 0.3155 - val_loss: 1.8035 - val_categorical_accuracy: 0.3168\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.9261 - categorical_accuracy: 0.2477Epoch 10: loss = 2.926107406616211, val_loss = 2.521705150604248\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 2.9261 - categorical_accuracy: 0.2477 - val_loss: 2.5217 - val_categorical_accuracy: 0.2315\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 3.4180 - categorical_accuracy: 0.1296Epoch 11: loss = 3.417956829071045, val_loss = 2.6410531997680664\n",
      "41/41 [==============================] - 4s 90ms/step - loss: 3.4180 - categorical_accuracy: 0.1296 - val_loss: 2.6411 - val_categorical_accuracy: 0.1264\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.5548 - categorical_accuracy: 0.1631Epoch 12: loss = 2.5548319816589355, val_loss = 2.528534412384033\n",
      "41/41 [==============================] - 4s 92ms/step - loss: 2.5548 - categorical_accuracy: 0.1631 - val_loss: 2.5285 - val_categorical_accuracy: 0.1706\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.2653 - categorical_accuracy: 0.2188Epoch 13: loss = 2.26531982421875, val_loss = 2.03946590423584\n",
      "41/41 [==============================] - 4s 103ms/step - loss: 2.2653 - categorical_accuracy: 0.2188 - val_loss: 2.0395 - val_categorical_accuracy: 0.2559\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.0542 - categorical_accuracy: 0.2675Epoch 14: loss = 2.0541610717773438, val_loss = 1.9758154153823853\n",
      "41/41 [==============================] - 4s 90ms/step - loss: 2.0542 - categorical_accuracy: 0.2675 - val_loss: 1.9758 - val_categorical_accuracy: 0.2826\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.0218 - categorical_accuracy: 0.2630Epoch 15: loss = 2.021806478500366, val_loss = 1.8809988498687744\n",
      "41/41 [==============================] - 4s 90ms/step - loss: 2.0218 - categorical_accuracy: 0.2630 - val_loss: 1.8810 - val_categorical_accuracy: 0.3420\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.9625 - categorical_accuracy: 0.2782Epoch 16: loss = 1.9624557495117188, val_loss = 1.9252254962921143\n",
      "41/41 [==============================] - 4s 89ms/step - loss: 1.9625 - categorical_accuracy: 0.2782 - val_loss: 1.9252 - val_categorical_accuracy: 0.2506\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.9726 - categorical_accuracy: 0.2904Restoring model weights from the end of the best epoch: 7.\n",
      "Epoch 17: loss = 1.9725524187088013, val_loss = 2.1403257846832275\n",
      "41/41 [==============================] - 4s 94ms/step - loss: 1.9726 - categorical_accuracy: 0.2904 - val_loss: 2.1403 - val_categorical_accuracy: 0.2209\n",
      "Epoch 17: early stopping\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.7363 - categorical_accuracy: 0.2940\n",
      "Epoch 1/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 3.1442 - categorical_accuracy: 0.0663Epoch 1: loss = 3.144117832183838, val_loss = 2.7926011085510254\n",
      "42/42 [==============================] - 9s 114ms/step - loss: 3.1441 - categorical_accuracy: 0.0663 - val_loss: 2.7926 - val_categorical_accuracy: 0.1524\n",
      "Epoch 2/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.8828 - categorical_accuracy: 0.1044Epoch 2: loss = 2.882648468017578, val_loss = 2.700491428375244\n",
      "42/42 [==============================] - 4s 105ms/step - loss: 2.8826 - categorical_accuracy: 0.1043 - val_loss: 2.7005 - val_categorical_accuracy: 0.1441\n",
      "Epoch 3/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.5828 - categorical_accuracy: 0.1387Epoch 3: loss = 2.583106756210327, val_loss = 2.429959774017334\n",
      "42/42 [==============================] - 4s 93ms/step - loss: 2.5831 - categorical_accuracy: 0.1386 - val_loss: 2.4300 - val_categorical_accuracy: 0.1928\n",
      "Epoch 4/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.3557 - categorical_accuracy: 0.2248Epoch 4: loss = 2.3559913635253906, val_loss = 2.232466697692871\n",
      "42/42 [==============================] - 4s 99ms/step - loss: 2.3560 - categorical_accuracy: 0.2247 - val_loss: 2.2325 - val_categorical_accuracy: 0.2637\n",
      "Epoch 5/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.1125 - categorical_accuracy: 0.2668Epoch 5: loss = 2.1126625537872314, val_loss = 1.7561264038085938\n",
      "42/42 [==============================] - 6s 140ms/step - loss: 2.1127 - categorical_accuracy: 0.2666 - val_loss: 1.7561 - val_categorical_accuracy: 0.3986\n",
      "Epoch 6/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.1139 - categorical_accuracy: 0.2904Epoch 6: loss = 2.11238956451416, val_loss = 1.8197399377822876\n",
      "42/42 [==============================] - 5s 117ms/step - loss: 2.1124 - categorical_accuracy: 0.2909 - val_loss: 1.8197 - val_categorical_accuracy: 0.3399\n",
      "Epoch 7/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.7601 - categorical_accuracy: 0.3819Epoch 7: loss = 1.75899076461792, val_loss = 1.7009516954421997\n",
      "42/42 [==============================] - 7s 179ms/step - loss: 1.7590 - categorical_accuracy: 0.3823 - val_loss: 1.7010 - val_categorical_accuracy: 0.4558\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5245 - categorical_accuracy: 0.4532Epoch 8: loss = 1.5244754552841187, val_loss = 2.600874900817871\n",
      "42/42 [==============================] - 9s 215ms/step - loss: 1.5245 - categorical_accuracy: 0.4532 - val_loss: 2.6009 - val_categorical_accuracy: 0.2447\n",
      "Epoch 9/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.9060 - categorical_accuracy: 0.3681Epoch 9: loss = 1.9045778512954712, val_loss = 1.270230770111084\n",
      "42/42 [==============================] - 5s 129ms/step - loss: 1.9046 - categorical_accuracy: 0.3686 - val_loss: 1.2702 - val_categorical_accuracy: 0.5351\n",
      "Epoch 10/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.3645 - categorical_accuracy: 0.4924Epoch 10: loss = 1.3655191659927368, val_loss = 1.3935214281082153\n",
      "42/42 [==============================] - 5s 129ms/step - loss: 1.3655 - categorical_accuracy: 0.4920 - val_loss: 1.3935 - val_categorical_accuracy: 0.5114\n",
      "Epoch 11/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.3940 - categorical_accuracy: 0.4855Epoch 11: loss = 1.3937331438064575, val_loss = 2.2897958755493164\n",
      "42/42 [==============================] - 5s 117ms/step - loss: 1.3937 - categorical_accuracy: 0.4859 - val_loss: 2.2898 - val_categorical_accuracy: 0.3613\n",
      "Epoch 12/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.8448 - categorical_accuracy: 0.3933Epoch 12: loss = 1.8465349674224854, val_loss = 1.93282949924469\n",
      "42/42 [==============================] - 5s 112ms/step - loss: 1.8465 - categorical_accuracy: 0.3930 - val_loss: 1.9328 - val_categorical_accuracy: 0.4131\n",
      "Epoch 13/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.0963 - categorical_accuracy: 0.3148Epoch 13: loss = 2.0948944091796875, val_loss = 1.5893465280532837\n",
      "42/42 [==============================] - 6s 142ms/step - loss: 2.0949 - categorical_accuracy: 0.3153 - val_loss: 1.5893 - val_categorical_accuracy: 0.4398\n",
      "Epoch 14/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.4008 - categorical_accuracy: 0.4970Epoch 14: loss = 1.4012895822525024, val_loss = 1.2200841903686523\n",
      "42/42 [==============================] - 5s 127ms/step - loss: 1.4013 - categorical_accuracy: 0.4966 - val_loss: 1.2201 - val_categorical_accuracy: 0.5884\n",
      "Epoch 15/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.2711 - categorical_accuracy: 0.5305Epoch 15: loss = 1.2721692323684692, val_loss = 1.2961055040359497\n",
      "42/42 [==============================] - 4s 107ms/step - loss: 1.2722 - categorical_accuracy: 0.5301 - val_loss: 1.2961 - val_categorical_accuracy: 0.5434\n",
      "Epoch 16/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.1516 - categorical_accuracy: 0.5694Epoch 16: loss = 1.1513813734054565, val_loss = 3.027226209640503\n",
      "42/42 [==============================] - 4s 93ms/step - loss: 1.1514 - categorical_accuracy: 0.5689 - val_loss: 3.0272 - val_categorical_accuracy: 0.3994\n",
      "Epoch 17/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.5039 - categorical_accuracy: 0.2248Epoch 17: loss = 2.503173828125, val_loss = 2.0478968620300293\n",
      "42/42 [==============================] - 4s 100ms/step - loss: 2.5032 - categorical_accuracy: 0.2247 - val_loss: 2.0479 - val_categorical_accuracy: 0.3163\n",
      "Epoch 18/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.8266 - categorical_accuracy: 0.3422Epoch 18: loss = 1.8256276845932007, val_loss = 1.4692282676696777\n",
      "42/42 [==============================] - 4s 101ms/step - loss: 1.8256 - categorical_accuracy: 0.3427 - val_loss: 1.4692 - val_categorical_accuracy: 0.4649\n",
      "Epoch 19/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.4157 - categorical_accuracy: 0.4809Epoch 19: loss = 1.4147089719772339, val_loss = 1.1645386219024658\n",
      "42/42 [==============================] - 4s 106ms/step - loss: 1.4147 - categorical_accuracy: 0.4813 - val_loss: 1.1645 - val_categorical_accuracy: 0.5930\n",
      "Epoch 20/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.1627 - categorical_accuracy: 0.5579Epoch 20: loss = 1.1623398065567017, val_loss = 1.0881900787353516\n",
      "42/42 [==============================] - 4s 96ms/step - loss: 1.1623 - categorical_accuracy: 0.5583 - val_loss: 1.0882 - val_categorical_accuracy: 0.6067\n",
      "Epoch 21/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.2013 - categorical_accuracy: 0.5633Epoch 21: loss = 1.2025352716445923, val_loss = 1.159090518951416\n",
      "42/42 [==============================] - 4s 100ms/step - loss: 1.2025 - categorical_accuracy: 0.5628 - val_loss: 1.1591 - val_categorical_accuracy: 0.5945\n",
      "Epoch 22/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.1928 - categorical_accuracy: 0.5518Epoch 22: loss = 1.1921559572219849, val_loss = 1.2567417621612549\n",
      "42/42 [==============================] - 4s 94ms/step - loss: 1.1922 - categorical_accuracy: 0.5522 - val_loss: 1.2567 - val_categorical_accuracy: 0.5495\n",
      "Epoch 23/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.2802 - categorical_accuracy: 0.5335Epoch 23: loss = 1.2793887853622437, val_loss = 0.929267406463623\n",
      "42/42 [==============================] - 5s 110ms/step - loss: 1.2794 - categorical_accuracy: 0.5339 - val_loss: 0.9293 - val_categorical_accuracy: 0.6730\n",
      "Epoch 24/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.0249 - categorical_accuracy: 0.6197Epoch 24: loss = 1.0241397619247437, val_loss = 1.1229581832885742\n",
      "42/42 [==============================] - 4s 102ms/step - loss: 1.0241 - categorical_accuracy: 0.6200 - val_loss: 1.1230 - val_categorical_accuracy: 0.6128\n",
      "Epoch 25/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.9054 - categorical_accuracy: 0.6494Epoch 25: loss = 0.9048896431922913, val_loss = 1.4286285638809204\n",
      "42/42 [==============================] - 4s 93ms/step - loss: 0.9049 - categorical_accuracy: 0.6497 - val_loss: 1.4286 - val_categorical_accuracy: 0.4985\n",
      "Epoch 26/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.1842 - categorical_accuracy: 0.5442Epoch 26: loss = 1.1839009523391724, val_loss = 0.9224161505699158\n",
      "42/42 [==============================] - 5s 109ms/step - loss: 1.1839 - categorical_accuracy: 0.5446 - val_loss: 0.9224 - val_categorical_accuracy: 0.6791\n",
      "Epoch 27/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.8864 - categorical_accuracy: 0.6692Epoch 27: loss = 0.8864735960960388, val_loss = 0.7875687479972839\n",
      "42/42 [==============================] - 5s 111ms/step - loss: 0.8865 - categorical_accuracy: 0.6695 - val_loss: 0.7876 - val_categorical_accuracy: 0.7134\n",
      "Epoch 28/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.8045 - categorical_accuracy: 0.6959Epoch 28: loss = 0.8047564029693604, val_loss = 0.7097374796867371\n",
      "42/42 [==============================] - 4s 102ms/step - loss: 0.8048 - categorical_accuracy: 0.6961 - val_loss: 0.7097 - val_categorical_accuracy: 0.7477\n",
      "Epoch 29/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.3217 - categorical_accuracy: 0.6258Epoch 29: loss = 1.321946144104004, val_loss = 1.2662255764007568\n",
      "42/42 [==============================] - 6s 139ms/step - loss: 1.3219 - categorical_accuracy: 0.6253 - val_loss: 1.2662 - val_categorical_accuracy: 0.6029\n",
      "Epoch 30/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.4213 - categorical_accuracy: 0.3041Epoch 30: loss = 2.421720266342163, val_loss = 1.8286205530166626\n",
      "42/42 [==============================] - 4s 101ms/step - loss: 2.4217 - categorical_accuracy: 0.3039 - val_loss: 1.8286 - val_categorical_accuracy: 0.4367\n",
      "Epoch 31/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.4849 - categorical_accuracy: 0.4779Epoch 31: loss = 1.4849058389663696, val_loss = 1.2491780519485474\n",
      "42/42 [==============================] - 4s 105ms/step - loss: 1.4849 - categorical_accuracy: 0.4775 - val_loss: 1.2492 - val_categorical_accuracy: 0.5366\n",
      "Epoch 32/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.1168 - categorical_accuracy: 0.5701Epoch 32: loss = 1.1167712211608887, val_loss = 1.3776761293411255\n",
      "42/42 [==============================] - 4s 102ms/step - loss: 1.1168 - categorical_accuracy: 0.5697 - val_loss: 1.3777 - val_categorical_accuracy: 0.5267\n",
      "Epoch 33/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.2692 - categorical_accuracy: 0.5503Epoch 33: loss = 1.2683777809143066, val_loss = 0.9354153275489807\n",
      "42/42 [==============================] - 4s 93ms/step - loss: 1.2684 - categorical_accuracy: 0.5506 - val_loss: 0.9354 - val_categorical_accuracy: 0.6296\n",
      "Epoch 34/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.9907 - categorical_accuracy: 0.6197Epoch 34: loss = 0.9901242256164551, val_loss = 0.8444669842720032\n",
      "42/42 [==============================] - 4s 101ms/step - loss: 0.9901 - categorical_accuracy: 0.6200 - val_loss: 0.8445 - val_categorical_accuracy: 0.6974\n",
      "Epoch 35/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.0575 - categorical_accuracy: 0.5953Epoch 35: loss = 1.057705283164978, val_loss = 1.464219570159912\n",
      "42/42 [==============================] - 4s 100ms/step - loss: 1.0577 - categorical_accuracy: 0.5956 - val_loss: 1.4642 - val_categorical_accuracy: 0.5023\n",
      "Epoch 36/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.0771 - categorical_accuracy: 0.5854Epoch 36: loss = 1.0763384103775024, val_loss = 0.8139970302581787\n",
      "42/42 [==============================] - 5s 121ms/step - loss: 1.0763 - categorical_accuracy: 0.5857 - val_loss: 0.8140 - val_categorical_accuracy: 0.7104\n",
      "Epoch 37/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.8477 - categorical_accuracy: 0.6707Epoch 37: loss = 0.8475376963615417, val_loss = 0.8275914192199707\n",
      "42/42 [==============================] - 5s 112ms/step - loss: 0.8475 - categorical_accuracy: 0.6710 - val_loss: 0.8276 - val_categorical_accuracy: 0.6913\n",
      "Epoch 38/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.8644 - categorical_accuracy: 0.6715Epoch 38: loss = 0.8639258146286011, val_loss = 0.7085723280906677\n",
      "42/42 [==============================] - 5s 111ms/step - loss: 0.8639 - categorical_accuracy: 0.6717 - val_loss: 0.7086 - val_categorical_accuracy: 0.7348\n",
      "Epoch 39/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.8180 - categorical_accuracy: 0.6806Epoch 39: loss = 0.8174771666526794, val_loss = 0.7123287320137024\n",
      "42/42 [==============================] - 5s 109ms/step - loss: 0.8175 - categorical_accuracy: 0.6809 - val_loss: 0.7123 - val_categorical_accuracy: 0.7302\n",
      "Epoch 40/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.7616 - categorical_accuracy: 0.7066Epoch 40: loss = 0.7623974084854126, val_loss = 0.7461091876029968\n",
      "42/42 [==============================] - 4s 100ms/step - loss: 0.7624 - categorical_accuracy: 0.7060 - val_loss: 0.7461 - val_categorical_accuracy: 0.7203\n",
      "Epoch 41/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.8962 - categorical_accuracy: 0.6570Epoch 41: loss = 0.8957347273826599, val_loss = 0.7992366552352905\n",
      "42/42 [==============================] - 4s 95ms/step - loss: 0.8957 - categorical_accuracy: 0.6573 - val_loss: 0.7992 - val_categorical_accuracy: 0.7309\n",
      "Epoch 42/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.7798 - categorical_accuracy: 0.6951Epoch 42: loss = 0.7791951894760132, val_loss = 0.7711551189422607\n",
      "42/42 [==============================] - 4s 96ms/step - loss: 0.7792 - categorical_accuracy: 0.6954 - val_loss: 0.7712 - val_categorical_accuracy: 0.6890\n",
      "Epoch 43/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.6935 - categorical_accuracy: 0.7226Epoch 43: loss = 0.6929287314414978, val_loss = 0.6071547269821167\n",
      "42/42 [==============================] - 4s 108ms/step - loss: 0.6929 - categorical_accuracy: 0.7228 - val_loss: 0.6072 - val_categorical_accuracy: 0.7668\n",
      "Epoch 44/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.7000 - categorical_accuracy: 0.7195Epoch 44: loss = 0.6994430422782898, val_loss = 0.6466619372367859\n",
      "42/42 [==============================] - 4s 104ms/step - loss: 0.6994 - categorical_accuracy: 0.7197 - val_loss: 0.6467 - val_categorical_accuracy: 0.7530\n",
      "Epoch 45/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.6177 - categorical_accuracy: 0.7470Epoch 45: loss = 0.6171978712081909, val_loss = 0.6374160647392273\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 0.6172 - categorical_accuracy: 0.7471 - val_loss: 0.6374 - val_categorical_accuracy: 0.7820\n",
      "Epoch 46/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.5676 - categorical_accuracy: 0.7675Epoch 46: loss = 0.5671356916427612, val_loss = 0.8498707413673401\n",
      "42/42 [==============================] - 5s 115ms/step - loss: 0.5671 - categorical_accuracy: 0.7677 - val_loss: 0.8499 - val_categorical_accuracy: 0.7119\n",
      "Epoch 47/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.6944 - categorical_accuracy: 0.7287Epoch 47: loss = 0.6940122246742249, val_loss = 0.5685545802116394\n",
      "42/42 [==============================] - 5s 121ms/step - loss: 0.6940 - categorical_accuracy: 0.7289 - val_loss: 0.5686 - val_categorical_accuracy: 0.7927\n",
      "Epoch 48/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.6141 - categorical_accuracy: 0.7622Epoch 48: loss = 0.6136693954467773, val_loss = 0.6937282085418701\n",
      "42/42 [==============================] - 4s 103ms/step - loss: 0.6137 - categorical_accuracy: 0.7624 - val_loss: 0.6937 - val_categorical_accuracy: 0.7569\n",
      "Epoch 49/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.6297 - categorical_accuracy: 0.7477Epoch 49: loss = 0.6321642994880676, val_loss = 0.6636390686035156\n",
      "42/42 [==============================] - 4s 95ms/step - loss: 0.6322 - categorical_accuracy: 0.7471 - val_loss: 0.6636 - val_categorical_accuracy: 0.7348\n",
      "Epoch 50/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.9170 - categorical_accuracy: 0.6603Epoch 50: loss = 0.9169759154319763, val_loss = 0.6278449296951294\n",
      "42/42 [==============================] - 4s 107ms/step - loss: 0.9170 - categorical_accuracy: 0.6603 - val_loss: 0.6278 - val_categorical_accuracy: 0.7599\n",
      "41/41 [==============================] - 1s 31ms/step - loss: 0.6278 - categorical_accuracy: 0.7599\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 3.1318 - categorical_accuracy: 0.0473Epoch 1: loss = 3.1317861080169678, val_loss = 3.0202057361602783\n",
      "41/41 [==============================] - 9s 124ms/step - loss: 3.1318 - categorical_accuracy: 0.0473 - val_loss: 3.0202 - val_categorical_accuracy: 0.0716\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 3.1389 - categorical_accuracy: 0.0823Epoch 2: loss = 3.138861656188965, val_loss = 3.3441245555877686\n",
      "41/41 [==============================] - 5s 129ms/step - loss: 3.1389 - categorical_accuracy: 0.0823 - val_loss: 3.3441 - val_categorical_accuracy: 0.0853\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.9533 - categorical_accuracy: 0.0976Epoch 3: loss = 2.9532997608184814, val_loss = 2.7385852336883545\n",
      "41/41 [==============================] - 5s 127ms/step - loss: 2.9533 - categorical_accuracy: 0.0976 - val_loss: 2.7386 - val_categorical_accuracy: 0.1112\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.6323 - categorical_accuracy: 0.1547Epoch 4: loss = 2.632256507873535, val_loss = 2.593939781188965\n",
      "41/41 [==============================] - 5s 110ms/step - loss: 2.6323 - categorical_accuracy: 0.1547 - val_loss: 2.5939 - val_categorical_accuracy: 0.1500\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.5913 - categorical_accuracy: 0.1593Epoch 5: loss = 2.5912961959838867, val_loss = 2.4222352504730225\n",
      "41/41 [==============================] - 4s 108ms/step - loss: 2.5913 - categorical_accuracy: 0.1593 - val_loss: 2.4222 - val_categorical_accuracy: 0.1881\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.5811 - categorical_accuracy: 0.2043Epoch 6: loss = 2.5810630321502686, val_loss = 2.4925248622894287\n",
      "41/41 [==============================] - 4s 105ms/step - loss: 2.5811 - categorical_accuracy: 0.2043 - val_loss: 2.4925 - val_categorical_accuracy: 0.1935\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.2756 - categorical_accuracy: 0.2264Epoch 7: loss = 2.2755584716796875, val_loss = 2.060307502746582\n",
      "41/41 [==============================] - 4s 99ms/step - loss: 2.2756 - categorical_accuracy: 0.2264 - val_loss: 2.0603 - val_categorical_accuracy: 0.2658\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.9649 - categorical_accuracy: 0.3163Epoch 8: loss = 1.9649317264556885, val_loss = 1.8550080060958862\n",
      "41/41 [==============================] - 4s 99ms/step - loss: 1.9649 - categorical_accuracy: 0.3163 - val_loss: 1.8550 - val_categorical_accuracy: 0.3191\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.8672 - categorical_accuracy: 0.3544Epoch 9: loss = 1.8672109842300415, val_loss = 1.743482232093811\n",
      "41/41 [==============================] - 4s 102ms/step - loss: 1.8672 - categorical_accuracy: 0.3544 - val_loss: 1.7435 - val_categorical_accuracy: 0.3960\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.9191 - categorical_accuracy: 0.3209Epoch 10: loss = 1.919101595878601, val_loss = 1.7365626096725464\n",
      "41/41 [==============================] - 4s 104ms/step - loss: 1.9191 - categorical_accuracy: 0.3209 - val_loss: 1.7366 - val_categorical_accuracy: 0.3542\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.9808 - categorical_accuracy: 0.3498Epoch 11: loss = 1.9808156490325928, val_loss = 2.2708046436309814\n",
      "41/41 [==============================] - 4s 100ms/step - loss: 1.9808 - categorical_accuracy: 0.3498 - val_loss: 2.2708 - val_categorical_accuracy: 0.1668\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.9038 - categorical_accuracy: 0.3209Epoch 12: loss = 1.9038056135177612, val_loss = 1.6622202396392822\n",
      "41/41 [==============================] - 4s 107ms/step - loss: 1.9038 - categorical_accuracy: 0.3209 - val_loss: 1.6622 - val_categorical_accuracy: 0.4158\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.7242 - categorical_accuracy: 0.3598Epoch 13: loss = 1.7241618633270264, val_loss = 1.6516644954681396\n",
      "41/41 [==============================] - 5s 126ms/step - loss: 1.7242 - categorical_accuracy: 0.3598 - val_loss: 1.6517 - val_categorical_accuracy: 0.3679\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.7027 - categorical_accuracy: 0.3720Epoch 14: loss = 1.7026771306991577, val_loss = 1.685021162033081\n",
      "41/41 [==============================] - 5s 118ms/step - loss: 1.7027 - categorical_accuracy: 0.3720 - val_loss: 1.6850 - val_categorical_accuracy: 0.3572\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.5760 - categorical_accuracy: 0.4040Epoch 15: loss = 1.5760349035263062, val_loss = 1.452117919921875\n",
      "41/41 [==============================] - 3s 84ms/step - loss: 1.5760 - categorical_accuracy: 0.4040 - val_loss: 1.4521 - val_categorical_accuracy: 0.4577\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.5088 - categorical_accuracy: 0.4367Epoch 16: loss = 1.5087618827819824, val_loss = 1.4625030755996704\n",
      "41/41 [==============================] - 4s 98ms/step - loss: 1.5088 - categorical_accuracy: 0.4367 - val_loss: 1.4625 - val_categorical_accuracy: 0.4783\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.3913 - categorical_accuracy: 0.4802Epoch 17: loss = 1.391308307647705, val_loss = 1.2858881950378418\n",
      "41/41 [==============================] - 4s 86ms/step - loss: 1.3913 - categorical_accuracy: 0.4802 - val_loss: 1.2859 - val_categorical_accuracy: 0.5545\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.3732 - categorical_accuracy: 0.4931Epoch 18: loss = 1.3732073307037354, val_loss = 1.5148383378982544\n",
      "41/41 [==============================] - 3s 85ms/step - loss: 1.3732 - categorical_accuracy: 0.4931 - val_loss: 1.5148 - val_categorical_accuracy: 0.4516\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.4591 - categorical_accuracy: 0.4649Epoch 19: loss = 1.4590696096420288, val_loss = 1.2763372659683228\n",
      "41/41 [==============================] - 4s 90ms/step - loss: 1.4591 - categorical_accuracy: 0.4649 - val_loss: 1.2763 - val_categorical_accuracy: 0.5385\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2767 - categorical_accuracy: 0.5335Epoch 20: loss = 1.2766520977020264, val_loss = 1.2228554487228394\n",
      "41/41 [==============================] - 3s 85ms/step - loss: 1.2767 - categorical_accuracy: 0.5335 - val_loss: 1.2229 - val_categorical_accuracy: 0.5484\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2205 - categorical_accuracy: 0.5518Epoch 21: loss = 1.2204984426498413, val_loss = 1.17014479637146\n",
      "41/41 [==============================] - 4s 93ms/step - loss: 1.2205 - categorical_accuracy: 0.5518 - val_loss: 1.1701 - val_categorical_accuracy: 0.5765\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2236 - categorical_accuracy: 0.5366Epoch 22: loss = 1.2236052751541138, val_loss = 1.2840863466262817\n",
      "41/41 [==============================] - 4s 108ms/step - loss: 1.2236 - categorical_accuracy: 0.5366 - val_loss: 1.2841 - val_categorical_accuracy: 0.4836\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1038 - categorical_accuracy: 0.5877Epoch 23: loss = 1.1037925481796265, val_loss = 1.1404587030410767\n",
      "41/41 [==============================] - 4s 93ms/step - loss: 1.1038 - categorical_accuracy: 0.5877 - val_loss: 1.1405 - val_categorical_accuracy: 0.5925\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1121 - categorical_accuracy: 0.5854Epoch 24: loss = 1.1120693683624268, val_loss = 1.1984214782714844\n",
      "41/41 [==============================] - 3s 81ms/step - loss: 1.1121 - categorical_accuracy: 0.5854 - val_loss: 1.1984 - val_categorical_accuracy: 0.5278\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0538 - categorical_accuracy: 0.5968Epoch 25: loss = 1.0537506341934204, val_loss = 0.9490593075752258\n",
      "41/41 [==============================] - 4s 93ms/step - loss: 1.0538 - categorical_accuracy: 0.5968 - val_loss: 0.9491 - val_categorical_accuracy: 0.6550\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.6546 - categorical_accuracy: 0.5206Epoch 26: loss = 1.6545666456222534, val_loss = 1.7395999431610107\n",
      "41/41 [==============================] - 4s 90ms/step - loss: 1.6546 - categorical_accuracy: 0.5206 - val_loss: 1.7396 - val_categorical_accuracy: 0.3976\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.5570 - categorical_accuracy: 0.4489Epoch 27: loss = 1.556994080543518, val_loss = 1.4484472274780273\n",
      "41/41 [==============================] - 3s 80ms/step - loss: 1.5570 - categorical_accuracy: 0.4489 - val_loss: 1.4484 - val_categorical_accuracy: 0.4303\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2514 - categorical_accuracy: 0.5191Epoch 28: loss = 1.251384973526001, val_loss = 1.2641459703445435\n",
      "41/41 [==============================] - 4s 88ms/step - loss: 1.2514 - categorical_accuracy: 0.5191 - val_loss: 1.2641 - val_categorical_accuracy: 0.5400\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1282 - categorical_accuracy: 0.5793Epoch 29: loss = 1.1281722784042358, val_loss = 0.9563872218132019\n",
      "41/41 [==============================] - 4s 100ms/step - loss: 1.1282 - categorical_accuracy: 0.5793 - val_loss: 0.9564 - val_categorical_accuracy: 0.6443\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0537 - categorical_accuracy: 0.6044Epoch 30: loss = 1.0536540746688843, val_loss = 0.9835405945777893\n",
      "41/41 [==============================] - 4s 94ms/step - loss: 1.0537 - categorical_accuracy: 0.6044 - val_loss: 0.9835 - val_categorical_accuracy: 0.6161\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.9668 - categorical_accuracy: 0.6280Epoch 31: loss = 0.9667628407478333, val_loss = 0.9591624140739441\n",
      "41/41 [==============================] - 6s 152ms/step - loss: 0.9668 - categorical_accuracy: 0.6280 - val_loss: 0.9592 - val_categorical_accuracy: 0.6672\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.9252 - categorical_accuracy: 0.6540Epoch 32: loss = 0.9251695871353149, val_loss = 0.9562504887580872\n",
      "41/41 [==============================] - 4s 89ms/step - loss: 0.9252 - categorical_accuracy: 0.6540 - val_loss: 0.9563 - val_categorical_accuracy: 0.6260\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1658 - categorical_accuracy: 0.5892Epoch 33: loss = 1.1658425331115723, val_loss = 1.4467010498046875\n",
      "41/41 [==============================] - 5s 122ms/step - loss: 1.1658 - categorical_accuracy: 0.5892 - val_loss: 1.4467 - val_categorical_accuracy: 0.4950\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1215 - categorical_accuracy: 0.5938Epoch 34: loss = 1.1215403079986572, val_loss = 1.1315772533416748\n",
      "41/41 [==============================] - 4s 101ms/step - loss: 1.1215 - categorical_accuracy: 0.5938 - val_loss: 1.1316 - val_categorical_accuracy: 0.5925\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0979 - categorical_accuracy: 0.6021Restoring model weights from the end of the best epoch: 25.\n",
      "Epoch 35: loss = 1.0979223251342773, val_loss = 1.1506396532058716\n",
      "41/41 [==============================] - 4s 101ms/step - loss: 1.0979 - categorical_accuracy: 0.6021 - val_loss: 1.1506 - val_categorical_accuracy: 0.6101\n",
      "Epoch 35: early stopping\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.9491 - categorical_accuracy: 0.6550\n",
      "Epoch 1/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 3.1463 - categorical_accuracy: 0.0770Epoch 1: loss = 3.1461188793182373, val_loss = 3.086801290512085\n",
      "42/42 [==============================] - 9s 117ms/step - loss: 3.1461 - categorical_accuracy: 0.0769 - val_loss: 3.0868 - val_categorical_accuracy: 0.1006\n",
      "Epoch 2/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.9428 - categorical_accuracy: 0.1174Epoch 2: loss = 2.9413912296295166, val_loss = 2.7271103858947754\n",
      "42/42 [==============================] - 4s 102ms/step - loss: 2.9414 - categorical_accuracy: 0.1181 - val_loss: 2.7271 - val_categorical_accuracy: 0.1364\n",
      "Epoch 3/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.5605 - categorical_accuracy: 0.1418Epoch 3: loss = 2.559379816055298, val_loss = 2.765984058380127\n",
      "42/42 [==============================] - 4s 98ms/step - loss: 2.5594 - categorical_accuracy: 0.1424 - val_loss: 2.7660 - val_categorical_accuracy: 0.0854\n",
      "Epoch 4/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.3410 - categorical_accuracy: 0.1867Epoch 4: loss = 2.3412296772003174, val_loss = 2.1089887619018555\n",
      "42/42 [==============================] - 4s 99ms/step - loss: 2.3412 - categorical_accuracy: 0.1866 - val_loss: 2.1090 - val_categorical_accuracy: 0.2561\n",
      "Epoch 5/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.1409 - categorical_accuracy: 0.2180Epoch 5: loss = 2.140709161758423, val_loss = 1.8842577934265137\n",
      "42/42 [==============================] - 5s 116ms/step - loss: 2.1407 - categorical_accuracy: 0.2178 - val_loss: 1.8843 - val_categorical_accuracy: 0.3041\n",
      "Epoch 6/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.4572 - categorical_accuracy: 0.1966Epoch 6: loss = 2.456221342086792, val_loss = 2.4007136821746826\n",
      "42/42 [==============================] - 4s 103ms/step - loss: 2.4562 - categorical_accuracy: 0.1973 - val_loss: 2.4007 - val_categorical_accuracy: 0.1768\n",
      "Epoch 7/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.2616 - categorical_accuracy: 0.2127Epoch 7: loss = 2.261326551437378, val_loss = 2.0077381134033203\n",
      "42/42 [==============================] - 5s 130ms/step - loss: 2.2613 - categorical_accuracy: 0.2133 - val_loss: 2.0077 - val_categorical_accuracy: 0.2774\n",
      "Epoch 8/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.1446 - categorical_accuracy: 0.2294Epoch 8: loss = 2.1445822715759277, val_loss = 1.9730983972549438\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 2.1446 - categorical_accuracy: 0.2292 - val_loss: 1.9731 - val_categorical_accuracy: 0.3133\n",
      "Epoch 9/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.9322 - categorical_accuracy: 0.2896Epoch 9: loss = 1.932066798210144, val_loss = 1.6640076637268066\n",
      "42/42 [==============================] - 6s 136ms/step - loss: 1.9321 - categorical_accuracy: 0.2894 - val_loss: 1.6640 - val_categorical_accuracy: 0.3895\n",
      "Epoch 10/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.9372 - categorical_accuracy: 0.2950Epoch 10: loss = 1.93821120262146, val_loss = 1.8705010414123535\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.9382 - categorical_accuracy: 0.2947 - val_loss: 1.8705 - val_categorical_accuracy: 0.3140\n",
      "Epoch 11/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.5372 - categorical_accuracy: 0.2317Epoch 11: loss = 2.5377275943756104, val_loss = 2.4192161560058594\n",
      "42/42 [==============================] - 5s 132ms/step - loss: 2.5377 - categorical_accuracy: 0.2315 - val_loss: 2.4192 - val_categorical_accuracy: 0.2050\n",
      "Epoch 12/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.1237 - categorical_accuracy: 0.2591Epoch 12: loss = 2.124401569366455, val_loss = 1.8445624113082886\n",
      "42/42 [==============================] - 5s 110ms/step - loss: 2.1244 - categorical_accuracy: 0.2589 - val_loss: 1.8446 - val_categorical_accuracy: 0.3056\n",
      "Epoch 13/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.9561 - categorical_accuracy: 0.2256Epoch 13: loss = 2.9554646015167236, val_loss = 2.2021806240081787\n",
      "42/42 [==============================] - 4s 99ms/step - loss: 2.9555 - categorical_accuracy: 0.2262 - val_loss: 2.2022 - val_categorical_accuracy: 0.2607\n",
      "Epoch 14/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.6924 - categorical_accuracy: 0.2264Epoch 14: loss = 2.6917974948883057, val_loss = 2.7602081298828125\n",
      "42/42 [==============================] - 4s 108ms/step - loss: 2.6918 - categorical_accuracy: 0.2262 - val_loss: 2.7602 - val_categorical_accuracy: 0.2645\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.0535 - categorical_accuracy: 0.2963Epoch 15: loss = 2.0534934997558594, val_loss = 2.2326126098632812\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 2.0535 - categorical_accuracy: 0.2963 - val_loss: 2.2326 - val_categorical_accuracy: 0.3910\n",
      "Epoch 16/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.0820 - categorical_accuracy: 0.3018Epoch 16: loss = 2.082366943359375, val_loss = 1.6718875169754028\n",
      "42/42 [==============================] - 5s 110ms/step - loss: 2.0824 - categorical_accuracy: 0.3016 - val_loss: 1.6719 - val_categorical_accuracy: 0.4070\n",
      "Epoch 17/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.8137 - categorical_accuracy: 0.3491Epoch 17: loss = 1.8142859935760498, val_loss = 1.8172816038131714\n",
      "42/42 [==============================] - 4s 98ms/step - loss: 1.8143 - categorical_accuracy: 0.3488 - val_loss: 1.8173 - val_categorical_accuracy: 0.3758\n",
      "Epoch 18/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.1407 - categorical_accuracy: 0.3148Epoch 18: loss = 2.140913486480713, val_loss = 3.6256263256073\n",
      "42/42 [==============================] - 4s 100ms/step - loss: 2.1409 - categorical_accuracy: 0.3145 - val_loss: 3.6256 - val_categorical_accuracy: 0.3918\n",
      "Epoch 19/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.3500 - categorical_accuracy: 0.2492Restoring model weights from the end of the best epoch: 9.\n",
      "Epoch 19: loss = 2.3498547077178955, val_loss = 2.150451183319092\n",
      "42/42 [==============================] - 4s 100ms/step - loss: 2.3499 - categorical_accuracy: 0.2490 - val_loss: 2.1505 - val_categorical_accuracy: 0.2348\n",
      "Epoch 19: early stopping\n",
      "41/41 [==============================] - 1s 34ms/step - loss: 1.6640 - categorical_accuracy: 0.3895\n",
      "Units: 16, Batch Size: 16, Dropout Rate: 0.1, Mean Score: 0.4518357217311859\n",
      "Units: 16, Batch Size: 16, Dropout Rate: 0.2, Mean Score: 0.5615125894546509\n",
      "Units: 16, Batch Size: 16, Dropout Rate: 0.3, Mean Score: 0.5973531305789948\n",
      "Units: 16, Batch Size: 32, Dropout Rate: 0.1, Mean Score: 0.6156281530857086\n",
      "Units: 16, Batch Size: 32, Dropout Rate: 0.2, Mean Score: 0.5943046808242798\n",
      "Units: 16, Batch Size: 32, Dropout Rate: 0.3, Mean Score: 0.5561542809009552\n",
      "Units: 32, Batch Size: 16, Dropout Rate: 0.1, Mean Score: 0.7653466463088989\n",
      "Units: 32, Batch Size: 16, Dropout Rate: 0.2, Mean Score: 0.6499568223953247\n",
      "Units: 32, Batch Size: 16, Dropout Rate: 0.3, Mean Score: 0.3576764613389969\n",
      "Units: 32, Batch Size: 32, Dropout Rate: 0.1, Mean Score: 0.6917692720890045\n",
      "Units: 32, Batch Size: 32, Dropout Rate: 0.2, Mean Score: 0.41572462767362595\n",
      "Units: 32, Batch Size: 32, Dropout Rate: 0.3, Mean Score: 0.4951920062303543\n",
      "Units: 64, Batch Size: 16, Dropout Rate: 0.1, Mean Score: 0.724570095539093\n",
      "Units: 64, Batch Size: 16, Dropout Rate: 0.2, Mean Score: 0.7242090106010437\n",
      "Units: 64, Batch Size: 16, Dropout Rate: 0.3, Mean Score: 0.7093346118927002\n",
      "Units: 64, Batch Size: 32, Dropout Rate: 0.1, Mean Score: 0.7196053564548492\n",
      "Units: 64, Batch Size: 32, Dropout Rate: 0.2, Mean Score: 0.5269459038972855\n",
      "Units: 64, Batch Size: 32, Dropout Rate: 0.3, Mean Score: 0.5222351402044296\n"
     ]
    }
   ],
   "source": [
    "# Callback do logowania strat w każdej epoce\n",
    "class LoggingCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        print(f\"Epoch {epoch+1}: loss = {logs.get('loss')}, val_loss = {logs.get('val_loss')}\")\n",
    "\n",
    "# Funkcja do budowania modelu\n",
    "def build_model(units=16, activation='relu', dropout_rate=0.1):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, return_sequences=True, activation=activation, input_shape=(30, 258)))\n",
    "    model.add(LSTM(units * 2, return_sequences=True, activation=activation))\n",
    "    model.add(LSTM(units, return_sequences=False, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units, activation=activation))\n",
    "    model.add(Dense(actions.shape[0], activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrapper KerasClassifier\n",
    "model = KerasClassifier(build_fn=build_model, verbose=1)\n",
    "\n",
    "# Definicja siatki hiperparametrów dla Grid Search (z dodanym dropout_rate)\n",
    "param_grid = {\n",
    "    'units': [16, 32, 64],\n",
    "    'batch_size': [16, 32],\n",
    "    'dropout_rate': [0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "# Funkcja do trenowania i ewaluacji modelu\n",
    "def train_and_evaluate(units, batch_size, dropout_rate, epochs=50):\n",
    "    kf = KFold(n_splits=2)\n",
    "    fold_scores = []\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        # Budowanie modelu\n",
    "        model = build_model(units=units, dropout_rate=dropout_rate)\n",
    "\n",
    "        # Trenowanie modelu\n",
    "        history = model.fit(\n",
    "            X_train_fold, y_train_fold, \n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size, \n",
    "            validation_data=(X_val_fold, y_val_fold), \n",
    "            callbacks=[early_stopping, LoggingCallback()]\n",
    "        )\n",
    "\n",
    "        # Ewaluacja modelu\n",
    "        val_loss, val_accuracy = model.evaluate(X_val_fold, y_val_fold)\n",
    "        fold_scores.append(val_accuracy)\n",
    "\n",
    "    mean_score = np.mean(fold_scores)\n",
    "    return mean_score\n",
    "\n",
    "# Przechowywanie wyników\n",
    "results = []\n",
    "\n",
    "# Iteracja przez różne kombinacje hiperparametrów\n",
    "for units in param_grid['units']:\n",
    "    for batch_size in param_grid['batch_size']:\n",
    "        for dropout_rate in param_grid['dropout_rate']:\n",
    "            mean_score = train_and_evaluate(units, batch_size, dropout_rate)\n",
    "            results.append({'units': units, 'batch_size': batch_size, 'dropout_rate': dropout_rate, 'mean_score': mean_score})\n",
    "\n",
    "# Konwersja wyników do DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Wyświetlanie wyników\n",
    "for result in results:\n",
    "    print(f\"Units: {result['units']}, Batch Size: {result['batch_size']}, Dropout Rate: {result['dropout_rate']}, Mean Score: {result['mean_score']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba jednostek: 16, Rozmiar partii: 16, Wskaźnik dropout: 0.1, Średni wynik: 0.4518357217311859\n",
      "Liczba jednostek: 16, Rozmiar partii: 16, Wskaźnik dropout: 0.2, Średni wynik: 0.5615125894546509\n",
      "Liczba jednostek: 16, Rozmiar partii: 16, Wskaźnik dropout: 0.3, Średni wynik: 0.5973531305789948\n",
      "Liczba jednostek: 16, Rozmiar partii: 32, Wskaźnik dropout: 0.1, Średni wynik: 0.6156281530857086\n",
      "Liczba jednostek: 16, Rozmiar partii: 32, Wskaźnik dropout: 0.2, Średni wynik: 0.5943046808242798\n",
      "Liczba jednostek: 16, Rozmiar partii: 32, Wskaźnik dropout: 0.3, Średni wynik: 0.5561542809009552\n",
      "Liczba jednostek: 32, Rozmiar partii: 16, Wskaźnik dropout: 0.1, Średni wynik: 0.7653466463088989\n",
      "Liczba jednostek: 32, Rozmiar partii: 16, Wskaźnik dropout: 0.2, Średni wynik: 0.6499568223953247\n",
      "Liczba jednostek: 32, Rozmiar partii: 16, Wskaźnik dropout: 0.3, Średni wynik: 0.3576764613389969\n",
      "Liczba jednostek: 32, Rozmiar partii: 32, Wskaźnik dropout: 0.1, Średni wynik: 0.6917692720890045\n",
      "Liczba jednostek: 32, Rozmiar partii: 32, Wskaźnik dropout: 0.2, Średni wynik: 0.41572462767362595\n",
      "Liczba jednostek: 32, Rozmiar partii: 32, Wskaźnik dropout: 0.3, Średni wynik: 0.4951920062303543\n",
      "Liczba jednostek: 64, Rozmiar partii: 16, Wskaźnik dropout: 0.1, Średni wynik: 0.724570095539093\n",
      "Liczba jednostek: 64, Rozmiar partii: 16, Wskaźnik dropout: 0.2, Średni wynik: 0.7242090106010437\n",
      "Liczba jednostek: 64, Rozmiar partii: 16, Wskaźnik dropout: 0.3, Średni wynik: 0.7093346118927002\n",
      "Liczba jednostek: 64, Rozmiar partii: 32, Wskaźnik dropout: 0.1, Średni wynik: 0.7196053564548492\n",
      "Liczba jednostek: 64, Rozmiar partii: 32, Wskaźnik dropout: 0.2, Średni wynik: 0.5269459038972855\n",
      "Liczba jednostek: 64, Rozmiar partii: 32, Wskaźnik dropout: 0.3, Średni wynik: 0.5222351402044296\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tabela przestawna wyników (Średni wynik testowy):\n",
      "batch_size          16                            32                    \n",
      "dropout_rate       0.1       0.2       0.3       0.1       0.2       0.3\n",
      "units                                                                   \n",
      "16            0.451836  0.561513  0.597353  0.615628  0.594305  0.556154\n",
      "32            0.765347  0.649957  0.357676  0.691769  0.415725  0.495192\n",
      "64            0.724570  0.724209  0.709335  0.719605  0.526946  0.522235\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Wyświetlanie wyników\n",
    "for result in results:\n",
    "    print(f\"Liczba jednostek: {result['units']}, Rozmiar partii: {result['batch_size']}, Wskaźnik dropout: {result['dropout_rate']}, Średni wynik: {result['mean_score']}\")\n",
    "\n",
    "# Wizualizacja wyników\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.lineplot(x=results_df['units'], y=results_df['mean_score'], hue=results_df['batch_size'], style=results_df['dropout_rate'], markers=True, dashes=False)\n",
    "plt.xlabel('Liczba jednostek')\n",
    "plt.ylabel('Średni wynik testowy')\n",
    "plt.title('Średni wynik testowy vs liczba jednostek dla różnych rozmiarów partii i wskaźników dropout')\n",
    "plt.legend(title='Rozmiar partii i wskaźnik dropout', loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Wykres rozkładu wyników dla różnych wartości liczby jednostek (Boxplot)\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.boxplot(x='units', y='mean_score', hue='dropout_rate', data=results_df)\n",
    "plt.xlabel('Liczba jednostek')\n",
    "plt.ylabel('Średni wynik testowy')\n",
    "plt.title('Rozkład średnich wyników testowych dla różnych liczby jednostek i wskaźników dropout')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Tabela przestawna wyników\n",
    "results_table = results_df.pivot(index=\"units\", columns=[\"batch_size\", \"dropout_rate\"], values=\"mean_score\")\n",
    "print(\"\\nTabela przestawna wyników (Średni wynik testowy):\")\n",
    "print(results_table)\n",
    "\n",
    "# Wykres przestawny wyników\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.heatmap(results_table, annot=True, cmap=\"YlGnBu\")\n",
    "plt.xlabel('Rozmiar partii i wskaźnik dropout')\n",
    "plt.ylabel('Liczba jednostek')\n",
    "plt.title('Mapa cieplna średnich wyników testowych dla różnych liczby jednostek, rozmiarów partii i wskaźników dropout')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kuba\\AppData\\Local\\Temp\\ipykernel_9768\\2247098176.py:35: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=build_model, verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 3.1252 - categorical_accuracy: 0.0687Epoch 1: loss = 3.122732400894165, val_loss = 2.8735368251800537\n",
      "82/82 [==============================] - 2s 10ms/step - loss: 3.1227 - categorical_accuracy: 0.0686 - val_loss: 2.8735 - val_categorical_accuracy: 0.1112\n",
      "Epoch 2/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 2.7502 - categorical_accuracy: 0.0992Epoch 2: loss = 2.7452540397644043, val_loss = 2.5589969158172607\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.7453 - categorical_accuracy: 0.0983 - val_loss: 2.5590 - val_categorical_accuracy: 0.2041\n",
      "Epoch 3/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 2.4817 - categorical_accuracy: 0.1700Epoch 3: loss = 2.4622411727905273, val_loss = 2.1862542629241943\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 2.4622 - categorical_accuracy: 0.1730 - val_loss: 2.1863 - val_categorical_accuracy: 0.2688\n",
      "Epoch 4/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 2.0751 - categorical_accuracy: 0.2817Epoch 4: loss = 2.055121898651123, val_loss = 1.8531357049942017\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.0551 - categorical_accuracy: 0.2889 - val_loss: 1.8531 - val_categorical_accuracy: 0.3534\n",
      "Epoch 5/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 1.8080 - categorical_accuracy: 0.3644Epoch 5: loss = 1.8046400547027588, val_loss = 1.6088082790374756\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 1.8046 - categorical_accuracy: 0.3659 - val_loss: 1.6088 - val_categorical_accuracy: 0.4303\n",
      "Epoch 6/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 1.5612 - categorical_accuracy: 0.4475Epoch 6: loss = 1.5631455183029175, val_loss = 1.329224705696106\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 1.5631 - categorical_accuracy: 0.4482 - val_loss: 1.3292 - val_categorical_accuracy: 0.5347\n",
      "Epoch 7/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 1.4345 - categorical_accuracy: 0.4704Epoch 7: loss = 1.4319193363189697, val_loss = 1.360827088356018\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 1.4319 - categorical_accuracy: 0.4726 - val_loss: 1.3608 - val_categorical_accuracy: 0.4752\n",
      "Epoch 8/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 1.3234 - categorical_accuracy: 0.5132Epoch 8: loss = 1.3174476623535156, val_loss = 1.190649151802063\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 1.3174 - categorical_accuracy: 0.5145 - val_loss: 1.1906 - val_categorical_accuracy: 0.5468\n",
      "Epoch 9/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 1.2318 - categorical_accuracy: 0.5428Epoch 9: loss = 1.226454734802246, val_loss = 1.1254843473434448\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 1.2265 - categorical_accuracy: 0.5412 - val_loss: 1.1255 - val_categorical_accuracy: 0.5941\n",
      "Epoch 10/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 1.1486 - categorical_accuracy: 0.5817Epoch 10: loss = 1.1453887224197388, val_loss = 1.0492477416992188\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 1.1454 - categorical_accuracy: 0.5816 - val_loss: 1.0492 - val_categorical_accuracy: 0.6192\n",
      "Epoch 11/50\n",
      "71/82 [========================>.....] - ETA: 0s - loss: 1.1006 - categorical_accuracy: 0.5775Epoch 11: loss = 1.099689245223999, val_loss = 1.03525972366333\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 1.0997 - categorical_accuracy: 0.5762 - val_loss: 1.0353 - val_categorical_accuracy: 0.5933\n",
      "Epoch 12/50\n",
      "74/82 [==========================>...] - ETA: 0s - loss: 1.0779 - categorical_accuracy: 0.5887Epoch 12: loss = 1.075984239578247, val_loss = 0.9629359245300293\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 1.0760 - categorical_accuracy: 0.5922 - val_loss: 0.9629 - val_categorical_accuracy: 0.6321\n",
      "Epoch 13/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.0114 - categorical_accuracy: 0.6098Epoch 13: loss = 1.0113866329193115, val_loss = 0.9438134431838989\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 1.0114 - categorical_accuracy: 0.6098 - val_loss: 0.9438 - val_categorical_accuracy: 0.6634\n",
      "Epoch 14/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.0013 - categorical_accuracy: 0.6265Epoch 14: loss = 1.0033193826675415, val_loss = 0.9372686147689819\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 1.0033 - categorical_accuracy: 0.6258 - val_loss: 0.9373 - val_categorical_accuracy: 0.6778\n",
      "Epoch 15/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 0.9585 - categorical_accuracy: 0.6447Epoch 15: loss = 0.954731285572052, val_loss = 0.8548890948295593\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.9547 - categorical_accuracy: 0.6486 - val_loss: 0.8549 - val_categorical_accuracy: 0.6908\n",
      "Epoch 16/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.9308 - categorical_accuracy: 0.6538Epoch 16: loss = 0.9252750277519226, val_loss = 0.8610022664070129\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.9253 - categorical_accuracy: 0.6578 - val_loss: 0.8610 - val_categorical_accuracy: 0.6756\n",
      "Epoch 17/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.8990 - categorical_accuracy: 0.6543Epoch 17: loss = 0.8962339758872986, val_loss = 0.8016297221183777\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.8962 - categorical_accuracy: 0.6547 - val_loss: 0.8016 - val_categorical_accuracy: 0.7327\n",
      "Epoch 18/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.8666 - categorical_accuracy: 0.6829Epoch 18: loss = 0.869439959526062, val_loss = 0.8055105805397034\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.8694 - categorical_accuracy: 0.6806 - val_loss: 0.8055 - val_categorical_accuracy: 0.7068\n",
      "Epoch 19/50\n",
      "72/82 [=========================>....] - ETA: 0s - loss: 0.8008 - categorical_accuracy: 0.7083Epoch 19: loss = 0.800723671913147, val_loss = 0.7645695209503174\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.8007 - categorical_accuracy: 0.7066 - val_loss: 0.7646 - val_categorical_accuracy: 0.7251\n",
      "Epoch 20/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.8625 - categorical_accuracy: 0.6826Epoch 20: loss = 0.8772662281990051, val_loss = 0.8248947262763977\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.8773 - categorical_accuracy: 0.6768 - val_loss: 0.8249 - val_categorical_accuracy: 0.6976\n",
      "Epoch 21/50\n",
      "72/82 [=========================>....] - ETA: 0s - loss: 0.8061 - categorical_accuracy: 0.7023Epoch 21: loss = 0.7994600534439087, val_loss = 0.7681211233139038\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.7995 - categorical_accuracy: 0.7066 - val_loss: 0.7681 - val_categorical_accuracy: 0.7281\n",
      "Epoch 22/50\n",
      "74/82 [==========================>...] - ETA: 0s - loss: 0.7540 - categorical_accuracy: 0.7103Epoch 22: loss = 0.766483724117279, val_loss = 0.8096659779548645\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.7665 - categorical_accuracy: 0.7058 - val_loss: 0.8097 - val_categorical_accuracy: 0.7281\n",
      "Epoch 23/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 0.7423 - categorical_accuracy: 0.7260Epoch 23: loss = 0.7450999021530151, val_loss = 0.730230987071991\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.7451 - categorical_accuracy: 0.7218 - val_loss: 0.7302 - val_categorical_accuracy: 0.7388\n",
      "Epoch 24/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.7489 - categorical_accuracy: 0.7248Epoch 24: loss = 0.7457005381584167, val_loss = 0.8310847878456116\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.7457 - categorical_accuracy: 0.7248 - val_loss: 0.8311 - val_categorical_accuracy: 0.7152\n",
      "Epoch 25/50\n",
      "72/82 [=========================>....] - ETA: 0s - loss: 0.7581 - categorical_accuracy: 0.7170Epoch 25: loss = 0.7472639083862305, val_loss = 0.7278637886047363\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.7473 - categorical_accuracy: 0.7210 - val_loss: 0.7279 - val_categorical_accuracy: 0.7350\n",
      "Epoch 26/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.7415 - categorical_accuracy: 0.7163Epoch 26: loss = 0.7379431128501892, val_loss = 0.799105167388916\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.7379 - categorical_accuracy: 0.7172 - val_loss: 0.7991 - val_categorical_accuracy: 0.6862\n",
      "Epoch 27/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.7439 - categorical_accuracy: 0.7172Epoch 27: loss = 0.7439231276512146, val_loss = 0.8541832566261292\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.7439 - categorical_accuracy: 0.7172 - val_loss: 0.8542 - val_categorical_accuracy: 0.6801\n",
      "Epoch 28/50\n",
      "71/82 [========================>.....] - ETA: 0s - loss: 0.7399 - categorical_accuracy: 0.7271Epoch 28: loss = 0.7233121395111084, val_loss = 0.6621983647346497\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.7233 - categorical_accuracy: 0.7340 - val_loss: 0.6622 - val_categorical_accuracy: 0.7532\n",
      "Epoch 29/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6676 - categorical_accuracy: 0.7515Epoch 29: loss = 0.6676025986671448, val_loss = 0.7229494452476501\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.6676 - categorical_accuracy: 0.7515 - val_loss: 0.7229 - val_categorical_accuracy: 0.7304\n",
      "Epoch 30/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 0.6595 - categorical_accuracy: 0.7397Epoch 30: loss = 0.6618098616600037, val_loss = 0.681448757648468\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.6618 - categorical_accuracy: 0.7363 - val_loss: 0.6814 - val_categorical_accuracy: 0.7388\n",
      "Epoch 31/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.6452 - categorical_accuracy: 0.7617Epoch 31: loss = 0.6518927812576294, val_loss = 0.6959375143051147\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.6519 - categorical_accuracy: 0.7614 - val_loss: 0.6959 - val_categorical_accuracy: 0.7388\n",
      "Epoch 32/50\n",
      "74/82 [==========================>...] - ETA: 0s - loss: 0.6457 - categorical_accuracy: 0.7568Epoch 32: loss = 0.6594281792640686, val_loss = 0.7962802648544312\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.6594 - categorical_accuracy: 0.7477 - val_loss: 0.7963 - val_categorical_accuracy: 0.7022\n",
      "Epoch 33/50\n",
      "72/82 [=========================>....] - ETA: 0s - loss: 0.6771 - categorical_accuracy: 0.7431Epoch 33: loss = 0.6602933406829834, val_loss = 0.6305433511734009\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.6603 - categorical_accuracy: 0.7500 - val_loss: 0.6305 - val_categorical_accuracy: 0.7761\n",
      "Epoch 34/50\n",
      "74/82 [==========================>...] - ETA: 0s - loss: 0.6178 - categorical_accuracy: 0.7635Epoch 34: loss = 0.6076036691665649, val_loss = 0.6629895567893982\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.6076 - categorical_accuracy: 0.7675 - val_loss: 0.6630 - val_categorical_accuracy: 0.7647\n",
      "Epoch 35/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.6308 - categorical_accuracy: 0.7477Epoch 35: loss = 0.6258552074432373, val_loss = 0.6434001326560974\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.6259 - categorical_accuracy: 0.7492 - val_loss: 0.6434 - val_categorical_accuracy: 0.7677\n",
      "Epoch 36/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 0.5952 - categorical_accuracy: 0.7792Epoch 36: loss = 0.5881975889205933, val_loss = 0.5887439846992493\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.5882 - categorical_accuracy: 0.7835 - val_loss: 0.5887 - val_categorical_accuracy: 0.7913\n",
      "Epoch 37/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.6174 - categorical_accuracy: 0.7633Epoch 37: loss = 0.6180341839790344, val_loss = 0.6200355887413025\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.6180 - categorical_accuracy: 0.7622 - val_loss: 0.6200 - val_categorical_accuracy: 0.7837\n",
      "Epoch 38/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 0.5791 - categorical_accuracy: 0.7809Epoch 38: loss = 0.589919924736023, val_loss = 0.6179891228675842\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.5899 - categorical_accuracy: 0.7790 - val_loss: 0.6180 - val_categorical_accuracy: 0.7883\n",
      "Epoch 39/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 0.5900 - categorical_accuracy: 0.7757Epoch 39: loss = 0.5846439003944397, val_loss = 0.6332255005836487\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.5846 - categorical_accuracy: 0.7744 - val_loss: 0.6332 - val_categorical_accuracy: 0.7609\n",
      "Epoch 40/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5979 - categorical_accuracy: 0.7744Epoch 40: loss = 0.5979155898094177, val_loss = 0.5715360641479492\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.5979 - categorical_accuracy: 0.7744 - val_loss: 0.5715 - val_categorical_accuracy: 0.7966\n",
      "Epoch 41/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 0.5773 - categorical_accuracy: 0.7883Epoch 41: loss = 0.5670378804206848, val_loss = 0.5942679643630981\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.5670 - categorical_accuracy: 0.7912 - val_loss: 0.5943 - val_categorical_accuracy: 0.7822\n",
      "Epoch 42/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 0.5491 - categorical_accuracy: 0.7796Epoch 42: loss = 0.5547471046447754, val_loss = 0.6618411540985107\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.5547 - categorical_accuracy: 0.7767 - val_loss: 0.6618 - val_categorical_accuracy: 0.7746\n",
      "Epoch 43/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.5341 - categorical_accuracy: 0.8076Epoch 43: loss = 0.5345508456230164, val_loss = 0.6740444898605347\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.5346 - categorical_accuracy: 0.8056 - val_loss: 0.6740 - val_categorical_accuracy: 0.7426\n",
      "Epoch 44/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 0.5778 - categorical_accuracy: 0.7748Epoch 44: loss = 0.5812370777130127, val_loss = 0.6146027445793152\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.5812 - categorical_accuracy: 0.7691 - val_loss: 0.6146 - val_categorical_accuracy: 0.7746\n",
      "Epoch 45/50\n",
      "74/82 [==========================>...] - ETA: 0s - loss: 0.5331 - categorical_accuracy: 0.7939Epoch 45: loss = 0.5233063101768494, val_loss = 0.5333565473556519\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.5233 - categorical_accuracy: 0.7973 - val_loss: 0.5334 - val_categorical_accuracy: 0.8065\n",
      "Epoch 46/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.5305 - categorical_accuracy: 0.7869Epoch 46: loss = 0.5229194164276123, val_loss = 0.5997214317321777\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.5229 - categorical_accuracy: 0.7896 - val_loss: 0.5997 - val_categorical_accuracy: 0.7883\n",
      "Epoch 47/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5090 - categorical_accuracy: 0.7835Epoch 47: loss = 0.5090203881263733, val_loss = 0.6079436540603638\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.5090 - categorical_accuracy: 0.7835 - val_loss: 0.6079 - val_categorical_accuracy: 0.7746\n",
      "Epoch 48/50\n",
      "74/82 [==========================>...] - ETA: 0s - loss: 0.5825 - categorical_accuracy: 0.7711Epoch 48: loss = 0.5796228647232056, val_loss = 0.5353260040283203\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.5796 - categorical_accuracy: 0.7698 - val_loss: 0.5353 - val_categorical_accuracy: 0.8233\n",
      "Epoch 49/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 0.4633 - categorical_accuracy: 0.8133Epoch 49: loss = 0.47586366534233093, val_loss = 0.5435442328453064\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.4759 - categorical_accuracy: 0.8072 - val_loss: 0.5435 - val_categorical_accuracy: 0.8104\n",
      "Epoch 50/50\n",
      "74/82 [==========================>...] - ETA: 0s - loss: 0.5156 - categorical_accuracy: 0.8074Epoch 50: loss = 0.5023818612098694, val_loss = 0.517825186252594\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.5024 - categorical_accuracy: 0.8117 - val_loss: 0.5178 - val_categorical_accuracy: 0.8165\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.5178 - categorical_accuracy: 0.8165\n",
      "Epoch 1/50\n",
      "75/83 [==========================>...] - ETA: 0s - loss: 3.1246 - categorical_accuracy: 0.0792Epoch 1: loss = 3.1040234565734863, val_loss = 2.8469972610473633\n",
      "83/83 [==============================] - 2s 10ms/step - loss: 3.1040 - categorical_accuracy: 0.0830 - val_loss: 2.8470 - val_categorical_accuracy: 0.1235\n",
      "Epoch 2/50\n",
      "79/83 [===========================>..] - ETA: 0s - loss: 2.6088 - categorical_accuracy: 0.1717Epoch 2: loss = 2.6082308292388916, val_loss = 2.2268638610839844\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.6082 - categorical_accuracy: 0.1698 - val_loss: 2.2269 - val_categorical_accuracy: 0.2729\n",
      "Epoch 3/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.1624 - categorical_accuracy: 0.2886Epoch 3: loss = 2.1610867977142334, val_loss = 1.883381962776184\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1611 - categorical_accuracy: 0.2902 - val_loss: 1.8834 - val_categorical_accuracy: 0.3514\n",
      "Epoch 4/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 1.8553 - categorical_accuracy: 0.3547Epoch 4: loss = 1.8498748540878296, val_loss = 1.5482667684555054\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.8499 - categorical_accuracy: 0.3572 - val_loss: 1.5483 - val_categorical_accuracy: 0.4931\n",
      "Epoch 5/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 1.6755 - categorical_accuracy: 0.4127Epoch 5: loss = 1.6656512022018433, val_loss = 1.4082196950912476\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.6657 - categorical_accuracy: 0.4143 - val_loss: 1.4082 - val_categorical_accuracy: 0.5175\n",
      "Epoch 6/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.4821 - categorical_accuracy: 0.4813Epoch 6: loss = 1.4821196794509888, val_loss = 1.263080358505249\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4821 - categorical_accuracy: 0.4813 - val_loss: 1.2631 - val_categorical_accuracy: 0.5518\n",
      "Epoch 7/50\n",
      "72/83 [=========================>....] - ETA: 0s - loss: 1.3889 - categorical_accuracy: 0.5061Epoch 7: loss = 1.3871369361877441, val_loss = 1.1629834175109863\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.3871 - categorical_accuracy: 0.5050 - val_loss: 1.1630 - val_categorical_accuracy: 0.6441\n",
      "Epoch 8/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 1.2542 - categorical_accuracy: 0.5617Epoch 8: loss = 1.2503987550735474, val_loss = 1.0828245878219604\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.2504 - categorical_accuracy: 0.5636 - val_loss: 1.0828 - val_categorical_accuracy: 0.6143\n",
      "Epoch 9/50\n",
      "72/83 [=========================>....] - ETA: 0s - loss: 1.1842 - categorical_accuracy: 0.5634Epoch 9: loss = 1.1790095567703247, val_loss = 0.9420262575149536\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.1790 - categorical_accuracy: 0.5712 - val_loss: 0.9420 - val_categorical_accuracy: 0.6852\n",
      "Epoch 10/50\n",
      "79/83 [===========================>..] - ETA: 0s - loss: 1.0702 - categorical_accuracy: 0.6052Epoch 10: loss = 1.0648914575576782, val_loss = 0.8807668089866638\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0649 - categorical_accuracy: 0.6085 - val_loss: 0.8808 - val_categorical_accuracy: 0.6837\n",
      "Epoch 11/50\n",
      "72/83 [=========================>....] - ETA: 0s - loss: 1.0625 - categorical_accuracy: 0.6137Epoch 11: loss = 1.04750657081604, val_loss = 0.8795368075370789\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0475 - categorical_accuracy: 0.6192 - val_loss: 0.8795 - val_categorical_accuracy: 0.6944\n",
      "Epoch 12/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.9769 - categorical_accuracy: 0.6528Epoch 12: loss = 0.9747239947319031, val_loss = 0.8003576397895813\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9747 - categorical_accuracy: 0.6542 - val_loss: 0.8004 - val_categorical_accuracy: 0.6997\n",
      "Epoch 13/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.9518 - categorical_accuracy: 0.6471Epoch 13: loss = 0.9526131749153137, val_loss = 0.7766703963279724\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9526 - categorical_accuracy: 0.6466 - val_loss: 0.7767 - val_categorical_accuracy: 0.7165\n",
      "Epoch 14/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.9408 - categorical_accuracy: 0.6479Epoch 14: loss = 0.940426230430603, val_loss = 0.7814822196960449\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9404 - categorical_accuracy: 0.6481 - val_loss: 0.7815 - val_categorical_accuracy: 0.7073\n",
      "Epoch 15/50\n",
      "72/83 [=========================>....] - ETA: 0s - loss: 0.9130 - categorical_accuracy: 0.6528Epoch 15: loss = 0.9122017025947571, val_loss = 0.694695234298706\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9122 - categorical_accuracy: 0.6596 - val_loss: 0.6947 - val_categorical_accuracy: 0.7470\n",
      "Epoch 16/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 0.8021 - categorical_accuracy: 0.7055Epoch 16: loss = 0.806190013885498, val_loss = 0.6883106827735901\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.8062 - categorical_accuracy: 0.7022 - val_loss: 0.6883 - val_categorical_accuracy: 0.7508\n",
      "Epoch 17/50\n",
      "72/83 [=========================>....] - ETA: 0s - loss: 0.8472 - categorical_accuracy: 0.6727Epoch 17: loss = 0.848371684551239, val_loss = 0.7288000583648682\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.8484 - categorical_accuracy: 0.6702 - val_loss: 0.7288 - val_categorical_accuracy: 0.7363\n",
      "Epoch 18/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.7953 - categorical_accuracy: 0.7215Epoch 18: loss = 0.7924304604530334, val_loss = 0.6319807171821594\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.7924 - categorical_accuracy: 0.7220 - val_loss: 0.6320 - val_categorical_accuracy: 0.7957\n",
      "Epoch 19/50\n",
      "71/83 [========================>.....] - ETA: 0s - loss: 0.7284 - categorical_accuracy: 0.7333Epoch 19: loss = 0.7162668108940125, val_loss = 0.743476390838623\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.7163 - categorical_accuracy: 0.7380 - val_loss: 0.7435 - val_categorical_accuracy: 0.7256\n",
      "Epoch 20/50\n",
      "72/83 [=========================>....] - ETA: 0s - loss: 0.7979 - categorical_accuracy: 0.7075Epoch 20: loss = 0.8153781890869141, val_loss = 0.7274552583694458\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.8154 - categorical_accuracy: 0.7037 - val_loss: 0.7275 - val_categorical_accuracy: 0.7462\n",
      "Epoch 21/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 0.7699 - categorical_accuracy: 0.7059Epoch 21: loss = 0.7668700218200684, val_loss = 0.6511015892028809\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.7669 - categorical_accuracy: 0.7053 - val_loss: 0.6511 - val_categorical_accuracy: 0.7790\n",
      "Epoch 22/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.6945 - categorical_accuracy: 0.7355Epoch 22: loss = 0.6940154433250427, val_loss = 0.597486138343811\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6940 - categorical_accuracy: 0.7357 - val_loss: 0.5975 - val_categorical_accuracy: 0.7927\n",
      "Epoch 23/50\n",
      "72/83 [=========================>....] - ETA: 0s - loss: 0.7265 - categorical_accuracy: 0.7405Epoch 23: loss = 0.7221524715423584, val_loss = 0.5835971236228943\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.7222 - categorical_accuracy: 0.7372 - val_loss: 0.5836 - val_categorical_accuracy: 0.7851\n",
      "Epoch 24/50\n",
      "72/83 [=========================>....] - ETA: 0s - loss: 0.6948 - categorical_accuracy: 0.7413Epoch 24: loss = 0.6920666694641113, val_loss = 0.5834484100341797\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6921 - categorical_accuracy: 0.7411 - val_loss: 0.5834 - val_categorical_accuracy: 0.7919\n",
      "Epoch 25/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 0.6319 - categorical_accuracy: 0.7509Epoch 25: loss = 0.635213315486908, val_loss = 0.6060651540756226\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6352 - categorical_accuracy: 0.7479 - val_loss: 0.6061 - val_categorical_accuracy: 0.7866\n",
      "Epoch 26/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.6580 - categorical_accuracy: 0.7523Epoch 26: loss = 0.6566173434257507, val_loss = 0.7067429423332214\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6566 - categorical_accuracy: 0.7525 - val_loss: 0.7067 - val_categorical_accuracy: 0.7370\n",
      "Epoch 27/50\n",
      "72/83 [=========================>....] - ETA: 0s - loss: 0.6639 - categorical_accuracy: 0.7396Epoch 27: loss = 0.673638641834259, val_loss = 0.579305112361908\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6736 - categorical_accuracy: 0.7403 - val_loss: 0.5793 - val_categorical_accuracy: 0.7942\n",
      "Epoch 28/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 0.6256 - categorical_accuracy: 0.7748Epoch 28: loss = 0.6310083866119385, val_loss = 0.5562605261802673\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6310 - categorical_accuracy: 0.7746 - val_loss: 0.5563 - val_categorical_accuracy: 0.7988\n",
      "Epoch 29/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.6592 - categorical_accuracy: 0.7386Epoch 29: loss = 0.6612977981567383, val_loss = 0.5816500186920166\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6613 - categorical_accuracy: 0.7380 - val_loss: 0.5817 - val_categorical_accuracy: 0.7934\n",
      "Epoch 30/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.6548 - categorical_accuracy: 0.7609Epoch 30: loss = 0.6548426151275635, val_loss = 0.5556914806365967\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6548 - categorical_accuracy: 0.7609 - val_loss: 0.5557 - val_categorical_accuracy: 0.7828\n",
      "Epoch 31/50\n",
      "72/83 [=========================>....] - ETA: 0s - loss: 0.5727 - categorical_accuracy: 0.7795Epoch 31: loss = 0.573486864566803, val_loss = 0.561519980430603\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5735 - categorical_accuracy: 0.7753 - val_loss: 0.5615 - val_categorical_accuracy: 0.8026\n",
      "Epoch 32/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 0.6201 - categorical_accuracy: 0.7603Epoch 32: loss = 0.6032068729400635, val_loss = 0.5905733704566956\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6032 - categorical_accuracy: 0.7677 - val_loss: 0.5906 - val_categorical_accuracy: 0.7782\n",
      "Epoch 33/50\n",
      "72/83 [=========================>....] - ETA: 0s - loss: 0.5796 - categorical_accuracy: 0.7700Epoch 33: loss = 0.5672103762626648, val_loss = 0.4572083055973053\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5672 - categorical_accuracy: 0.7730 - val_loss: 0.4572 - val_categorical_accuracy: 0.8270\n",
      "Epoch 34/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 0.5161 - categorical_accuracy: 0.8086Epoch 34: loss = 0.5167635083198547, val_loss = 0.5217776298522949\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5168 - categorical_accuracy: 0.8088 - val_loss: 0.5218 - val_categorical_accuracy: 0.8171\n",
      "Epoch 35/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 0.5478 - categorical_accuracy: 0.7930Epoch 35: loss = 0.5488901138305664, val_loss = 0.4298429787158966\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5489 - categorical_accuracy: 0.7921 - val_loss: 0.4298 - val_categorical_accuracy: 0.8392\n",
      "Epoch 36/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 0.5506 - categorical_accuracy: 0.7911Epoch 36: loss = 0.55521160364151, val_loss = 0.5101678967475891\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5552 - categorical_accuracy: 0.7890 - val_loss: 0.5102 - val_categorical_accuracy: 0.8270\n",
      "Epoch 37/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 0.5436 - categorical_accuracy: 0.8022Epoch 37: loss = 0.5317909121513367, val_loss = 0.5860981345176697\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5318 - categorical_accuracy: 0.8050 - val_loss: 0.5861 - val_categorical_accuracy: 0.7774\n",
      "Epoch 38/50\n",
      "79/83 [===========================>..] - ETA: 0s - loss: 0.5216 - categorical_accuracy: 0.7991Epoch 38: loss = 0.5181951522827148, val_loss = 0.4708491861820221\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5182 - categorical_accuracy: 0.7974 - val_loss: 0.4708 - val_categorical_accuracy: 0.8079\n",
      "Epoch 39/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 0.5446 - categorical_accuracy: 0.7842Epoch 39: loss = 0.5287978649139404, val_loss = 0.4238826334476471\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5288 - categorical_accuracy: 0.7928 - val_loss: 0.4239 - val_categorical_accuracy: 0.8384\n",
      "Epoch 40/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.5106 - categorical_accuracy: 0.8065Epoch 40: loss = 0.5106362700462341, val_loss = 0.6091487407684326\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5106 - categorical_accuracy: 0.8065 - val_loss: 0.6091 - val_categorical_accuracy: 0.7691\n",
      "Epoch 41/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 0.5045 - categorical_accuracy: 0.7962Epoch 41: loss = 0.4992867410182953, val_loss = 0.4713161289691925\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4993 - categorical_accuracy: 0.7951 - val_loss: 0.4713 - val_categorical_accuracy: 0.8346\n",
      "Epoch 42/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 0.5090 - categorical_accuracy: 0.8018Epoch 42: loss = 0.5166251063346863, val_loss = 0.38831403851509094\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.5166 - categorical_accuracy: 0.7951 - val_loss: 0.3883 - val_categorical_accuracy: 0.8514\n",
      "Epoch 43/50\n",
      "72/83 [=========================>....] - ETA: 0s - loss: 0.4949 - categorical_accuracy: 0.8090Epoch 43: loss = 0.4745495617389679, val_loss = 0.39952999353408813\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.4745 - categorical_accuracy: 0.8180 - val_loss: 0.3995 - val_categorical_accuracy: 0.8323\n",
      "Epoch 44/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 0.4324 - categorical_accuracy: 0.8262Epoch 44: loss = 0.4477452039718628, val_loss = 0.39369964599609375\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.4477 - categorical_accuracy: 0.8172 - val_loss: 0.3937 - val_categorical_accuracy: 0.8438\n",
      "Epoch 45/50\n",
      "72/83 [=========================>....] - ETA: 0s - loss: 0.4633 - categorical_accuracy: 0.8134Epoch 45: loss = 0.44716379046440125, val_loss = 0.36211568117141724\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4472 - categorical_accuracy: 0.8203 - val_loss: 0.3621 - val_categorical_accuracy: 0.8613\n",
      "Epoch 46/50\n",
      "72/83 [=========================>....] - ETA: 0s - loss: 0.4240 - categorical_accuracy: 0.8229Epoch 46: loss = 0.42287006974220276, val_loss = 0.39922282099723816\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4229 - categorical_accuracy: 0.8241 - val_loss: 0.3992 - val_categorical_accuracy: 0.8537\n",
      "Epoch 47/50\n",
      "72/83 [=========================>....] - ETA: 0s - loss: 0.4504 - categorical_accuracy: 0.8160Epoch 47: loss = 0.4356409013271332, val_loss = 0.34370046854019165\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4356 - categorical_accuracy: 0.8210 - val_loss: 0.3437 - val_categorical_accuracy: 0.8620\n",
      "Epoch 48/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 0.4176 - categorical_accuracy: 0.8450Epoch 48: loss = 0.4278046190738678, val_loss = 0.44359859824180603\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.4278 - categorical_accuracy: 0.8393 - val_loss: 0.4436 - val_categorical_accuracy: 0.8369\n",
      "Epoch 49/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 0.5125 - categorical_accuracy: 0.8091Epoch 49: loss = 0.5252874493598938, val_loss = 0.470339834690094\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.5253 - categorical_accuracy: 0.8081 - val_loss: 0.4703 - val_categorical_accuracy: 0.7980\n",
      "Epoch 50/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.4706 - categorical_accuracy: 0.8102Epoch 50: loss = 0.46868830919265747, val_loss = 0.4594862461090088\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.4687 - categorical_accuracy: 0.8111 - val_loss: 0.4595 - val_categorical_accuracy: 0.8163\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.4595 - categorical_accuracy: 0.8163\n",
      "Epoch 1/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 3.1728 - categorical_accuracy: 0.0706Epoch 1: loss = 3.1588892936706543, val_loss = 2.9732120037078857\n",
      "82/82 [==============================] - 2s 9ms/step - loss: 3.1589 - categorical_accuracy: 0.0724 - val_loss: 2.9732 - val_categorical_accuracy: 0.0807\n",
      "Epoch 2/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 2.8682 - categorical_accuracy: 0.0839Epoch 2: loss = 2.8662378787994385, val_loss = 2.751565933227539\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.8662 - categorical_accuracy: 0.0838 - val_loss: 2.7516 - val_categorical_accuracy: 0.0838\n",
      "Epoch 3/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 2.7311 - categorical_accuracy: 0.1012Epoch 3: loss = 2.7290987968444824, val_loss = 2.6379499435424805\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.7291 - categorical_accuracy: 0.1021 - val_loss: 2.6379 - val_categorical_accuracy: 0.0922\n",
      "Epoch 4/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 2.6608 - categorical_accuracy: 0.1216Epoch 4: loss = 2.6509764194488525, val_loss = 2.6013500690460205\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 2.6510 - categorical_accuracy: 0.1242 - val_loss: 2.6014 - val_categorical_accuracy: 0.1135\n",
      "Epoch 5/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 2.5647 - categorical_accuracy: 0.1474Epoch 5: loss = 2.5627925395965576, val_loss = 2.4705092906951904\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.5628 - categorical_accuracy: 0.1479 - val_loss: 2.4705 - val_categorical_accuracy: 0.2034\n",
      "Epoch 6/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 2.3738 - categorical_accuracy: 0.2260Epoch 6: loss = 2.3676528930664062, val_loss = 2.2506585121154785\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.3677 - categorical_accuracy: 0.2348 - val_loss: 2.2507 - val_categorical_accuracy: 0.2589\n",
      "Epoch 7/50\n",
      "74/82 [==========================>...] - ETA: 0s - loss: 2.2287 - categorical_accuracy: 0.2669Epoch 7: loss = 2.219881772994995, val_loss = 2.099362373352051\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.2199 - categorical_accuracy: 0.2652 - val_loss: 2.0994 - val_categorical_accuracy: 0.2673\n",
      "Epoch 8/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 2.0386 - categorical_accuracy: 0.2730Epoch 8: loss = 2.0339622497558594, val_loss = 1.8676906824111938\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.0340 - categorical_accuracy: 0.2752 - val_loss: 1.8677 - val_categorical_accuracy: 0.3092\n",
      "Epoch 9/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 1.8895 - categorical_accuracy: 0.3133Epoch 9: loss = 1.8785512447357178, val_loss = 1.7637276649475098\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 1.8786 - categorical_accuracy: 0.3186 - val_loss: 1.7637 - val_categorical_accuracy: 0.3442\n",
      "Epoch 10/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 1.7454 - categorical_accuracy: 0.3616Epoch 10: loss = 1.7343707084655762, val_loss = 1.6484757661819458\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 1.7344 - categorical_accuracy: 0.3628 - val_loss: 1.6485 - val_categorical_accuracy: 0.3922\n",
      "Epoch 11/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 1.6600 - categorical_accuracy: 0.3967Epoch 11: loss = 1.6537150144577026, val_loss = 1.5921924114227295\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 1.6537 - categorical_accuracy: 0.4024 - val_loss: 1.5922 - val_categorical_accuracy: 0.4714\n",
      "Epoch 12/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 1.5615 - categorical_accuracy: 0.4383Epoch 12: loss = 1.5506449937820435, val_loss = 1.4111499786376953\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 1.5506 - categorical_accuracy: 0.4466 - val_loss: 1.4111 - val_categorical_accuracy: 0.5209\n",
      "Epoch 13/50\n",
      "74/82 [==========================>...] - ETA: 0s - loss: 1.4789 - categorical_accuracy: 0.4485Epoch 13: loss = 1.4761766195297241, val_loss = 1.324102759361267\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 1.4762 - categorical_accuracy: 0.4505 - val_loss: 1.3241 - val_categorical_accuracy: 0.5270\n",
      "Epoch 14/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 1.3932 - categorical_accuracy: 0.5096Epoch 14: loss = 1.3969686031341553, val_loss = 1.2409483194351196\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 1.3970 - categorical_accuracy: 0.5061 - val_loss: 1.2409 - val_categorical_accuracy: 0.5682\n",
      "Epoch 15/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 1.3180 - categorical_accuracy: 0.5106Epoch 15: loss = 1.3105801343917847, val_loss = 1.1816272735595703\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 1.3106 - categorical_accuracy: 0.5137 - val_loss: 1.1816 - val_categorical_accuracy: 0.6085\n",
      "Epoch 16/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 1.2733 - categorical_accuracy: 0.5428Epoch 16: loss = 1.2847737073898315, val_loss = 1.0867971181869507\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 1.2848 - categorical_accuracy: 0.5366 - val_loss: 1.0868 - val_categorical_accuracy: 0.6527\n",
      "Epoch 17/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 1.2225 - categorical_accuracy: 0.5567Epoch 17: loss = 1.215889573097229, val_loss = 1.1229192018508911\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 1.2159 - categorical_accuracy: 0.5572 - val_loss: 1.1229 - val_categorical_accuracy: 0.6017\n",
      "Epoch 18/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 1.1635 - categorical_accuracy: 0.5722Epoch 18: loss = 1.154891014099121, val_loss = 1.0383381843566895\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 1.1549 - categorical_accuracy: 0.5762 - val_loss: 1.0383 - val_categorical_accuracy: 0.6375\n",
      "Epoch 19/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.1484 - categorical_accuracy: 0.5945Epoch 19: loss = 1.148386001586914, val_loss = 0.9573989510536194\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 1.1484 - categorical_accuracy: 0.5945 - val_loss: 0.9574 - val_categorical_accuracy: 0.7167\n",
      "Epoch 20/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 1.0784 - categorical_accuracy: 0.6127Epoch 20: loss = 1.0941085815429688, val_loss = 1.0398423671722412\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 1.0941 - categorical_accuracy: 0.6082 - val_loss: 1.0398 - val_categorical_accuracy: 0.6436\n",
      "Epoch 21/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 1.0544 - categorical_accuracy: 0.6250Epoch 21: loss = 1.0500065088272095, val_loss = 0.9525289535522461\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 1.0500 - categorical_accuracy: 0.6258 - val_loss: 0.9525 - val_categorical_accuracy: 0.6809\n",
      "Epoch 22/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 1.0145 - categorical_accuracy: 0.6317Epoch 22: loss = 1.0152207612991333, val_loss = 0.8448594808578491\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 1.0152 - categorical_accuracy: 0.6311 - val_loss: 0.8449 - val_categorical_accuracy: 0.7273\n",
      "Epoch 23/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 1.0033 - categorical_accuracy: 0.6177Epoch 23: loss = 1.0040103197097778, val_loss = 0.878966748714447\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 1.0040 - categorical_accuracy: 0.6189 - val_loss: 0.8790 - val_categorical_accuracy: 0.7243\n",
      "Epoch 24/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.9752 - categorical_accuracy: 0.6575Epoch 24: loss = 0.968423068523407, val_loss = 0.8650877475738525\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.9684 - categorical_accuracy: 0.6608 - val_loss: 0.8651 - val_categorical_accuracy: 0.6893\n",
      "Epoch 25/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.9335 - categorical_accuracy: 0.6591Epoch 25: loss = 0.9450908899307251, val_loss = 0.8690570592880249\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.9451 - categorical_accuracy: 0.6547 - val_loss: 0.8691 - val_categorical_accuracy: 0.6900\n",
      "Epoch 26/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 0.8960 - categorical_accuracy: 0.6653Epoch 26: loss = 0.8995682597160339, val_loss = 0.8045864701271057\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.8996 - categorical_accuracy: 0.6677 - val_loss: 0.8046 - val_categorical_accuracy: 0.7045\n",
      "Epoch 27/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.8834 - categorical_accuracy: 0.6721Epoch 27: loss = 0.8885412216186523, val_loss = 0.7841026186943054\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.8885 - categorical_accuracy: 0.6700 - val_loss: 0.7841 - val_categorical_accuracy: 0.7045\n",
      "Epoch 28/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.8808 - categorical_accuracy: 0.6713Epoch 28: loss = 0.870322048664093, val_loss = 0.7416878938674927\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.8703 - categorical_accuracy: 0.6761 - val_loss: 0.7417 - val_categorical_accuracy: 0.7449\n",
      "Epoch 29/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 0.9407 - categorical_accuracy: 0.6583Epoch 29: loss = 0.9306145906448364, val_loss = 0.7419796586036682\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.9306 - categorical_accuracy: 0.6623 - val_loss: 0.7420 - val_categorical_accuracy: 0.7372\n",
      "Epoch 30/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 0.8881 - categorical_accuracy: 0.6867Epoch 30: loss = 0.8877619504928589, val_loss = 0.7893850207328796\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.8878 - categorical_accuracy: 0.6860 - val_loss: 0.7894 - val_categorical_accuracy: 0.7144\n",
      "Epoch 31/50\n",
      "74/82 [==========================>...] - ETA: 0s - loss: 0.8953 - categorical_accuracy: 0.6622Epoch 31: loss = 0.8893422484397888, val_loss = 0.761658787727356\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.8893 - categorical_accuracy: 0.6662 - val_loss: 0.7617 - val_categorical_accuracy: 0.7426\n",
      "Epoch 32/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.8140 - categorical_accuracy: 0.7051Epoch 32: loss = 0.8180216550827026, val_loss = 0.8072529435157776\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.8180 - categorical_accuracy: 0.7043 - val_loss: 0.8073 - val_categorical_accuracy: 0.7007\n",
      "Epoch 33/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.8233 - categorical_accuracy: 0.6964Restoring model weights from the end of the best epoch: 28.\n",
      "Epoch 33: loss = 0.8280354142189026, val_loss = 0.9074953198432922\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.8280 - categorical_accuracy: 0.6974 - val_loss: 0.9075 - val_categorical_accuracy: 0.6596\n",
      "Epoch 33: early stopping\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7417 - categorical_accuracy: 0.7449\n",
      "Epoch 1/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 3.2253 - categorical_accuracy: 0.0548Epoch 1: loss = 3.220597982406616, val_loss = 3.1776204109191895\n",
      "83/83 [==============================] - 2s 9ms/step - loss: 3.2206 - categorical_accuracy: 0.0564 - val_loss: 3.1776 - val_categorical_accuracy: 0.0739\n",
      "Epoch 2/50\n",
      "72/83 [=========================>....] - ETA: 0s - loss: 3.0725 - categorical_accuracy: 0.0894Epoch 2: loss = 3.062145948410034, val_loss = 2.904222011566162\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 3.0621 - categorical_accuracy: 0.0868 - val_loss: 2.9042 - val_categorical_accuracy: 0.0701\n",
      "Epoch 3/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.8616 - categorical_accuracy: 0.0910Epoch 3: loss = 2.8621480464935303, val_loss = 2.728135347366333\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.8621 - categorical_accuracy: 0.0922 - val_loss: 2.7281 - val_categorical_accuracy: 0.0732\n",
      "Epoch 4/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.7384 - categorical_accuracy: 0.0907Epoch 4: loss = 2.738063097000122, val_loss = 2.6435658931732178\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.7381 - categorical_accuracy: 0.0906 - val_loss: 2.6436 - val_categorical_accuracy: 0.0671\n",
      "Epoch 5/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.6784 - categorical_accuracy: 0.0853Epoch 5: loss = 2.6783668994903564, val_loss = 2.6250216960906982\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.6784 - categorical_accuracy: 0.0853 - val_loss: 2.6250 - val_categorical_accuracy: 0.1212\n",
      "Epoch 6/50\n",
      "75/83 [==========================>...] - ETA: 0s - loss: 2.6201 - categorical_accuracy: 0.1183Epoch 6: loss = 2.624541759490967, val_loss = 2.590909719467163\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.6245 - categorical_accuracy: 0.1150 - val_loss: 2.5909 - val_categorical_accuracy: 0.1044\n",
      "Epoch 7/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 2.6329 - categorical_accuracy: 0.0959Epoch 7: loss = 2.6354150772094727, val_loss = 2.5958433151245117\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.6354 - categorical_accuracy: 0.0952 - val_loss: 2.5958 - val_categorical_accuracy: 0.0854\n",
      "Epoch 8/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.6269 - categorical_accuracy: 0.1111Epoch 8: loss = 2.627469062805176, val_loss = 2.5896389484405518\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.6275 - categorical_accuracy: 0.1112 - val_loss: 2.5896 - val_categorical_accuracy: 0.1044\n",
      "Epoch 9/50\n",
      "74/83 [=========================>....] - ETA: 0s - loss: 2.5911 - categorical_accuracy: 0.1030Epoch 9: loss = 2.5863704681396484, val_loss = 2.5648043155670166\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.5864 - categorical_accuracy: 0.1043 - val_loss: 2.5648 - val_categorical_accuracy: 0.0777\n",
      "Epoch 10/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 2.6010 - categorical_accuracy: 0.1019Epoch 10: loss = 2.6059415340423584, val_loss = 2.620724678039551\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.6059 - categorical_accuracy: 0.0975 - val_loss: 2.6207 - val_categorical_accuracy: 0.1326\n",
      "Epoch 11/50\n",
      "74/83 [=========================>....] - ETA: 0s - loss: 2.5845 - categorical_accuracy: 0.1073Epoch 11: loss = 2.581164836883545, val_loss = 2.543802261352539\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.5812 - categorical_accuracy: 0.1097 - val_loss: 2.5438 - val_categorical_accuracy: 0.1021\n",
      "Epoch 12/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 2.5874 - categorical_accuracy: 0.0959Epoch 12: loss = 2.583827495574951, val_loss = 2.53816556930542\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.5838 - categorical_accuracy: 0.0990 - val_loss: 2.5382 - val_categorical_accuracy: 0.1014\n",
      "Epoch 13/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.5393 - categorical_accuracy: 0.1219Epoch 13: loss = 2.53841495513916, val_loss = 2.5349509716033936\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.5384 - categorical_accuracy: 0.1234 - val_loss: 2.5350 - val_categorical_accuracy: 0.1212\n",
      "Epoch 14/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 2.5390 - categorical_accuracy: 0.1276Epoch 14: loss = 2.5357518196105957, val_loss = 2.5005640983581543\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.5358 - categorical_accuracy: 0.1280 - val_loss: 2.5006 - val_categorical_accuracy: 0.1502\n",
      "Epoch 15/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 2.5518 - categorical_accuracy: 0.1122Epoch 15: loss = 2.5424211025238037, val_loss = 2.5201327800750732\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.5424 - categorical_accuracy: 0.1165 - val_loss: 2.5201 - val_categorical_accuracy: 0.1159\n",
      "Epoch 16/50\n",
      "72/83 [=========================>....] - ETA: 0s - loss: 2.4993 - categorical_accuracy: 0.1319Epoch 16: loss = 2.5030415058135986, val_loss = 2.5131263732910156\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.5030 - categorical_accuracy: 0.1310 - val_loss: 2.5131 - val_categorical_accuracy: 0.1212\n",
      "Epoch 17/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 2.4655 - categorical_accuracy: 0.1498Epoch 17: loss = 2.4754765033721924, val_loss = 2.4912681579589844\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.4755 - categorical_accuracy: 0.1478 - val_loss: 2.4913 - val_categorical_accuracy: 0.1349\n",
      "Epoch 18/50\n",
      "75/83 [==========================>...] - ETA: 0s - loss: 2.4892 - categorical_accuracy: 0.1367Epoch 18: loss = 2.4861676692962646, val_loss = 2.4503977298736572\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.4862 - categorical_accuracy: 0.1401 - val_loss: 2.4504 - val_categorical_accuracy: 0.1677\n",
      "Epoch 19/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 2.4761 - categorical_accuracy: 0.1601Epoch 19: loss = 2.4773662090301514, val_loss = 2.502427816390991\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.4774 - categorical_accuracy: 0.1622 - val_loss: 2.5024 - val_categorical_accuracy: 0.1098\n",
      "Epoch 20/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.4376 - categorical_accuracy: 0.1822Epoch 20: loss = 2.437885284423828, val_loss = 2.4782116413116455\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.4379 - categorical_accuracy: 0.1820 - val_loss: 2.4782 - val_categorical_accuracy: 0.1700\n",
      "Epoch 21/50\n",
      "72/83 [=========================>....] - ETA: 0s - loss: 2.4293 - categorical_accuracy: 0.1623Epoch 21: loss = 2.421504259109497, val_loss = 2.420614242553711\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.4215 - categorical_accuracy: 0.1645 - val_loss: 2.4206 - val_categorical_accuracy: 0.1784\n",
      "Epoch 22/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 2.3762 - categorical_accuracy: 0.1909Epoch 22: loss = 2.376843214035034, val_loss = 2.344907760620117\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.3768 - categorical_accuracy: 0.1889 - val_loss: 2.3449 - val_categorical_accuracy: 0.1898\n",
      "Epoch 23/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.3950 - categorical_accuracy: 0.1858Epoch 23: loss = 2.3949644565582275, val_loss = 2.392085313796997\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.3950 - categorical_accuracy: 0.1858 - val_loss: 2.3921 - val_categorical_accuracy: 0.1616\n",
      "Epoch 24/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 2.3597 - categorical_accuracy: 0.1807Epoch 24: loss = 2.371246099472046, val_loss = 2.36008358001709\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.3712 - categorical_accuracy: 0.1767 - val_loss: 2.3601 - val_categorical_accuracy: 0.1745\n",
      "Epoch 25/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 2.3621 - categorical_accuracy: 0.1935Epoch 25: loss = 2.3578083515167236, val_loss = 2.317612886428833\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.3578 - categorical_accuracy: 0.1980 - val_loss: 2.3176 - val_categorical_accuracy: 0.1989\n",
      "Epoch 26/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 2.3191 - categorical_accuracy: 0.1892Epoch 26: loss = 2.3340251445770264, val_loss = 2.4243431091308594\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.3340 - categorical_accuracy: 0.1866 - val_loss: 2.4243 - val_categorical_accuracy: 0.1593\n",
      "Epoch 27/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.3281 - categorical_accuracy: 0.2145Epoch 27: loss = 2.3287198543548584, val_loss = 2.338541269302368\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.3287 - categorical_accuracy: 0.2133 - val_loss: 2.3385 - val_categorical_accuracy: 0.1822\n",
      "Epoch 28/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 2.2975 - categorical_accuracy: 0.2012Epoch 28: loss = 2.297746419906616, val_loss = 2.3750429153442383\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.2977 - categorical_accuracy: 0.2018 - val_loss: 2.3750 - val_categorical_accuracy: 0.1639\n",
      "Epoch 29/50\n",
      "72/83 [=========================>....] - ETA: 0s - loss: 2.3310 - categorical_accuracy: 0.1988Epoch 29: loss = 2.323147773742676, val_loss = 2.317471504211426\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.3231 - categorical_accuracy: 0.1965 - val_loss: 2.3175 - val_categorical_accuracy: 0.1913\n",
      "Epoch 30/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 2.2844 - categorical_accuracy: 0.2132Epoch 30: loss = 2.2940902709960938, val_loss = 2.4651410579681396\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.2941 - categorical_accuracy: 0.2049 - val_loss: 2.4651 - val_categorical_accuracy: 0.1547\n",
      "Epoch 31/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 2.2824 - categorical_accuracy: 0.2235Epoch 31: loss = 2.274374008178711, val_loss = 2.277150869369507\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.2744 - categorical_accuracy: 0.2300 - val_loss: 2.2772 - val_categorical_accuracy: 0.2104\n",
      "Epoch 32/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.2538 - categorical_accuracy: 0.2184Epoch 32: loss = 2.2498843669891357, val_loss = 2.2500081062316895\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.2499 - categorical_accuracy: 0.2193 - val_loss: 2.2500 - val_categorical_accuracy: 0.2241\n",
      "Epoch 33/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 2.2787 - categorical_accuracy: 0.2038Epoch 33: loss = 2.2668962478637695, val_loss = 2.315648078918457\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.2669 - categorical_accuracy: 0.2087 - val_loss: 2.3156 - val_categorical_accuracy: 0.1867\n",
      "Epoch 34/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 2.2655 - categorical_accuracy: 0.2149Epoch 34: loss = 2.276881217956543, val_loss = 2.312166452407837\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.2769 - categorical_accuracy: 0.2155 - val_loss: 2.3122 - val_categorical_accuracy: 0.1997\n",
      "Epoch 35/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 2.2442 - categorical_accuracy: 0.2227Epoch 35: loss = 2.247375249862671, val_loss = 2.298990249633789\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.2474 - categorical_accuracy: 0.2216 - val_loss: 2.2990 - val_categorical_accuracy: 0.2127\n",
      "Epoch 36/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 2.1966 - categorical_accuracy: 0.2531Epoch 36: loss = 2.2004714012145996, val_loss = 2.2635419368743896\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.2005 - categorical_accuracy: 0.2513 - val_loss: 2.2635 - val_categorical_accuracy: 0.2149\n",
      "Epoch 37/50\n",
      "75/83 [==========================>...] - ETA: 0s - loss: 2.2212 - categorical_accuracy: 0.2283Restoring model weights from the end of the best epoch: 32.\n",
      "Epoch 37: loss = 2.224491596221924, val_loss = 2.302396535873413\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.2245 - categorical_accuracy: 0.2254 - val_loss: 2.3024 - val_categorical_accuracy: 0.2127\n",
      "Epoch 37: early stopping\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.2500 - categorical_accuracy: 0.2241\n",
      "Epoch 1/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 3.2399 - categorical_accuracy: 0.0503Epoch 1: loss = 3.2380502223968506, val_loss = 3.1941685676574707\n",
      "82/82 [==============================] - 2s 9ms/step - loss: 3.2381 - categorical_accuracy: 0.0503 - val_loss: 3.1942 - val_categorical_accuracy: 0.0388\n",
      "Epoch 2/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 3.1028 - categorical_accuracy: 0.0675Epoch 2: loss = 3.0983543395996094, val_loss = 3.009263753890991\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 3.0984 - categorical_accuracy: 0.0663 - val_loss: 3.0093 - val_categorical_accuracy: 0.0708\n",
      "Epoch 3/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 2.9776 - categorical_accuracy: 0.0765Epoch 3: loss = 2.972363233566284, val_loss = 2.935783863067627\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.9724 - categorical_accuracy: 0.0762 - val_loss: 2.9358 - val_categorical_accuracy: 0.0784\n",
      "Epoch 4/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 2.9013 - categorical_accuracy: 0.0950Epoch 4: loss = 2.8945398330688477, val_loss = 2.839308261871338\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.8945 - categorical_accuracy: 0.0976 - val_loss: 2.8393 - val_categorical_accuracy: 0.0792\n",
      "Epoch 5/50\n",
      "74/82 [==========================>...] - ETA: 0s - loss: 2.8229 - categorical_accuracy: 0.1005Epoch 5: loss = 2.8225910663604736, val_loss = 2.817775011062622\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.8226 - categorical_accuracy: 0.0991 - val_loss: 2.8178 - val_categorical_accuracy: 0.0929\n",
      "Epoch 6/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 2.7684 - categorical_accuracy: 0.0986Epoch 6: loss = 2.762972354888916, val_loss = 2.6915693283081055\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 2.7630 - categorical_accuracy: 0.1014 - val_loss: 2.6916 - val_categorical_accuracy: 0.0784\n",
      "Epoch 7/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 2.7070 - categorical_accuracy: 0.0942Epoch 7: loss = 2.7028448581695557, val_loss = 2.6554794311523438\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.7028 - categorical_accuracy: 0.0945 - val_loss: 2.6555 - val_categorical_accuracy: 0.1005\n",
      "Epoch 8/50\n",
      "70/82 [========================>.....] - ETA: 0s - loss: 2.6394 - categorical_accuracy: 0.1089Epoch 8: loss = 2.6533114910125732, val_loss = 2.627990484237671\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 2.6533 - categorical_accuracy: 0.1021 - val_loss: 2.6280 - val_categorical_accuracy: 0.0830\n",
      "Epoch 9/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 2.6159 - categorical_accuracy: 0.1094Epoch 9: loss = 2.6112945079803467, val_loss = 2.5926809310913086\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.6113 - categorical_accuracy: 0.1098 - val_loss: 2.5927 - val_categorical_accuracy: 0.0868\n",
      "Epoch 10/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.5966 - categorical_accuracy: 0.1103Epoch 10: loss = 2.5973474979400635, val_loss = 2.5779242515563965\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 2.5973 - categorical_accuracy: 0.1098 - val_loss: 2.5779 - val_categorical_accuracy: 0.0929\n",
      "Epoch 11/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 2.5847 - categorical_accuracy: 0.1179Epoch 11: loss = 2.5833778381347656, val_loss = 2.569021701812744\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.5834 - categorical_accuracy: 0.1181 - val_loss: 2.5690 - val_categorical_accuracy: 0.1066\n",
      "Epoch 12/50\n",
      "74/82 [==========================>...] - ETA: 0s - loss: 2.5706 - categorical_accuracy: 0.1377Epoch 12: loss = 2.5746641159057617, val_loss = 2.5835909843444824\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.5747 - categorical_accuracy: 0.1357 - val_loss: 2.5836 - val_categorical_accuracy: 0.1470\n",
      "Epoch 13/50\n",
      "70/82 [========================>.....] - ETA: 0s - loss: 2.5788 - categorical_accuracy: 0.1259Epoch 13: loss = 2.5775582790374756, val_loss = 2.567939519882202\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 2.5776 - categorical_accuracy: 0.1250 - val_loss: 2.5679 - val_categorical_accuracy: 0.1181\n",
      "Epoch 14/50\n",
      "72/82 [=========================>....] - ETA: 0s - loss: 2.5627 - categorical_accuracy: 0.1380Epoch 14: loss = 2.5585577487945557, val_loss = 2.5692756175994873\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 2.5586 - categorical_accuracy: 0.1387 - val_loss: 2.5693 - val_categorical_accuracy: 0.1607\n",
      "Epoch 15/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 2.5349 - categorical_accuracy: 0.1472Epoch 15: loss = 2.5371925830841064, val_loss = 2.5473101139068604\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.5372 - categorical_accuracy: 0.1456 - val_loss: 2.5473 - val_categorical_accuracy: 0.1927\n",
      "Epoch 16/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 2.5283 - categorical_accuracy: 0.1442Epoch 16: loss = 2.5282680988311768, val_loss = 2.5666215419769287\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.5283 - categorical_accuracy: 0.1441 - val_loss: 2.5666 - val_categorical_accuracy: 0.1188\n",
      "Epoch 17/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 2.4989 - categorical_accuracy: 0.1635Epoch 17: loss = 2.499642848968506, val_loss = 2.5366814136505127\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.4996 - categorical_accuracy: 0.1631 - val_loss: 2.5367 - val_categorical_accuracy: 0.1447\n",
      "Epoch 18/50\n",
      "74/82 [==========================>...] - ETA: 0s - loss: 2.5009 - categorical_accuracy: 0.1529Epoch 18: loss = 2.4947168827056885, val_loss = 2.5346226692199707\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 2.4947 - categorical_accuracy: 0.1570 - val_loss: 2.5346 - val_categorical_accuracy: 0.1417\n",
      "Epoch 19/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 2.4943 - categorical_accuracy: 0.1474Epoch 19: loss = 2.498764991760254, val_loss = 2.510932683944702\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.4988 - categorical_accuracy: 0.1425 - val_loss: 2.5109 - val_categorical_accuracy: 0.1561\n",
      "Epoch 20/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 2.4412 - categorical_accuracy: 0.1891Epoch 20: loss = 2.4407079219818115, val_loss = 2.4564666748046875\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.4407 - categorical_accuracy: 0.1890 - val_loss: 2.4565 - val_categorical_accuracy: 0.1523\n",
      "Epoch 21/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 2.4196 - categorical_accuracy: 0.1859Epoch 21: loss = 2.4227511882781982, val_loss = 2.493142604827881\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.4228 - categorical_accuracy: 0.1845 - val_loss: 2.4931 - val_categorical_accuracy: 0.1485\n",
      "Epoch 22/50\n",
      "72/82 [=========================>....] - ETA: 0s - loss: 2.4118 - categorical_accuracy: 0.1719Epoch 22: loss = 2.405763864517212, val_loss = 2.431648015975952\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.4058 - categorical_accuracy: 0.1776 - val_loss: 2.4316 - val_categorical_accuracy: 0.1660\n",
      "Epoch 23/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.3831 - categorical_accuracy: 0.1921Epoch 23: loss = 2.3831288814544678, val_loss = 2.447575092315674\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 2.3831 - categorical_accuracy: 0.1921 - val_loss: 2.4476 - val_categorical_accuracy: 0.1478\n",
      "Epoch 24/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 2.3798 - categorical_accuracy: 0.1851Epoch 24: loss = 2.379976511001587, val_loss = 2.5252649784088135\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.3800 - categorical_accuracy: 0.1867 - val_loss: 2.5253 - val_categorical_accuracy: 0.1081\n",
      "Epoch 25/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 2.3616 - categorical_accuracy: 0.1972Epoch 25: loss = 2.36008358001709, val_loss = 2.511596441268921\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.3601 - categorical_accuracy: 0.1928 - val_loss: 2.5116 - val_categorical_accuracy: 0.1241\n",
      "Epoch 26/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 2.3554 - categorical_accuracy: 0.2046Epoch 26: loss = 2.363621950149536, val_loss = 2.39556622505188\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.3636 - categorical_accuracy: 0.1974 - val_loss: 2.3956 - val_categorical_accuracy: 0.1569\n",
      "Epoch 27/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 2.3933 - categorical_accuracy: 0.1758Epoch 27: loss = 2.384694814682007, val_loss = 2.4575514793395996\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.3847 - categorical_accuracy: 0.1784 - val_loss: 2.4576 - val_categorical_accuracy: 0.1379\n",
      "Epoch 28/50\n",
      "72/82 [=========================>....] - ETA: 0s - loss: 2.3263 - categorical_accuracy: 0.2179Epoch 28: loss = 2.331319808959961, val_loss = 2.490473985671997\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 2.3313 - categorical_accuracy: 0.2149 - val_loss: 2.4905 - val_categorical_accuracy: 0.1241\n",
      "Epoch 29/50\n",
      "70/82 [========================>.....] - ETA: 0s - loss: 2.3304 - categorical_accuracy: 0.1875Epoch 29: loss = 2.32668399810791, val_loss = 2.4922757148742676\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 2.3267 - categorical_accuracy: 0.1951 - val_loss: 2.4923 - val_categorical_accuracy: 0.1181\n",
      "Epoch 30/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 2.3452 - categorical_accuracy: 0.1942Epoch 30: loss = 2.332487106323242, val_loss = 2.4331183433532715\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.3325 - categorical_accuracy: 0.1997 - val_loss: 2.4331 - val_categorical_accuracy: 0.1287\n",
      "Epoch 31/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 2.3082 - categorical_accuracy: 0.2158Restoring model weights from the end of the best epoch: 26.\n",
      "Epoch 31: loss = 2.3087902069091797, val_loss = 2.5485634803771973\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 2.3088 - categorical_accuracy: 0.2134 - val_loss: 2.5486 - val_categorical_accuracy: 0.0883\n",
      "Epoch 31: early stopping\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.3956 - categorical_accuracy: 0.1569\n",
      "Epoch 1/50\n",
      "79/83 [===========================>..] - ETA: 0s - loss: 3.2360 - categorical_accuracy: 0.0491Epoch 1: loss = 3.2355082035064697, val_loss = 3.2192649841308594\n",
      "83/83 [==============================] - 2s 9ms/step - loss: 3.2355 - categorical_accuracy: 0.0480 - val_loss: 3.2193 - val_categorical_accuracy: 0.0427\n",
      "Epoch 2/50\n",
      "72/83 [=========================>....] - ETA: 0s - loss: 3.2180 - categorical_accuracy: 0.0365Epoch 2: loss = 3.218294382095337, val_loss = 3.2202110290527344\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 3.2183 - categorical_accuracy: 0.0381 - val_loss: 3.2202 - val_categorical_accuracy: 0.0404\n",
      "Epoch 3/50\n",
      "72/83 [=========================>....] - ETA: 0s - loss: 3.2170 - categorical_accuracy: 0.0495Epoch 3: loss = 3.2173867225646973, val_loss = 3.220578908920288\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 3.2174 - categorical_accuracy: 0.0495 - val_loss: 3.2206 - val_categorical_accuracy: 0.0404\n",
      "Epoch 4/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 3.2169 - categorical_accuracy: 0.0411Epoch 4: loss = 3.2171196937561035, val_loss = 3.2209630012512207\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 3.2171 - categorical_accuracy: 0.0434 - val_loss: 3.2210 - val_categorical_accuracy: 0.0404\n",
      "Epoch 5/50\n",
      "74/83 [=========================>....] - ETA: 0s - loss: 3.2160 - categorical_accuracy: 0.0557Epoch 5: loss = 3.216132402420044, val_loss = 3.22149658203125\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 3.2161 - categorical_accuracy: 0.0556 - val_loss: 3.2215 - val_categorical_accuracy: 0.0404\n",
      "Epoch 6/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 3.2161 - categorical_accuracy: 0.0488Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 6: loss = 3.216294050216675, val_loss = 3.222050666809082\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 3.2163 - categorical_accuracy: 0.0465 - val_loss: 3.2221 - val_categorical_accuracy: 0.0404\n",
      "Epoch 6: early stopping\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3.2193 - categorical_accuracy: 0.0427\n",
      "Epoch 1/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 3.1886 - categorical_accuracy: 0.0684Epoch 1: loss = 3.176957368850708, val_loss = 3.1016318798065186\n",
      "41/41 [==============================] - 2s 14ms/step - loss: 3.1770 - categorical_accuracy: 0.0694 - val_loss: 3.1016 - val_categorical_accuracy: 0.0724\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.9131 - categorical_accuracy: 0.0991Epoch 2: loss = 2.9131052494049072, val_loss = 2.7193078994750977\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 2.9131 - categorical_accuracy: 0.0991 - val_loss: 2.7193 - val_categorical_accuracy: 0.1272\n",
      "Epoch 3/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 2.6902 - categorical_accuracy: 0.1284Epoch 3: loss = 2.683793783187866, val_loss = 2.501113176345825\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 2.6838 - categorical_accuracy: 0.1326 - val_loss: 2.5011 - val_categorical_accuracy: 0.1851\n",
      "Epoch 4/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 2.4234 - categorical_accuracy: 0.2045Epoch 4: loss = 2.4141647815704346, val_loss = 2.2791054248809814\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 2.4142 - categorical_accuracy: 0.2066 - val_loss: 2.2791 - val_categorical_accuracy: 0.2110\n",
      "Epoch 5/50\n",
      "34/41 [=======================>......] - ETA: 0s - loss: 2.2872 - categorical_accuracy: 0.2261Epoch 5: loss = 2.2791106700897217, val_loss = 2.11676025390625\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 2.2791 - categorical_accuracy: 0.2271 - val_loss: 2.1168 - val_categorical_accuracy: 0.2909\n",
      "Epoch 6/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 2.1412 - categorical_accuracy: 0.2708Epoch 6: loss = 2.137946128845215, val_loss = 2.0435004234313965\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 2.1379 - categorical_accuracy: 0.2744 - val_loss: 2.0435 - val_categorical_accuracy: 0.2902\n",
      "Epoch 7/50\n",
      "33/41 [=======================>......] - ETA: 0s - loss: 2.0590 - categorical_accuracy: 0.2689Epoch 7: loss = 2.0538132190704346, val_loss = 1.8957017660140991\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 2.0538 - categorical_accuracy: 0.2752 - val_loss: 1.8957 - val_categorical_accuracy: 0.3496\n",
      "Epoch 8/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.9264 - categorical_accuracy: 0.3167Epoch 8: loss = 1.9251749515533447, val_loss = 1.7810426950454712\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.9252 - categorical_accuracy: 0.3209 - val_loss: 1.7810 - val_categorical_accuracy: 0.4021\n",
      "Epoch 9/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 1.8424 - categorical_accuracy: 0.3490Epoch 9: loss = 1.8295055627822876, val_loss = 1.6771607398986816\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.8295 - categorical_accuracy: 0.3544 - val_loss: 1.6772 - val_categorical_accuracy: 0.4059\n",
      "Epoch 10/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 1.7468 - categorical_accuracy: 0.3672Epoch 10: loss = 1.7540819644927979, val_loss = 1.6493473052978516\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.7541 - categorical_accuracy: 0.3636 - val_loss: 1.6493 - val_categorical_accuracy: 0.4372\n",
      "Epoch 11/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 1.6945 - categorical_accuracy: 0.3828Epoch 11: loss = 1.6810057163238525, val_loss = 1.5325661897659302\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.6810 - categorical_accuracy: 0.3902 - val_loss: 1.5326 - val_categorical_accuracy: 0.4791\n",
      "Epoch 12/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 1.5493 - categorical_accuracy: 0.4557Epoch 12: loss = 1.5461262464523315, val_loss = 1.3797575235366821\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.5461 - categorical_accuracy: 0.4581 - val_loss: 1.3798 - val_categorical_accuracy: 0.5598\n",
      "Epoch 13/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 1.4600 - categorical_accuracy: 0.4729Epoch 13: loss = 1.4763424396514893, val_loss = 1.3246885538101196\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 1.4763 - categorical_accuracy: 0.4695 - val_loss: 1.3247 - val_categorical_accuracy: 0.5560\n",
      "Epoch 14/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 1.4195 - categorical_accuracy: 0.4957Epoch 14: loss = 1.419692873954773, val_loss = 1.2411245107650757\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.4197 - categorical_accuracy: 0.5023 - val_loss: 1.2411 - val_categorical_accuracy: 0.6062\n",
      "Epoch 15/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.3319 - categorical_accuracy: 0.5203Epoch 15: loss = 1.3254878520965576, val_loss = 1.1614291667938232\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.3255 - categorical_accuracy: 0.5236 - val_loss: 1.1614 - val_categorical_accuracy: 0.6245\n",
      "Epoch 16/50\n",
      "34/41 [=======================>......] - ETA: 0s - loss: 1.2811 - categorical_accuracy: 0.5423Epoch 16: loss = 1.2642649412155151, val_loss = 1.1270352602005005\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.2643 - categorical_accuracy: 0.5488 - val_loss: 1.1270 - val_categorical_accuracy: 0.6139\n",
      "Epoch 17/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 1.2252 - categorical_accuracy: 0.5652Epoch 17: loss = 1.2346245050430298, val_loss = 1.0506131649017334\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.2346 - categorical_accuracy: 0.5617 - val_loss: 1.0506 - val_categorical_accuracy: 0.6542\n",
      "Epoch 18/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.2195 - categorical_accuracy: 0.5566Epoch 18: loss = 1.223690390586853, val_loss = 1.0487854480743408\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.2237 - categorical_accuracy: 0.5572 - val_loss: 1.0488 - val_categorical_accuracy: 0.6458\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1388 - categorical_accuracy: 0.5739Epoch 19: loss = 1.1387722492218018, val_loss = 0.995913028717041\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 1.1388 - categorical_accuracy: 0.5739 - val_loss: 0.9959 - val_categorical_accuracy: 0.6565\n",
      "Epoch 20/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 1.1292 - categorical_accuracy: 0.5857Epoch 20: loss = 1.115606427192688, val_loss = 0.9813572764396667\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.1156 - categorical_accuracy: 0.5892 - val_loss: 0.9814 - val_categorical_accuracy: 0.6618\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0881 - categorical_accuracy: 0.6067Epoch 21: loss = 1.0881404876708984, val_loss = 0.9395431280136108\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.0881 - categorical_accuracy: 0.6067 - val_loss: 0.9395 - val_categorical_accuracy: 0.6778\n",
      "Epoch 22/50\n",
      "34/41 [=======================>......] - ETA: 0s - loss: 0.9784 - categorical_accuracy: 0.6443Epoch 22: loss = 0.9961622953414917, val_loss = 0.9205650687217712\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.9962 - categorical_accuracy: 0.6387 - val_loss: 0.9206 - val_categorical_accuracy: 0.6816\n",
      "Epoch 23/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.0306 - categorical_accuracy: 0.6182Epoch 23: loss = 1.0276607275009155, val_loss = 0.9314398765563965\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.0277 - categorical_accuracy: 0.6220 - val_loss: 0.9314 - val_categorical_accuracy: 0.6695\n",
      "Epoch 24/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.9895 - categorical_accuracy: 0.6225Epoch 24: loss = 0.9787458181381226, val_loss = 0.859736442565918\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.9787 - categorical_accuracy: 0.6265 - val_loss: 0.8597 - val_categorical_accuracy: 0.6915\n",
      "Epoch 25/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.9513 - categorical_accuracy: 0.6351Epoch 25: loss = 0.9458646774291992, val_loss = 0.9001413583755493\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 0.9459 - categorical_accuracy: 0.6402 - val_loss: 0.9001 - val_categorical_accuracy: 0.6740\n",
      "Epoch 26/50\n",
      "34/41 [=======================>......] - ETA: 0s - loss: 0.9318 - categorical_accuracy: 0.6535Epoch 26: loss = 0.9206855297088623, val_loss = 0.8440255522727966\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.9207 - categorical_accuracy: 0.6532 - val_loss: 0.8440 - val_categorical_accuracy: 0.7045\n",
      "Epoch 27/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.9427 - categorical_accuracy: 0.6363Epoch 27: loss = 0.9529755711555481, val_loss = 0.8959273099899292\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.9530 - categorical_accuracy: 0.6326 - val_loss: 0.8959 - val_categorical_accuracy: 0.6809\n",
      "Epoch 28/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.8652 - categorical_accuracy: 0.6814Epoch 28: loss = 0.889663577079773, val_loss = 0.8114745616912842\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.8897 - categorical_accuracy: 0.6730 - val_loss: 0.8115 - val_categorical_accuracy: 0.7098\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.8878 - categorical_accuracy: 0.6448Epoch 29: loss = 0.8878034353256226, val_loss = 0.9241271018981934\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.8878 - categorical_accuracy: 0.6448 - val_loss: 0.9241 - val_categorical_accuracy: 0.6809\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.8911 - categorical_accuracy: 0.6562Epoch 30: loss = 0.8911052942276001, val_loss = 0.826510488986969\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 0.8911 - categorical_accuracy: 0.6562 - val_loss: 0.8265 - val_categorical_accuracy: 0.6908\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.8596 - categorical_accuracy: 0.6761Epoch 31: loss = 0.8596299290657043, val_loss = 0.807314932346344\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.8596 - categorical_accuracy: 0.6761 - val_loss: 0.8073 - val_categorical_accuracy: 0.6938\n",
      "Epoch 32/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.8878 - categorical_accuracy: 0.6519Epoch 32: loss = 0.8667728900909424, val_loss = 0.7901169657707214\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.8668 - categorical_accuracy: 0.6631 - val_loss: 0.7901 - val_categorical_accuracy: 0.7068\n",
      "Epoch 33/50\n",
      "33/41 [=======================>......] - ETA: 0s - loss: 0.8511 - categorical_accuracy: 0.6667Epoch 33: loss = 0.8595171570777893, val_loss = 0.8060764670372009\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.8595 - categorical_accuracy: 0.6654 - val_loss: 0.8061 - val_categorical_accuracy: 0.6992\n",
      "Epoch 34/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.8414 - categorical_accuracy: 0.6816Epoch 34: loss = 0.8391347527503967, val_loss = 0.7563843131065369\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.8391 - categorical_accuracy: 0.6799 - val_loss: 0.7564 - val_categorical_accuracy: 0.7372\n",
      "Epoch 35/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.8244 - categorical_accuracy: 0.6780Epoch 35: loss = 0.8377443552017212, val_loss = 0.7877529859542847\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.8377 - categorical_accuracy: 0.6738 - val_loss: 0.7878 - val_categorical_accuracy: 0.6999\n",
      "Epoch 36/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.8218 - categorical_accuracy: 0.6926Epoch 36: loss = 0.8170952200889587, val_loss = 0.7354035377502441\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 0.8171 - categorical_accuracy: 0.6959 - val_loss: 0.7354 - val_categorical_accuracy: 0.7296\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.7644 - categorical_accuracy: 0.7088Epoch 37: loss = 0.7644442319869995, val_loss = 0.7659463286399841\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.7644 - categorical_accuracy: 0.7088 - val_loss: 0.7659 - val_categorical_accuracy: 0.7182\n",
      "Epoch 38/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.7707 - categorical_accuracy: 0.7153Epoch 38: loss = 0.7597538828849792, val_loss = 0.7633359432220459\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.7598 - categorical_accuracy: 0.7172 - val_loss: 0.7633 - val_categorical_accuracy: 0.7030\n",
      "Epoch 39/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 0.7834 - categorical_accuracy: 0.6875Epoch 39: loss = 0.7941933870315552, val_loss = 0.7541609406471252\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.7942 - categorical_accuracy: 0.6890 - val_loss: 0.7542 - val_categorical_accuracy: 0.7487\n",
      "Epoch 40/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.7654 - categorical_accuracy: 0.7052Epoch 40: loss = 0.7615363001823425, val_loss = 0.7106209397315979\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.7615 - categorical_accuracy: 0.7111 - val_loss: 0.7106 - val_categorical_accuracy: 0.7502\n",
      "Epoch 41/50\n",
      "34/41 [=======================>......] - ETA: 0s - loss: 0.7700 - categorical_accuracy: 0.7059Epoch 41: loss = 0.784683346748352, val_loss = 0.7101684212684631\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.7847 - categorical_accuracy: 0.6928 - val_loss: 0.7102 - val_categorical_accuracy: 0.7357\n",
      "Epoch 42/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 0.7507 - categorical_accuracy: 0.7097Epoch 42: loss = 0.743781328201294, val_loss = 0.7518364191055298\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.7438 - categorical_accuracy: 0.7119 - val_loss: 0.7518 - val_categorical_accuracy: 0.7235\n",
      "Epoch 43/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.7256 - categorical_accuracy: 0.7205Epoch 43: loss = 0.7298437356948853, val_loss = 0.6932876706123352\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.7298 - categorical_accuracy: 0.7188 - val_loss: 0.6933 - val_categorical_accuracy: 0.7517\n",
      "Epoch 44/50\n",
      "34/41 [=======================>......] - ETA: 0s - loss: 0.7116 - categorical_accuracy: 0.7206Epoch 44: loss = 0.7330386638641357, val_loss = 0.6812950968742371\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.7330 - categorical_accuracy: 0.7149 - val_loss: 0.6813 - val_categorical_accuracy: 0.7517\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.7216 - categorical_accuracy: 0.7302Epoch 45: loss = 0.7216428518295288, val_loss = 0.6906487345695496\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.7216 - categorical_accuracy: 0.7302 - val_loss: 0.6906 - val_categorical_accuracy: 0.7677\n",
      "Epoch 46/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.7303 - categorical_accuracy: 0.7075Epoch 46: loss = 0.7313486337661743, val_loss = 0.7228357195854187\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.7313 - categorical_accuracy: 0.7058 - val_loss: 0.7228 - val_categorical_accuracy: 0.7441\n",
      "Epoch 47/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 0.7575 - categorical_accuracy: 0.6998Epoch 47: loss = 0.7589079141616821, val_loss = 0.6856775879859924\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 0.7589 - categorical_accuracy: 0.7035 - val_loss: 0.6857 - val_categorical_accuracy: 0.7570\n",
      "Epoch 48/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.7265 - categorical_accuracy: 0.7289Epoch 48: loss = 0.7243427038192749, val_loss = 0.6914925575256348\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.7243 - categorical_accuracy: 0.7256 - val_loss: 0.6915 - val_categorical_accuracy: 0.7502\n",
      "Epoch 49/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.6995 - categorical_accuracy: 0.7258Restoring model weights from the end of the best epoch: 44.\n",
      "Epoch 49: loss = 0.707686185836792, val_loss = 0.6821053624153137\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.7077 - categorical_accuracy: 0.7233 - val_loss: 0.6821 - val_categorical_accuracy: 0.7494\n",
      "Epoch 49: early stopping\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6813 - categorical_accuracy: 0.7517\n",
      "Epoch 1/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 3.1768 - categorical_accuracy: 0.0526Epoch 1: loss = 3.175889492034912, val_loss = 3.05378794670105\n",
      "42/42 [==============================] - 2s 14ms/step - loss: 3.1759 - categorical_accuracy: 0.0533 - val_loss: 3.0538 - val_categorical_accuracy: 0.0808\n",
      "Epoch 2/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.9209 - categorical_accuracy: 0.0930Epoch 2: loss = 2.9200665950775146, val_loss = 2.769042491912842\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 2.9201 - categorical_accuracy: 0.0929 - val_loss: 2.7690 - val_categorical_accuracy: 0.1052\n",
      "Epoch 3/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.6968 - categorical_accuracy: 0.1105Epoch 3: loss = 2.695660352706909, val_loss = 2.6010477542877197\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 2.6957 - categorical_accuracy: 0.1104 - val_loss: 2.6010 - val_categorical_accuracy: 0.1265\n",
      "Epoch 4/50\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 2.5892 - categorical_accuracy: 0.1461Epoch 4: loss = 2.5619308948516846, val_loss = 2.503380537033081\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 2.5619 - categorical_accuracy: 0.1523 - val_loss: 2.5034 - val_categorical_accuracy: 0.1905\n",
      "Epoch 5/50\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 2.4817 - categorical_accuracy: 0.1866Epoch 5: loss = 2.461989641189575, val_loss = 2.3203258514404297\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 2.4620 - categorical_accuracy: 0.1866 - val_loss: 2.3203 - val_categorical_accuracy: 0.2271\n",
      "Epoch 6/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 2.3528 - categorical_accuracy: 0.2051Epoch 6: loss = 2.3504445552825928, val_loss = 2.197100877761841\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 2.3504 - categorical_accuracy: 0.2056 - val_loss: 2.1971 - val_categorical_accuracy: 0.2508\n",
      "Epoch 7/50\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 2.2290 - categorical_accuracy: 0.2151Epoch 7: loss = 2.217411756515503, val_loss = 2.055445671081543\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 2.2174 - categorical_accuracy: 0.2193 - val_loss: 2.0554 - val_categorical_accuracy: 0.2736\n",
      "Epoch 8/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.0743 - categorical_accuracy: 0.2569Epoch 8: loss = 2.074038028717041, val_loss = 1.9212965965270996\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 2.0740 - categorical_accuracy: 0.2567 - val_loss: 1.9213 - val_categorical_accuracy: 0.3125\n",
      "Epoch 9/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.9810 - categorical_accuracy: 0.2591Epoch 9: loss = 1.981247067451477, val_loss = 1.8319181203842163\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.9812 - categorical_accuracy: 0.2589 - val_loss: 1.8319 - val_categorical_accuracy: 0.3384\n",
      "Epoch 10/50\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 1.9297 - categorical_accuracy: 0.2768Epoch 10: loss = 1.92532479763031, val_loss = 1.8777806758880615\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 1.9253 - categorical_accuracy: 0.2856 - val_loss: 1.8778 - val_categorical_accuracy: 0.2851\n",
      "Epoch 11/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.8755 - categorical_accuracy: 0.2851Epoch 11: loss = 1.8751763105392456, val_loss = 1.7105828523635864\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 1.8752 - categorical_accuracy: 0.2856 - val_loss: 1.7106 - val_categorical_accuracy: 0.3514\n",
      "Epoch 12/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.7955 - categorical_accuracy: 0.3056Epoch 12: loss = 1.7963759899139404, val_loss = 1.6879537105560303\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 1.7964 - categorical_accuracy: 0.3054 - val_loss: 1.6880 - val_categorical_accuracy: 0.3567\n",
      "Epoch 13/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 1.7096 - categorical_accuracy: 0.3528Epoch 13: loss = 1.7232654094696045, val_loss = 1.7852305173873901\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.7233 - categorical_accuracy: 0.3458 - val_loss: 1.7852 - val_categorical_accuracy: 0.3125\n",
      "Epoch 14/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.8748 - categorical_accuracy: 0.3117Epoch 14: loss = 1.8753060102462769, val_loss = 1.6169575452804565\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 1.8753 - categorical_accuracy: 0.3115 - val_loss: 1.6170 - val_categorical_accuracy: 0.3872\n",
      "Epoch 15/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.7064 - categorical_accuracy: 0.3415Epoch 15: loss = 1.7063918113708496, val_loss = 1.6029112339019775\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.7064 - categorical_accuracy: 0.3412 - val_loss: 1.6029 - val_categorical_accuracy: 0.3925\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6477 - categorical_accuracy: 0.3770Epoch 16: loss = 1.6476778984069824, val_loss = 1.5877453088760376\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.6477 - categorical_accuracy: 0.3770 - val_loss: 1.5877 - val_categorical_accuracy: 0.3902\n",
      "Epoch 17/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.6270 - categorical_accuracy: 0.3680Epoch 17: loss = 1.6260486841201782, val_loss = 1.5044546127319336\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 1.6260 - categorical_accuracy: 0.3679 - val_loss: 1.5045 - val_categorical_accuracy: 0.4550\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6096 - categorical_accuracy: 0.3793Epoch 18: loss = 1.6096068620681763, val_loss = 1.5070310831069946\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 1.6096 - categorical_accuracy: 0.3793 - val_loss: 1.5070 - val_categorical_accuracy: 0.4611\n",
      "Epoch 19/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.5954 - categorical_accuracy: 0.3788Epoch 19: loss = 1.5955034494400024, val_loss = 1.458748698234558\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.5955 - categorical_accuracy: 0.3785 - val_loss: 1.4587 - val_categorical_accuracy: 0.4954\n",
      "Epoch 20/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 1.6462 - categorical_accuracy: 0.3668Epoch 20: loss = 1.6368701457977295, val_loss = 1.4953995943069458\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.6369 - categorical_accuracy: 0.3717 - val_loss: 1.4954 - val_categorical_accuracy: 0.4558\n",
      "Epoch 21/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 1.5698 - categorical_accuracy: 0.3982Epoch 21: loss = 1.5678160190582275, val_loss = 1.4443931579589844\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 1.5678 - categorical_accuracy: 0.3953 - val_loss: 1.4444 - val_categorical_accuracy: 0.4848\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5228 - categorical_accuracy: 0.4219Epoch 22: loss = 1.5228137969970703, val_loss = 1.4324513673782349\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.5228 - categorical_accuracy: 0.4219 - val_loss: 1.4325 - val_categorical_accuracy: 0.4893\n",
      "Epoch 23/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 1.5001 - categorical_accuracy: 0.4143Epoch 23: loss = 1.5047218799591064, val_loss = 1.4133708477020264\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.5047 - categorical_accuracy: 0.4136 - val_loss: 1.4134 - val_categorical_accuracy: 0.5160\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4917 - categorical_accuracy: 0.4273Epoch 24: loss = 1.491721749305725, val_loss = 1.3759865760803223\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 1.4917 - categorical_accuracy: 0.4273 - val_loss: 1.3760 - val_categorical_accuracy: 0.5343\n",
      "Epoch 25/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.4503 - categorical_accuracy: 0.4345Epoch 25: loss = 1.4495673179626465, val_loss = 1.3314846754074097\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.4496 - categorical_accuracy: 0.4349 - val_loss: 1.3315 - val_categorical_accuracy: 0.5389\n",
      "Epoch 26/50\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 1.4574 - categorical_accuracy: 0.4476Epoch 26: loss = 1.4576843976974487, val_loss = 1.348130226135254\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 1.4577 - categorical_accuracy: 0.4486 - val_loss: 1.3481 - val_categorical_accuracy: 0.5427\n",
      "Epoch 27/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.3934 - categorical_accuracy: 0.4543Epoch 27: loss = 1.3936233520507812, val_loss = 1.3112311363220215\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.3936 - categorical_accuracy: 0.4539 - val_loss: 1.3112 - val_categorical_accuracy: 0.5244\n",
      "Epoch 28/50\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 1.4090 - categorical_accuracy: 0.4669Epoch 28: loss = 1.4003515243530273, val_loss = 1.2734805345535278\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 1.4004 - categorical_accuracy: 0.4768 - val_loss: 1.2735 - val_categorical_accuracy: 0.5716\n",
      "Epoch 29/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.3673 - categorical_accuracy: 0.4825Epoch 29: loss = 1.3662761449813843, val_loss = 1.2658312320709229\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.3663 - categorical_accuracy: 0.4829 - val_loss: 1.2658 - val_categorical_accuracy: 0.5473\n",
      "Epoch 30/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.3825 - categorical_accuracy: 0.4779Epoch 30: loss = 1.3820278644561768, val_loss = 1.2527803182601929\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 1.3820 - categorical_accuracy: 0.4783 - val_loss: 1.2528 - val_categorical_accuracy: 0.5617\n",
      "Epoch 31/50\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 1.3170 - categorical_accuracy: 0.4706Epoch 31: loss = 1.3251512050628662, val_loss = 1.257651448249817\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 1.3252 - categorical_accuracy: 0.4684 - val_loss: 1.2577 - val_categorical_accuracy: 0.5511\n",
      "Epoch 32/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.3384 - categorical_accuracy: 0.4840Epoch 32: loss = 1.3384169340133667, val_loss = 1.2201932668685913\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.3384 - categorical_accuracy: 0.4836 - val_loss: 1.2202 - val_categorical_accuracy: 0.5793\n",
      "Epoch 33/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 1.2865 - categorical_accuracy: 0.5321Epoch 33: loss = 1.2983380556106567, val_loss = 1.2555104494094849\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.2983 - categorical_accuracy: 0.5225 - val_loss: 1.2555 - val_categorical_accuracy: 0.5450\n",
      "Epoch 34/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.3033 - categorical_accuracy: 0.4909Epoch 34: loss = 1.304363489151001, val_loss = 1.430662989616394\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.3044 - categorical_accuracy: 0.4905 - val_loss: 1.4307 - val_categorical_accuracy: 0.4909\n",
      "Epoch 35/50\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 1.3412 - categorical_accuracy: 0.4818Epoch 35: loss = 1.3302431106567383, val_loss = 1.3016610145568848\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.3302 - categorical_accuracy: 0.4943 - val_loss: 1.3017 - val_categorical_accuracy: 0.5236\n",
      "Epoch 36/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 1.2486 - categorical_accuracy: 0.5214Epoch 36: loss = 1.2483770847320557, val_loss = 1.16165292263031\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.2484 - categorical_accuracy: 0.5248 - val_loss: 1.1617 - val_categorical_accuracy: 0.5960\n",
      "Epoch 37/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.2234 - categorical_accuracy: 0.5267Epoch 37: loss = 1.2226977348327637, val_loss = 1.268545389175415\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 1.2227 - categorical_accuracy: 0.5270 - val_loss: 1.2685 - val_categorical_accuracy: 0.5328\n",
      "Epoch 38/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.2209 - categorical_accuracy: 0.5259Epoch 38: loss = 1.2216094732284546, val_loss = 1.13215970993042\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 1.2216 - categorical_accuracy: 0.5255 - val_loss: 1.1322 - val_categorical_accuracy: 0.5938\n",
      "Epoch 39/50\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 1.1908 - categorical_accuracy: 0.5495Epoch 39: loss = 1.1883403062820435, val_loss = 1.1102501153945923\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 1.1883 - categorical_accuracy: 0.5499 - val_loss: 1.1103 - val_categorical_accuracy: 0.6128\n",
      "Epoch 40/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.1602 - categorical_accuracy: 0.5480Epoch 40: loss = 1.159843921661377, val_loss = 1.1882930994033813\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 1.1598 - categorical_accuracy: 0.5484 - val_loss: 1.1883 - val_categorical_accuracy: 0.5564\n",
      "Epoch 41/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.2182 - categorical_accuracy: 0.5373Epoch 41: loss = 1.2173231840133667, val_loss = 1.0898629426956177\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.2173 - categorical_accuracy: 0.5377 - val_loss: 1.0899 - val_categorical_accuracy: 0.6136\n",
      "Epoch 42/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 1.1472 - categorical_accuracy: 0.5689Epoch 42: loss = 1.1443758010864258, val_loss = 1.109959363937378\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.1444 - categorical_accuracy: 0.5674 - val_loss: 1.1100 - val_categorical_accuracy: 0.5884\n",
      "Epoch 43/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 1.1361 - categorical_accuracy: 0.5577Epoch 43: loss = 1.1496860980987549, val_loss = 1.0694023370742798\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 1.1497 - categorical_accuracy: 0.5560 - val_loss: 1.0694 - val_categorical_accuracy: 0.5976\n",
      "Epoch 44/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.1569 - categorical_accuracy: 0.5450Epoch 44: loss = 1.1571460962295532, val_loss = 1.2567331790924072\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 1.1571 - categorical_accuracy: 0.5453 - val_loss: 1.2567 - val_categorical_accuracy: 0.5191\n",
      "Epoch 45/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 1.1912 - categorical_accuracy: 0.5436Epoch 45: loss = 1.1866146326065063, val_loss = 1.0903079509735107\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.1866 - categorical_accuracy: 0.5446 - val_loss: 1.0903 - val_categorical_accuracy: 0.5976\n",
      "Epoch 46/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.1481 - categorical_accuracy: 0.5770Epoch 46: loss = 1.1476166248321533, val_loss = 1.0839518308639526\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.1476 - categorical_accuracy: 0.5773 - val_loss: 1.0840 - val_categorical_accuracy: 0.5838\n",
      "Epoch 47/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 1.1727 - categorical_accuracy: 0.5510Epoch 47: loss = 1.1693731546401978, val_loss = 1.7184524536132812\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 1.1694 - categorical_accuracy: 0.5575 - val_loss: 1.7185 - val_categorical_accuracy: 0.4261\n",
      "Epoch 48/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 1.4516 - categorical_accuracy: 0.4936Epoch 48: loss = 1.437278151512146, val_loss = 1.0596826076507568\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.4373 - categorical_accuracy: 0.4950 - val_loss: 1.0597 - val_categorical_accuracy: 0.6181\n",
      "Epoch 49/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.0763 - categorical_accuracy: 0.6029Epoch 49: loss = 1.0784729719161987, val_loss = 1.2940653562545776\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.0785 - categorical_accuracy: 0.6024 - val_loss: 1.2941 - val_categorical_accuracy: 0.5183\n",
      "Epoch 50/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.3576 - categorical_accuracy: 0.4848Epoch 50: loss = 1.3573652505874634, val_loss = 1.1105741262435913\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 1.3574 - categorical_accuracy: 0.4851 - val_loss: 1.1106 - val_categorical_accuracy: 0.5991\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 1.1106 - categorical_accuracy: 0.5991\n",
      "Epoch 1/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 3.1924 - categorical_accuracy: 0.0566Epoch 1: loss = 3.1881871223449707, val_loss = 3.0620229244232178\n",
      "41/41 [==============================] - 2s 14ms/step - loss: 3.1882 - categorical_accuracy: 0.0549 - val_loss: 3.0620 - val_categorical_accuracy: 0.0861\n",
      "Epoch 2/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 2.9396 - categorical_accuracy: 0.0946Epoch 2: loss = 2.925199508666992, val_loss = 2.765953779220581\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 2.9252 - categorical_accuracy: 0.0945 - val_loss: 2.7660 - val_categorical_accuracy: 0.0914\n",
      "Epoch 3/50\n",
      "33/41 [=======================>......] - ETA: 0s - loss: 2.7650 - categorical_accuracy: 0.0928Epoch 3: loss = 2.7489449977874756, val_loss = 2.6195762157440186\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 2.7489 - categorical_accuracy: 0.0998 - val_loss: 2.6196 - val_categorical_accuracy: 0.0906\n",
      "Epoch 4/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 2.6144 - categorical_accuracy: 0.1377Epoch 4: loss = 2.6206016540527344, val_loss = 2.517056941986084\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 2.6206 - categorical_accuracy: 0.1334 - val_loss: 2.5171 - val_categorical_accuracy: 0.1394\n",
      "Epoch 5/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 2.5071 - categorical_accuracy: 0.1639Epoch 5: loss = 2.4882824420928955, val_loss = 2.319086790084839\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 2.4883 - categorical_accuracy: 0.1707 - val_loss: 2.3191 - val_categorical_accuracy: 0.2551\n",
      "Epoch 6/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 2.2714 - categorical_accuracy: 0.2289Epoch 6: loss = 2.265184164047241, val_loss = 2.0680434703826904\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 2.2652 - categorical_accuracy: 0.2241 - val_loss: 2.0680 - val_categorical_accuracy: 0.3252\n",
      "Epoch 7/50\n",
      "33/41 [=======================>......] - ETA: 0s - loss: 2.0715 - categorical_accuracy: 0.2831Epoch 7: loss = 2.0592575073242188, val_loss = 1.8384257555007935\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 2.0593 - categorical_accuracy: 0.2889 - val_loss: 1.8384 - val_categorical_accuracy: 0.3976\n",
      "Epoch 8/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.8723 - categorical_accuracy: 0.3421Epoch 8: loss = 1.8712948560714722, val_loss = 1.6134635210037231\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.8713 - categorical_accuracy: 0.3430 - val_loss: 1.6135 - val_categorical_accuracy: 0.4638\n",
      "Epoch 9/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 1.7689 - categorical_accuracy: 0.3698Epoch 9: loss = 1.7583035230636597, val_loss = 1.4965882301330566\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.7583 - categorical_accuracy: 0.3659 - val_loss: 1.4966 - val_categorical_accuracy: 0.5156\n",
      "Epoch 10/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.6132 - categorical_accuracy: 0.3894Epoch 10: loss = 1.6136070489883423, val_loss = 1.4003890752792358\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 1.6136 - categorical_accuracy: 0.3918 - val_loss: 1.4004 - val_categorical_accuracy: 0.5209\n",
      "Epoch 11/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.5852 - categorical_accuracy: 0.4079Epoch 11: loss = 1.564873456954956, val_loss = 1.3555859327316284\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.5649 - categorical_accuracy: 0.4200 - val_loss: 1.3556 - val_categorical_accuracy: 0.5133\n",
      "Epoch 12/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 1.5202 - categorical_accuracy: 0.4566Epoch 12: loss = 1.4923142194747925, val_loss = 1.2595850229263306\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.4923 - categorical_accuracy: 0.4581 - val_loss: 1.2596 - val_categorical_accuracy: 0.5720\n",
      "Epoch 13/50\n",
      "34/41 [=======================>......] - ETA: 0s - loss: 1.4583 - categorical_accuracy: 0.4375Epoch 13: loss = 1.460866093635559, val_loss = 1.2928802967071533\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.4609 - categorical_accuracy: 0.4360 - val_loss: 1.2929 - val_categorical_accuracy: 0.5484\n",
      "Epoch 14/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.4229 - categorical_accuracy: 0.4704Epoch 14: loss = 1.427164912223816, val_loss = 1.2876296043395996\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.4272 - categorical_accuracy: 0.4680 - val_loss: 1.2876 - val_categorical_accuracy: 0.5156\n",
      "Epoch 15/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.3465 - categorical_accuracy: 0.4797Epoch 15: loss = 1.3281277418136597, val_loss = 1.1668095588684082\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.3281 - categorical_accuracy: 0.4832 - val_loss: 1.1668 - val_categorical_accuracy: 0.5704\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2739 - categorical_accuracy: 0.5236Epoch 16: loss = 1.2738873958587646, val_loss = 1.2834434509277344\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.2739 - categorical_accuracy: 0.5236 - val_loss: 1.2834 - val_categorical_accuracy: 0.5423\n",
      "Epoch 17/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.2782 - categorical_accuracy: 0.5220Epoch 17: loss = 1.2794594764709473, val_loss = 1.1596084833145142\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.2795 - categorical_accuracy: 0.5206 - val_loss: 1.1596 - val_categorical_accuracy: 0.5644\n",
      "Epoch 18/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.2480 - categorical_accuracy: 0.5490Epoch 18: loss = 1.2427611351013184, val_loss = 1.114375352859497\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.2428 - categorical_accuracy: 0.5480 - val_loss: 1.1144 - val_categorical_accuracy: 0.5918\n",
      "Epoch 19/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 1.1821 - categorical_accuracy: 0.5347Epoch 19: loss = 1.18598210811615, val_loss = 1.1096539497375488\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.1860 - categorical_accuracy: 0.5335 - val_loss: 1.1097 - val_categorical_accuracy: 0.5765\n",
      "Epoch 20/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 1.1562 - categorical_accuracy: 0.5362Epoch 20: loss = 1.1536160707473755, val_loss = 1.022486686706543\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 1.1536 - categorical_accuracy: 0.5351 - val_loss: 1.0225 - val_categorical_accuracy: 0.6070\n",
      "Epoch 21/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.1454 - categorical_accuracy: 0.5557Epoch 21: loss = 1.1316964626312256, val_loss = 1.0198440551757812\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.1317 - categorical_accuracy: 0.5587 - val_loss: 1.0198 - val_categorical_accuracy: 0.6344\n",
      "Epoch 22/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.1366 - categorical_accuracy: 0.5684Epoch 22: loss = 1.135338544845581, val_loss = 0.99112868309021\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.1353 - categorical_accuracy: 0.5724 - val_loss: 0.9911 - val_categorical_accuracy: 0.6420\n",
      "Epoch 23/50\n",
      "34/41 [=======================>......] - ETA: 0s - loss: 1.1123 - categorical_accuracy: 0.5551Epoch 23: loss = 1.093088150024414, val_loss = 0.9790482521057129\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.0931 - categorical_accuracy: 0.5671 - val_loss: 0.9790 - val_categorical_accuracy: 0.6794\n",
      "Epoch 24/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.1484 - categorical_accuracy: 0.5329Epoch 24: loss = 1.1453887224197388, val_loss = 0.9800629615783691\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 1.1454 - categorical_accuracy: 0.5396 - val_loss: 0.9801 - val_categorical_accuracy: 0.6458\n",
      "Epoch 25/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.0386 - categorical_accuracy: 0.5785Epoch 25: loss = 1.031444787979126, val_loss = 0.9394769072532654\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.0314 - categorical_accuracy: 0.5846 - val_loss: 0.9395 - val_categorical_accuracy: 0.6778\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0088 - categorical_accuracy: 0.6189Epoch 26: loss = 1.0088425874710083, val_loss = 0.9410213232040405\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.0088 - categorical_accuracy: 0.6189 - val_loss: 0.9410 - val_categorical_accuracy: 0.6900\n",
      "Epoch 27/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.0528 - categorical_accuracy: 0.6014Epoch 27: loss = 1.0426764488220215, val_loss = 0.9003791809082031\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.0427 - categorical_accuracy: 0.6113 - val_loss: 0.9004 - val_categorical_accuracy: 0.6908\n",
      "Epoch 28/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.9261 - categorical_accuracy: 0.6478Epoch 28: loss = 0.9602847099304199, val_loss = 0.9398698210716248\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.9603 - categorical_accuracy: 0.6387 - val_loss: 0.9399 - val_categorical_accuracy: 0.6649\n",
      "Epoch 29/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.9786 - categorical_accuracy: 0.6266Epoch 29: loss = 0.9730982780456543, val_loss = 0.8700686693191528\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 0.9731 - categorical_accuracy: 0.6280 - val_loss: 0.8701 - val_categorical_accuracy: 0.7190\n",
      "Epoch 30/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.9336 - categorical_accuracy: 0.6189Epoch 30: loss = 0.9256815910339355, val_loss = 0.889997661113739\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.9257 - categorical_accuracy: 0.6242 - val_loss: 0.8900 - val_categorical_accuracy: 0.6999\n",
      "Epoch 31/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.9514 - categorical_accuracy: 0.6216Epoch 31: loss = 0.9558888077735901, val_loss = 0.8738211393356323\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.9559 - categorical_accuracy: 0.6220 - val_loss: 0.8738 - val_categorical_accuracy: 0.6847\n",
      "Epoch 32/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.9078 - categorical_accuracy: 0.6580Epoch 32: loss = 0.9071878790855408, val_loss = 0.8325625061988831\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.9072 - categorical_accuracy: 0.6593 - val_loss: 0.8326 - val_categorical_accuracy: 0.7357\n",
      "Epoch 33/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.8734 - categorical_accuracy: 0.6648Epoch 33: loss = 0.8678259253501892, val_loss = 0.8460211753845215\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.8678 - categorical_accuracy: 0.6677 - val_loss: 0.8460 - val_categorical_accuracy: 0.7129\n",
      "Epoch 34/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.8861 - categorical_accuracy: 0.6484Epoch 34: loss = 0.8861696124076843, val_loss = 0.8803948760032654\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.8862 - categorical_accuracy: 0.6456 - val_loss: 0.8804 - val_categorical_accuracy: 0.6961\n",
      "Epoch 35/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.8602 - categorical_accuracy: 0.6748Epoch 35: loss = 0.8637719750404358, val_loss = 0.8093326687812805\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.8638 - categorical_accuracy: 0.6730 - val_loss: 0.8093 - val_categorical_accuracy: 0.7395\n",
      "Epoch 36/50\n",
      "34/41 [=======================>......] - ETA: 0s - loss: 0.8591 - categorical_accuracy: 0.6719Epoch 36: loss = 0.8354039192199707, val_loss = 0.836482048034668\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.8354 - categorical_accuracy: 0.6761 - val_loss: 0.8365 - val_categorical_accuracy: 0.7014\n",
      "Epoch 37/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.8620 - categorical_accuracy: 0.6723Epoch 37: loss = 0.8513337969779968, val_loss = 0.8066831827163696\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 0.8513 - categorical_accuracy: 0.6753 - val_loss: 0.8067 - val_categorical_accuracy: 0.6999\n",
      "Epoch 38/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.9241 - categorical_accuracy: 0.6453Epoch 38: loss = 0.9173648357391357, val_loss = 0.8378061056137085\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.9174 - categorical_accuracy: 0.6463 - val_loss: 0.8378 - val_categorical_accuracy: 0.7053\n",
      "Epoch 39/50\n",
      "33/41 [=======================>......] - ETA: 0s - loss: 0.8459 - categorical_accuracy: 0.6733Epoch 39: loss = 0.8364545106887817, val_loss = 0.7367419004440308\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.8365 - categorical_accuracy: 0.6784 - val_loss: 0.7367 - val_categorical_accuracy: 0.7761\n",
      "Epoch 40/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.8077 - categorical_accuracy: 0.6910Epoch 40: loss = 0.8100224137306213, val_loss = 0.803685188293457\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.8100 - categorical_accuracy: 0.6905 - val_loss: 0.8037 - val_categorical_accuracy: 0.7190\n",
      "Epoch 41/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.7897 - categorical_accuracy: 0.7101Epoch 41: loss = 0.7953184843063354, val_loss = 0.7180813550949097\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.7953 - categorical_accuracy: 0.7027 - val_loss: 0.7181 - val_categorical_accuracy: 0.7708\n",
      "Epoch 42/50\n",
      "33/41 [=======================>......] - ETA: 0s - loss: 0.7422 - categorical_accuracy: 0.7150Epoch 42: loss = 0.7571654915809631, val_loss = 0.7413254976272583\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 0.7572 - categorical_accuracy: 0.7088 - val_loss: 0.7413 - val_categorical_accuracy: 0.7624\n",
      "Epoch 43/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 0.7834 - categorical_accuracy: 0.7152Epoch 43: loss = 0.8023176193237305, val_loss = 0.7471052408218384\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.8023 - categorical_accuracy: 0.7058 - val_loss: 0.7471 - val_categorical_accuracy: 0.7418\n",
      "Epoch 44/50\n",
      "34/41 [=======================>......] - ETA: 0s - loss: 0.7482 - categorical_accuracy: 0.7077Epoch 44: loss = 0.7392579317092896, val_loss = 0.7746528387069702\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.7393 - categorical_accuracy: 0.7134 - val_loss: 0.7747 - val_categorical_accuracy: 0.7235\n",
      "Epoch 45/50\n",
      "34/41 [=======================>......] - ETA: 0s - loss: 0.7200 - categorical_accuracy: 0.7215Epoch 45: loss = 0.7123758792877197, val_loss = 0.7078080773353577\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.7124 - categorical_accuracy: 0.7256 - val_loss: 0.7078 - val_categorical_accuracy: 0.7647\n",
      "Epoch 46/50\n",
      "34/41 [=======================>......] - ETA: 0s - loss: 0.7288 - categorical_accuracy: 0.7279Epoch 46: loss = 0.7438014149665833, val_loss = 0.6992695331573486\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 0.7438 - categorical_accuracy: 0.7195 - val_loss: 0.6993 - val_categorical_accuracy: 0.7867\n",
      "Epoch 47/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.7483 - categorical_accuracy: 0.7109Epoch 47: loss = 0.7353978753089905, val_loss = 0.7139241695404053\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.7354 - categorical_accuracy: 0.7172 - val_loss: 0.7139 - val_categorical_accuracy: 0.7822\n",
      "Epoch 48/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.7778 - categorical_accuracy: 0.7179Epoch 48: loss = 0.7795246243476868, val_loss = 0.7058572769165039\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.7795 - categorical_accuracy: 0.7180 - val_loss: 0.7059 - val_categorical_accuracy: 0.7784\n",
      "Epoch 49/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.6980 - categorical_accuracy: 0.7318Epoch 49: loss = 0.6929967999458313, val_loss = 0.6865467429161072\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.6930 - categorical_accuracy: 0.7348 - val_loss: 0.6865 - val_categorical_accuracy: 0.7669\n",
      "Epoch 50/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.7160 - categorical_accuracy: 0.7348Epoch 50: loss = 0.7076466083526611, val_loss = 0.6680881977081299\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 0.7076 - categorical_accuracy: 0.7340 - val_loss: 0.6681 - val_categorical_accuracy: 0.7928\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6681 - categorical_accuracy: 0.7928\n",
      "Epoch 1/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 3.1764 - categorical_accuracy: 0.0526Epoch 1: loss = 3.176445484161377, val_loss = 3.082350254058838\n",
      "42/42 [==============================] - 2s 14ms/step - loss: 3.1764 - categorical_accuracy: 0.0526 - val_loss: 3.0824 - val_categorical_accuracy: 0.0442\n",
      "Epoch 2/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 3.0181 - categorical_accuracy: 0.0854Epoch 2: loss = 3.01822829246521, val_loss = 2.936396837234497\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 3.0182 - categorical_accuracy: 0.0853 - val_loss: 2.9364 - val_categorical_accuracy: 0.1037\n",
      "Epoch 3/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 2.9248 - categorical_accuracy: 0.0905Epoch 3: loss = 2.9250829219818115, val_loss = 2.845045804977417\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 2.9251 - categorical_accuracy: 0.0906 - val_loss: 2.8450 - val_categorical_accuracy: 0.1037\n",
      "Epoch 4/50\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 2.8615 - categorical_accuracy: 0.0864Epoch 4: loss = 2.850245714187622, val_loss = 2.739964485168457\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 2.8502 - categorical_accuracy: 0.0891 - val_loss: 2.7400 - val_categorical_accuracy: 0.1341\n",
      "Epoch 5/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.7310 - categorical_accuracy: 0.1166Epoch 5: loss = 2.7303755283355713, val_loss = 2.5635602474212646\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 2.7304 - categorical_accuracy: 0.1165 - val_loss: 2.5636 - val_categorical_accuracy: 0.2127\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.5435 - categorical_accuracy: 0.1493Epoch 6: loss = 2.5435235500335693, val_loss = 2.346558094024658\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 2.5435 - categorical_accuracy: 0.1493 - val_loss: 2.3466 - val_categorical_accuracy: 0.2401\n",
      "Epoch 7/50\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 2.4086 - categorical_accuracy: 0.1654Epoch 7: loss = 2.398113250732422, val_loss = 2.2097952365875244\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 2.3981 - categorical_accuracy: 0.1706 - val_loss: 2.2098 - val_categorical_accuracy: 0.2797\n",
      "Epoch 8/50\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 2.2981 - categorical_accuracy: 0.2050Epoch 8: loss = 2.2790958881378174, val_loss = 2.117255449295044\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 2.2791 - categorical_accuracy: 0.2163 - val_loss: 2.1173 - val_categorical_accuracy: 0.3178\n",
      "Epoch 9/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.2162 - categorical_accuracy: 0.2340Epoch 9: loss = 2.2164480686187744, val_loss = 1.9934546947479248\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 2.2164 - categorical_accuracy: 0.2338 - val_loss: 1.9935 - val_categorical_accuracy: 0.3605\n",
      "Epoch 10/50\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 2.0950 - categorical_accuracy: 0.2601Epoch 10: loss = 2.1119329929351807, val_loss = 1.9909627437591553\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 2.1119 - categorical_accuracy: 0.2536 - val_loss: 1.9910 - val_categorical_accuracy: 0.3430\n",
      "Epoch 11/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 2.0853 - categorical_accuracy: 0.2732Epoch 11: loss = 2.082775592803955, val_loss = 1.8700305223464966\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 2.0828 - categorical_accuracy: 0.2727 - val_loss: 1.8700 - val_categorical_accuracy: 0.3910\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.9948 - categorical_accuracy: 0.3054Epoch 12: loss = 1.9948002099990845, val_loss = 1.7763293981552124\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 1.9948 - categorical_accuracy: 0.3054 - val_loss: 1.7763 - val_categorical_accuracy: 0.4055\n",
      "Epoch 13/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 1.9342 - categorical_accuracy: 0.3388Epoch 13: loss = 1.9372066259384155, val_loss = 1.7507731914520264\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.9372 - categorical_accuracy: 0.3351 - val_loss: 1.7508 - val_categorical_accuracy: 0.4276\n",
      "Epoch 14/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.8738 - categorical_accuracy: 0.3508Epoch 14: loss = 1.86937415599823, val_loss = 1.6360238790512085\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.8694 - categorical_accuracy: 0.3557 - val_loss: 1.6360 - val_categorical_accuracy: 0.4931\n",
      "Epoch 15/50\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 1.7860 - categorical_accuracy: 0.3897Epoch 15: loss = 1.785537838935852, val_loss = 1.563264012336731\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 1.7855 - categorical_accuracy: 0.3968 - val_loss: 1.5633 - val_categorical_accuracy: 0.4741\n",
      "Epoch 16/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 1.7465 - categorical_accuracy: 0.3966Epoch 16: loss = 1.7412461042404175, val_loss = 1.456229329109192\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.7412 - categorical_accuracy: 0.3953 - val_loss: 1.4562 - val_categorical_accuracy: 0.5892\n",
      "Epoch 17/50\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 1.6309 - categorical_accuracy: 0.4531Epoch 17: loss = 1.635748267173767, val_loss = 1.63785982131958\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 1.6357 - categorical_accuracy: 0.4494 - val_loss: 1.6379 - val_categorical_accuracy: 0.4756\n",
      "Epoch 18/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 1.6671 - categorical_accuracy: 0.4183Epoch 18: loss = 1.6622854471206665, val_loss = 1.3718585968017578\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.6623 - categorical_accuracy: 0.4204 - val_loss: 1.3719 - val_categorical_accuracy: 0.5412\n",
      "Epoch 19/50\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 1.6277 - categorical_accuracy: 0.4210Epoch 19: loss = 1.6229438781738281, val_loss = 1.4099236726760864\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 1.6229 - categorical_accuracy: 0.4181 - val_loss: 1.4099 - val_categorical_accuracy: 0.5450\n",
      "Epoch 20/50\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 1.5351 - categorical_accuracy: 0.4568Epoch 20: loss = 1.5124268531799316, val_loss = 1.2669038772583008\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 1.5124 - categorical_accuracy: 0.4631 - val_loss: 1.2669 - val_categorical_accuracy: 0.6021\n",
      "Epoch 21/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 1.4691 - categorical_accuracy: 0.4803Epoch 21: loss = 1.472703456878662, val_loss = 1.241780400276184\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.4727 - categorical_accuracy: 0.4752 - val_loss: 1.2418 - val_categorical_accuracy: 0.5846\n",
      "Epoch 22/50\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 1.4840 - categorical_accuracy: 0.4494Epoch 22: loss = 1.4703497886657715, val_loss = 1.1663715839385986\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 1.4703 - categorical_accuracy: 0.4593 - val_loss: 1.1664 - val_categorical_accuracy: 0.6250\n",
      "Epoch 23/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.3839 - categorical_accuracy: 0.5145Epoch 23: loss = 1.382907748222351, val_loss = 1.2070425748825073\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 1.3829 - categorical_accuracy: 0.5149 - val_loss: 1.2070 - val_categorical_accuracy: 0.5945\n",
      "Epoch 24/50\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 1.3809 - categorical_accuracy: 0.4964Epoch 24: loss = 1.3733220100402832, val_loss = 1.1935189962387085\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 1.3733 - categorical_accuracy: 0.5011 - val_loss: 1.1935 - val_categorical_accuracy: 0.5960\n",
      "Epoch 25/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.4063 - categorical_accuracy: 0.4726Epoch 25: loss = 1.4065955877304077, val_loss = 1.0923967361450195\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 1.4066 - categorical_accuracy: 0.4722 - val_loss: 1.0924 - val_categorical_accuracy: 0.6319\n",
      "Epoch 26/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.2815 - categorical_accuracy: 0.5305Epoch 26: loss = 1.282177448272705, val_loss = 1.1062207221984863\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 1.2822 - categorical_accuracy: 0.5301 - val_loss: 1.1062 - val_categorical_accuracy: 0.6014\n",
      "Epoch 27/50\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 1.2774 - categorical_accuracy: 0.5349Epoch 27: loss = 1.2727007865905762, val_loss = 1.0792484283447266\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 1.2727 - categorical_accuracy: 0.5385 - val_loss: 1.0792 - val_categorical_accuracy: 0.6288\n",
      "Epoch 28/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 1.2357 - categorical_accuracy: 0.5561Epoch 28: loss = 1.2372313737869263, val_loss = 1.0932371616363525\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.2372 - categorical_accuracy: 0.5514 - val_loss: 1.0932 - val_categorical_accuracy: 0.6052\n",
      "Epoch 29/50\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 1.2997 - categorical_accuracy: 0.5110Epoch 29: loss = 1.2727839946746826, val_loss = 1.0289384126663208\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 1.2728 - categorical_accuracy: 0.5278 - val_loss: 1.0289 - val_categorical_accuracy: 0.6349\n",
      "Epoch 30/50\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 1.2048 - categorical_accuracy: 0.5530Epoch 30: loss = 1.1967170238494873, val_loss = 1.0363906621932983\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 1.1967 - categorical_accuracy: 0.5628 - val_loss: 1.0364 - val_categorical_accuracy: 0.6143\n",
      "Epoch 31/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 1.1553 - categorical_accuracy: 0.5674Epoch 31: loss = 1.1380671262741089, val_loss = 1.039970874786377\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.1381 - categorical_accuracy: 0.5765 - val_loss: 1.0400 - val_categorical_accuracy: 0.6204\n",
      "Epoch 32/50\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 1.1650 - categorical_accuracy: 0.5836Epoch 32: loss = 1.1559135913848877, val_loss = 1.1765329837799072\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 1.1559 - categorical_accuracy: 0.5872 - val_loss: 1.1765 - val_categorical_accuracy: 0.5831\n",
      "Epoch 33/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.6127 - categorical_accuracy: 0.4733Epoch 33: loss = 1.6129400730133057, val_loss = 1.4152971506118774\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.6129 - categorical_accuracy: 0.4730 - val_loss: 1.4153 - val_categorical_accuracy: 0.5114\n",
      "Epoch 34/50\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 1.4954 - categorical_accuracy: 0.4733Restoring model weights from the end of the best epoch: 29.\n",
      "Epoch 34: loss = 1.497955322265625, val_loss = 1.2867687940597534\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 1.4980 - categorical_accuracy: 0.4646 - val_loss: 1.2868 - val_categorical_accuracy: 0.5419\n",
      "Epoch 34: early stopping\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 1.0289 - categorical_accuracy: 0.6349\n",
      "Epoch 1/50\n",
      "33/41 [=======================>......] - ETA: 0s - loss: 3.2363 - categorical_accuracy: 0.0417Epoch 1: loss = 3.228616952896118, val_loss = 3.188129186630249\n",
      "41/41 [==============================] - 2s 15ms/step - loss: 3.2286 - categorical_accuracy: 0.0427 - val_loss: 3.1881 - val_categorical_accuracy: 0.1036\n",
      "Epoch 2/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 3.1329 - categorical_accuracy: 0.0781Epoch 2: loss = 3.1296777725219727, val_loss = 3.1012368202209473\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 3.1297 - categorical_accuracy: 0.0785 - val_loss: 3.1012 - val_categorical_accuracy: 0.1081\n",
      "Epoch 3/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 3.0165 - categorical_accuracy: 0.1106Epoch 3: loss = 3.0104434490203857, val_loss = 2.9540514945983887\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 3.0104 - categorical_accuracy: 0.1128 - val_loss: 2.9541 - val_categorical_accuracy: 0.1112\n",
      "Epoch 4/50\n",
      "34/41 [=======================>......] - ETA: 0s - loss: 2.8740 - categorical_accuracy: 0.1314Epoch 4: loss = 2.86335825920105, val_loss = 2.772634506225586\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 2.8634 - categorical_accuracy: 0.1380 - val_loss: 2.7726 - val_categorical_accuracy: 0.1219\n",
      "Epoch 5/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 2.6868 - categorical_accuracy: 0.1493Epoch 5: loss = 2.683448553085327, val_loss = 2.601383686065674\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 2.6834 - categorical_accuracy: 0.1509 - val_loss: 2.6014 - val_categorical_accuracy: 0.1637\n",
      "Epoch 6/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 2.5217 - categorical_accuracy: 0.1698Epoch 6: loss = 2.518427848815918, val_loss = 2.433424472808838\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 2.5184 - categorical_accuracy: 0.1753 - val_loss: 2.4334 - val_categorical_accuracy: 0.2216\n",
      "Epoch 7/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 2.4602 - categorical_accuracy: 0.1835Epoch 7: loss = 2.4591891765594482, val_loss = 2.304166078567505\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 2.4592 - categorical_accuracy: 0.1822 - val_loss: 2.3042 - val_categorical_accuracy: 0.2529\n",
      "Epoch 8/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 2.2870 - categorical_accuracy: 0.2340Epoch 8: loss = 2.293854236602783, val_loss = 2.171062469482422\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 2.2939 - categorical_accuracy: 0.2294 - val_loss: 2.1711 - val_categorical_accuracy: 0.2925\n",
      "Epoch 9/50\n",
      "34/41 [=======================>......] - ETA: 0s - loss: 2.2183 - categorical_accuracy: 0.2528Epoch 9: loss = 2.2070059776306152, val_loss = 2.0918402671813965\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 2.2070 - categorical_accuracy: 0.2515 - val_loss: 2.0918 - val_categorical_accuracy: 0.3130\n",
      "Epoch 10/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 2.1339 - categorical_accuracy: 0.2559Epoch 10: loss = 2.13044810295105, val_loss = 2.0055994987487793\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 2.1304 - categorical_accuracy: 0.2584 - val_loss: 2.0056 - val_categorical_accuracy: 0.3496\n",
      "Epoch 11/50\n",
      "33/41 [=======================>......] - ETA: 0s - loss: 2.0509 - categorical_accuracy: 0.3049Epoch 11: loss = 2.0498404502868652, val_loss = 1.9197032451629639\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 2.0498 - categorical_accuracy: 0.3049 - val_loss: 1.9197 - val_categorical_accuracy: 0.3778\n",
      "Epoch 12/50\n",
      "33/41 [=======================>......] - ETA: 0s - loss: 1.9889 - categorical_accuracy: 0.3106Epoch 12: loss = 1.9836581945419312, val_loss = 1.8908393383026123\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.9837 - categorical_accuracy: 0.2988 - val_loss: 1.8908 - val_categorical_accuracy: 0.3351\n",
      "Epoch 13/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.9082 - categorical_accuracy: 0.3378Epoch 13: loss = 1.9280983209609985, val_loss = 1.7333403825759888\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.9281 - categorical_accuracy: 0.3316 - val_loss: 1.7333 - val_categorical_accuracy: 0.4219\n",
      "Epoch 14/50\n",
      "34/41 [=======================>......] - ETA: 0s - loss: 1.8967 - categorical_accuracy: 0.3327Epoch 14: loss = 1.8881579637527466, val_loss = 1.685166597366333\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.8882 - categorical_accuracy: 0.3277 - val_loss: 1.6852 - val_categorical_accuracy: 0.4120\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.8321 - categorical_accuracy: 0.3369Epoch 15: loss = 1.8320560455322266, val_loss = 1.663365364074707\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.8321 - categorical_accuracy: 0.3369 - val_loss: 1.6634 - val_categorical_accuracy: 0.4097\n",
      "Epoch 16/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.7754 - categorical_accuracy: 0.3438Epoch 16: loss = 1.7632761001586914, val_loss = 1.6556646823883057\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.7633 - categorical_accuracy: 0.3521 - val_loss: 1.6557 - val_categorical_accuracy: 0.4128\n",
      "Epoch 17/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 1.7823 - categorical_accuracy: 0.3594Epoch 17: loss = 1.7755863666534424, val_loss = 1.632445216178894\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.7756 - categorical_accuracy: 0.3636 - val_loss: 1.6324 - val_categorical_accuracy: 0.4204\n",
      "Epoch 18/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.6811 - categorical_accuracy: 0.4003Epoch 18: loss = 1.6859227418899536, val_loss = 1.5827908515930176\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.6859 - categorical_accuracy: 0.3963 - val_loss: 1.5828 - val_categorical_accuracy: 0.4417\n",
      "Epoch 19/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.7087 - categorical_accuracy: 0.3792Epoch 19: loss = 1.700256109237671, val_loss = 1.5232343673706055\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 1.7003 - categorical_accuracy: 0.3773 - val_loss: 1.5232 - val_categorical_accuracy: 0.4562\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.6371 - categorical_accuracy: 0.3758Epoch 20: loss = 1.6371450424194336, val_loss = 1.5865756273269653\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 1.6371 - categorical_accuracy: 0.3758 - val_loss: 1.5866 - val_categorical_accuracy: 0.4440\n",
      "Epoch 21/50\n",
      "34/41 [=======================>......] - ETA: 0s - loss: 1.6363 - categorical_accuracy: 0.4017Epoch 21: loss = 1.6514865159988403, val_loss = 1.4573025703430176\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.6515 - categorical_accuracy: 0.3895 - val_loss: 1.4573 - val_categorical_accuracy: 0.4745\n",
      "Epoch 22/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.6232 - categorical_accuracy: 0.3885Epoch 22: loss = 1.6176913976669312, val_loss = 1.4890621900558472\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.6177 - categorical_accuracy: 0.3925 - val_loss: 1.4891 - val_categorical_accuracy: 0.4570\n",
      "Epoch 23/50\n",
      "34/41 [=======================>......] - ETA: 0s - loss: 1.5698 - categorical_accuracy: 0.4053Epoch 23: loss = 1.5709654092788696, val_loss = 1.4530398845672607\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.5710 - categorical_accuracy: 0.4078 - val_loss: 1.4530 - val_categorical_accuracy: 0.4669\n",
      "Epoch 24/50\n",
      "34/41 [=======================>......] - ETA: 0s - loss: 1.5024 - categorical_accuracy: 0.4449Epoch 24: loss = 1.5048162937164307, val_loss = 1.465689778327942\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.5048 - categorical_accuracy: 0.4398 - val_loss: 1.4657 - val_categorical_accuracy: 0.4707\n",
      "Epoch 25/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.5064 - categorical_accuracy: 0.4358Epoch 25: loss = 1.5232059955596924, val_loss = 1.5127769708633423\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.5232 - categorical_accuracy: 0.4314 - val_loss: 1.5128 - val_categorical_accuracy: 0.4196\n",
      "Epoch 26/50\n",
      "34/41 [=======================>......] - ETA: 0s - loss: 1.5629 - categorical_accuracy: 0.4283Epoch 26: loss = 1.550883412361145, val_loss = 1.5140366554260254\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.5509 - categorical_accuracy: 0.4314 - val_loss: 1.5140 - val_categorical_accuracy: 0.4296\n",
      "Epoch 27/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.5237 - categorical_accuracy: 0.4271Epoch 27: loss = 1.5212448835372925, val_loss = 1.463570475578308\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.5212 - categorical_accuracy: 0.4261 - val_loss: 1.4636 - val_categorical_accuracy: 0.4341\n",
      "Epoch 28/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.4573 - categorical_accuracy: 0.4409Epoch 28: loss = 1.4545445442199707, val_loss = 1.3662117719650269\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.4545 - categorical_accuracy: 0.4375 - val_loss: 1.3662 - val_categorical_accuracy: 0.4943\n",
      "Epoch 29/50\n",
      "33/41 [=======================>......] - ETA: 0s - loss: 1.4317 - categorical_accuracy: 0.4441Epoch 29: loss = 1.447780966758728, val_loss = 1.3559603691101074\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.4478 - categorical_accuracy: 0.4428 - val_loss: 1.3560 - val_categorical_accuracy: 0.5004\n",
      "Epoch 30/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.4454 - categorical_accuracy: 0.4485Epoch 30: loss = 1.4436914920806885, val_loss = 1.3846036195755005\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.4437 - categorical_accuracy: 0.4535 - val_loss: 1.3846 - val_categorical_accuracy: 0.4730\n",
      "Epoch 31/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.4012 - categorical_accuracy: 0.4713Epoch 31: loss = 1.4043079614639282, val_loss = 1.3995397090911865\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.4043 - categorical_accuracy: 0.4672 - val_loss: 1.3995 - val_categorical_accuracy: 0.4760\n",
      "Epoch 32/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.3779 - categorical_accuracy: 0.4766Epoch 32: loss = 1.3793567419052124, val_loss = 1.3007677793502808\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 1.3794 - categorical_accuracy: 0.4756 - val_loss: 1.3008 - val_categorical_accuracy: 0.5293\n",
      "Epoch 33/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.3525 - categorical_accuracy: 0.4856Epoch 33: loss = 1.3489701747894287, val_loss = 1.2590008974075317\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.3490 - categorical_accuracy: 0.4878 - val_loss: 1.2590 - val_categorical_accuracy: 0.5491\n",
      "Epoch 34/50\n",
      "34/41 [=======================>......] - ETA: 0s - loss: 1.3496 - categorical_accuracy: 0.4743Epoch 34: loss = 1.3622361421585083, val_loss = 1.2586275339126587\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.3622 - categorical_accuracy: 0.4680 - val_loss: 1.2586 - val_categorical_accuracy: 0.5476\n",
      "Epoch 35/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.3961 - categorical_accuracy: 0.4696Epoch 35: loss = 1.3947856426239014, val_loss = 1.269317626953125\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.3948 - categorical_accuracy: 0.4688 - val_loss: 1.2693 - val_categorical_accuracy: 0.5369\n",
      "Epoch 36/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.3707 - categorical_accuracy: 0.4823Epoch 36: loss = 1.3621286153793335, val_loss = 1.3722788095474243\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.3621 - categorical_accuracy: 0.4809 - val_loss: 1.3723 - val_categorical_accuracy: 0.4653\n",
      "Epoch 37/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 1.3105 - categorical_accuracy: 0.5000Epoch 37: loss = 1.3175370693206787, val_loss = 1.2615381479263306\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.3175 - categorical_accuracy: 0.4947 - val_loss: 1.2615 - val_categorical_accuracy: 0.5446\n",
      "Epoch 38/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 1.3044 - categorical_accuracy: 0.4957Epoch 38: loss = 1.316915512084961, val_loss = 1.2395436763763428\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.3169 - categorical_accuracy: 0.4878 - val_loss: 1.2395 - val_categorical_accuracy: 0.5522\n",
      "Epoch 39/50\n",
      "33/41 [=======================>......] - ETA: 0s - loss: 1.3107 - categorical_accuracy: 0.5170Epoch 39: loss = 1.3087395429611206, val_loss = 1.2642130851745605\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.3087 - categorical_accuracy: 0.5084 - val_loss: 1.2642 - val_categorical_accuracy: 0.5324\n",
      "Epoch 40/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.2496 - categorical_accuracy: 0.5270Epoch 40: loss = 1.2441174983978271, val_loss = 1.4660788774490356\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.2441 - categorical_accuracy: 0.5320 - val_loss: 1.4661 - val_categorical_accuracy: 0.4410\n",
      "Epoch 41/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.3054 - categorical_accuracy: 0.5266Epoch 41: loss = 1.3006033897399902, val_loss = 1.1641249656677246\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 1.3006 - categorical_accuracy: 0.5290 - val_loss: 1.1641 - val_categorical_accuracy: 0.5834\n",
      "Epoch 42/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 1.2354 - categorical_accuracy: 0.5365Epoch 42: loss = 1.2580326795578003, val_loss = 1.2091842889785767\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.2580 - categorical_accuracy: 0.5305 - val_loss: 1.2092 - val_categorical_accuracy: 0.5758\n",
      "Epoch 43/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.2564 - categorical_accuracy: 0.5296Epoch 43: loss = 1.2631274461746216, val_loss = 1.1040418148040771\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.2631 - categorical_accuracy: 0.5274 - val_loss: 1.1040 - val_categorical_accuracy: 0.6154\n",
      "Epoch 44/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.2531 - categorical_accuracy: 0.5414Epoch 44: loss = 1.2618447542190552, val_loss = 1.096335530281067\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.2618 - categorical_accuracy: 0.5389 - val_loss: 1.0963 - val_categorical_accuracy: 0.6161\n",
      "Epoch 45/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.2233 - categorical_accuracy: 0.5457Epoch 45: loss = 1.2161835432052612, val_loss = 1.225258708000183\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.2162 - categorical_accuracy: 0.5473 - val_loss: 1.2253 - val_categorical_accuracy: 0.5240\n",
      "Epoch 46/50\n",
      "33/41 [=======================>......] - ETA: 0s - loss: 1.2531 - categorical_accuracy: 0.5473Epoch 46: loss = 1.272592306137085, val_loss = 1.2633123397827148\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.2726 - categorical_accuracy: 0.5343 - val_loss: 1.2633 - val_categorical_accuracy: 0.5232\n",
      "Epoch 47/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 1.2105 - categorical_accuracy: 0.5443Epoch 47: loss = 1.2073001861572266, val_loss = 1.1786141395568848\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 1.2073 - categorical_accuracy: 0.5442 - val_loss: 1.1786 - val_categorical_accuracy: 0.5583\n",
      "Epoch 48/50\n",
      "34/41 [=======================>......] - ETA: 0s - loss: 1.1694 - categorical_accuracy: 0.5708Epoch 48: loss = 1.1445326805114746, val_loss = 1.1469478607177734\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.1445 - categorical_accuracy: 0.5770 - val_loss: 1.1469 - val_categorical_accuracy: 0.5377\n",
      "Epoch 49/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 1.1688 - categorical_accuracy: 0.5556Restoring model weights from the end of the best epoch: 44.\n",
      "Epoch 49: loss = 1.16366708278656, val_loss = 1.191078782081604\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.1637 - categorical_accuracy: 0.5587 - val_loss: 1.1911 - val_categorical_accuracy: 0.5857\n",
      "Epoch 49: early stopping\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.0963 - categorical_accuracy: 0.6161\n",
      "Epoch 1/50\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 3.2478 - categorical_accuracy: 0.0498Epoch 1: loss = 3.2437236309051514, val_loss = 3.19547700881958\n",
      "42/42 [==============================] - 2s 16ms/step - loss: 3.2437 - categorical_accuracy: 0.0487 - val_loss: 3.1955 - val_categorical_accuracy: 0.0686\n",
      "Epoch 2/50\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 3.1661 - categorical_accuracy: 0.0579Epoch 2: loss = 3.1566121578216553, val_loss = 3.050442695617676\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 3.1566 - categorical_accuracy: 0.0632 - val_loss: 3.0504 - val_categorical_accuracy: 0.0518\n",
      "Epoch 3/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 3.0682 - categorical_accuracy: 0.0648Epoch 3: loss = 3.068413019180298, val_loss = 2.9936487674713135\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 3.0684 - categorical_accuracy: 0.0647 - val_loss: 2.9936 - val_categorical_accuracy: 0.1159\n",
      "Epoch 4/50\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 3.0017 - categorical_accuracy: 0.0800Epoch 4: loss = 2.9983317852020264, val_loss = 2.9252824783325195\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 2.9983 - categorical_accuracy: 0.0815 - val_loss: 2.9253 - val_categorical_accuracy: 0.0892\n",
      "Epoch 5/50\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 2.9619 - categorical_accuracy: 0.0997Epoch 5: loss = 2.9564168453216553, val_loss = 2.876267671585083\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 2.9564 - categorical_accuracy: 0.0967 - val_loss: 2.8763 - val_categorical_accuracy: 0.0838\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.9086 - categorical_accuracy: 0.0982Epoch 6: loss = 2.9085769653320312, val_loss = 2.846588373184204\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 2.9086 - categorical_accuracy: 0.0982 - val_loss: 2.8466 - val_categorical_accuracy: 0.0777\n",
      "Epoch 7/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.9110 - categorical_accuracy: 0.1021Epoch 7: loss = 2.911166191101074, val_loss = 2.860123872756958\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 2.9112 - categorical_accuracy: 0.1021 - val_loss: 2.8601 - val_categorical_accuracy: 0.0991\n",
      "Epoch 8/50\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 2.8865 - categorical_accuracy: 0.0825Epoch 8: loss = 2.874697685241699, val_loss = 2.8457424640655518\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 2.8747 - categorical_accuracy: 0.0853 - val_loss: 2.8457 - val_categorical_accuracy: 0.1098\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.8322 - categorical_accuracy: 0.1234Epoch 9: loss = 2.832176685333252, val_loss = 2.779667854309082\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 2.8322 - categorical_accuracy: 0.1234 - val_loss: 2.7797 - val_categorical_accuracy: 0.1204\n",
      "Epoch 10/50\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 2.8260 - categorical_accuracy: 0.1170Epoch 10: loss = 2.8199639320373535, val_loss = 2.8046419620513916\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 2.8200 - categorical_accuracy: 0.1165 - val_loss: 2.8046 - val_categorical_accuracy: 0.1357\n",
      "Epoch 11/50\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 2.8038 - categorical_accuracy: 0.1170Epoch 11: loss = 2.803406238555908, val_loss = 2.7607944011688232\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 2.8034 - categorical_accuracy: 0.1196 - val_loss: 2.7608 - val_categorical_accuracy: 0.1395\n",
      "Epoch 12/50\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 2.7699 - categorical_accuracy: 0.1208Epoch 12: loss = 2.768433094024658, val_loss = 2.703162908554077\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 2.7684 - categorical_accuracy: 0.1272 - val_loss: 2.7032 - val_categorical_accuracy: 0.1532\n",
      "Epoch 13/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.7292 - categorical_accuracy: 0.1418Epoch 13: loss = 2.729426622390747, val_loss = 2.673562526702881\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 2.7294 - categorical_accuracy: 0.1417 - val_loss: 2.6736 - val_categorical_accuracy: 0.1524\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.7013 - categorical_accuracy: 0.1333Epoch 14: loss = 2.7013063430786133, val_loss = 2.620227813720703\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 2.7013 - categorical_accuracy: 0.1333 - val_loss: 2.6202 - val_categorical_accuracy: 0.1410\n",
      "Epoch 15/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 2.6429 - categorical_accuracy: 0.1390Epoch 15: loss = 2.6489639282226562, val_loss = 2.901179075241089\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 2.6490 - categorical_accuracy: 0.1379 - val_loss: 2.9012 - val_categorical_accuracy: 0.0930\n",
      "Epoch 16/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 3.0174 - categorical_accuracy: 0.0921Epoch 16: loss = 2.9935262203216553, val_loss = 2.6239497661590576\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 2.9935 - categorical_accuracy: 0.0960 - val_loss: 2.6239 - val_categorical_accuracy: 0.1280\n",
      "Epoch 17/50\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 2.6404 - categorical_accuracy: 0.1402Epoch 17: loss = 2.6405861377716064, val_loss = 2.6000444889068604\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 2.6406 - categorical_accuracy: 0.1356 - val_loss: 2.6000 - val_categorical_accuracy: 0.1616\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.5888 - categorical_accuracy: 0.1455Epoch 18: loss = 2.5888447761535645, val_loss = 2.558781623840332\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 2.5888 - categorical_accuracy: 0.1455 - val_loss: 2.5588 - val_categorical_accuracy: 0.1608\n",
      "Epoch 19/50\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 2.5614 - categorical_accuracy: 0.1384Epoch 19: loss = 2.5666797161102295, val_loss = 2.5447070598602295\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 2.5667 - categorical_accuracy: 0.1318 - val_loss: 2.5447 - val_categorical_accuracy: 0.1646\n",
      "Epoch 20/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.5122 - categorical_accuracy: 0.1593Epoch 20: loss = 2.5125041007995605, val_loss = 2.5558974742889404\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 2.5125 - categorical_accuracy: 0.1592 - val_loss: 2.5559 - val_categorical_accuracy: 0.1395\n",
      "Epoch 21/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.5100 - categorical_accuracy: 0.1609Epoch 21: loss = 2.5128753185272217, val_loss = 2.4812302589416504\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 2.5129 - categorical_accuracy: 0.1599 - val_loss: 2.4812 - val_categorical_accuracy: 0.1806\n",
      "Epoch 22/50\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 2.4701 - categorical_accuracy: 0.1618Epoch 22: loss = 2.4640023708343506, val_loss = 2.4825892448425293\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 2.4640 - categorical_accuracy: 0.1637 - val_loss: 2.4826 - val_categorical_accuracy: 0.1662\n",
      "Epoch 23/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.4649 - categorical_accuracy: 0.1532Epoch 23: loss = 2.464963436126709, val_loss = 2.443176746368408\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 2.4650 - categorical_accuracy: 0.1531 - val_loss: 2.4432 - val_categorical_accuracy: 0.1715\n",
      "Epoch 24/50\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 2.4138 - categorical_accuracy: 0.1714Epoch 24: loss = 2.418168783187866, val_loss = 2.452920436859131\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 2.4182 - categorical_accuracy: 0.1721 - val_loss: 2.4529 - val_categorical_accuracy: 0.1654\n",
      "Epoch 25/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 2.4268 - categorical_accuracy: 0.1675Epoch 25: loss = 2.4345967769622803, val_loss = 2.4251580238342285\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 2.4346 - categorical_accuracy: 0.1630 - val_loss: 2.4252 - val_categorical_accuracy: 0.1799\n",
      "Epoch 26/50\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 2.4061 - categorical_accuracy: 0.1719Epoch 26: loss = 2.3959906101226807, val_loss = 2.4370224475860596\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 2.3960 - categorical_accuracy: 0.1706 - val_loss: 2.4370 - val_categorical_accuracy: 0.1639\n",
      "Epoch 27/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.3743 - categorical_accuracy: 0.1791Epoch 27: loss = 2.3743703365325928, val_loss = 2.4046711921691895\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 2.3744 - categorical_accuracy: 0.1790 - val_loss: 2.4047 - val_categorical_accuracy: 0.1502\n",
      "Epoch 28/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.3516 - categorical_accuracy: 0.1829Epoch 28: loss = 2.350160598754883, val_loss = 2.3446576595306396\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 2.3502 - categorical_accuracy: 0.1835 - val_loss: 2.3447 - val_categorical_accuracy: 0.1905\n",
      "Epoch 29/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 2.3638 - categorical_accuracy: 0.1851Epoch 29: loss = 2.3619959354400635, val_loss = 2.355152130126953\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 2.3620 - categorical_accuracy: 0.1874 - val_loss: 2.3552 - val_categorical_accuracy: 0.1761\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.3102 - categorical_accuracy: 0.2026Epoch 30: loss = 2.3101894855499268, val_loss = 2.2997353076934814\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 2.3102 - categorical_accuracy: 0.2026 - val_loss: 2.2997 - val_categorical_accuracy: 0.2127\n",
      "Epoch 31/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.3110 - categorical_accuracy: 0.2012Epoch 31: loss = 2.311452865600586, val_loss = 2.349961519241333\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 2.3115 - categorical_accuracy: 0.2011 - val_loss: 2.3500 - val_categorical_accuracy: 0.1784\n",
      "Epoch 32/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.2747 - categorical_accuracy: 0.2066Epoch 32: loss = 2.274580955505371, val_loss = 2.3495943546295166\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 2.2746 - categorical_accuracy: 0.2072 - val_loss: 2.3496 - val_categorical_accuracy: 0.1669\n",
      "Epoch 33/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 2.2647 - categorical_accuracy: 0.2171Epoch 33: loss = 2.263953924179077, val_loss = 2.492542266845703\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 2.2640 - categorical_accuracy: 0.2171 - val_loss: 2.4925 - val_categorical_accuracy: 0.1189\n",
      "Epoch 34/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.2765 - categorical_accuracy: 0.2210Epoch 34: loss = 2.2757980823516846, val_loss = 2.253005027770996\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 2.2758 - categorical_accuracy: 0.2209 - val_loss: 2.2530 - val_categorical_accuracy: 0.2309\n",
      "Epoch 35/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.2387 - categorical_accuracy: 0.2119Epoch 35: loss = 2.2389025688171387, val_loss = 2.226630687713623\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 2.2389 - categorical_accuracy: 0.2125 - val_loss: 2.2266 - val_categorical_accuracy: 0.2210\n",
      "Epoch 36/50\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 2.1957 - categorical_accuracy: 0.2080Epoch 36: loss = 2.211350679397583, val_loss = 2.251354455947876\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 2.2114 - categorical_accuracy: 0.2018 - val_loss: 2.2514 - val_categorical_accuracy: 0.1951\n",
      "Epoch 37/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 2.2446 - categorical_accuracy: 0.2048Epoch 37: loss = 2.2408974170684814, val_loss = 2.2682201862335205\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 2.2409 - categorical_accuracy: 0.2064 - val_loss: 2.2682 - val_categorical_accuracy: 0.2149\n",
      "Epoch 38/50\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 2.2520 - categorical_accuracy: 0.2134Epoch 38: loss = 2.242286443710327, val_loss = 2.169738531112671\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 2.2423 - categorical_accuracy: 0.2163 - val_loss: 2.1697 - val_categorical_accuracy: 0.2691\n",
      "Epoch 39/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.2513 - categorical_accuracy: 0.2104Epoch 39: loss = 2.251436948776245, val_loss = 2.374732732772827\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 2.2514 - categorical_accuracy: 0.2102 - val_loss: 2.3747 - val_categorical_accuracy: 0.1547\n",
      "Epoch 40/50\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 2.2012 - categorical_accuracy: 0.2143Epoch 40: loss = 2.196960687637329, val_loss = 2.468998908996582\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 2.1970 - categorical_accuracy: 0.2148 - val_loss: 2.4690 - val_categorical_accuracy: 0.1395\n",
      "Epoch 41/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.1629 - categorical_accuracy: 0.2266Epoch 41: loss = 2.167311191558838, val_loss = 2.397135019302368\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 2.1673 - categorical_accuracy: 0.2262 - val_loss: 2.3971 - val_categorical_accuracy: 0.1524\n",
      "Epoch 42/50\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 2.1642 - categorical_accuracy: 0.2408Epoch 42: loss = 2.1528074741363525, val_loss = 2.614420175552368\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 2.1528 - categorical_accuracy: 0.2422 - val_loss: 2.6144 - val_categorical_accuracy: 0.1044\n",
      "Epoch 43/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 2.2547 - categorical_accuracy: 0.2220Restoring model weights from the end of the best epoch: 38.\n",
      "Epoch 43: loss = 2.2494590282440186, val_loss = 2.289541006088257\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 2.2495 - categorical_accuracy: 0.2232 - val_loss: 2.2895 - val_categorical_accuracy: 0.2005\n",
      "Epoch 43: early stopping\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2.1697 - categorical_accuracy: 0.2691\n",
      "Epoch 1/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 2.9702 - categorical_accuracy: 0.0910Epoch 1: loss = 2.9559454917907715, val_loss = 2.65877628326416\n",
      "82/82 [==============================] - 2s 10ms/step - loss: 2.9559 - categorical_accuracy: 0.0922 - val_loss: 2.6588 - val_categorical_accuracy: 0.1059\n",
      "Epoch 2/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 2.4729 - categorical_accuracy: 0.1828Epoch 2: loss = 2.4722049236297607, val_loss = 2.1936163902282715\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 2.4722 - categorical_accuracy: 0.1822 - val_loss: 2.1936 - val_categorical_accuracy: 0.2399\n",
      "Epoch 3/50\n",
      "74/82 [==========================>...] - ETA: 0s - loss: 2.0278 - categorical_accuracy: 0.3117Epoch 3: loss = 2.0101442337036133, val_loss = 1.837288498878479\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 2.0101 - categorical_accuracy: 0.3110 - val_loss: 1.8373 - val_categorical_accuracy: 0.3199\n",
      "Epoch 4/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 1.6941 - categorical_accuracy: 0.4140Epoch 4: loss = 1.6817030906677246, val_loss = 1.4782177209854126\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 1.6817 - categorical_accuracy: 0.4146 - val_loss: 1.4782 - val_categorical_accuracy: 0.4935\n",
      "Epoch 5/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 1.4729 - categorical_accuracy: 0.4825Epoch 5: loss = 1.4697588682174683, val_loss = 1.3772798776626587\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 1.4698 - categorical_accuracy: 0.4817 - val_loss: 1.3773 - val_categorical_accuracy: 0.5400\n",
      "Epoch 6/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.3472 - categorical_accuracy: 0.5086Epoch 6: loss = 1.352049469947815, val_loss = 1.212942361831665\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 1.3520 - categorical_accuracy: 0.5069 - val_loss: 1.2129 - val_categorical_accuracy: 0.5743\n",
      "Epoch 7/50\n",
      "74/82 [==========================>...] - ETA: 0s - loss: 1.1957 - categorical_accuracy: 0.5617Epoch 7: loss = 1.1897677183151245, val_loss = 1.0479209423065186\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 1.1898 - categorical_accuracy: 0.5724 - val_loss: 1.0479 - val_categorical_accuracy: 0.6359\n",
      "Epoch 8/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.0605 - categorical_accuracy: 0.6157Epoch 8: loss = 1.0604509115219116, val_loss = 1.072306752204895\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 1.0605 - categorical_accuracy: 0.6159 - val_loss: 1.0723 - val_categorical_accuracy: 0.6108\n",
      "Epoch 9/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 1.0468 - categorical_accuracy: 0.6131Epoch 9: loss = 1.0481584072113037, val_loss = 0.9941187500953674\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 1.0482 - categorical_accuracy: 0.6098 - val_loss: 0.9941 - val_categorical_accuracy: 0.6299\n",
      "Epoch 10/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 0.9820 - categorical_accuracy: 0.6404Epoch 10: loss = 0.9746350646018982, val_loss = 0.9136461615562439\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.9746 - categorical_accuracy: 0.6418 - val_loss: 0.9136 - val_categorical_accuracy: 0.6664\n",
      "Epoch 11/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8895 - categorical_accuracy: 0.6723Epoch 11: loss = 0.8894504308700562, val_loss = 0.8354699611663818\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.8895 - categorical_accuracy: 0.6723 - val_loss: 0.8355 - val_categorical_accuracy: 0.7136\n",
      "Epoch 12/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.8323 - categorical_accuracy: 0.6953Epoch 12: loss = 0.8420766592025757, val_loss = 0.7416626811027527\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.8421 - categorical_accuracy: 0.6898 - val_loss: 0.7417 - val_categorical_accuracy: 0.7456\n",
      "Epoch 13/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.8027 - categorical_accuracy: 0.7055Epoch 13: loss = 0.8063772916793823, val_loss = 0.7472286224365234\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.8064 - categorical_accuracy: 0.7035 - val_loss: 0.7472 - val_categorical_accuracy: 0.7570\n",
      "Epoch 14/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.7831 - categorical_accuracy: 0.7196Epoch 14: loss = 0.7779948711395264, val_loss = 0.745680570602417\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.7780 - categorical_accuracy: 0.7203 - val_loss: 0.7457 - val_categorical_accuracy: 0.7220\n",
      "Epoch 15/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 0.7429 - categorical_accuracy: 0.7191Epoch 15: loss = 0.7436695694923401, val_loss = 0.6973859667778015\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.7437 - categorical_accuracy: 0.7195 - val_loss: 0.6974 - val_categorical_accuracy: 0.7433\n",
      "Epoch 16/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.6519 - categorical_accuracy: 0.7631Epoch 16: loss = 0.6483598947525024, val_loss = 0.7500993609428406\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.6484 - categorical_accuracy: 0.7630 - val_loss: 0.7501 - val_categorical_accuracy: 0.7388\n",
      "Epoch 17/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.6267 - categorical_accuracy: 0.7668Epoch 17: loss = 0.6193315386772156, val_loss = 0.5861891508102417\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.6193 - categorical_accuracy: 0.7698 - val_loss: 0.5862 - val_categorical_accuracy: 0.8096\n",
      "Epoch 18/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6581 - categorical_accuracy: 0.7538Epoch 18: loss = 0.6581070423126221, val_loss = 0.6198053956031799\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.6581 - categorical_accuracy: 0.7538 - val_loss: 0.6198 - val_categorical_accuracy: 0.7807\n",
      "Epoch 19/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.6185 - categorical_accuracy: 0.7654Epoch 19: loss = 0.6187317967414856, val_loss = 0.6884505152702332\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.6187 - categorical_accuracy: 0.7645 - val_loss: 0.6885 - val_categorical_accuracy: 0.7570\n",
      "Epoch 20/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.5752 - categorical_accuracy: 0.7805Epoch 20: loss = 0.5772114992141724, val_loss = 0.596290111541748\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.5772 - categorical_accuracy: 0.7790 - val_loss: 0.5963 - val_categorical_accuracy: 0.7883\n",
      "Epoch 21/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.5866 - categorical_accuracy: 0.7859Epoch 21: loss = 0.5833125114440918, val_loss = 0.5729563236236572\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.5833 - categorical_accuracy: 0.7858 - val_loss: 0.5730 - val_categorical_accuracy: 0.7867\n",
      "Epoch 22/50\n",
      "74/82 [==========================>...] - ETA: 0s - loss: 0.5180 - categorical_accuracy: 0.8142Epoch 22: loss = 0.536957859992981, val_loss = 0.5783485770225525\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.5370 - categorical_accuracy: 0.8087 - val_loss: 0.5783 - val_categorical_accuracy: 0.7989\n",
      "Epoch 23/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.5448 - categorical_accuracy: 0.7994Epoch 23: loss = 0.5429610013961792, val_loss = 0.5964691638946533\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.5430 - categorical_accuracy: 0.8003 - val_loss: 0.5965 - val_categorical_accuracy: 0.7875\n",
      "Epoch 24/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.4793 - categorical_accuracy: 0.8383Epoch 24: loss = 0.48132556676864624, val_loss = 0.538165271282196\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.4813 - categorical_accuracy: 0.8377 - val_loss: 0.5382 - val_categorical_accuracy: 0.8065\n",
      "Epoch 25/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.5173 - categorical_accuracy: 0.8039Epoch 25: loss = 0.5129565000534058, val_loss = 0.5074145197868347\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.5130 - categorical_accuracy: 0.8064 - val_loss: 0.5074 - val_categorical_accuracy: 0.8142\n",
      "Epoch 26/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 0.4600 - categorical_accuracy: 0.8296Epoch 26: loss = 0.453584760427475, val_loss = 0.48913294076919556\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.4536 - categorical_accuracy: 0.8300 - val_loss: 0.4891 - val_categorical_accuracy: 0.8294\n",
      "Epoch 27/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.4710 - categorical_accuracy: 0.8211Epoch 27: loss = 0.46816644072532654, val_loss = 0.473909854888916\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.4682 - categorical_accuracy: 0.8224 - val_loss: 0.4739 - val_categorical_accuracy: 0.8286\n",
      "Epoch 28/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 0.5715 - categorical_accuracy: 0.7927Epoch 28: loss = 0.5700644254684448, val_loss = 0.6223991513252258\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.5701 - categorical_accuracy: 0.7927 - val_loss: 0.6224 - val_categorical_accuracy: 0.7799\n",
      "Epoch 29/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 0.4836 - categorical_accuracy: 0.8142Epoch 29: loss = 0.4832373857498169, val_loss = 0.47945764660835266\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.4832 - categorical_accuracy: 0.8163 - val_loss: 0.4795 - val_categorical_accuracy: 0.8286\n",
      "Epoch 30/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.4000 - categorical_accuracy: 0.8480Epoch 30: loss = 0.39926204085350037, val_loss = 0.47820430994033813\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.3993 - categorical_accuracy: 0.8476 - val_loss: 0.4782 - val_categorical_accuracy: 0.8294\n",
      "Epoch 31/50\n",
      "74/82 [==========================>...] - ETA: 0s - loss: 0.3875 - categorical_accuracy: 0.8522Epoch 31: loss = 0.39069902896881104, val_loss = 0.47862640023231506\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.3907 - categorical_accuracy: 0.8506 - val_loss: 0.4786 - val_categorical_accuracy: 0.8347\n",
      "Epoch 32/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.3906 - categorical_accuracy: 0.8547Epoch 32: loss = 0.39332887530326843, val_loss = 0.47178924083709717\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.3933 - categorical_accuracy: 0.8544 - val_loss: 0.4718 - val_categorical_accuracy: 0.8149\n",
      "Epoch 33/50\n",
      "74/82 [==========================>...] - ETA: 0s - loss: 0.4332 - categorical_accuracy: 0.8345Epoch 33: loss = 0.43139341473579407, val_loss = 0.49116432666778564\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.4314 - categorical_accuracy: 0.8354 - val_loss: 0.4912 - val_categorical_accuracy: 0.8324\n",
      "Epoch 34/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.3798 - categorical_accuracy: 0.8573Epoch 34: loss = 0.37979087233543396, val_loss = 0.4168711006641388\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.3798 - categorical_accuracy: 0.8567 - val_loss: 0.4169 - val_categorical_accuracy: 0.8507\n",
      "Epoch 35/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.3970 - categorical_accuracy: 0.8550Epoch 35: loss = 0.3955349326133728, val_loss = 0.4642745852470398\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.3955 - categorical_accuracy: 0.8559 - val_loss: 0.4643 - val_categorical_accuracy: 0.8439\n",
      "Epoch 36/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 0.3603 - categorical_accuracy: 0.8750Epoch 36: loss = 0.3587392568588257, val_loss = 0.4789261817932129\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.3587 - categorical_accuracy: 0.8765 - val_loss: 0.4789 - val_categorical_accuracy: 0.8340\n",
      "Epoch 37/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.3227 - categorical_accuracy: 0.8789Epoch 37: loss = 0.32652440667152405, val_loss = 0.4521760940551758\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.3265 - categorical_accuracy: 0.8780 - val_loss: 0.4522 - val_categorical_accuracy: 0.8309\n",
      "Epoch 38/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 0.3526 - categorical_accuracy: 0.8647Epoch 38: loss = 0.35414931178092957, val_loss = 0.401309996843338\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.3541 - categorical_accuracy: 0.8636 - val_loss: 0.4013 - val_categorical_accuracy: 0.8705\n",
      "Epoch 39/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 0.3027 - categorical_accuracy: 0.8924Epoch 39: loss = 0.29893797636032104, val_loss = 0.4542587399482727\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.2989 - categorical_accuracy: 0.8941 - val_loss: 0.4543 - val_categorical_accuracy: 0.8462\n",
      "Epoch 40/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3323 - categorical_accuracy: 0.8636Epoch 40: loss = 0.3322795629501343, val_loss = 0.5757802724838257\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.3323 - categorical_accuracy: 0.8636 - val_loss: 0.5758 - val_categorical_accuracy: 0.8111\n",
      "Epoch 41/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 0.4128 - categorical_accuracy: 0.8497Epoch 41: loss = 0.4139076769351959, val_loss = 0.3974931836128235\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.4139 - categorical_accuracy: 0.8476 - val_loss: 0.3975 - val_categorical_accuracy: 0.8652\n",
      "Epoch 42/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.3762 - categorical_accuracy: 0.8495Epoch 42: loss = 0.37854403257369995, val_loss = 0.3898070454597473\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.3785 - categorical_accuracy: 0.8491 - val_loss: 0.3898 - val_categorical_accuracy: 0.8660\n",
      "Epoch 43/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.3444 - categorical_accuracy: 0.8654Epoch 43: loss = 0.3476501405239105, val_loss = 0.35581961274147034\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.3477 - categorical_accuracy: 0.8636 - val_loss: 0.3558 - val_categorical_accuracy: 0.8812\n",
      "Epoch 44/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.3369 - categorical_accuracy: 0.8686Epoch 44: loss = 0.33640387654304504, val_loss = 0.49608999490737915\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.3364 - categorical_accuracy: 0.8697 - val_loss: 0.4961 - val_categorical_accuracy: 0.8180\n",
      "Epoch 45/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.3647 - categorical_accuracy: 0.8644Epoch 45: loss = 0.3683730661869049, val_loss = 0.41687914729118347\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.3684 - categorical_accuracy: 0.8636 - val_loss: 0.4169 - val_categorical_accuracy: 0.8553\n",
      "Epoch 46/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.3110 - categorical_accuracy: 0.8798Epoch 46: loss = 0.30711692571640015, val_loss = 0.3533586859703064\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.3071 - categorical_accuracy: 0.8819 - val_loss: 0.3534 - val_categorical_accuracy: 0.8736\n",
      "Epoch 47/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3057 - categorical_accuracy: 0.8826Epoch 47: loss = 0.3057499825954437, val_loss = 0.39242032170295715\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.3057 - categorical_accuracy: 0.8826 - val_loss: 0.3924 - val_categorical_accuracy: 0.8629\n",
      "Epoch 48/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.3019 - categorical_accuracy: 0.8856Epoch 48: loss = 0.29856523871421814, val_loss = 0.42792195081710815\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.2986 - categorical_accuracy: 0.8872 - val_loss: 0.4279 - val_categorical_accuracy: 0.8439\n",
      "Epoch 49/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.2565 - categorical_accuracy: 0.9008Epoch 49: loss = 0.25438907742500305, val_loss = 0.28550952672958374\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.2544 - categorical_accuracy: 0.9009 - val_loss: 0.2855 - val_categorical_accuracy: 0.9040\n",
      "Epoch 50/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.2602 - categorical_accuracy: 0.8969Epoch 50: loss = 0.26018160581588745, val_loss = 0.30343571305274963\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.2602 - categorical_accuracy: 0.8971 - val_loss: 0.3034 - val_categorical_accuracy: 0.8987\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3034 - categorical_accuracy: 0.8987\n",
      "Epoch 1/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.9660 - categorical_accuracy: 0.0823Epoch 1: loss = 2.966031312942505, val_loss = 2.560938835144043\n",
      "83/83 [==============================] - 2s 12ms/step - loss: 2.9660 - categorical_accuracy: 0.0823 - val_loss: 2.5609 - val_categorical_accuracy: 0.1280\n",
      "Epoch 2/50\n",
      "75/83 [==========================>...] - ETA: 0s - loss: 2.3924 - categorical_accuracy: 0.1792Epoch 2: loss = 2.3872039318084717, val_loss = 2.142115354537964\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.3872 - categorical_accuracy: 0.1797 - val_loss: 2.1421 - val_categorical_accuracy: 0.2576\n",
      "Epoch 3/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.9595 - categorical_accuracy: 0.2685Epoch 3: loss = 1.965754508972168, val_loss = 1.6685072183609009\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9658 - categorical_accuracy: 0.2696 - val_loss: 1.6685 - val_categorical_accuracy: 0.4200\n",
      "Epoch 4/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 1.6315 - categorical_accuracy: 0.4285Epoch 4: loss = 1.633070945739746, val_loss = 1.3607149124145508\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.6331 - categorical_accuracy: 0.4288 - val_loss: 1.3607 - val_categorical_accuracy: 0.5404\n",
      "Epoch 5/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 1.3994 - categorical_accuracy: 0.4840Epoch 5: loss = 1.3823283910751343, val_loss = 1.1536153554916382\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.3823 - categorical_accuracy: 0.4890 - val_loss: 1.1536 - val_categorical_accuracy: 0.6136\n",
      "Epoch 6/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.2134 - categorical_accuracy: 0.5610Epoch 6: loss = 1.2124756574630737, val_loss = 0.9893511533737183\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.2125 - categorical_accuracy: 0.5605 - val_loss: 0.9894 - val_categorical_accuracy: 0.6761\n",
      "Epoch 7/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 1.0927 - categorical_accuracy: 0.5977Epoch 7: loss = 1.0864869356155396, val_loss = 0.9708412885665894\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0865 - categorical_accuracy: 0.6009 - val_loss: 0.9708 - val_categorical_accuracy: 0.6555\n",
      "Epoch 8/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.9733 - categorical_accuracy: 0.6443Epoch 8: loss = 0.9701284766197205, val_loss = 0.9787028431892395\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.9701 - categorical_accuracy: 0.6451 - val_loss: 0.9787 - val_categorical_accuracy: 0.6456\n",
      "Epoch 9/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.8988 - categorical_accuracy: 0.6761Epoch 9: loss = 0.8981581330299377, val_loss = 0.8291390538215637\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.8982 - categorical_accuracy: 0.6763 - val_loss: 0.8291 - val_categorical_accuracy: 0.7195\n",
      "Epoch 10/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 0.8447 - categorical_accuracy: 0.7031Epoch 10: loss = 0.8450615406036377, val_loss = 0.7012825608253479\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.8451 - categorical_accuracy: 0.7014 - val_loss: 0.7013 - val_categorical_accuracy: 0.7660\n",
      "Epoch 11/50\n",
      "74/83 [=========================>....] - ETA: 0s - loss: 0.8586 - categorical_accuracy: 0.6807Epoch 11: loss = 0.8493738770484924, val_loss = 0.7490634322166443\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.8494 - categorical_accuracy: 0.6778 - val_loss: 0.7491 - val_categorical_accuracy: 0.7218\n",
      "Epoch 12/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.7767 - categorical_accuracy: 0.7096Epoch 12: loss = 0.7778584361076355, val_loss = 0.6311045289039612\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.7779 - categorical_accuracy: 0.7091 - val_loss: 0.6311 - val_categorical_accuracy: 0.7866\n",
      "Epoch 13/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 0.7489 - categorical_accuracy: 0.7059Epoch 13: loss = 0.7576013207435608, val_loss = 0.6158406138420105\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.7576 - categorical_accuracy: 0.7060 - val_loss: 0.6158 - val_categorical_accuracy: 0.7919\n",
      "Epoch 14/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 0.6682 - categorical_accuracy: 0.7523Epoch 14: loss = 0.6640875935554504, val_loss = 0.588748037815094\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6641 - categorical_accuracy: 0.7532 - val_loss: 0.5887 - val_categorical_accuracy: 0.7858\n",
      "Epoch 15/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 0.7183 - categorical_accuracy: 0.7427Epoch 15: loss = 0.7155972123146057, val_loss = 0.5477907061576843\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.7156 - categorical_accuracy: 0.7426 - val_loss: 0.5478 - val_categorical_accuracy: 0.8178\n",
      "Epoch 16/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.6605 - categorical_accuracy: 0.7531Epoch 16: loss = 0.6593987345695496, val_loss = 0.7256686687469482\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6594 - categorical_accuracy: 0.7540 - val_loss: 0.7257 - val_categorical_accuracy: 0.7195\n",
      "Epoch 17/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 0.6502 - categorical_accuracy: 0.7604Epoch 17: loss = 0.6478845477104187, val_loss = 0.5306709408760071\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6479 - categorical_accuracy: 0.7601 - val_loss: 0.5307 - val_categorical_accuracy: 0.8171\n",
      "Epoch 18/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.5446 - categorical_accuracy: 0.7988Epoch 18: loss = 0.5441997051239014, val_loss = 0.5421613454818726\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5442 - categorical_accuracy: 0.7989 - val_loss: 0.5422 - val_categorical_accuracy: 0.8277\n",
      "Epoch 19/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.5476 - categorical_accuracy: 0.7901Epoch 19: loss = 0.5507692098617554, val_loss = 0.5039815306663513\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5508 - categorical_accuracy: 0.7898 - val_loss: 0.5040 - val_categorical_accuracy: 0.8285\n",
      "Epoch 20/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 0.7053 - categorical_accuracy: 0.7419Epoch 20: loss = 0.687724232673645, val_loss = 0.5443791151046753\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6877 - categorical_accuracy: 0.7494 - val_loss: 0.5444 - val_categorical_accuracy: 0.7904\n",
      "Epoch 21/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 0.4811 - categorical_accuracy: 0.8173Epoch 21: loss = 0.5012843608856201, val_loss = 0.4947620630264282\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5013 - categorical_accuracy: 0.8096 - val_loss: 0.4948 - val_categorical_accuracy: 0.8293\n",
      "Epoch 22/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.4551 - categorical_accuracy: 0.8270Epoch 22: loss = 0.4547416567802429, val_loss = 0.458926260471344\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4547 - categorical_accuracy: 0.8271 - val_loss: 0.4589 - val_categorical_accuracy: 0.8460\n",
      "Epoch 23/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 0.4607 - categorical_accuracy: 0.8425Epoch 23: loss = 0.4580799639225006, val_loss = 0.5076195597648621\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4581 - categorical_accuracy: 0.8416 - val_loss: 0.5076 - val_categorical_accuracy: 0.8201\n",
      "Epoch 24/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 0.4629 - categorical_accuracy: 0.8409Epoch 24: loss = 0.4648844599723816, val_loss = 0.4658825099468231\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.4649 - categorical_accuracy: 0.8393 - val_loss: 0.4659 - val_categorical_accuracy: 0.8361\n",
      "Epoch 25/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.5114 - categorical_accuracy: 0.8148Epoch 25: loss = 0.5126608610153198, val_loss = 0.4099261164665222\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.5127 - categorical_accuracy: 0.8149 - val_loss: 0.4099 - val_categorical_accuracy: 0.8651\n",
      "Epoch 26/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 0.5630 - categorical_accuracy: 0.7938Epoch 26: loss = 0.547738254070282, val_loss = 0.4077529013156891\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5477 - categorical_accuracy: 0.7997 - val_loss: 0.4078 - val_categorical_accuracy: 0.8712\n",
      "Epoch 27/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 0.4718 - categorical_accuracy: 0.8322Epoch 27: loss = 0.46737971901893616, val_loss = 0.4082789123058319\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4674 - categorical_accuracy: 0.8340 - val_loss: 0.4083 - val_categorical_accuracy: 0.8559\n",
      "Epoch 28/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 0.3800 - categorical_accuracy: 0.8702Epoch 28: loss = 0.3821299076080322, val_loss = 0.38606250286102295\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.3821 - categorical_accuracy: 0.8682 - val_loss: 0.3861 - val_categorical_accuracy: 0.8742\n",
      "Epoch 29/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 0.4005 - categorical_accuracy: 0.8470Epoch 29: loss = 0.39110472798347473, val_loss = 0.40582117438316345\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.3911 - categorical_accuracy: 0.8515 - val_loss: 0.4058 - val_categorical_accuracy: 0.8712\n",
      "Epoch 30/50\n",
      "75/83 [==========================>...] - ETA: 0s - loss: 0.4479 - categorical_accuracy: 0.8300Epoch 30: loss = 0.43784353137016296, val_loss = 0.4958650469779968\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.4378 - categorical_accuracy: 0.8317 - val_loss: 0.4959 - val_categorical_accuracy: 0.8407\n",
      "Epoch 31/50\n",
      "79/83 [===========================>..] - ETA: 0s - loss: 0.3946 - categorical_accuracy: 0.8489Epoch 31: loss = 0.3919912576675415, val_loss = 0.33859315514564514\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.3920 - categorical_accuracy: 0.8507 - val_loss: 0.3386 - val_categorical_accuracy: 0.8834\n",
      "Epoch 32/50\n",
      "79/83 [===========================>..] - ETA: 0s - loss: 0.3248 - categorical_accuracy: 0.8742Epoch 32: loss = 0.3274632692337036, val_loss = 0.3705345690250397\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.3275 - categorical_accuracy: 0.8736 - val_loss: 0.3705 - val_categorical_accuracy: 0.8758\n",
      "Epoch 33/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 0.3415 - categorical_accuracy: 0.8711Epoch 33: loss = 0.34178659319877625, val_loss = 0.35912296175956726\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.3418 - categorical_accuracy: 0.8705 - val_loss: 0.3591 - val_categorical_accuracy: 0.8727\n",
      "Epoch 34/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 0.2889 - categorical_accuracy: 0.8914Epoch 34: loss = 0.2864394783973694, val_loss = 0.3379054069519043\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.2864 - categorical_accuracy: 0.8926 - val_loss: 0.3379 - val_categorical_accuracy: 0.8857\n",
      "Epoch 35/50\n",
      "79/83 [===========================>..] - ETA: 0s - loss: 0.3251 - categorical_accuracy: 0.8726Epoch 35: loss = 0.31914985179901123, val_loss = 0.3809601962566376\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.3191 - categorical_accuracy: 0.8751 - val_loss: 0.3810 - val_categorical_accuracy: 0.8750\n",
      "Epoch 36/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 0.2781 - categorical_accuracy: 0.8939Epoch 36: loss = 0.27435848116874695, val_loss = 0.3825654983520508\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.2744 - categorical_accuracy: 0.8957 - val_loss: 0.3826 - val_categorical_accuracy: 0.8628\n",
      "Epoch 37/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.2585 - categorical_accuracy: 0.8979Epoch 37: loss = 0.2588534653186798, val_loss = 0.33420974016189575\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.2589 - categorical_accuracy: 0.8979 - val_loss: 0.3342 - val_categorical_accuracy: 0.8910\n",
      "Epoch 38/50\n",
      "74/83 [=========================>....] - ETA: 0s - loss: 0.3204 - categorical_accuracy: 0.8775Epoch 38: loss = 0.32494446635246277, val_loss = 0.35074061155319214\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.3249 - categorical_accuracy: 0.8759 - val_loss: 0.3507 - val_categorical_accuracy: 0.8796\n",
      "Epoch 39/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.3801 - categorical_accuracy: 0.8627Epoch 39: loss = 0.37585633993148804, val_loss = 0.4074898362159729\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.3759 - categorical_accuracy: 0.8644 - val_loss: 0.4075 - val_categorical_accuracy: 0.8552\n",
      "Epoch 40/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.2544 - categorical_accuracy: 0.9074Epoch 40: loss = 0.2533048093318939, val_loss = 0.3084777593612671\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.2533 - categorical_accuracy: 0.9078 - val_loss: 0.3085 - val_categorical_accuracy: 0.8933\n",
      "Epoch 41/50\n",
      "75/83 [==========================>...] - ETA: 0s - loss: 0.2711 - categorical_accuracy: 0.9000Epoch 41: loss = 0.2731952369213104, val_loss = 0.633443295955658\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.2732 - categorical_accuracy: 0.8995 - val_loss: 0.6334 - val_categorical_accuracy: 0.8026\n",
      "Epoch 42/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 0.2584 - categorical_accuracy: 0.8997Epoch 42: loss = 0.2511906027793884, val_loss = 0.3843904733657837\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.2512 - categorical_accuracy: 0.9048 - val_loss: 0.3844 - val_categorical_accuracy: 0.8712\n",
      "Epoch 43/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 0.2986 - categorical_accuracy: 0.8799Epoch 43: loss = 0.2963477373123169, val_loss = 0.34535154700279236\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.2963 - categorical_accuracy: 0.8827 - val_loss: 0.3454 - val_categorical_accuracy: 0.9002\n",
      "Epoch 44/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 0.2326 - categorical_accuracy: 0.9131Epoch 44: loss = 0.23345208168029785, val_loss = 0.3113352358341217\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.2335 - categorical_accuracy: 0.9132 - val_loss: 0.3113 - val_categorical_accuracy: 0.9017\n",
      "Epoch 45/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 0.2593 - categorical_accuracy: 0.9095Restoring model weights from the end of the best epoch: 40.\n",
      "Epoch 45: loss = 0.26010146737098694, val_loss = 0.43099769949913025\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.2601 - categorical_accuracy: 0.9071 - val_loss: 0.4310 - val_categorical_accuracy: 0.8712\n",
      "Epoch 45: early stopping\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.3085 - categorical_accuracy: 0.8933\n",
      "Epoch 1/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 3.1403 - categorical_accuracy: 0.0699Epoch 1: loss = 3.1216347217559814, val_loss = 2.827564001083374\n",
      "82/82 [==============================] - 2s 10ms/step - loss: 3.1216 - categorical_accuracy: 0.0701 - val_loss: 2.8276 - val_categorical_accuracy: 0.0998\n",
      "Epoch 2/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 2.6027 - categorical_accuracy: 0.1453Epoch 2: loss = 2.5921947956085205, val_loss = 2.3107314109802246\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 2.5922 - categorical_accuracy: 0.1494 - val_loss: 2.3107 - val_categorical_accuracy: 0.2003\n",
      "Epoch 3/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.1407 - categorical_accuracy: 0.2805Epoch 3: loss = 2.1407008171081543, val_loss = 1.8856794834136963\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 2.1407 - categorical_accuracy: 0.2805 - val_loss: 1.8857 - val_categorical_accuracy: 0.3762\n",
      "Epoch 4/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 1.7498 - categorical_accuracy: 0.3972Epoch 4: loss = 1.7467997074127197, val_loss = 1.6013875007629395\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 1.7468 - categorical_accuracy: 0.4002 - val_loss: 1.6014 - val_categorical_accuracy: 0.4318\n",
      "Epoch 5/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 1.6027 - categorical_accuracy: 0.4241Epoch 5: loss = 1.5830568075180054, val_loss = 1.3361108303070068\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 1.5831 - categorical_accuracy: 0.4291 - val_loss: 1.3361 - val_categorical_accuracy: 0.5644\n",
      "Epoch 6/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 1.3961 - categorical_accuracy: 0.4968Epoch 6: loss = 1.3965195417404175, val_loss = 1.240096926689148\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 1.3965 - categorical_accuracy: 0.4954 - val_loss: 1.2401 - val_categorical_accuracy: 0.5514\n",
      "Epoch 7/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.2391 - categorical_accuracy: 0.5445Epoch 7: loss = 1.2351044416427612, val_loss = 1.2281978130340576\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 1.2351 - categorical_accuracy: 0.5442 - val_loss: 1.2282 - val_categorical_accuracy: 0.5407\n",
      "Epoch 8/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.1696 - categorical_accuracy: 0.5671Epoch 8: loss = 1.1705384254455566, val_loss = 1.1473205089569092\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 1.1705 - categorical_accuracy: 0.5671 - val_loss: 1.1473 - val_categorical_accuracy: 0.5689\n",
      "Epoch 9/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.1080 - categorical_accuracy: 0.5852Epoch 9: loss = 1.1057833433151245, val_loss = 1.0402982234954834\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 1.1058 - categorical_accuracy: 0.5869 - val_loss: 1.0403 - val_categorical_accuracy: 0.6177\n",
      "Epoch 10/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 1.0211 - categorical_accuracy: 0.6187Epoch 10: loss = 1.0259277820587158, val_loss = 0.9277659058570862\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 1.0259 - categorical_accuracy: 0.6166 - val_loss: 0.9278 - val_categorical_accuracy: 0.6748\n",
      "Epoch 11/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 0.9899 - categorical_accuracy: 0.6515Epoch 11: loss = 0.985249936580658, val_loss = 0.8784978985786438\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.9852 - categorical_accuracy: 0.6502 - val_loss: 0.8785 - val_categorical_accuracy: 0.7212\n",
      "Epoch 12/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.9254 - categorical_accuracy: 0.6727Epoch 12: loss = 0.9220969676971436, val_loss = 0.9143445491790771\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.9221 - categorical_accuracy: 0.6738 - val_loss: 0.9143 - val_categorical_accuracy: 0.6695\n",
      "Epoch 13/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.8777 - categorical_accuracy: 0.6797Epoch 13: loss = 0.8774589896202087, val_loss = 0.7864181399345398\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.8775 - categorical_accuracy: 0.6799 - val_loss: 0.7864 - val_categorical_accuracy: 0.7098\n",
      "Epoch 14/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.8431 - categorical_accuracy: 0.7062Epoch 14: loss = 0.841335117816925, val_loss = 0.906803548336029\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.8413 - categorical_accuracy: 0.7081 - val_loss: 0.9068 - val_categorical_accuracy: 0.6740\n",
      "Epoch 15/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.8372 - categorical_accuracy: 0.6971Epoch 15: loss = 0.8332791924476624, val_loss = 0.6979956030845642\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.8333 - categorical_accuracy: 0.6982 - val_loss: 0.6980 - val_categorical_accuracy: 0.7708\n",
      "Epoch 16/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.7740 - categorical_accuracy: 0.7264Epoch 16: loss = 0.7739605903625488, val_loss = 0.7220278978347778\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.7740 - categorical_accuracy: 0.7264 - val_loss: 0.7220 - val_categorical_accuracy: 0.7494\n",
      "Epoch 17/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 0.7513 - categorical_accuracy: 0.7295Epoch 17: loss = 0.7486098408699036, val_loss = 0.7291138768196106\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.7486 - categorical_accuracy: 0.7279 - val_loss: 0.7291 - val_categorical_accuracy: 0.7365\n",
      "Epoch 18/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.7228 - categorical_accuracy: 0.7313Epoch 18: loss = 0.7244451642036438, val_loss = 0.7115148901939392\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.7244 - categorical_accuracy: 0.7294 - val_loss: 0.7115 - val_categorical_accuracy: 0.7357\n",
      "Epoch 19/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.8301 - categorical_accuracy: 0.6969Epoch 19: loss = 0.8205796480178833, val_loss = 0.6537649631500244\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.8206 - categorical_accuracy: 0.6989 - val_loss: 0.6538 - val_categorical_accuracy: 0.7464\n",
      "Epoch 20/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.6729 - categorical_accuracy: 0.7589Epoch 20: loss = 0.6731619238853455, val_loss = 0.6565631628036499\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.6732 - categorical_accuracy: 0.7591 - val_loss: 0.6566 - val_categorical_accuracy: 0.7510\n",
      "Epoch 21/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.6793 - categorical_accuracy: 0.7438Epoch 21: loss = 0.6836547255516052, val_loss = 0.6434584856033325\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.6837 - categorical_accuracy: 0.7439 - val_loss: 0.6435 - val_categorical_accuracy: 0.7677\n",
      "Epoch 22/50\n",
      "72/82 [=========================>....] - ETA: 0s - loss: 0.5910 - categorical_accuracy: 0.7830Epoch 22: loss = 0.6051744818687439, val_loss = 0.653201162815094\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.6052 - categorical_accuracy: 0.7812 - val_loss: 0.6532 - val_categorical_accuracy: 0.7639\n",
      "Epoch 23/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 0.5719 - categorical_accuracy: 0.7793Epoch 23: loss = 0.5760359764099121, val_loss = 0.5456258654594421\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.5760 - categorical_accuracy: 0.7790 - val_loss: 0.5456 - val_categorical_accuracy: 0.8165\n",
      "Epoch 24/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.6038 - categorical_accuracy: 0.7500Epoch 24: loss = 0.5998138189315796, val_loss = 0.6189738512039185\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.5998 - categorical_accuracy: 0.7523 - val_loss: 0.6190 - val_categorical_accuracy: 0.7799\n",
      "Epoch 25/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.5622 - categorical_accuracy: 0.8044Epoch 25: loss = 0.5712313055992126, val_loss = 0.813403844833374\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.5712 - categorical_accuracy: 0.7988 - val_loss: 0.8134 - val_categorical_accuracy: 0.7289\n",
      "Epoch 26/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6030 - categorical_accuracy: 0.7759Epoch 26: loss = 0.6030332446098328, val_loss = 0.5644811987876892\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.6030 - categorical_accuracy: 0.7759 - val_loss: 0.5645 - val_categorical_accuracy: 0.7814\n",
      "Epoch 27/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.5686 - categorical_accuracy: 0.7901Epoch 27: loss = 0.5674039125442505, val_loss = 0.6559370756149292\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.5674 - categorical_accuracy: 0.7896 - val_loss: 0.6559 - val_categorical_accuracy: 0.7746\n",
      "Epoch 28/50\n",
      "74/82 [==========================>...] - ETA: 0s - loss: 0.5827 - categorical_accuracy: 0.7863Restoring model weights from the end of the best epoch: 23.\n",
      "Epoch 28: loss = 0.5658738017082214, val_loss = 0.5727550387382507\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.5659 - categorical_accuracy: 0.7965 - val_loss: 0.5728 - val_categorical_accuracy: 0.7906\n",
      "Epoch 28: early stopping\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5456 - categorical_accuracy: 0.8165\n",
      "Epoch 1/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 3.0969 - categorical_accuracy: 0.0666Epoch 1: loss = 3.083545207977295, val_loss = 2.7690255641937256\n",
      "83/83 [==============================] - 2s 10ms/step - loss: 3.0835 - categorical_accuracy: 0.0693 - val_loss: 2.7690 - val_categorical_accuracy: 0.0915\n",
      "Epoch 2/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 2.6978 - categorical_accuracy: 0.1209Epoch 2: loss = 2.691399335861206, val_loss = 2.349616050720215\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.6914 - categorical_accuracy: 0.1203 - val_loss: 2.3496 - val_categorical_accuracy: 0.2409\n",
      "Epoch 3/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 2.3117 - categorical_accuracy: 0.2332Epoch 3: loss = 2.305964946746826, val_loss = 2.0724830627441406\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.3060 - categorical_accuracy: 0.2315 - val_loss: 2.0725 - val_categorical_accuracy: 0.3300\n",
      "Epoch 4/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.9707 - categorical_accuracy: 0.3295Epoch 4: loss = 1.9711120128631592, val_loss = 1.6240379810333252\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9711 - categorical_accuracy: 0.3290 - val_loss: 1.6240 - val_categorical_accuracy: 0.4619\n",
      "Epoch 5/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.6820 - categorical_accuracy: 0.4005Epoch 5: loss = 1.6854076385498047, val_loss = 1.348819375038147\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.6854 - categorical_accuracy: 0.3976 - val_loss: 1.3488 - val_categorical_accuracy: 0.5617\n",
      "Epoch 6/50\n",
      "79/83 [===========================>..] - ETA: 0s - loss: 1.4792 - categorical_accuracy: 0.4684Epoch 6: loss = 1.4817367792129517, val_loss = 1.2568798065185547\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4817 - categorical_accuracy: 0.4669 - val_loss: 1.2569 - val_categorical_accuracy: 0.5419\n",
      "Epoch 7/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.3342 - categorical_accuracy: 0.5154Epoch 7: loss = 1.3350509405136108, val_loss = 1.0938351154327393\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.3351 - categorical_accuracy: 0.5164 - val_loss: 1.0938 - val_categorical_accuracy: 0.6075\n",
      "Epoch 8/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.2592 - categorical_accuracy: 0.5409Epoch 8: loss = 1.2617590427398682, val_loss = 1.0393446683883667\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.2618 - categorical_accuracy: 0.5407 - val_loss: 1.0393 - val_categorical_accuracy: 0.6410\n",
      "Epoch 9/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.1395 - categorical_accuracy: 0.5756Epoch 9: loss = 1.1360806226730347, val_loss = 0.9751358032226562\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.1361 - categorical_accuracy: 0.5765 - val_loss: 0.9751 - val_categorical_accuracy: 0.6639\n",
      "Epoch 10/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.1302 - categorical_accuracy: 0.5764Epoch 10: loss = 1.1303623914718628, val_loss = 0.9535436034202576\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.1304 - categorical_accuracy: 0.5773 - val_loss: 0.9535 - val_categorical_accuracy: 0.6372\n",
      "Epoch 11/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 1.0746 - categorical_accuracy: 0.5998Epoch 11: loss = 1.0764451026916504, val_loss = 0.9366176128387451\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0764 - categorical_accuracy: 0.5956 - val_loss: 0.9366 - val_categorical_accuracy: 0.6524\n",
      "Epoch 12/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 1.0630 - categorical_accuracy: 0.6069Epoch 12: loss = 1.0573863983154297, val_loss = 0.9121289253234863\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0574 - categorical_accuracy: 0.6108 - val_loss: 0.9121 - val_categorical_accuracy: 0.6799\n",
      "Epoch 13/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 0.9666 - categorical_accuracy: 0.6299Epoch 13: loss = 0.9697861671447754, val_loss = 0.7991737723350525\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.9698 - categorical_accuracy: 0.6291 - val_loss: 0.7992 - val_categorical_accuracy: 0.7470\n",
      "Epoch 14/50\n",
      "75/83 [==========================>...] - ETA: 0s - loss: 0.9380 - categorical_accuracy: 0.6417Epoch 14: loss = 0.930249035358429, val_loss = 0.8277267813682556\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.9302 - categorical_accuracy: 0.6436 - val_loss: 0.8277 - val_categorical_accuracy: 0.7180\n",
      "Epoch 15/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 0.8939 - categorical_accuracy: 0.6688Epoch 15: loss = 0.8868212699890137, val_loss = 0.7517139911651611\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.8868 - categorical_accuracy: 0.6710 - val_loss: 0.7517 - val_categorical_accuracy: 0.7530\n",
      "Epoch 16/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.8949 - categorical_accuracy: 0.6570Epoch 16: loss = 0.8950561881065369, val_loss = 0.6957905292510986\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.8951 - categorical_accuracy: 0.6565 - val_loss: 0.6958 - val_categorical_accuracy: 0.7607\n",
      "Epoch 17/50\n",
      "74/83 [=========================>....] - ETA: 0s - loss: 0.8641 - categorical_accuracy: 0.6698Epoch 17: loss = 0.8629980683326721, val_loss = 0.7502144575119019\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.8630 - categorical_accuracy: 0.6717 - val_loss: 0.7502 - val_categorical_accuracy: 0.7165\n",
      "Epoch 18/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 0.7859 - categorical_accuracy: 0.6989Epoch 18: loss = 0.7951565384864807, val_loss = 0.7949358224868774\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.7952 - categorical_accuracy: 0.6976 - val_loss: 0.7949 - val_categorical_accuracy: 0.7096\n",
      "Epoch 19/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 0.8723 - categorical_accuracy: 0.6635Epoch 19: loss = 0.8772414326667786, val_loss = 0.6948375701904297\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.8772 - categorical_accuracy: 0.6649 - val_loss: 0.6948 - val_categorical_accuracy: 0.7447\n",
      "Epoch 20/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 0.8025 - categorical_accuracy: 0.7072Epoch 20: loss = 0.7998092174530029, val_loss = 0.7312453389167786\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.7998 - categorical_accuracy: 0.7053 - val_loss: 0.7312 - val_categorical_accuracy: 0.7233\n",
      "Epoch 21/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 0.7768 - categorical_accuracy: 0.7311Epoch 21: loss = 0.768074631690979, val_loss = 0.6571871638298035\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.7681 - categorical_accuracy: 0.7327 - val_loss: 0.6572 - val_categorical_accuracy: 0.7698\n",
      "Epoch 22/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.7608 - categorical_accuracy: 0.7149Epoch 22: loss = 0.7602986693382263, val_loss = 0.7085527181625366\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.7603 - categorical_accuracy: 0.7152 - val_loss: 0.7086 - val_categorical_accuracy: 0.7409\n",
      "Epoch 23/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 0.7649 - categorical_accuracy: 0.6997Epoch 23: loss = 0.7627259492874146, val_loss = 0.6218398213386536\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.7627 - categorical_accuracy: 0.7022 - val_loss: 0.6218 - val_categorical_accuracy: 0.7912\n",
      "Epoch 24/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 0.7071 - categorical_accuracy: 0.7332Epoch 24: loss = 0.7085960507392883, val_loss = 0.6593072414398193\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.7086 - categorical_accuracy: 0.7312 - val_loss: 0.6593 - val_categorical_accuracy: 0.7622\n",
      "Epoch 25/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 0.7946 - categorical_accuracy: 0.6842Epoch 25: loss = 0.791649341583252, val_loss = 0.6415798664093018\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.7916 - categorical_accuracy: 0.6862 - val_loss: 0.6416 - val_categorical_accuracy: 0.7851\n",
      "Epoch 26/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 0.7333 - categorical_accuracy: 0.7245Epoch 26: loss = 0.7207894325256348, val_loss = 0.6379734873771667\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.7208 - categorical_accuracy: 0.7304 - val_loss: 0.6380 - val_categorical_accuracy: 0.7675\n",
      "Epoch 27/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 0.6598 - categorical_accuracy: 0.7330Epoch 27: loss = 0.6658003330230713, val_loss = 0.6773741245269775\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6658 - categorical_accuracy: 0.7319 - val_loss: 0.6774 - val_categorical_accuracy: 0.7508\n",
      "Epoch 28/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.6775 - categorical_accuracy: 0.7361Restoring model weights from the end of the best epoch: 23.\n",
      "Epoch 28: loss = 0.6828919053077698, val_loss = 0.7023922801017761\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6829 - categorical_accuracy: 0.7350 - val_loss: 0.7024 - val_categorical_accuracy: 0.7264\n",
      "Epoch 28: early stopping\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.6218 - categorical_accuracy: 0.7912\n",
      "Epoch 1/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 3.0636 - categorical_accuracy: 0.0658Epoch 1: loss = 3.049361228942871, val_loss = 2.8112525939941406\n",
      "82/82 [==============================] - 2s 11ms/step - loss: 3.0494 - categorical_accuracy: 0.0648 - val_loss: 2.8113 - val_categorical_accuracy: 0.0967\n",
      "Epoch 2/50\n",
      "74/82 [==========================>...] - ETA: 0s - loss: 2.6560 - categorical_accuracy: 0.1427Epoch 2: loss = 2.639432668685913, val_loss = 2.4910268783569336\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 2.6394 - categorical_accuracy: 0.1502 - val_loss: 2.4910 - val_categorical_accuracy: 0.1759\n",
      "Epoch 3/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 2.3721 - categorical_accuracy: 0.1907Epoch 3: loss = 2.3589847087860107, val_loss = 2.1090168952941895\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 2.3590 - categorical_accuracy: 0.1921 - val_loss: 2.1090 - val_categorical_accuracy: 0.3366\n",
      "Epoch 4/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.0439 - categorical_accuracy: 0.3072Epoch 4: loss = 2.043919086456299, val_loss = 1.8461110591888428\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 2.0439 - categorical_accuracy: 0.3072 - val_loss: 1.8461 - val_categorical_accuracy: 0.3991\n",
      "Epoch 5/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.8673 - categorical_accuracy: 0.3346Epoch 5: loss = 1.8673259019851685, val_loss = 1.5934913158416748\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 1.8673 - categorical_accuracy: 0.3346 - val_loss: 1.5935 - val_categorical_accuracy: 0.4775\n",
      "Epoch 6/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 1.6756 - categorical_accuracy: 0.3973Epoch 6: loss = 1.6668972969055176, val_loss = 1.4042507410049438\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 1.6669 - categorical_accuracy: 0.4009 - val_loss: 1.4043 - val_categorical_accuracy: 0.5567\n",
      "Epoch 7/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 1.5420 - categorical_accuracy: 0.4435Epoch 7: loss = 1.5303995609283447, val_loss = 1.2868924140930176\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 1.5304 - categorical_accuracy: 0.4428 - val_loss: 1.2869 - val_categorical_accuracy: 0.5613\n",
      "Epoch 8/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 1.4144 - categorical_accuracy: 0.4803Epoch 8: loss = 1.4078576564788818, val_loss = 1.1925883293151855\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 1.4079 - categorical_accuracy: 0.4832 - val_loss: 1.1926 - val_categorical_accuracy: 0.6146\n",
      "Epoch 9/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 1.3458 - categorical_accuracy: 0.5154Epoch 9: loss = 1.3295644521713257, val_loss = 1.08070707321167\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 1.3296 - categorical_accuracy: 0.5183 - val_loss: 1.0807 - val_categorical_accuracy: 0.6474\n",
      "Epoch 10/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 1.2598 - categorical_accuracy: 0.5369Epoch 10: loss = 1.2485560178756714, val_loss = 1.1814143657684326\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 1.2486 - categorical_accuracy: 0.5404 - val_loss: 1.1814 - val_categorical_accuracy: 0.5994\n",
      "Epoch 11/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.1631 - categorical_accuracy: 0.5750Epoch 11: loss = 1.1564855575561523, val_loss = 0.9740629196166992\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 1.1565 - categorical_accuracy: 0.5777 - val_loss: 0.9741 - val_categorical_accuracy: 0.6634\n",
      "Epoch 12/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 1.1414 - categorical_accuracy: 0.6019Epoch 12: loss = 1.130218744277954, val_loss = 0.9243798851966858\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 1.1302 - categorical_accuracy: 0.6044 - val_loss: 0.9244 - val_categorical_accuracy: 0.6984\n",
      "Epoch 13/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.0502 - categorical_accuracy: 0.6086Epoch 13: loss = 1.0538502931594849, val_loss = 0.9350975751876831\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 1.0539 - categorical_accuracy: 0.6075 - val_loss: 0.9351 - val_categorical_accuracy: 0.6733\n",
      "Epoch 14/50\n",
      "72/82 [=========================>....] - ETA: 0s - loss: 1.0789 - categorical_accuracy: 0.6016Epoch 14: loss = 1.1100642681121826, val_loss = 1.0098841190338135\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 1.1101 - categorical_accuracy: 0.5953 - val_loss: 1.0099 - val_categorical_accuracy: 0.6649\n",
      "Epoch 15/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 0.9957 - categorical_accuracy: 0.6329Epoch 15: loss = 0.9970049858093262, val_loss = 0.9675903916358948\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.9970 - categorical_accuracy: 0.6319 - val_loss: 0.9676 - val_categorical_accuracy: 0.6664\n",
      "Epoch 16/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 0.9823 - categorical_accuracy: 0.6336Epoch 16: loss = 0.9836150407791138, val_loss = 0.9018051028251648\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.9836 - categorical_accuracy: 0.6341 - val_loss: 0.9018 - val_categorical_accuracy: 0.6824\n",
      "Epoch 17/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 0.9534 - categorical_accuracy: 0.6562Epoch 17: loss = 0.9437289237976074, val_loss = 0.8260045051574707\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.9437 - categorical_accuracy: 0.6570 - val_loss: 0.8260 - val_categorical_accuracy: 0.7136\n",
      "Epoch 18/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 0.9267 - categorical_accuracy: 0.6667Epoch 18: loss = 0.9242907166481018, val_loss = 0.7705446481704712\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.9243 - categorical_accuracy: 0.6669 - val_loss: 0.7705 - val_categorical_accuracy: 0.7540\n",
      "Epoch 19/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 0.8469 - categorical_accuracy: 0.6875Epoch 19: loss = 0.8343729972839355, val_loss = 0.7238901257514954\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.8344 - categorical_accuracy: 0.6898 - val_loss: 0.7239 - val_categorical_accuracy: 0.7677\n",
      "Epoch 20/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.8535 - categorical_accuracy: 0.6956Epoch 20: loss = 0.8599180579185486, val_loss = 0.8128416538238525\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.8599 - categorical_accuracy: 0.6898 - val_loss: 0.8128 - val_categorical_accuracy: 0.7372\n",
      "Epoch 21/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 0.8380 - categorical_accuracy: 0.6986Epoch 21: loss = 0.8543093800544739, val_loss = 0.833469808101654\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.8543 - categorical_accuracy: 0.6905 - val_loss: 0.8335 - val_categorical_accuracy: 0.7129\n",
      "Epoch 22/50\n",
      "72/82 [=========================>....] - ETA: 0s - loss: 0.8678 - categorical_accuracy: 0.6693Epoch 22: loss = 0.8605708479881287, val_loss = 0.7484549880027771\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.8606 - categorical_accuracy: 0.6753 - val_loss: 0.7485 - val_categorical_accuracy: 0.7327\n",
      "Epoch 23/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 0.7762 - categorical_accuracy: 0.7056Epoch 23: loss = 0.7712018489837646, val_loss = 0.7350167036056519\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.7712 - categorical_accuracy: 0.7073 - val_loss: 0.7350 - val_categorical_accuracy: 0.7380\n",
      "Epoch 24/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 0.7386 - categorical_accuracy: 0.7209Epoch 24: loss = 0.7533608675003052, val_loss = 0.6869184970855713\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.7534 - categorical_accuracy: 0.7142 - val_loss: 0.6869 - val_categorical_accuracy: 0.7768\n",
      "Epoch 25/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 0.7462 - categorical_accuracy: 0.7183Epoch 25: loss = 0.7648342251777649, val_loss = 0.6959350109100342\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.7648 - categorical_accuracy: 0.7111 - val_loss: 0.6959 - val_categorical_accuracy: 0.7548\n",
      "Epoch 26/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.7755 - categorical_accuracy: 0.7066Epoch 26: loss = 0.7755045294761658, val_loss = 0.7002239227294922\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.7755 - categorical_accuracy: 0.7066 - val_loss: 0.7002 - val_categorical_accuracy: 0.7433\n",
      "Epoch 27/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.6633 - categorical_accuracy: 0.7577Epoch 27: loss = 0.6653333306312561, val_loss = 0.6756121516227722\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.6653 - categorical_accuracy: 0.7569 - val_loss: 0.6756 - val_categorical_accuracy: 0.7540\n",
      "Epoch 28/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 0.7566 - categorical_accuracy: 0.7089Epoch 28: loss = 0.7561448216438293, val_loss = 0.7423678040504456\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.7561 - categorical_accuracy: 0.7081 - val_loss: 0.7424 - val_categorical_accuracy: 0.7350\n",
      "Epoch 29/50\n",
      "72/82 [=========================>....] - ETA: 0s - loss: 0.7518 - categorical_accuracy: 0.7292Epoch 29: loss = 0.7598264813423157, val_loss = 0.6521018147468567\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.7598 - categorical_accuracy: 0.7264 - val_loss: 0.6521 - val_categorical_accuracy: 0.7715\n",
      "Epoch 30/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 0.6903 - categorical_accuracy: 0.7350Epoch 30: loss = 0.6915454268455505, val_loss = 0.6150087714195251\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.6915 - categorical_accuracy: 0.7355 - val_loss: 0.6150 - val_categorical_accuracy: 0.7708\n",
      "Epoch 31/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 0.6993 - categorical_accuracy: 0.7483Epoch 31: loss = 0.6952111124992371, val_loss = 0.6021089553833008\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.6952 - categorical_accuracy: 0.7462 - val_loss: 0.6021 - val_categorical_accuracy: 0.7875\n",
      "Epoch 32/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6489 - categorical_accuracy: 0.7782Epoch 32: loss = 0.6489381194114685, val_loss = 0.6549058556556702\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.6489 - categorical_accuracy: 0.7782 - val_loss: 0.6549 - val_categorical_accuracy: 0.7700\n",
      "Epoch 33/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.6468 - categorical_accuracy: 0.7539Epoch 33: loss = 0.6532188653945923, val_loss = 0.6290815472602844\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.6532 - categorical_accuracy: 0.7500 - val_loss: 0.6291 - val_categorical_accuracy: 0.7738\n",
      "Epoch 34/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6714 - categorical_accuracy: 0.7508Epoch 34: loss = 0.6714293956756592, val_loss = 0.7254801988601685\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.6714 - categorical_accuracy: 0.7508 - val_loss: 0.7255 - val_categorical_accuracy: 0.7426\n",
      "Epoch 35/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.7005 - categorical_accuracy: 0.7336Epoch 35: loss = 0.6964644193649292, val_loss = 0.6034244894981384\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.6965 - categorical_accuracy: 0.7363 - val_loss: 0.6034 - val_categorical_accuracy: 0.8050\n",
      "Epoch 36/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6354 - categorical_accuracy: 0.7691Epoch 36: loss = 0.6353974938392639, val_loss = 0.5764874815940857\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.6354 - categorical_accuracy: 0.7691 - val_loss: 0.5765 - val_categorical_accuracy: 0.8058\n",
      "Epoch 37/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.7033 - categorical_accuracy: 0.7321Epoch 37: loss = 0.7056081295013428, val_loss = 0.6604719758033752\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.7056 - categorical_accuracy: 0.7309 - val_loss: 0.6605 - val_categorical_accuracy: 0.7479\n",
      "Epoch 38/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 0.5995 - categorical_accuracy: 0.7680Epoch 38: loss = 0.5884649753570557, val_loss = 0.6408930420875549\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.5885 - categorical_accuracy: 0.7691 - val_loss: 0.6409 - val_categorical_accuracy: 0.7631\n",
      "Epoch 39/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6365 - categorical_accuracy: 0.7530Epoch 39: loss = 0.6365166306495667, val_loss = 0.6423090696334839\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.6365 - categorical_accuracy: 0.7530 - val_loss: 0.6423 - val_categorical_accuracy: 0.7570\n",
      "Epoch 40/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.6419 - categorical_accuracy: 0.7630Epoch 40: loss = 0.6295438408851624, val_loss = 0.5509893298149109\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.6295 - categorical_accuracy: 0.7675 - val_loss: 0.5510 - val_categorical_accuracy: 0.8073\n",
      "Epoch 41/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 0.5851 - categorical_accuracy: 0.7829Epoch 41: loss = 0.590546190738678, val_loss = 0.6136502027511597\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.5905 - categorical_accuracy: 0.7790 - val_loss: 0.6137 - val_categorical_accuracy: 0.7700\n",
      "Epoch 42/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.5748 - categorical_accuracy: 0.7906Epoch 42: loss = 0.5747731924057007, val_loss = 0.5516766309738159\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.5748 - categorical_accuracy: 0.7927 - val_loss: 0.5517 - val_categorical_accuracy: 0.8035\n",
      "Epoch 43/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5867 - categorical_accuracy: 0.7759Epoch 43: loss = 0.5866940021514893, val_loss = 0.5648260116577148\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.5867 - categorical_accuracy: 0.7759 - val_loss: 0.5648 - val_categorical_accuracy: 0.8088\n",
      "Epoch 44/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 0.5560 - categorical_accuracy: 0.7920Epoch 44: loss = 0.563869059085846, val_loss = 0.5260562300682068\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.5639 - categorical_accuracy: 0.7927 - val_loss: 0.5261 - val_categorical_accuracy: 0.8233\n",
      "Epoch 45/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.5236 - categorical_accuracy: 0.8019Epoch 45: loss = 0.5309242606163025, val_loss = 0.5190072655677795\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.5309 - categorical_accuracy: 0.7988 - val_loss: 0.5190 - val_categorical_accuracy: 0.8324\n",
      "Epoch 46/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 0.5297 - categorical_accuracy: 0.7979Epoch 46: loss = 0.5247500538825989, val_loss = 0.48348963260650635\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.5248 - categorical_accuracy: 0.8034 - val_loss: 0.4835 - val_categorical_accuracy: 0.8165\n",
      "Epoch 47/50\n",
      "72/82 [=========================>....] - ETA: 0s - loss: 0.6205 - categorical_accuracy: 0.7595Epoch 47: loss = 0.611007571220398, val_loss = 0.5198632478713989\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.6110 - categorical_accuracy: 0.7630 - val_loss: 0.5199 - val_categorical_accuracy: 0.8324\n",
      "Epoch 48/50\n",
      "73/82 [=========================>....] - ETA: 0s - loss: 0.5032 - categorical_accuracy: 0.8116Epoch 48: loss = 0.5052404999732971, val_loss = 0.48705872893333435\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.5052 - categorical_accuracy: 0.8087 - val_loss: 0.4871 - val_categorical_accuracy: 0.8279\n",
      "Epoch 49/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5109 - categorical_accuracy: 0.7988Epoch 49: loss = 0.5109264254570007, val_loss = 0.4936373829841614\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.5109 - categorical_accuracy: 0.7988 - val_loss: 0.4936 - val_categorical_accuracy: 0.8256\n",
      "Epoch 50/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.5335 - categorical_accuracy: 0.7875Epoch 50: loss = 0.5264162421226501, val_loss = 0.5304427146911621\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.5264 - categorical_accuracy: 0.7912 - val_loss: 0.5304 - val_categorical_accuracy: 0.8020\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5304 - categorical_accuracy: 0.8020\n",
      "Epoch 1/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 3.1539 - categorical_accuracy: 0.0649Epoch 1: loss = 3.140282154083252, val_loss = 2.9018115997314453\n",
      "83/83 [==============================] - 2s 10ms/step - loss: 3.1403 - categorical_accuracy: 0.0670 - val_loss: 2.9018 - val_categorical_accuracy: 0.0663\n",
      "Epoch 2/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.8245 - categorical_accuracy: 0.0952Epoch 2: loss = 2.8245086669921875, val_loss = 2.6312224864959717\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.8245 - categorical_accuracy: 0.0952 - val_loss: 2.6312 - val_categorical_accuracy: 0.1502\n",
      "Epoch 3/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 2.6116 - categorical_accuracy: 0.1218Epoch 3: loss = 2.6078670024871826, val_loss = 2.333932399749756\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.6079 - categorical_accuracy: 0.1226 - val_loss: 2.3339 - val_categorical_accuracy: 0.2005\n",
      "Epoch 4/50\n",
      "79/83 [===========================>..] - ETA: 0s - loss: 2.3808 - categorical_accuracy: 0.1661Epoch 4: loss = 2.3742384910583496, val_loss = 2.1469686031341553\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.3742 - categorical_accuracy: 0.1660 - val_loss: 2.1470 - val_categorical_accuracy: 0.2835\n",
      "Epoch 5/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 2.2854 - categorical_accuracy: 0.1883Epoch 5: loss = 2.280684471130371, val_loss = 2.179473876953125\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.2807 - categorical_accuracy: 0.1896 - val_loss: 2.1795 - val_categorical_accuracy: 0.2096\n",
      "Epoch 6/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 2.1460 - categorical_accuracy: 0.2087Epoch 6: loss = 2.145993947982788, val_loss = 2.1128509044647217\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1460 - categorical_accuracy: 0.2087 - val_loss: 2.1129 - val_categorical_accuracy: 0.2470\n",
      "Epoch 7/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 2.1612 - categorical_accuracy: 0.2228Epoch 7: loss = 2.152327299118042, val_loss = 1.8627756834030151\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1523 - categorical_accuracy: 0.2209 - val_loss: 1.8628 - val_categorical_accuracy: 0.3742\n",
      "Epoch 8/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 1.9885 - categorical_accuracy: 0.2703Epoch 8: loss = 1.9843498468399048, val_loss = 1.7823642492294312\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9843 - categorical_accuracy: 0.2696 - val_loss: 1.7824 - val_categorical_accuracy: 0.3773\n",
      "Epoch 9/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.9515 - categorical_accuracy: 0.2736Epoch 9: loss = 1.951525330543518, val_loss = 1.753126621246338\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9515 - categorical_accuracy: 0.2734 - val_loss: 1.7531 - val_categorical_accuracy: 0.4169\n",
      "Epoch 10/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.8483 - categorical_accuracy: 0.3140Epoch 10: loss = 1.8469892740249634, val_loss = 1.7184844017028809\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8470 - categorical_accuracy: 0.3153 - val_loss: 1.7185 - val_categorical_accuracy: 0.3422\n",
      "Epoch 11/50\n",
      "73/83 [=========================>....] - ETA: 0s - loss: 1.8261 - categorical_accuracy: 0.3031Epoch 11: loss = 1.8297995328903198, val_loss = 1.6839815378189087\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8298 - categorical_accuracy: 0.3016 - val_loss: 1.6840 - val_categorical_accuracy: 0.3857\n",
      "Epoch 12/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 1.7909 - categorical_accuracy: 0.3277Epoch 12: loss = 1.7946714162826538, val_loss = 1.5647127628326416\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.7947 - categorical_accuracy: 0.3275 - val_loss: 1.5647 - val_categorical_accuracy: 0.4840\n",
      "Epoch 13/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 1.7001 - categorical_accuracy: 0.3571Epoch 13: loss = 1.7001750469207764, val_loss = 1.5416009426116943\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.7002 - categorical_accuracy: 0.3572 - val_loss: 1.5416 - val_categorical_accuracy: 0.4596\n",
      "Epoch 14/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 1.6076 - categorical_accuracy: 0.3945Epoch 14: loss = 1.6039294004440308, val_loss = 1.4413328170776367\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.6039 - categorical_accuracy: 0.3983 - val_loss: 1.4413 - val_categorical_accuracy: 0.5252\n",
      "Epoch 15/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.5900 - categorical_accuracy: 0.3850Epoch 15: loss = 1.5856167078018188, val_loss = 1.4533765316009521\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5856 - categorical_accuracy: 0.3877 - val_loss: 1.4534 - val_categorical_accuracy: 0.4688\n",
      "Epoch 16/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 1.5533 - categorical_accuracy: 0.4252Epoch 16: loss = 1.5494927167892456, val_loss = 1.3151799440383911\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5495 - categorical_accuracy: 0.4288 - val_loss: 1.3152 - val_categorical_accuracy: 0.5244\n",
      "Epoch 17/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.4847 - categorical_accuracy: 0.4314Epoch 17: loss = 1.4835660457611084, val_loss = 1.2681416273117065\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4836 - categorical_accuracy: 0.4318 - val_loss: 1.2681 - val_categorical_accuracy: 0.5671\n",
      "Epoch 18/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 1.3921 - categorical_accuracy: 0.4643Epoch 18: loss = 1.388312578201294, val_loss = 1.2491869926452637\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.3883 - categorical_accuracy: 0.4653 - val_loss: 1.2492 - val_categorical_accuracy: 0.5488\n",
      "Epoch 19/50\n",
      "75/83 [==========================>...] - ETA: 0s - loss: 1.3340 - categorical_accuracy: 0.4867Epoch 19: loss = 1.3416608572006226, val_loss = 1.230596899986267\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.3417 - categorical_accuracy: 0.4874 - val_loss: 1.2306 - val_categorical_accuracy: 0.5373\n",
      "Epoch 20/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.3464 - categorical_accuracy: 0.4622Epoch 20: loss = 1.3432611227035522, val_loss = 1.2875233888626099\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.3433 - categorical_accuracy: 0.4638 - val_loss: 1.2875 - val_categorical_accuracy: 0.5282\n",
      "Epoch 21/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 1.2734 - categorical_accuracy: 0.5128Epoch 21: loss = 1.267377257347107, val_loss = 1.0990177392959595\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.2674 - categorical_accuracy: 0.5110 - val_loss: 1.0990 - val_categorical_accuracy: 0.6410\n",
      "Epoch 22/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.2007 - categorical_accuracy: 0.5478Epoch 22: loss = 1.2029495239257812, val_loss = 1.059398889541626\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.2029 - categorical_accuracy: 0.5468 - val_loss: 1.0594 - val_categorical_accuracy: 0.6059\n",
      "Epoch 23/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 1.2355 - categorical_accuracy: 0.5341Epoch 23: loss = 1.2332090139389038, val_loss = 1.0039945840835571\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.2332 - categorical_accuracy: 0.5316 - val_loss: 1.0040 - val_categorical_accuracy: 0.6700\n",
      "Epoch 24/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 1.2362 - categorical_accuracy: 0.5377Epoch 24: loss = 1.229177713394165, val_loss = 1.1923478841781616\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.2292 - categorical_accuracy: 0.5423 - val_loss: 1.1923 - val_categorical_accuracy: 0.5465\n",
      "Epoch 25/50\n",
      "75/83 [==========================>...] - ETA: 0s - loss: 1.1536 - categorical_accuracy: 0.5650Epoch 25: loss = 1.149396538734436, val_loss = 0.9787566065788269\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.1494 - categorical_accuracy: 0.5666 - val_loss: 0.9788 - val_categorical_accuracy: 0.6608\n",
      "Epoch 26/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 1.2243 - categorical_accuracy: 0.5473Epoch 26: loss = 1.2219041585922241, val_loss = 0.9795969724655151\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.2219 - categorical_accuracy: 0.5476 - val_loss: 0.9796 - val_categorical_accuracy: 0.6479\n",
      "Epoch 27/50\n",
      "74/83 [=========================>....] - ETA: 0s - loss: 1.2203 - categorical_accuracy: 0.5389Epoch 27: loss = 1.2074729204177856, val_loss = 1.087241291999817\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.2075 - categorical_accuracy: 0.5453 - val_loss: 1.0872 - val_categorical_accuracy: 0.6220\n",
      "Epoch 28/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.0909 - categorical_accuracy: 0.5960Epoch 28: loss = 1.0917493104934692, val_loss = 0.9018709063529968\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0917 - categorical_accuracy: 0.5956 - val_loss: 0.9019 - val_categorical_accuracy: 0.6944\n",
      "Epoch 29/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 1.0523 - categorical_accuracy: 0.5942Epoch 29: loss = 1.0584908723831177, val_loss = 0.8771198391914368\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0585 - categorical_accuracy: 0.5925 - val_loss: 0.8771 - val_categorical_accuracy: 0.6883\n",
      "Epoch 30/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.1079 - categorical_accuracy: 0.5716Epoch 30: loss = 1.1075992584228516, val_loss = 0.8779897689819336\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.1076 - categorical_accuracy: 0.5720 - val_loss: 0.8780 - val_categorical_accuracy: 0.6921\n",
      "Epoch 31/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 1.0127 - categorical_accuracy: 0.6061Epoch 31: loss = 1.012472152709961, val_loss = 1.1674284934997559\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0125 - categorical_accuracy: 0.6093 - val_loss: 1.1674 - val_categorical_accuracy: 0.5617\n",
      "Epoch 32/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 1.0100 - categorical_accuracy: 0.6077Epoch 32: loss = 1.0031760931015015, val_loss = 0.8472784161567688\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0032 - categorical_accuracy: 0.6131 - val_loss: 0.8473 - val_categorical_accuracy: 0.7012\n",
      "Epoch 33/50\n",
      "75/83 [==========================>...] - ETA: 0s - loss: 1.0110 - categorical_accuracy: 0.6100Epoch 33: loss = 1.0037214756011963, val_loss = 0.8499460816383362\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0037 - categorical_accuracy: 0.6101 - val_loss: 0.8499 - val_categorical_accuracy: 0.6898\n",
      "Epoch 34/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.9601 - categorical_accuracy: 0.6197Epoch 34: loss = 0.9595667719841003, val_loss = 0.8718313574790955\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.9596 - categorical_accuracy: 0.6200 - val_loss: 0.8718 - val_categorical_accuracy: 0.6883\n",
      "Epoch 35/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 0.9533 - categorical_accuracy: 0.6234Epoch 35: loss = 0.9624142646789551, val_loss = 0.9220796823501587\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.9624 - categorical_accuracy: 0.6184 - val_loss: 0.9221 - val_categorical_accuracy: 0.6524\n",
      "Epoch 36/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 0.9551 - categorical_accuracy: 0.6266Epoch 36: loss = 0.9501339793205261, val_loss = 0.9441417455673218\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.9501 - categorical_accuracy: 0.6306 - val_loss: 0.9441 - val_categorical_accuracy: 0.6433\n",
      "Epoch 37/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 0.9277 - categorical_accuracy: 0.6359Epoch 37: loss = 0.9201424717903137, val_loss = 0.8170749545097351\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.9201 - categorical_accuracy: 0.6398 - val_loss: 0.8171 - val_categorical_accuracy: 0.7043\n",
      "Epoch 38/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 0.9064 - categorical_accuracy: 0.6619Epoch 38: loss = 0.916365921497345, val_loss = 0.9425740242004395\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.9164 - categorical_accuracy: 0.6580 - val_loss: 0.9426 - val_categorical_accuracy: 0.6402\n",
      "Epoch 39/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 0.8909 - categorical_accuracy: 0.6641Epoch 39: loss = 0.8859046101570129, val_loss = 0.7216982841491699\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.8859 - categorical_accuracy: 0.6679 - val_loss: 0.7217 - val_categorical_accuracy: 0.7523\n",
      "Epoch 40/50\n",
      "74/83 [=========================>....] - ETA: 0s - loss: 0.8743 - categorical_accuracy: 0.6672Epoch 40: loss = 0.8895949721336365, val_loss = 1.2085620164871216\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.8896 - categorical_accuracy: 0.6641 - val_loss: 1.2086 - val_categorical_accuracy: 0.5152\n",
      "Epoch 41/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.8932 - categorical_accuracy: 0.6639Epoch 41: loss = 0.8925520777702332, val_loss = 0.7151392698287964\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.8926 - categorical_accuracy: 0.6641 - val_loss: 0.7151 - val_categorical_accuracy: 0.7370\n",
      "Epoch 42/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.8258 - categorical_accuracy: 0.6806Epoch 42: loss = 0.825667142868042, val_loss = 0.7453137636184692\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.8257 - categorical_accuracy: 0.6809 - val_loss: 0.7453 - val_categorical_accuracy: 0.7104\n",
      "Epoch 43/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 0.8505 - categorical_accuracy: 0.6727Epoch 43: loss = 0.8610507845878601, val_loss = 1.1770391464233398\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.8611 - categorical_accuracy: 0.6717 - val_loss: 1.1770 - val_categorical_accuracy: 0.6014\n",
      "Epoch 44/50\n",
      "75/83 [==========================>...] - ETA: 0s - loss: 0.8986 - categorical_accuracy: 0.6583Epoch 44: loss = 0.883820116519928, val_loss = 0.7925806045532227\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.8838 - categorical_accuracy: 0.6687 - val_loss: 0.7926 - val_categorical_accuracy: 0.6898\n",
      "Epoch 45/50\n",
      "75/83 [==========================>...] - ETA: 0s - loss: 0.7830 - categorical_accuracy: 0.6992Epoch 45: loss = 0.7910772562026978, val_loss = 0.9217522144317627\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.7911 - categorical_accuracy: 0.6954 - val_loss: 0.9218 - val_categorical_accuracy: 0.6402\n",
      "Epoch 46/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 0.8245 - categorical_accuracy: 0.6900Epoch 46: loss = 0.821757435798645, val_loss = 0.6562058329582214\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.8218 - categorical_accuracy: 0.6900 - val_loss: 0.6562 - val_categorical_accuracy: 0.7698\n",
      "Epoch 47/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 0.7914 - categorical_accuracy: 0.7064Epoch 47: loss = 0.7925261855125427, val_loss = 0.6675876975059509\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.7925 - categorical_accuracy: 0.7053 - val_loss: 0.6676 - val_categorical_accuracy: 0.7515\n",
      "Epoch 48/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.8399 - categorical_accuracy: 0.6768Epoch 48: loss = 0.8392571210861206, val_loss = 0.6924029588699341\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.8393 - categorical_accuracy: 0.6771 - val_loss: 0.6924 - val_categorical_accuracy: 0.7370\n",
      "Epoch 49/50\n",
      "74/83 [=========================>....] - ETA: 0s - loss: 0.7515 - categorical_accuracy: 0.7078Epoch 49: loss = 0.7370644807815552, val_loss = 0.7223058342933655\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.7371 - categorical_accuracy: 0.7152 - val_loss: 0.7223 - val_categorical_accuracy: 0.7081\n",
      "Epoch 50/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 0.9741 - categorical_accuracy: 0.6477Epoch 50: loss = 0.9618194103240967, val_loss = 0.7421718835830688\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.9618 - categorical_accuracy: 0.6527 - val_loss: 0.7422 - val_categorical_accuracy: 0.7188\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.7422 - categorical_accuracy: 0.7188\n",
      "Epoch 1/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 3.1073 - categorical_accuracy: 0.0773Epoch 1: loss = 3.0729033946990967, val_loss = 2.7731781005859375\n",
      "41/41 [==============================] - 2s 16ms/step - loss: 3.0729 - categorical_accuracy: 0.0816 - val_loss: 2.7732 - val_categorical_accuracy: 0.0800\n",
      "Epoch 2/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 2.6260 - categorical_accuracy: 0.1436Epoch 2: loss = 2.612454414367676, val_loss = 2.429466485977173\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 2.6125 - categorical_accuracy: 0.1486 - val_loss: 2.4295 - val_categorical_accuracy: 0.2422\n",
      "Epoch 3/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 2.1704 - categorical_accuracy: 0.2812Epoch 3: loss = 2.1473453044891357, val_loss = 1.8652734756469727\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 2.1473 - categorical_accuracy: 0.2934 - val_loss: 1.8653 - val_categorical_accuracy: 0.3884\n",
      "Epoch 4/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 1.7664 - categorical_accuracy: 0.3991Epoch 4: loss = 1.7308886051177979, val_loss = 1.5467172861099243\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.7309 - categorical_accuracy: 0.4146 - val_loss: 1.5467 - val_categorical_accuracy: 0.4821\n",
      "Epoch 5/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 1.5017 - categorical_accuracy: 0.4737Epoch 5: loss = 1.4854060411453247, val_loss = 1.304002285003662\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.4854 - categorical_accuracy: 0.4802 - val_loss: 1.3040 - val_categorical_accuracy: 0.5651\n",
      "Epoch 6/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.2079 - categorical_accuracy: 0.5777Epoch 6: loss = 1.201964259147644, val_loss = 1.1005789041519165\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 1.2020 - categorical_accuracy: 0.5816 - val_loss: 1.1006 - val_categorical_accuracy: 0.6443\n",
      "Epoch 7/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.0849 - categorical_accuracy: 0.6064Epoch 7: loss = 1.0955220460891724, val_loss = 0.9821282029151917\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.0955 - categorical_accuracy: 0.6059 - val_loss: 0.9821 - val_categorical_accuracy: 0.6390\n",
      "Epoch 8/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.0407 - categorical_accuracy: 0.6320Epoch 8: loss = 1.030547857284546, val_loss = 0.9245273470878601\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 1.0305 - categorical_accuracy: 0.6364 - val_loss: 0.9245 - val_categorical_accuracy: 0.6748\n",
      "Epoch 9/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.9519 - categorical_accuracy: 0.6520Epoch 9: loss = 0.9479615092277527, val_loss = 0.8366552591323853\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.9480 - categorical_accuracy: 0.6555 - val_loss: 0.8367 - val_categorical_accuracy: 0.7136\n",
      "Epoch 10/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.9484 - categorical_accuracy: 0.6630Epoch 10: loss = 0.9324795007705688, val_loss = 0.8374195694923401\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 0.9325 - categorical_accuracy: 0.6669 - val_loss: 0.8374 - val_categorical_accuracy: 0.6931\n",
      "Epoch 11/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 0.8378 - categorical_accuracy: 0.6974Epoch 11: loss = 0.8329068422317505, val_loss = 0.8820903897285461\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.8329 - categorical_accuracy: 0.7027 - val_loss: 0.8821 - val_categorical_accuracy: 0.6908\n",
      "Epoch 12/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 0.7892 - categorical_accuracy: 0.7241Epoch 12: loss = 0.7968961000442505, val_loss = 0.7325316071510315\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.7969 - categorical_accuracy: 0.7188 - val_loss: 0.7325 - val_categorical_accuracy: 0.7380\n",
      "Epoch 13/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.7167 - categorical_accuracy: 0.7398Epoch 13: loss = 0.7174104452133179, val_loss = 0.7151415944099426\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 0.7174 - categorical_accuracy: 0.7409 - val_loss: 0.7151 - val_categorical_accuracy: 0.7464\n",
      "Epoch 14/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.6945 - categorical_accuracy: 0.7509Epoch 14: loss = 0.6884286403656006, val_loss = 0.6692084074020386\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.6884 - categorical_accuracy: 0.7500 - val_loss: 0.6692 - val_categorical_accuracy: 0.7616\n",
      "Epoch 15/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.6684 - categorical_accuracy: 0.7534Epoch 15: loss = 0.6728659868240356, val_loss = 0.6891700625419617\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 0.6729 - categorical_accuracy: 0.7470 - val_loss: 0.6892 - val_categorical_accuracy: 0.7570\n",
      "Epoch 16/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.6773 - categorical_accuracy: 0.7635Epoch 16: loss = 0.6761868000030518, val_loss = 0.701473593711853\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.6762 - categorical_accuracy: 0.7630 - val_loss: 0.7015 - val_categorical_accuracy: 0.7380\n",
      "Epoch 17/50\n",
      "34/41 [=======================>......] - ETA: 0s - loss: 0.6458 - categorical_accuracy: 0.7629Epoch 17: loss = 0.6506428718566895, val_loss = 0.7169151306152344\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.6506 - categorical_accuracy: 0.7630 - val_loss: 0.7169 - val_categorical_accuracy: 0.7365\n",
      "Epoch 18/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.6457 - categorical_accuracy: 0.7551Epoch 18: loss = 0.6206023097038269, val_loss = 0.6527277827262878\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 0.6206 - categorical_accuracy: 0.7652 - val_loss: 0.6527 - val_categorical_accuracy: 0.7723\n",
      "Epoch 19/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.5902 - categorical_accuracy: 0.7906Epoch 19: loss = 0.592337429523468, val_loss = 0.627114474773407\n",
      "41/41 [==============================] - 1s 12ms/step - loss: 0.5923 - categorical_accuracy: 0.7889 - val_loss: 0.6271 - val_categorical_accuracy: 0.7898\n",
      "Epoch 20/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.6142 - categorical_accuracy: 0.7772Epoch 20: loss = 0.6155579686164856, val_loss = 0.6691649556159973\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.6156 - categorical_accuracy: 0.7790 - val_loss: 0.6692 - val_categorical_accuracy: 0.7624\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.5561 - categorical_accuracy: 0.7980Epoch 21: loss = 0.556108832359314, val_loss = 0.560302197933197\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.5561 - categorical_accuracy: 0.7980 - val_loss: 0.5603 - val_categorical_accuracy: 0.7936\n",
      "Epoch 22/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.5183 - categorical_accuracy: 0.7973Epoch 22: loss = 0.5188194513320923, val_loss = 0.6215453147888184\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 0.5188 - categorical_accuracy: 0.7950 - val_loss: 0.6215 - val_categorical_accuracy: 0.7784\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4939 - categorical_accuracy: 0.8209Epoch 23: loss = 0.4939108192920685, val_loss = 0.5113971829414368\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.4939 - categorical_accuracy: 0.8209 - val_loss: 0.5114 - val_categorical_accuracy: 0.8294\n",
      "Epoch 24/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.5006 - categorical_accuracy: 0.8176Epoch 24: loss = 0.5023728609085083, val_loss = 0.5448402166366577\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.5024 - categorical_accuracy: 0.8171 - val_loss: 0.5448 - val_categorical_accuracy: 0.8012\n",
      "Epoch 25/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 0.4871 - categorical_accuracy: 0.8076Epoch 25: loss = 0.5006123185157776, val_loss = 0.5176390409469604\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 0.5006 - categorical_accuracy: 0.7973 - val_loss: 0.5176 - val_categorical_accuracy: 0.8195\n",
      "Epoch 26/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 0.4966 - categorical_accuracy: 0.8107Epoch 26: loss = 0.5078955292701721, val_loss = 0.506764829158783\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.5079 - categorical_accuracy: 0.8049 - val_loss: 0.5068 - val_categorical_accuracy: 0.8302\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4548 - categorical_accuracy: 0.8277Epoch 27: loss = 0.45483919978141785, val_loss = 0.5081479549407959\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.4548 - categorical_accuracy: 0.8277 - val_loss: 0.5081 - val_categorical_accuracy: 0.8225\n",
      "Epoch 28/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.4045 - categorical_accuracy: 0.8391Epoch 28: loss = 0.4030438959598541, val_loss = 0.46454331278800964\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 0.4030 - categorical_accuracy: 0.8392 - val_loss: 0.4645 - val_categorical_accuracy: 0.8317\n",
      "Epoch 29/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.4339 - categorical_accuracy: 0.8336Epoch 29: loss = 0.4464265704154968, val_loss = 0.45888930559158325\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.4464 - categorical_accuracy: 0.8323 - val_loss: 0.4589 - val_categorical_accuracy: 0.8462\n",
      "Epoch 30/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 0.4294 - categorical_accuracy: 0.8375Epoch 30: loss = 0.41480985283851624, val_loss = 0.4940323531627655\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.4148 - categorical_accuracy: 0.8407 - val_loss: 0.4940 - val_categorical_accuracy: 0.8157\n",
      "Epoch 31/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.3986 - categorical_accuracy: 0.8559Epoch 31: loss = 0.3942458927631378, val_loss = 0.42496228218078613\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 0.3942 - categorical_accuracy: 0.8544 - val_loss: 0.4250 - val_categorical_accuracy: 0.8477\n",
      "Epoch 32/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.3868 - categorical_accuracy: 0.8505Epoch 32: loss = 0.3949875235557556, val_loss = 0.4312266409397125\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.3950 - categorical_accuracy: 0.8468 - val_loss: 0.4312 - val_categorical_accuracy: 0.8545\n",
      "Epoch 33/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 0.3865 - categorical_accuracy: 0.8363Epoch 33: loss = 0.3778223991394043, val_loss = 0.4272097945213318\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.3778 - categorical_accuracy: 0.8407 - val_loss: 0.4272 - val_categorical_accuracy: 0.8568\n",
      "Epoch 34/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.3719 - categorical_accuracy: 0.8412Epoch 34: loss = 0.3779599964618683, val_loss = 0.44118911027908325\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.3780 - categorical_accuracy: 0.8392 - val_loss: 0.4412 - val_categorical_accuracy: 0.8401\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.3556 - categorical_accuracy: 0.8605Epoch 35: loss = 0.35561472177505493, val_loss = 0.457253634929657\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.3556 - categorical_accuracy: 0.8605 - val_loss: 0.4573 - val_categorical_accuracy: 0.8462\n",
      "Epoch 36/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.3726 - categorical_accuracy: 0.8550Restoring model weights from the end of the best epoch: 31.\n",
      "Epoch 36: loss = 0.376418799161911, val_loss = 0.5945029854774475\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.3764 - categorical_accuracy: 0.8559 - val_loss: 0.5945 - val_categorical_accuracy: 0.7852\n",
      "Epoch 36: early stopping\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.4250 - categorical_accuracy: 0.8477\n",
      "Epoch 1/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 3.0670 - categorical_accuracy: 0.0812Epoch 1: loss = 3.056771993637085, val_loss = 2.618426561355591\n",
      "42/42 [==============================] - 2s 17ms/step - loss: 3.0568 - categorical_accuracy: 0.0845 - val_loss: 2.6184 - val_categorical_accuracy: 0.1936\n",
      "Epoch 2/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.5368 - categorical_accuracy: 0.1914Epoch 2: loss = 2.531810760498047, val_loss = 2.205759286880493\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 2.5318 - categorical_accuracy: 0.1912 - val_loss: 2.2058 - val_categorical_accuracy: 0.2965\n",
      "Epoch 3/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.1082 - categorical_accuracy: 0.3000Epoch 3: loss = 2.1048498153686523, val_loss = 1.842907428741455\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 2.1048 - categorical_accuracy: 0.2986 - val_loss: 1.8429 - val_categorical_accuracy: 0.3834\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.8090 - categorical_accuracy: 0.3869Epoch 4: loss = 1.8090078830718994, val_loss = 1.8305368423461914\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1.8090 - categorical_accuracy: 0.3869 - val_loss: 1.8305 - val_categorical_accuracy: 0.3788\n",
      "Epoch 5/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 1.6673 - categorical_accuracy: 0.4127Epoch 5: loss = 1.6711266040802002, val_loss = 1.3993444442749023\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 1.6711 - categorical_accuracy: 0.4136 - val_loss: 1.3993 - val_categorical_accuracy: 0.5053\n",
      "Epoch 6/50\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 1.4644 - categorical_accuracy: 0.4774Epoch 6: loss = 1.4571062326431274, val_loss = 1.1968427896499634\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1.4571 - categorical_accuracy: 0.4783 - val_loss: 1.1968 - val_categorical_accuracy: 0.6075\n",
      "Epoch 7/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 1.2957 - categorical_accuracy: 0.5312Epoch 7: loss = 1.2969337701797485, val_loss = 1.101577639579773\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 1.2969 - categorical_accuracy: 0.5301 - val_loss: 1.1016 - val_categorical_accuracy: 0.6387\n",
      "Epoch 8/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 1.1804 - categorical_accuracy: 0.5817Epoch 8: loss = 1.1725291013717651, val_loss = 1.0333657264709473\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1.1725 - categorical_accuracy: 0.5826 - val_loss: 1.0334 - val_categorical_accuracy: 0.6463\n",
      "Epoch 9/50\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 1.1965 - categorical_accuracy: 0.5634Epoch 9: loss = 1.1890567541122437, val_loss = 0.9624444842338562\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 1.1891 - categorical_accuracy: 0.5666 - val_loss: 0.9624 - val_categorical_accuracy: 0.6738\n",
      "Epoch 10/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.1043 - categorical_accuracy: 0.5968Epoch 10: loss = 1.1048688888549805, val_loss = 0.9700155258178711\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1.1049 - categorical_accuracy: 0.5963 - val_loss: 0.9700 - val_categorical_accuracy: 0.6799\n",
      "Epoch 11/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.0599 - categorical_accuracy: 0.6133Epoch 11: loss = 1.0554156303405762, val_loss = 0.7903568744659424\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 1.0554 - categorical_accuracy: 0.6154 - val_loss: 0.7904 - val_categorical_accuracy: 0.7401\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.9065 - categorical_accuracy: 0.6702Epoch 12: loss = 0.9065179228782654, val_loss = 0.8281499147415161\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.9065 - categorical_accuracy: 0.6702 - val_loss: 0.8281 - val_categorical_accuracy: 0.7142\n",
      "Epoch 13/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.9034 - categorical_accuracy: 0.6727Epoch 13: loss = 0.9113568663597107, val_loss = 0.9818041920661926\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 0.9114 - categorical_accuracy: 0.6687 - val_loss: 0.9818 - val_categorical_accuracy: 0.6380\n",
      "Epoch 14/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.9384 - categorical_accuracy: 0.6654Epoch 14: loss = 0.939470112323761, val_loss = 0.7824591398239136\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.9395 - categorical_accuracy: 0.6649 - val_loss: 0.7825 - val_categorical_accuracy: 0.7043\n",
      "Epoch 15/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.8868 - categorical_accuracy: 0.6667Epoch 15: loss = 0.8853488564491272, val_loss = 0.7331723570823669\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.8853 - categorical_accuracy: 0.6657 - val_loss: 0.7332 - val_categorical_accuracy: 0.7370\n",
      "Epoch 16/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.7731 - categorical_accuracy: 0.7141Epoch 16: loss = 0.7695862054824829, val_loss = 0.7771535515785217\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.7696 - categorical_accuracy: 0.7159 - val_loss: 0.7772 - val_categorical_accuracy: 0.7012\n",
      "Epoch 17/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.9296 - categorical_accuracy: 0.6586Epoch 17: loss = 0.9203457236289978, val_loss = 0.7287100553512573\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.9203 - categorical_accuracy: 0.6603 - val_loss: 0.7287 - val_categorical_accuracy: 0.7470\n",
      "Epoch 18/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.7583 - categorical_accuracy: 0.7262Epoch 18: loss = 0.7569921612739563, val_loss = 0.7054372429847717\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.7570 - categorical_accuracy: 0.7258 - val_loss: 0.7054 - val_categorical_accuracy: 0.7454\n",
      "Epoch 19/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.7092 - categorical_accuracy: 0.7276Epoch 19: loss = 0.7100193500518799, val_loss = 0.6230122447013855\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.7100 - categorical_accuracy: 0.7266 - val_loss: 0.6230 - val_categorical_accuracy: 0.7820\n",
      "Epoch 20/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.7014 - categorical_accuracy: 0.7305Epoch 20: loss = 0.6995859742164612, val_loss = 0.6179841756820679\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.6996 - categorical_accuracy: 0.7296 - val_loss: 0.6180 - val_categorical_accuracy: 0.7904\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.6606 - categorical_accuracy: 0.7426Epoch 21: loss = 0.6606317758560181, val_loss = 0.6179664134979248\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.6606 - categorical_accuracy: 0.7426 - val_loss: 0.6180 - val_categorical_accuracy: 0.7950\n",
      "Epoch 22/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.6127 - categorical_accuracy: 0.7716Epoch 22: loss = 0.6242314577102661, val_loss = 0.5641505718231201\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.6242 - categorical_accuracy: 0.7669 - val_loss: 0.5642 - val_categorical_accuracy: 0.7881\n",
      "Epoch 23/50\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.6170 - categorical_accuracy: 0.7750Epoch 23: loss = 0.6224932670593262, val_loss = 0.6142473220825195\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.6225 - categorical_accuracy: 0.7784 - val_loss: 0.6142 - val_categorical_accuracy: 0.7790\n",
      "Epoch 24/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.6057 - categorical_accuracy: 0.7789Epoch 24: loss = 0.6038458943367004, val_loss = 1.5986195802688599\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.6038 - categorical_accuracy: 0.7784 - val_loss: 1.5986 - val_categorical_accuracy: 0.5465\n",
      "Epoch 25/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.1660 - categorical_accuracy: 0.6195Epoch 25: loss = 1.1535106897354126, val_loss = 0.6834278702735901\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 1.1535 - categorical_accuracy: 0.6238 - val_loss: 0.6834 - val_categorical_accuracy: 0.7515\n",
      "Epoch 26/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.6739 - categorical_accuracy: 0.7475Epoch 26: loss = 0.6775047779083252, val_loss = 0.5881674885749817\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.6775 - categorical_accuracy: 0.7441 - val_loss: 0.5882 - val_categorical_accuracy: 0.7980\n",
      "Epoch 27/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.6112 - categorical_accuracy: 0.7727Epoch 27: loss = 0.6083858013153076, val_loss = 0.5545874238014221\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.6084 - categorical_accuracy: 0.7746 - val_loss: 0.5546 - val_categorical_accuracy: 0.8079\n",
      "Epoch 28/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.5674 - categorical_accuracy: 0.7828Epoch 28: loss = 0.5722103714942932, val_loss = 0.6912415027618408\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.5722 - categorical_accuracy: 0.7791 - val_loss: 0.6912 - val_categorical_accuracy: 0.7645\n",
      "Epoch 29/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.6812 - categorical_accuracy: 0.7452Epoch 29: loss = 0.6758254766464233, val_loss = 0.5543193221092224\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.6758 - categorical_accuracy: 0.7464 - val_loss: 0.5543 - val_categorical_accuracy: 0.8034\n",
      "Epoch 30/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.5305 - categorical_accuracy: 0.8026Epoch 30: loss = 0.5301361680030823, val_loss = 0.5021894574165344\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.5301 - categorical_accuracy: 0.8027 - val_loss: 0.5022 - val_categorical_accuracy: 0.8209\n",
      "Epoch 31/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.5322 - categorical_accuracy: 0.7961Epoch 31: loss = 0.5356898307800293, val_loss = 0.619029700756073\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.5357 - categorical_accuracy: 0.7944 - val_loss: 0.6190 - val_categorical_accuracy: 0.7812\n",
      "Epoch 32/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.7025 - categorical_accuracy: 0.7398Epoch 32: loss = 0.6962645649909973, val_loss = 0.521160900592804\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.6963 - categorical_accuracy: 0.7433 - val_loss: 0.5212 - val_categorical_accuracy: 0.8163\n",
      "Epoch 33/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.5383 - categorical_accuracy: 0.8037Epoch 33: loss = 0.5470836758613586, val_loss = 0.5403237342834473\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.5471 - categorical_accuracy: 0.7989 - val_loss: 0.5403 - val_categorical_accuracy: 0.8018\n",
      "Epoch 34/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.7289 - categorical_accuracy: 0.7316Epoch 34: loss = 0.72255939245224, val_loss = 0.5473926663398743\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.7226 - categorical_accuracy: 0.7350 - val_loss: 0.5474 - val_categorical_accuracy: 0.8011\n",
      "Epoch 35/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.5098 - categorical_accuracy: 0.8086Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 35: loss = 0.5093220472335815, val_loss = 0.5754379034042358\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.5093 - categorical_accuracy: 0.8088 - val_loss: 0.5754 - val_categorical_accuracy: 0.7881\n",
      "Epoch 35: early stopping\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.5022 - categorical_accuracy: 0.8209\n",
      "Epoch 1/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 3.1276 - categorical_accuracy: 0.0769Epoch 1: loss = 3.117886543273926, val_loss = 2.896787166595459\n",
      "41/41 [==============================] - 2s 16ms/step - loss: 3.1179 - categorical_accuracy: 0.0755 - val_loss: 2.8968 - val_categorical_accuracy: 0.0944\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.7486 - categorical_accuracy: 0.1128Epoch 2: loss = 2.7486143112182617, val_loss = 2.6124799251556396\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 2.7486 - categorical_accuracy: 0.1128 - val_loss: 2.6125 - val_categorical_accuracy: 0.1173\n",
      "Epoch 3/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 2.4401 - categorical_accuracy: 0.1875Epoch 3: loss = 2.4338362216949463, val_loss = 2.2360384464263916\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 2.4338 - categorical_accuracy: 0.1875 - val_loss: 2.2360 - val_categorical_accuracy: 0.2620\n",
      "Epoch 4/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 2.0878 - categorical_accuracy: 0.2763Epoch 4: loss = 2.0872480869293213, val_loss = 1.9359633922576904\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 2.0872 - categorical_accuracy: 0.2744 - val_loss: 1.9360 - val_categorical_accuracy: 0.3092\n",
      "Epoch 5/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 1.8922 - categorical_accuracy: 0.3316Epoch 5: loss = 1.8503985404968262, val_loss = 1.610561728477478\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.8504 - categorical_accuracy: 0.3506 - val_loss: 1.6106 - val_categorical_accuracy: 0.5194\n",
      "Epoch 6/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 1.6630 - categorical_accuracy: 0.3993Epoch 6: loss = 1.6504077911376953, val_loss = 1.4380404949188232\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 1.6504 - categorical_accuracy: 0.4070 - val_loss: 1.4380 - val_categorical_accuracy: 0.5019\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.4697 - categorical_accuracy: 0.4627Epoch 7: loss = 1.4696736335754395, val_loss = 1.2667893171310425\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.4697 - categorical_accuracy: 0.4627 - val_loss: 1.2668 - val_categorical_accuracy: 0.6215\n",
      "Epoch 8/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 1.3732 - categorical_accuracy: 0.5082Epoch 8: loss = 1.36030912399292, val_loss = 1.1270726919174194\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 1.3603 - categorical_accuracy: 0.5152 - val_loss: 1.1271 - val_categorical_accuracy: 0.6200\n",
      "Epoch 9/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.2521 - categorical_accuracy: 0.5389Epoch 9: loss = 1.2497227191925049, val_loss = 1.0574151277542114\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.2497 - categorical_accuracy: 0.5373 - val_loss: 1.0574 - val_categorical_accuracy: 0.6542\n",
      "Epoch 10/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 1.1339 - categorical_accuracy: 0.5913Epoch 10: loss = 1.1355699300765991, val_loss = 0.9997901916503906\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.1356 - categorical_accuracy: 0.5938 - val_loss: 0.9998 - val_categorical_accuracy: 0.6679\n",
      "Epoch 11/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.0954 - categorical_accuracy: 0.6062Epoch 11: loss = 1.0926889181137085, val_loss = 0.9887823462486267\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 1.0927 - categorical_accuracy: 0.6052 - val_loss: 0.9888 - val_categorical_accuracy: 0.6695\n",
      "Epoch 12/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.0426 - categorical_accuracy: 0.6394Epoch 12: loss = 1.0354053974151611, val_loss = 0.8728736042976379\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.0354 - categorical_accuracy: 0.6380 - val_loss: 0.8729 - val_categorical_accuracy: 0.7205\n",
      "Epoch 13/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 0.9841 - categorical_accuracy: 0.6595Epoch 13: loss = 0.9695325493812561, val_loss = 0.8310903906822205\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 0.9695 - categorical_accuracy: 0.6631 - val_loss: 0.8311 - val_categorical_accuracy: 0.7152\n",
      "Epoch 14/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.9280 - categorical_accuracy: 0.6537Epoch 14: loss = 0.9183016419410706, val_loss = 0.7865106463432312\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 0.9183 - categorical_accuracy: 0.6623 - val_loss: 0.7865 - val_categorical_accuracy: 0.7464\n",
      "Epoch 15/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.9161 - categorical_accuracy: 0.6623Epoch 15: loss = 0.9012944102287292, val_loss = 0.8091335296630859\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 0.9013 - categorical_accuracy: 0.6692 - val_loss: 0.8091 - val_categorical_accuracy: 0.7304\n",
      "Epoch 16/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 0.8030 - categorical_accuracy: 0.7097Epoch 16: loss = 0.8114541172981262, val_loss = 0.7314298748970032\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.8115 - categorical_accuracy: 0.7027 - val_loss: 0.7314 - val_categorical_accuracy: 0.7502\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.7700 - categorical_accuracy: 0.7264Epoch 17: loss = 0.770025372505188, val_loss = 0.7311246395111084\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 0.7700 - categorical_accuracy: 0.7264 - val_loss: 0.7311 - val_categorical_accuracy: 0.7517\n",
      "Epoch 18/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 0.7685 - categorical_accuracy: 0.7253Epoch 18: loss = 0.7633119225502014, val_loss = 0.6903924345970154\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.7633 - categorical_accuracy: 0.7287 - val_loss: 0.6904 - val_categorical_accuracy: 0.7807\n",
      "Epoch 19/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 0.7282 - categorical_accuracy: 0.7357Epoch 19: loss = 0.7179734110832214, val_loss = 0.6529483199119568\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.7180 - categorical_accuracy: 0.7370 - val_loss: 0.6529 - val_categorical_accuracy: 0.7692\n",
      "Epoch 20/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 0.7281 - categorical_accuracy: 0.7303Epoch 20: loss = 0.7435612082481384, val_loss = 0.6773103475570679\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 0.7436 - categorical_accuracy: 0.7233 - val_loss: 0.6773 - val_categorical_accuracy: 0.7517\n",
      "Epoch 21/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.6750 - categorical_accuracy: 0.7449Epoch 21: loss = 0.6669851541519165, val_loss = 0.6291345357894897\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.6670 - categorical_accuracy: 0.7500 - val_loss: 0.6291 - val_categorical_accuracy: 0.7784\n",
      "Epoch 22/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.6647 - categorical_accuracy: 0.7588Epoch 22: loss = 0.6615694761276245, val_loss = 0.7169446349143982\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.6616 - categorical_accuracy: 0.7599 - val_loss: 0.7169 - val_categorical_accuracy: 0.7403\n",
      "Epoch 23/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.6785 - categorical_accuracy: 0.7523Epoch 23: loss = 0.6821045279502869, val_loss = 0.6266879439353943\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 0.6821 - categorical_accuracy: 0.7515 - val_loss: 0.6267 - val_categorical_accuracy: 0.7829\n",
      "Epoch 24/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.6505 - categorical_accuracy: 0.7483Epoch 24: loss = 0.6382194757461548, val_loss = 0.5994014143943787\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.6382 - categorical_accuracy: 0.7530 - val_loss: 0.5994 - val_categorical_accuracy: 0.7883\n",
      "Epoch 25/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.5644 - categorical_accuracy: 0.7863Epoch 25: loss = 0.5709795951843262, val_loss = 0.5699731707572937\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 0.5710 - categorical_accuracy: 0.7858 - val_loss: 0.5700 - val_categorical_accuracy: 0.8073\n",
      "Epoch 26/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.6202 - categorical_accuracy: 0.7760Epoch 26: loss = 0.6320884227752686, val_loss = 0.597655713558197\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.6321 - categorical_accuracy: 0.7721 - val_loss: 0.5977 - val_categorical_accuracy: 0.7791\n",
      "Epoch 27/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.5904 - categorical_accuracy: 0.7901Epoch 27: loss = 0.5892147421836853, val_loss = 0.5292056798934937\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 0.5892 - categorical_accuracy: 0.7881 - val_loss: 0.5292 - val_categorical_accuracy: 0.8248\n",
      "Epoch 28/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.5678 - categorical_accuracy: 0.7875Epoch 28: loss = 0.5697250366210938, val_loss = 0.616024374961853\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.5697 - categorical_accuracy: 0.7851 - val_loss: 0.6160 - val_categorical_accuracy: 0.7685\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.5505 - categorical_accuracy: 0.8034Epoch 29: loss = 0.5504846572875977, val_loss = 0.5954126119613647\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 0.5505 - categorical_accuracy: 0.8034 - val_loss: 0.5954 - val_categorical_accuracy: 0.7738\n",
      "Epoch 30/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.5778 - categorical_accuracy: 0.7909Epoch 30: loss = 0.576492428779602, val_loss = 0.5341041088104248\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.5765 - categorical_accuracy: 0.7904 - val_loss: 0.5341 - val_categorical_accuracy: 0.8134\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.5717 - categorical_accuracy: 0.7889Epoch 31: loss = 0.5716954469680786, val_loss = 0.5176467299461365\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.5717 - categorical_accuracy: 0.7889 - val_loss: 0.5176 - val_categorical_accuracy: 0.8279\n",
      "Epoch 32/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 0.5443 - categorical_accuracy: 0.8092Epoch 32: loss = 0.5504795908927917, val_loss = 0.5565630793571472\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 0.5505 - categorical_accuracy: 0.8072 - val_loss: 0.5566 - val_categorical_accuracy: 0.8134\n",
      "Epoch 33/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.5010 - categorical_accuracy: 0.8015Epoch 33: loss = 0.5082616209983826, val_loss = 0.4808541238307953\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.5083 - categorical_accuracy: 0.8018 - val_loss: 0.4809 - val_categorical_accuracy: 0.8347\n",
      "Epoch 34/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 0.4900 - categorical_accuracy: 0.8152Epoch 34: loss = 0.49302932620048523, val_loss = 0.4584499001502991\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.4930 - categorical_accuracy: 0.8133 - val_loss: 0.4584 - val_categorical_accuracy: 0.8294\n",
      "Epoch 35/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.4722 - categorical_accuracy: 0.8133Epoch 35: loss = 0.48085105419158936, val_loss = 0.49214065074920654\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.4809 - categorical_accuracy: 0.8117 - val_loss: 0.4921 - val_categorical_accuracy: 0.8218\n",
      "Epoch 36/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.5448 - categorical_accuracy: 0.7931Epoch 36: loss = 0.5571900606155396, val_loss = 0.48865368962287903\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 0.5572 - categorical_accuracy: 0.7904 - val_loss: 0.4887 - val_categorical_accuracy: 0.8393\n",
      "Epoch 37/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.4568 - categorical_accuracy: 0.8247Epoch 37: loss = 0.4676007926464081, val_loss = 0.5571793913841248\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.4676 - categorical_accuracy: 0.8178 - val_loss: 0.5572 - val_categorical_accuracy: 0.8027\n",
      "Epoch 38/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 0.4717 - categorical_accuracy: 0.8134Epoch 38: loss = 0.4661920964717865, val_loss = 0.49874913692474365\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.4662 - categorical_accuracy: 0.8171 - val_loss: 0.4987 - val_categorical_accuracy: 0.8241\n",
      "Epoch 39/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.5011 - categorical_accuracy: 0.8039Restoring model weights from the end of the best epoch: 34.\n",
      "Epoch 39: loss = 0.500459611415863, val_loss = 0.5260652899742126\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.5005 - categorical_accuracy: 0.8056 - val_loss: 0.5261 - val_categorical_accuracy: 0.8165\n",
      "Epoch 39: early stopping\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4584 - categorical_accuracy: 0.8294\n",
      "Epoch 1/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 3.1445 - categorical_accuracy: 0.0688Epoch 1: loss = 3.133897542953491, val_loss = 2.8589468002319336\n",
      "42/42 [==============================] - 2s 16ms/step - loss: 3.1339 - categorical_accuracy: 0.0724 - val_loss: 2.8589 - val_categorical_accuracy: 0.0869\n",
      "Epoch 2/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 2.8094 - categorical_accuracy: 0.0817Epoch 2: loss = 2.803969144821167, val_loss = 2.5391409397125244\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 2.8040 - categorical_accuracy: 0.0830 - val_loss: 2.5391 - val_categorical_accuracy: 0.2683\n",
      "Epoch 3/50\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 2.5085 - categorical_accuracy: 0.1780Epoch 3: loss = 2.5068888664245605, val_loss = 2.2307345867156982\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 2.5069 - categorical_accuracy: 0.1706 - val_loss: 2.2307 - val_categorical_accuracy: 0.3407\n",
      "Epoch 4/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 2.2333 - categorical_accuracy: 0.2444Epoch 4: loss = 2.22355055809021, val_loss = 2.0426299571990967\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 2.2236 - categorical_accuracy: 0.2490 - val_loss: 2.0426 - val_categorical_accuracy: 0.3620\n",
      "Epoch 5/50\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 2.0449 - categorical_accuracy: 0.2734Epoch 5: loss = 2.035867929458618, val_loss = 1.6759378910064697\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 2.0359 - categorical_accuracy: 0.2826 - val_loss: 1.6759 - val_categorical_accuracy: 0.4672\n",
      "Epoch 6/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.7640 - categorical_accuracy: 0.3891Epoch 6: loss = 1.7661727666854858, val_loss = 1.4299222230911255\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 1.7662 - categorical_accuracy: 0.3861 - val_loss: 1.4299 - val_categorical_accuracy: 0.5564\n",
      "Epoch 7/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.6490 - categorical_accuracy: 0.4108Epoch 7: loss = 1.649876356124878, val_loss = 1.3664023876190186\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1.6499 - categorical_accuracy: 0.4105 - val_loss: 1.3664 - val_categorical_accuracy: 0.5198\n",
      "Epoch 8/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.4217 - categorical_accuracy: 0.4893Epoch 8: loss = 1.4222182035446167, val_loss = 1.104292392730713\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1.4222 - categorical_accuracy: 0.4890 - val_loss: 1.1043 - val_categorical_accuracy: 0.6654\n",
      "Epoch 9/50\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 1.3611 - categorical_accuracy: 0.5217Epoch 9: loss = 1.3450446128845215, val_loss = 1.1150482892990112\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 1.3450 - categorical_accuracy: 0.5301 - val_loss: 1.1150 - val_categorical_accuracy: 0.6159\n",
      "Epoch 10/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.2100 - categorical_accuracy: 0.5695Epoch 10: loss = 1.2171497344970703, val_loss = 0.9698582291603088\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 1.2171 - categorical_accuracy: 0.5666 - val_loss: 0.9699 - val_categorical_accuracy: 0.6745\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1743 - categorical_accuracy: 0.5613Epoch 11: loss = 1.174336314201355, val_loss = 0.9355378746986389\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1.1743 - categorical_accuracy: 0.5613 - val_loss: 0.9355 - val_categorical_accuracy: 0.6905\n",
      "Epoch 12/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 1.1196 - categorical_accuracy: 0.5938Epoch 12: loss = 1.1104775667190552, val_loss = 0.8336098194122314\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 1.1105 - categorical_accuracy: 0.5963 - val_loss: 0.8336 - val_categorical_accuracy: 0.7172\n",
      "Epoch 13/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.0765 - categorical_accuracy: 0.6055Epoch 13: loss = 1.0799598693847656, val_loss = 0.8043646216392517\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 1.0800 - categorical_accuracy: 0.6040 - val_loss: 0.8044 - val_categorical_accuracy: 0.7370\n",
      "Epoch 14/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.9844 - categorical_accuracy: 0.6383Epoch 14: loss = 0.982620358467102, val_loss = 0.8627103567123413\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.9826 - categorical_accuracy: 0.6390 - val_loss: 0.8627 - val_categorical_accuracy: 0.7027\n",
      "Epoch 15/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.0110 - categorical_accuracy: 0.6425Epoch 15: loss = 1.0114067792892456, val_loss = 0.7574852108955383\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1.0114 - categorical_accuracy: 0.6420 - val_loss: 0.7575 - val_categorical_accuracy: 0.7454\n",
      "Epoch 16/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.9347 - categorical_accuracy: 0.6667Epoch 16: loss = 0.9331395626068115, val_loss = 0.7237372398376465\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.9331 - categorical_accuracy: 0.6657 - val_loss: 0.7237 - val_categorical_accuracy: 0.7652\n",
      "Epoch 17/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.9224 - categorical_accuracy: 0.6608Epoch 17: loss = 0.9219543933868408, val_loss = 0.7411715388298035\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.9220 - categorical_accuracy: 0.6611 - val_loss: 0.7412 - val_categorical_accuracy: 0.7370\n",
      "Epoch 18/50\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.8609 - categorical_accuracy: 0.6936Epoch 18: loss = 0.8751350045204163, val_loss = 0.7109242081642151\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.8751 - categorical_accuracy: 0.6870 - val_loss: 0.7109 - val_categorical_accuracy: 0.7698\n",
      "Epoch 19/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.9186 - categorical_accuracy: 0.6456Epoch 19: loss = 0.9179277420043945, val_loss = 0.7295241951942444\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.9179 - categorical_accuracy: 0.6458 - val_loss: 0.7295 - val_categorical_accuracy: 0.7431\n",
      "Epoch 20/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.8053 - categorical_accuracy: 0.7055Epoch 20: loss = 0.8091409802436829, val_loss = 0.7270985841751099\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.8091 - categorical_accuracy: 0.7053 - val_loss: 0.7271 - val_categorical_accuracy: 0.7325\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.8208 - categorical_accuracy: 0.6855Epoch 21: loss = 0.8207516074180603, val_loss = 0.7585293650627136\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.8208 - categorical_accuracy: 0.6855 - val_loss: 0.7585 - val_categorical_accuracy: 0.7157\n",
      "Epoch 22/50\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.8034 - categorical_accuracy: 0.7127Epoch 22: loss = 0.7915142178535461, val_loss = 0.6547065377235413\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.7915 - categorical_accuracy: 0.7152 - val_loss: 0.6547 - val_categorical_accuracy: 0.7721\n",
      "Epoch 23/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.7383 - categorical_accuracy: 0.7180Epoch 23: loss = 0.7385421991348267, val_loss = 0.5546383261680603\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.7385 - categorical_accuracy: 0.7182 - val_loss: 0.5546 - val_categorical_accuracy: 0.8117\n",
      "Epoch 24/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.8223 - categorical_accuracy: 0.6795Epoch 24: loss = 0.8113449215888977, val_loss = 0.6719812154769897\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.8113 - categorical_accuracy: 0.6855 - val_loss: 0.6720 - val_categorical_accuracy: 0.7660\n",
      "Epoch 25/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.0461 - categorical_accuracy: 0.6438Epoch 25: loss = 1.0350700616836548, val_loss = 0.7359610795974731\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 1.0351 - categorical_accuracy: 0.6466 - val_loss: 0.7360 - val_categorical_accuracy: 0.7424\n",
      "Epoch 26/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.8615 - categorical_accuracy: 0.6931Epoch 26: loss = 0.8525216579437256, val_loss = 0.5777108073234558\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.8525 - categorical_accuracy: 0.6946 - val_loss: 0.5777 - val_categorical_accuracy: 0.7889\n",
      "Epoch 27/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.6477 - categorical_accuracy: 0.7617Epoch 27: loss = 0.6481053829193115, val_loss = 0.5487363934516907\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.6481 - categorical_accuracy: 0.7609 - val_loss: 0.5487 - val_categorical_accuracy: 0.8064\n",
      "Epoch 28/50\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.6972 - categorical_accuracy: 0.7196Epoch 28: loss = 0.691942036151886, val_loss = 0.5594699382781982\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.6919 - categorical_accuracy: 0.7243 - val_loss: 0.5595 - val_categorical_accuracy: 0.7950\n",
      "Epoch 29/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.7237 - categorical_accuracy: 0.7292Epoch 29: loss = 0.729921281337738, val_loss = 0.710648238658905\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.7299 - categorical_accuracy: 0.7251 - val_loss: 0.7106 - val_categorical_accuracy: 0.7340\n",
      "Epoch 30/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.9400 - categorical_accuracy: 0.6645Epoch 30: loss = 0.9201009273529053, val_loss = 0.5693631172180176\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.9201 - categorical_accuracy: 0.6748 - val_loss: 0.5694 - val_categorical_accuracy: 0.7904\n",
      "Epoch 31/50\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.6659 - categorical_accuracy: 0.7413Epoch 31: loss = 0.6596277952194214, val_loss = 0.6267624497413635\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.6596 - categorical_accuracy: 0.7456 - val_loss: 0.6268 - val_categorical_accuracy: 0.7683\n",
      "Epoch 32/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.6278 - categorical_accuracy: 0.7548Restoring model weights from the end of the best epoch: 27.\n",
      "Epoch 32: loss = 0.6277080178260803, val_loss = 0.5517181754112244\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.6277 - categorical_accuracy: 0.7532 - val_loss: 0.5517 - val_categorical_accuracy: 0.7995\n",
      "Epoch 32: early stopping\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.5487 - categorical_accuracy: 0.8064\n",
      "Epoch 1/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 3.2314 - categorical_accuracy: 0.0431Epoch 1: loss = 3.2218759059906006, val_loss = 3.1483054161071777\n",
      "41/41 [==============================] - 2s 16ms/step - loss: 3.2219 - categorical_accuracy: 0.0427 - val_loss: 3.1483 - val_categorical_accuracy: 0.0457\n",
      "Epoch 2/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 3.0109 - categorical_accuracy: 0.0825Epoch 2: loss = 3.002032518386841, val_loss = 2.892524003982544\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 3.0020 - categorical_accuracy: 0.0823 - val_loss: 2.8925 - val_categorical_accuracy: 0.1165\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.8054 - categorical_accuracy: 0.1303Epoch 3: loss = 2.805421829223633, val_loss = 2.6430649757385254\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 2.8054 - categorical_accuracy: 0.1303 - val_loss: 2.6431 - val_categorical_accuracy: 0.1363\n",
      "Epoch 4/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 2.5849 - categorical_accuracy: 0.1446Epoch 4: loss = 2.565998077392578, val_loss = 2.442699432373047\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 2.5660 - categorical_accuracy: 0.1517 - val_loss: 2.4427 - val_categorical_accuracy: 0.1790\n",
      "Epoch 5/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 2.4267 - categorical_accuracy: 0.1900Epoch 5: loss = 2.4189796447753906, val_loss = 2.2421047687530518\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 2.4190 - categorical_accuracy: 0.1921 - val_loss: 2.2421 - val_categorical_accuracy: 0.2658\n",
      "Epoch 6/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 2.2638 - categorical_accuracy: 0.2286Epoch 6: loss = 2.2579691410064697, val_loss = 2.116117477416992\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 2.2580 - categorical_accuracy: 0.2271 - val_loss: 2.1161 - val_categorical_accuracy: 0.2963\n",
      "Epoch 7/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 2.1064 - categorical_accuracy: 0.2665Epoch 7: loss = 2.096966505050659, val_loss = 1.8793503046035767\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 2.0970 - categorical_accuracy: 0.2713 - val_loss: 1.8794 - val_categorical_accuracy: 0.3412\n",
      "Epoch 8/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.9439 - categorical_accuracy: 0.3189Epoch 8: loss = 1.9351774454116821, val_loss = 1.7504252195358276\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 1.9352 - categorical_accuracy: 0.3194 - val_loss: 1.7504 - val_categorical_accuracy: 0.3861\n",
      "Epoch 9/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 1.8765 - categorical_accuracy: 0.3393Epoch 9: loss = 1.854807734489441, val_loss = 1.6569501161575317\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.8548 - categorical_accuracy: 0.3460 - val_loss: 1.6570 - val_categorical_accuracy: 0.4859\n",
      "Epoch 10/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 1.7582 - categorical_accuracy: 0.3830Epoch 10: loss = 1.7571519613265991, val_loss = 1.550066351890564\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.7572 - categorical_accuracy: 0.3841 - val_loss: 1.5501 - val_categorical_accuracy: 0.4806\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.6512 - categorical_accuracy: 0.4177Epoch 11: loss = 1.651241421699524, val_loss = 1.485691785812378\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 1.6512 - categorical_accuracy: 0.4177 - val_loss: 1.4857 - val_categorical_accuracy: 0.5034\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.5898 - categorical_accuracy: 0.4413Epoch 12: loss = 1.5898011922836304, val_loss = 1.3950062990188599\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.5898 - categorical_accuracy: 0.4413 - val_loss: 1.3950 - val_categorical_accuracy: 0.5545\n",
      "Epoch 13/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 1.5639 - categorical_accuracy: 0.4437Epoch 13: loss = 1.569507122039795, val_loss = 1.3830097913742065\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.5695 - categorical_accuracy: 0.4451 - val_loss: 1.3830 - val_categorical_accuracy: 0.5461\n",
      "Epoch 14/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.5046 - categorical_accuracy: 0.4586Epoch 14: loss = 1.4885350465774536, val_loss = 1.3355145454406738\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.4885 - categorical_accuracy: 0.4642 - val_loss: 1.3355 - val_categorical_accuracy: 0.5407\n",
      "Epoch 15/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 1.4180 - categorical_accuracy: 0.4748Epoch 15: loss = 1.4444236755371094, val_loss = 1.2549362182617188\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 1.4444 - categorical_accuracy: 0.4649 - val_loss: 1.2549 - val_categorical_accuracy: 0.5941\n",
      "Epoch 16/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.3650 - categorical_accuracy: 0.4916Epoch 16: loss = 1.3491833209991455, val_loss = 1.1611100435256958\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.3492 - categorical_accuracy: 0.4909 - val_loss: 1.1611 - val_categorical_accuracy: 0.6215\n",
      "Epoch 17/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.3423 - categorical_accuracy: 0.5184Epoch 17: loss = 1.341409683227539, val_loss = 1.1470704078674316\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.3414 - categorical_accuracy: 0.5198 - val_loss: 1.1471 - val_categorical_accuracy: 0.6337\n",
      "Epoch 18/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 1.3125 - categorical_accuracy: 0.5269Epoch 18: loss = 1.3023180961608887, val_loss = 1.129636287689209\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.3023 - categorical_accuracy: 0.5335 - val_loss: 1.1296 - val_categorical_accuracy: 0.6550\n",
      "Epoch 19/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.2346 - categorical_accuracy: 0.5492Epoch 19: loss = 1.2362351417541504, val_loss = 1.1193701028823853\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 1.2362 - categorical_accuracy: 0.5480 - val_loss: 1.1194 - val_categorical_accuracy: 0.5872\n",
      "Epoch 20/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.2621 - categorical_accuracy: 0.5272Epoch 20: loss = 1.261624813079834, val_loss = 1.0662989616394043\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.2616 - categorical_accuracy: 0.5274 - val_loss: 1.0663 - val_categorical_accuracy: 0.6352\n",
      "Epoch 21/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 1.1669 - categorical_accuracy: 0.5920Epoch 21: loss = 1.1758999824523926, val_loss = 0.9913941025733948\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.1759 - categorical_accuracy: 0.5846 - val_loss: 0.9914 - val_categorical_accuracy: 0.6908\n",
      "Epoch 22/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 1.1621 - categorical_accuracy: 0.5833Epoch 22: loss = 1.1651558876037598, val_loss = 0.9683758020401001\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 1.1652 - categorical_accuracy: 0.5777 - val_loss: 0.9684 - val_categorical_accuracy: 0.6938\n",
      "Epoch 23/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 1.0891 - categorical_accuracy: 0.5929Epoch 23: loss = 1.107013463973999, val_loss = 0.979317307472229\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.1070 - categorical_accuracy: 0.5922 - val_loss: 0.9793 - val_categorical_accuracy: 0.6794\n",
      "Epoch 24/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 1.1681 - categorical_accuracy: 0.5773Epoch 24: loss = 1.1500978469848633, val_loss = 0.9139310121536255\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.1501 - categorical_accuracy: 0.5899 - val_loss: 0.9139 - val_categorical_accuracy: 0.7281\n",
      "Epoch 25/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.0904 - categorical_accuracy: 0.5962Epoch 25: loss = 1.0837819576263428, val_loss = 0.9208521246910095\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 1.0838 - categorical_accuracy: 0.5998 - val_loss: 0.9209 - val_categorical_accuracy: 0.6794\n",
      "Epoch 26/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.0726 - categorical_accuracy: 0.6000Epoch 26: loss = 1.0669090747833252, val_loss = 0.8917701244354248\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.0669 - categorical_accuracy: 0.6021 - val_loss: 0.8918 - val_categorical_accuracy: 0.7205\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0728 - categorical_accuracy: 0.6021Epoch 27: loss = 1.0728329420089722, val_loss = 0.9133806824684143\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 1.0728 - categorical_accuracy: 0.6021 - val_loss: 0.9134 - val_categorical_accuracy: 0.6976\n",
      "Epoch 28/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.0473 - categorical_accuracy: 0.6039Epoch 28: loss = 1.0470523834228516, val_loss = 0.957047164440155\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.0471 - categorical_accuracy: 0.6098 - val_loss: 0.9570 - val_categorical_accuracy: 0.6405\n",
      "Epoch 29/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.9646 - categorical_accuracy: 0.6292Epoch 29: loss = 0.9766822457313538, val_loss = 0.9545952081680298\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 0.9767 - categorical_accuracy: 0.6212 - val_loss: 0.9546 - val_categorical_accuracy: 0.6649\n",
      "Epoch 30/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 1.0578 - categorical_accuracy: 0.6151Epoch 30: loss = 1.0330965518951416, val_loss = 0.9657393097877502\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 1.0331 - categorical_accuracy: 0.6235 - val_loss: 0.9657 - val_categorical_accuracy: 0.6131\n",
      "Epoch 31/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 0.9819 - categorical_accuracy: 0.6473Epoch 31: loss = 0.9618231654167175, val_loss = 0.8631564974784851\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.9618 - categorical_accuracy: 0.6540 - val_loss: 0.8632 - val_categorical_accuracy: 0.6725\n",
      "Epoch 32/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 0.9183 - categorical_accuracy: 0.6455Epoch 32: loss = 0.9179169535636902, val_loss = 0.8212568163871765\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.9179 - categorical_accuracy: 0.6494 - val_loss: 0.8213 - val_categorical_accuracy: 0.7395\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.9272 - categorical_accuracy: 0.6479Epoch 33: loss = 0.9271562099456787, val_loss = 0.8857397437095642\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 0.9272 - categorical_accuracy: 0.6479 - val_loss: 0.8857 - val_categorical_accuracy: 0.7037\n",
      "Epoch 34/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 0.9662 - categorical_accuracy: 0.6545Epoch 34: loss = 0.9558413624763489, val_loss = 0.8267431855201721\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.9558 - categorical_accuracy: 0.6578 - val_loss: 0.8267 - val_categorical_accuracy: 0.7212\n",
      "Epoch 35/50\n",
      "34/41 [=======================>......] - ETA: 0s - loss: 0.9158 - categorical_accuracy: 0.6691Epoch 35: loss = 0.919096052646637, val_loss = 0.8301544785499573\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.9191 - categorical_accuracy: 0.6623 - val_loss: 0.8302 - val_categorical_accuracy: 0.7030\n",
      "Epoch 36/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.8680 - categorical_accuracy: 0.6745Epoch 36: loss = 0.8783060312271118, val_loss = 0.8534746170043945\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.8783 - categorical_accuracy: 0.6692 - val_loss: 0.8535 - val_categorical_accuracy: 0.6969\n",
      "Epoch 37/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.8762 - categorical_accuracy: 0.7008Epoch 37: loss = 0.8765696287155151, val_loss = 0.7837832570075989\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 0.8766 - categorical_accuracy: 0.6974 - val_loss: 0.7838 - val_categorical_accuracy: 0.7350\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.8388 - categorical_accuracy: 0.6829Epoch 38: loss = 0.8388219475746155, val_loss = 0.763936460018158\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.8388 - categorical_accuracy: 0.6829 - val_loss: 0.7639 - val_categorical_accuracy: 0.7365\n",
      "Epoch 39/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.8954 - categorical_accuracy: 0.6655Epoch 39: loss = 0.9022731184959412, val_loss = 0.8740593194961548\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.9023 - categorical_accuracy: 0.6631 - val_loss: 0.8741 - val_categorical_accuracy: 0.6679\n",
      "Epoch 40/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 0.8762 - categorical_accuracy: 0.6687Epoch 40: loss = 0.865915834903717, val_loss = 0.8418810367584229\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 0.8659 - categorical_accuracy: 0.6776 - val_loss: 0.8419 - val_categorical_accuracy: 0.6855\n",
      "Epoch 41/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.7831 - categorical_accuracy: 0.6970Epoch 41: loss = 0.7811501026153564, val_loss = 0.7740163803100586\n",
      "41/41 [==============================] - 1s 12ms/step - loss: 0.7812 - categorical_accuracy: 0.7005 - val_loss: 0.7740 - val_categorical_accuracy: 0.7235\n",
      "Epoch 42/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.7498 - categorical_accuracy: 0.7387Epoch 42: loss = 0.7564701437950134, val_loss = 0.7613245844841003\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.7565 - categorical_accuracy: 0.7363 - val_loss: 0.7613 - val_categorical_accuracy: 0.7205\n",
      "Epoch 43/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 0.8042 - categorical_accuracy: 0.7153Epoch 43: loss = 0.8011637330055237, val_loss = 0.7545154690742493\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.8012 - categorical_accuracy: 0.7149 - val_loss: 0.7545 - val_categorical_accuracy: 0.7281\n",
      "Epoch 44/50\n",
      "34/41 [=======================>......] - ETA: 0s - loss: 0.7718 - categorical_accuracy: 0.6994Epoch 44: loss = 0.7919699549674988, val_loss = 0.8207101225852966\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 0.7920 - categorical_accuracy: 0.6936 - val_loss: 0.8207 - val_categorical_accuracy: 0.7174\n",
      "Epoch 45/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.7938 - categorical_accuracy: 0.7027Epoch 45: loss = 0.7946909666061401, val_loss = 0.7465510964393616\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.7947 - categorical_accuracy: 0.7043 - val_loss: 0.7466 - val_categorical_accuracy: 0.7403\n",
      "Epoch 46/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 0.8490 - categorical_accuracy: 0.6768Epoch 46: loss = 0.8581659197807312, val_loss = 0.812669038772583\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.8582 - categorical_accuracy: 0.6715 - val_loss: 0.8127 - val_categorical_accuracy: 0.6954\n",
      "Epoch 47/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.8087 - categorical_accuracy: 0.7027Epoch 47: loss = 0.7948929667472839, val_loss = 0.7265114784240723\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 0.7949 - categorical_accuracy: 0.7058 - val_loss: 0.7265 - val_categorical_accuracy: 0.7471\n",
      "Epoch 48/50\n",
      "35/41 [========================>.....] - ETA: 0s - loss: 0.7481 - categorical_accuracy: 0.7312Epoch 48: loss = 0.7516832947731018, val_loss = 0.77018141746521\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.7517 - categorical_accuracy: 0.7302 - val_loss: 0.7702 - val_categorical_accuracy: 0.7182\n",
      "Epoch 49/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.7681 - categorical_accuracy: 0.7220Epoch 49: loss = 0.7645368576049805, val_loss = 0.7495772838592529\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.7645 - categorical_accuracy: 0.7233 - val_loss: 0.7496 - val_categorical_accuracy: 0.7228\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.7226 - categorical_accuracy: 0.7287Epoch 50: loss = 0.722557544708252, val_loss = 0.7461124658584595\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 0.7226 - categorical_accuracy: 0.7287 - val_loss: 0.7461 - val_categorical_accuracy: 0.7251\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7461 - categorical_accuracy: 0.7251\n",
      "Epoch 1/50\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 3.2270 - categorical_accuracy: 0.0495Epoch 1: loss = 3.210294246673584, val_loss = 3.0704033374786377\n",
      "42/42 [==============================] - 3s 17ms/step - loss: 3.2103 - categorical_accuracy: 0.0503 - val_loss: 3.0704 - val_categorical_accuracy: 0.0762\n",
      "Epoch 2/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 2.9419 - categorical_accuracy: 0.0822Epoch 2: loss = 2.938016891479492, val_loss = 2.7881381511688232\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 2.9380 - categorical_accuracy: 0.0784 - val_loss: 2.7881 - val_categorical_accuracy: 0.1128\n",
      "Epoch 3/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 2.7749 - categorical_accuracy: 0.0896Epoch 3: loss = 2.7760074138641357, val_loss = 2.6889989376068115\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 2.7760 - categorical_accuracy: 0.0868 - val_loss: 2.6890 - val_categorical_accuracy: 0.0953\n",
      "Epoch 4/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.7371 - categorical_accuracy: 0.0828Epoch 4: loss = 2.7364654541015625, val_loss = 2.6740264892578125\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 2.7365 - categorical_accuracy: 0.0815 - val_loss: 2.6740 - val_categorical_accuracy: 0.0877\n",
      "Epoch 5/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.6939 - categorical_accuracy: 0.0898Epoch 5: loss = 2.6922061443328857, val_loss = 2.6319003105163574\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 2.6922 - categorical_accuracy: 0.0899 - val_loss: 2.6319 - val_categorical_accuracy: 0.0800\n",
      "Epoch 6/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.6841 - categorical_accuracy: 0.0976Epoch 6: loss = 2.6836600303649902, val_loss = 2.620361089706421\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 2.6837 - categorical_accuracy: 0.0975 - val_loss: 2.6204 - val_categorical_accuracy: 0.1052\n",
      "Epoch 7/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 2.6728 - categorical_accuracy: 0.0929Epoch 7: loss = 2.6696105003356934, val_loss = 2.593513011932373\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 2.6696 - categorical_accuracy: 0.0967 - val_loss: 2.5935 - val_categorical_accuracy: 0.1014\n",
      "Epoch 8/50\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 2.6079 - categorical_accuracy: 0.1242Epoch 8: loss = 2.6039087772369385, val_loss = 2.55647611618042\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 2.6039 - categorical_accuracy: 0.1280 - val_loss: 2.5565 - val_categorical_accuracy: 0.1242\n",
      "Epoch 9/50\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 2.5380 - categorical_accuracy: 0.1267Epoch 9: loss = 2.529250144958496, val_loss = 2.4418349266052246\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 2.5293 - categorical_accuracy: 0.1310 - val_loss: 2.4418 - val_categorical_accuracy: 0.1845\n",
      "Epoch 10/50\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 2.4593 - categorical_accuracy: 0.1486Epoch 10: loss = 2.452930212020874, val_loss = 2.319070816040039\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 2.4529 - categorical_accuracy: 0.1546 - val_loss: 2.3191 - val_categorical_accuracy: 0.2348\n",
      "Epoch 11/50\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 2.3831 - categorical_accuracy: 0.1936Epoch 11: loss = 2.368757486343384, val_loss = 2.179126501083374\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 2.3688 - categorical_accuracy: 0.1942 - val_loss: 2.1791 - val_categorical_accuracy: 0.2515\n",
      "Epoch 12/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 2.2260 - categorical_accuracy: 0.2083Epoch 12: loss = 2.2169015407562256, val_loss = 2.076369047164917\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 2.2169 - categorical_accuracy: 0.2117 - val_loss: 2.0764 - val_categorical_accuracy: 0.2652\n",
      "Epoch 13/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 2.1106 - categorical_accuracy: 0.2401Epoch 13: loss = 2.1014773845672607, val_loss = 1.954954743385315\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 2.1015 - categorical_accuracy: 0.2422 - val_loss: 1.9550 - val_categorical_accuracy: 0.3277\n",
      "Epoch 14/50\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 2.0535 - categorical_accuracy: 0.2283Epoch 14: loss = 2.050415515899658, val_loss = 1.9259285926818848\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 2.0504 - categorical_accuracy: 0.2270 - val_loss: 1.9259 - val_categorical_accuracy: 0.2645\n",
      "Epoch 15/50\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 1.9674 - categorical_accuracy: 0.2587Epoch 15: loss = 1.980924129486084, val_loss = 1.8359140157699585\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 1.9809 - categorical_accuracy: 0.2567 - val_loss: 1.8359 - val_categorical_accuracy: 0.3582\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.9578 - categorical_accuracy: 0.2574Epoch 16: loss = 1.957844614982605, val_loss = 1.9165387153625488\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.9578 - categorical_accuracy: 0.2574 - val_loss: 1.9165 - val_categorical_accuracy: 0.3262\n",
      "Epoch 17/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 1.9274 - categorical_accuracy: 0.2837Epoch 17: loss = 1.9226908683776855, val_loss = 1.7686090469360352\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 1.9227 - categorical_accuracy: 0.2818 - val_loss: 1.7686 - val_categorical_accuracy: 0.3681\n",
      "Epoch 18/50\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 1.8702 - categorical_accuracy: 0.2960Epoch 18: loss = 1.871076226234436, val_loss = 1.788258671760559\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 1.8711 - categorical_accuracy: 0.2947 - val_loss: 1.7883 - val_categorical_accuracy: 0.3483\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.9015 - categorical_accuracy: 0.2826Epoch 19: loss = 1.901458501815796, val_loss = 1.7559857368469238\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.9015 - categorical_accuracy: 0.2826 - val_loss: 1.7560 - val_categorical_accuracy: 0.3780\n",
      "Epoch 20/50\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 1.8254 - categorical_accuracy: 0.3030Epoch 20: loss = 1.8279895782470703, val_loss = 1.7007704973220825\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 1.8280 - categorical_accuracy: 0.2955 - val_loss: 1.7008 - val_categorical_accuracy: 0.3750\n",
      "Epoch 21/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.7800 - categorical_accuracy: 0.3281Epoch 21: loss = 1.77976393699646, val_loss = 1.6648706197738647\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.7798 - categorical_accuracy: 0.3267 - val_loss: 1.6649 - val_categorical_accuracy: 0.3933\n",
      "Epoch 22/50\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 1.7525 - categorical_accuracy: 0.3203Epoch 22: loss = 1.7465829849243164, val_loss = 1.6166268587112427\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 1.7466 - categorical_accuracy: 0.3153 - val_loss: 1.6166 - val_categorical_accuracy: 0.4230\n",
      "Epoch 23/50\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 1.7382 - categorical_accuracy: 0.3446Epoch 23: loss = 1.7485706806182861, val_loss = 1.6466355323791504\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 1.7486 - categorical_accuracy: 0.3412 - val_loss: 1.6466 - val_categorical_accuracy: 0.3697\n",
      "Epoch 24/50\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 1.7232 - categorical_accuracy: 0.3353Epoch 24: loss = 1.7201008796691895, val_loss = 1.6729826927185059\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.7201 - categorical_accuracy: 0.3420 - val_loss: 1.6730 - val_categorical_accuracy: 0.3697\n",
      "Epoch 25/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.6774 - categorical_accuracy: 0.3590Epoch 25: loss = 1.6775692701339722, val_loss = 1.6332420110702515\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1.6776 - categorical_accuracy: 0.3587 - val_loss: 1.6332 - val_categorical_accuracy: 0.3704\n",
      "Epoch 26/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.6726 - categorical_accuracy: 0.3659Epoch 26: loss = 1.6733235120773315, val_loss = 1.624715805053711\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 1.6733 - categorical_accuracy: 0.3656 - val_loss: 1.6247 - val_categorical_accuracy: 0.3697\n",
      "Epoch 27/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.7269 - categorical_accuracy: 0.3359Epoch 27: loss = 1.7237643003463745, val_loss = 1.5929630994796753\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.7238 - categorical_accuracy: 0.3397 - val_loss: 1.5930 - val_categorical_accuracy: 0.3872\n",
      "Epoch 28/50\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 1.6446 - categorical_accuracy: 0.3775Epoch 28: loss = 1.637925148010254, val_loss = 1.8033838272094727\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 1.6379 - categorical_accuracy: 0.3785 - val_loss: 1.8034 - val_categorical_accuracy: 0.3049\n",
      "Epoch 29/50\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 1.6202 - categorical_accuracy: 0.3516Epoch 29: loss = 1.6139060258865356, val_loss = 1.9085437059402466\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 1.6139 - categorical_accuracy: 0.3618 - val_loss: 1.9085 - val_categorical_accuracy: 0.2767\n",
      "Epoch 30/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 1.5740 - categorical_accuracy: 0.3849Epoch 30: loss = 1.5896458625793457, val_loss = 1.7066829204559326\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.5896 - categorical_accuracy: 0.3831 - val_loss: 1.7067 - val_categorical_accuracy: 0.3582\n",
      "Epoch 31/50\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 1.6162 - categorical_accuracy: 0.3632Epoch 31: loss = 1.6053147315979004, val_loss = 1.6406757831573486\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 1.6053 - categorical_accuracy: 0.3717 - val_loss: 1.6407 - val_categorical_accuracy: 0.3361\n",
      "Epoch 32/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 1.5582 - categorical_accuracy: 0.3980Restoring model weights from the end of the best epoch: 27.\n",
      "Epoch 32: loss = 1.5528616905212402, val_loss = 1.6191160678863525\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 1.5529 - categorical_accuracy: 0.3968 - val_loss: 1.6191 - val_categorical_accuracy: 0.3849\n",
      "Epoch 32: early stopping\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 1.5930 - categorical_accuracy: 0.3872\n",
      "Epoch 1/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 2.7068 - categorical_accuracy: 0.1602Epoch 1: loss = 2.695028305053711, val_loss = 2.240661859512329\n",
      "82/82 [==============================] - 2s 13ms/step - loss: 2.6950 - categorical_accuracy: 0.1639 - val_loss: 2.2407 - val_categorical_accuracy: 0.2452\n",
      "Epoch 2/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 1.9052 - categorical_accuracy: 0.3462Epoch 2: loss = 1.8943368196487427, val_loss = 1.5490049123764038\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 1.8943 - categorical_accuracy: 0.3453 - val_loss: 1.5490 - val_categorical_accuracy: 0.4783\n",
      "Epoch 3/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 1.4000 - categorical_accuracy: 0.4968Epoch 3: loss = 1.3936583995819092, val_loss = 1.112144947052002\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 1.3937 - categorical_accuracy: 0.5015 - val_loss: 1.1121 - val_categorical_accuracy: 0.6070\n",
      "Epoch 4/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.1551 - categorical_accuracy: 0.5864Epoch 4: loss = 1.156736969947815, val_loss = 1.1571953296661377\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 1.1567 - categorical_accuracy: 0.5861 - val_loss: 1.1572 - val_categorical_accuracy: 0.5659\n",
      "Epoch 5/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9376 - categorical_accuracy: 0.6677Epoch 5: loss = 0.9376081228256226, val_loss = 0.8047898411750793\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.9376 - categorical_accuracy: 0.6677 - val_loss: 0.8048 - val_categorical_accuracy: 0.7212\n",
      "Epoch 6/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 0.8396 - categorical_accuracy: 0.7025Epoch 6: loss = 0.8364662528038025, val_loss = 0.7838144302368164\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.8365 - categorical_accuracy: 0.7035 - val_loss: 0.7838 - val_categorical_accuracy: 0.7312\n",
      "Epoch 7/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.7871 - categorical_accuracy: 0.7068Epoch 7: loss = 0.7859777212142944, val_loss = 0.7322699427604675\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.7860 - categorical_accuracy: 0.7066 - val_loss: 0.7323 - val_categorical_accuracy: 0.7586\n",
      "Epoch 8/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.7030 - categorical_accuracy: 0.7428Epoch 8: loss = 0.6975893974304199, val_loss = 0.6980015635490417\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.6976 - categorical_accuracy: 0.7447 - val_loss: 0.6980 - val_categorical_accuracy: 0.7327\n",
      "Epoch 9/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.6293 - categorical_accuracy: 0.7623Epoch 9: loss = 0.630009651184082, val_loss = 0.6598336100578308\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.6300 - categorical_accuracy: 0.7614 - val_loss: 0.6598 - val_categorical_accuracy: 0.7624\n",
      "Epoch 10/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 0.6497 - categorical_accuracy: 0.7689Epoch 10: loss = 0.6527507901191711, val_loss = 0.7083696722984314\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.6528 - categorical_accuracy: 0.7691 - val_loss: 0.7084 - val_categorical_accuracy: 0.7494\n",
      "Epoch 11/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.6261 - categorical_accuracy: 0.7631Epoch 11: loss = 0.6270352602005005, val_loss = 0.6704267263412476\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.6270 - categorical_accuracy: 0.7630 - val_loss: 0.6704 - val_categorical_accuracy: 0.7609\n",
      "Epoch 12/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.5921 - categorical_accuracy: 0.7732Epoch 12: loss = 0.5891034007072449, val_loss = 0.7786849141120911\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.5891 - categorical_accuracy: 0.7744 - val_loss: 0.7787 - val_categorical_accuracy: 0.7312\n",
      "Epoch 13/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.5810 - categorical_accuracy: 0.7821Epoch 13: loss = 0.5751374959945679, val_loss = 0.5498728156089783\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.5751 - categorical_accuracy: 0.7858 - val_loss: 0.5499 - val_categorical_accuracy: 0.8065\n",
      "Epoch 14/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.4918 - categorical_accuracy: 0.8179Epoch 14: loss = 0.49474120140075684, val_loss = 0.53689044713974\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.4947 - categorical_accuracy: 0.8171 - val_loss: 0.5369 - val_categorical_accuracy: 0.8134\n",
      "Epoch 15/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4772 - categorical_accuracy: 0.8270Epoch 15: loss = 0.4771742820739746, val_loss = 0.5442183017730713\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.4772 - categorical_accuracy: 0.8270 - val_loss: 0.5442 - val_categorical_accuracy: 0.8157\n",
      "Epoch 16/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 0.4462 - categorical_accuracy: 0.8354Epoch 16: loss = 0.4571584463119507, val_loss = 0.7286496758460999\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.4572 - categorical_accuracy: 0.8308 - val_loss: 0.7286 - val_categorical_accuracy: 0.7433\n",
      "Epoch 17/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.5850 - categorical_accuracy: 0.7820Epoch 17: loss = 0.5842120051383972, val_loss = 0.5233398675918579\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.5842 - categorical_accuracy: 0.7820 - val_loss: 0.5233 - val_categorical_accuracy: 0.8256\n",
      "Epoch 18/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.4333 - categorical_accuracy: 0.8414Epoch 18: loss = 0.43378910422325134, val_loss = 0.4789959490299225\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.4338 - categorical_accuracy: 0.8415 - val_loss: 0.4790 - val_categorical_accuracy: 0.8469\n",
      "Epoch 19/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.4133 - categorical_accuracy: 0.8498Epoch 19: loss = 0.4144397974014282, val_loss = 0.4657953083515167\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.4144 - categorical_accuracy: 0.8506 - val_loss: 0.4658 - val_categorical_accuracy: 0.8492\n",
      "Epoch 20/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 0.3497 - categorical_accuracy: 0.8627Epoch 20: loss = 0.3536997437477112, val_loss = 0.5749585032463074\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.3537 - categorical_accuracy: 0.8620 - val_loss: 0.5750 - val_categorical_accuracy: 0.7898\n",
      "Epoch 21/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.4634 - categorical_accuracy: 0.8229Epoch 21: loss = 0.4591812491416931, val_loss = 0.6169624924659729\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.4592 - categorical_accuracy: 0.8232 - val_loss: 0.6170 - val_categorical_accuracy: 0.7814\n",
      "Epoch 22/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.3412 - categorical_accuracy: 0.8773Epoch 22: loss = 0.34178292751312256, val_loss = 0.463673859834671\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.3418 - categorical_accuracy: 0.8765 - val_loss: 0.4637 - val_categorical_accuracy: 0.8431\n",
      "Epoch 23/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.3422 - categorical_accuracy: 0.8702Epoch 23: loss = 0.3425193428993225, val_loss = 0.5357825756072998\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.3425 - categorical_accuracy: 0.8697 - val_loss: 0.5358 - val_categorical_accuracy: 0.8119\n",
      "Epoch 24/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.3908 - categorical_accuracy: 0.8492Epoch 24: loss = 0.3910149931907654, val_loss = 0.4957622289657593\n",
      "82/82 [==============================] - 1s 13ms/step - loss: 0.3910 - categorical_accuracy: 0.8483 - val_loss: 0.4958 - val_categorical_accuracy: 0.8218\n",
      "Epoch 25/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.4045 - categorical_accuracy: 0.8395Epoch 25: loss = 0.4057217240333557, val_loss = 0.4126969873905182\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.4057 - categorical_accuracy: 0.8384 - val_loss: 0.4127 - val_categorical_accuracy: 0.8644\n",
      "Epoch 26/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 0.2913 - categorical_accuracy: 0.8892Epoch 26: loss = 0.2953035235404968, val_loss = 0.5579506158828735\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.2953 - categorical_accuracy: 0.8864 - val_loss: 0.5580 - val_categorical_accuracy: 0.8119\n",
      "Epoch 27/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 0.2837 - categorical_accuracy: 0.9011Epoch 27: loss = 0.28412389755249023, val_loss = 0.35678574442863464\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.2841 - categorical_accuracy: 0.8994 - val_loss: 0.3568 - val_categorical_accuracy: 0.8888\n",
      "Epoch 28/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.2696 - categorical_accuracy: 0.8997Epoch 28: loss = 0.27292600274086, val_loss = 0.3609626293182373\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.2729 - categorical_accuracy: 0.8979 - val_loss: 0.3610 - val_categorical_accuracy: 0.8743\n",
      "Epoch 29/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.3465 - categorical_accuracy: 0.8822Epoch 29: loss = 0.3594399094581604, val_loss = 1.2486079931259155\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.3594 - categorical_accuracy: 0.8780 - val_loss: 1.2486 - val_categorical_accuracy: 0.6458\n",
      "Epoch 30/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 0.3600 - categorical_accuracy: 0.8734Epoch 30: loss = 0.3534955382347107, val_loss = 0.358582466840744\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.3535 - categorical_accuracy: 0.8765 - val_loss: 0.3586 - val_categorical_accuracy: 0.8934\n",
      "Epoch 31/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.2215 - categorical_accuracy: 0.9203Epoch 31: loss = 0.22127574682235718, val_loss = 0.3295225203037262\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.2213 - categorical_accuracy: 0.9192 - val_loss: 0.3295 - val_categorical_accuracy: 0.9025\n",
      "Epoch 32/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.2403 - categorical_accuracy: 0.9062Epoch 32: loss = 0.2417609691619873, val_loss = 0.38016554713249207\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.2418 - categorical_accuracy: 0.9070 - val_loss: 0.3802 - val_categorical_accuracy: 0.8781\n",
      "Epoch 33/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2544 - categorical_accuracy: 0.9070Epoch 33: loss = 0.25440019369125366, val_loss = 0.481518030166626\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.2544 - categorical_accuracy: 0.9070 - val_loss: 0.4815 - val_categorical_accuracy: 0.8378\n",
      "Epoch 34/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.2470 - categorical_accuracy: 0.9103Epoch 34: loss = 0.24356970191001892, val_loss = 0.4526725709438324\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.2436 - categorical_accuracy: 0.9116 - val_loss: 0.4527 - val_categorical_accuracy: 0.8370\n",
      "Epoch 35/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 0.2786 - categorical_accuracy: 0.8817Epoch 35: loss = 0.26978424191474915, val_loss = 0.4289112091064453\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.2698 - categorical_accuracy: 0.8872 - val_loss: 0.4289 - val_categorical_accuracy: 0.8728\n",
      "Epoch 36/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.2428 - categorical_accuracy: 0.9062Restoring model weights from the end of the best epoch: 31.\n",
      "Epoch 36: loss = 0.2488557994365692, val_loss = 0.4996393620967865\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.2489 - categorical_accuracy: 0.9040 - val_loss: 0.4996 - val_categorical_accuracy: 0.8477\n",
      "Epoch 36: early stopping\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3295 - categorical_accuracy: 0.9025\n",
      "Epoch 1/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 2.8592 - categorical_accuracy: 0.0945Epoch 1: loss = 2.8579626083374023, val_loss = 2.5491042137145996\n",
      "83/83 [==============================] - 2s 16ms/step - loss: 2.8580 - categorical_accuracy: 0.0952 - val_loss: 2.5491 - val_categorical_accuracy: 0.1349\n",
      "Epoch 2/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 2.2850 - categorical_accuracy: 0.2281Epoch 2: loss = 2.270505666732788, val_loss = 1.8711836338043213\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.2705 - categorical_accuracy: 0.2353 - val_loss: 1.8712 - val_categorical_accuracy: 0.3613\n",
      "Epoch 3/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 1.6195 - categorical_accuracy: 0.4239Epoch 3: loss = 1.6103383302688599, val_loss = 1.2710570096969604\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.6103 - categorical_accuracy: 0.4250 - val_loss: 1.2711 - val_categorical_accuracy: 0.5655\n",
      "Epoch 4/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 1.2266 - categorical_accuracy: 0.5601Epoch 4: loss = 1.2211103439331055, val_loss = 1.035294771194458\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.2211 - categorical_accuracy: 0.5621 - val_loss: 1.0353 - val_categorical_accuracy: 0.6372\n",
      "Epoch 5/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 1.0981 - categorical_accuracy: 0.6055Epoch 5: loss = 1.0928360223770142, val_loss = 0.8583438992500305\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.0928 - categorical_accuracy: 0.6078 - val_loss: 0.8583 - val_categorical_accuracy: 0.6982\n",
      "Epoch 6/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 0.8761 - categorical_accuracy: 0.6771Epoch 6: loss = 0.8915841579437256, val_loss = 0.9212111234664917\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.8916 - categorical_accuracy: 0.6740 - val_loss: 0.9212 - val_categorical_accuracy: 0.6890\n",
      "Epoch 7/50\n",
      "79/83 [===========================>..] - ETA: 0s - loss: 0.8276 - categorical_accuracy: 0.7041Epoch 7: loss = 0.8242340683937073, val_loss = 0.9010188579559326\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.8242 - categorical_accuracy: 0.7053 - val_loss: 0.9010 - val_categorical_accuracy: 0.6707\n",
      "Epoch 8/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 0.9209 - categorical_accuracy: 0.6734Epoch 8: loss = 0.9155287146568298, val_loss = 0.6954262256622314\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 0.9155 - categorical_accuracy: 0.6748 - val_loss: 0.6954 - val_categorical_accuracy: 0.7553\n",
      "Epoch 9/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 0.7167 - categorical_accuracy: 0.7308Epoch 9: loss = 0.7316105961799622, val_loss = 0.8837970495223999\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.7316 - categorical_accuracy: 0.7251 - val_loss: 0.8838 - val_categorical_accuracy: 0.6905\n",
      "Epoch 10/50\n",
      "79/83 [===========================>..] - ETA: 0s - loss: 0.9144 - categorical_accuracy: 0.6883Epoch 10: loss = 0.9066853523254395, val_loss = 0.6554393768310547\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.9067 - categorical_accuracy: 0.6908 - val_loss: 0.6554 - val_categorical_accuracy: 0.7683\n",
      "Epoch 11/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.6402 - categorical_accuracy: 0.7729Epoch 11: loss = 0.6401492357254028, val_loss = 0.6188146471977234\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6401 - categorical_accuracy: 0.7730 - val_loss: 0.6188 - val_categorical_accuracy: 0.7652\n",
      "Epoch 12/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.7611 - categorical_accuracy: 0.7264Epoch 12: loss = 0.7605131268501282, val_loss = 0.6436047554016113\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.7605 - categorical_accuracy: 0.7266 - val_loss: 0.6436 - val_categorical_accuracy: 0.7812\n",
      "Epoch 13/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 0.5870 - categorical_accuracy: 0.7859Epoch 13: loss = 0.5867435336112976, val_loss = 0.5789206027984619\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.5867 - categorical_accuracy: 0.7867 - val_loss: 0.5789 - val_categorical_accuracy: 0.7980\n",
      "Epoch 14/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.5613 - categorical_accuracy: 0.7901Epoch 14: loss = 0.5609388947486877, val_loss = 0.5814133882522583\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.5609 - categorical_accuracy: 0.7890 - val_loss: 0.5814 - val_categorical_accuracy: 0.8026\n",
      "Epoch 15/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 0.4652 - categorical_accuracy: 0.8277Epoch 15: loss = 0.4808475077152252, val_loss = 0.5942938923835754\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.4808 - categorical_accuracy: 0.8225 - val_loss: 0.5943 - val_categorical_accuracy: 0.7668\n",
      "Epoch 16/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.6469 - categorical_accuracy: 0.7692Epoch 16: loss = 0.6468740701675415, val_loss = 0.4612659811973572\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6469 - categorical_accuracy: 0.7692 - val_loss: 0.4613 - val_categorical_accuracy: 0.8498\n",
      "Epoch 17/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 0.4831 - categorical_accuracy: 0.8156Epoch 17: loss = 0.484703004360199, val_loss = 0.45728757977485657\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.4847 - categorical_accuracy: 0.8142 - val_loss: 0.4573 - val_categorical_accuracy: 0.8384\n",
      "Epoch 18/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.4441 - categorical_accuracy: 0.8316Epoch 18: loss = 0.4444456398487091, val_loss = 0.463277667760849\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.4444 - categorical_accuracy: 0.8317 - val_loss: 0.4633 - val_categorical_accuracy: 0.8407\n",
      "Epoch 19/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 0.4612 - categorical_accuracy: 0.8266Epoch 19: loss = 0.46281179785728455, val_loss = 0.7475057244300842\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.4628 - categorical_accuracy: 0.8256 - val_loss: 0.7475 - val_categorical_accuracy: 0.7256\n",
      "Epoch 20/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 0.4263 - categorical_accuracy: 0.8414Epoch 20: loss = 0.4231244921684265, val_loss = 0.5136141777038574\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.4231 - categorical_accuracy: 0.8416 - val_loss: 0.5136 - val_categorical_accuracy: 0.8155\n",
      "Epoch 21/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.4703 - categorical_accuracy: 0.8316Epoch 21: loss = 0.4713079035282135, val_loss = 0.4779386818408966\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.4713 - categorical_accuracy: 0.8309 - val_loss: 0.4779 - val_categorical_accuracy: 0.8171\n",
      "Epoch 22/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.4420 - categorical_accuracy: 0.8369Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 22: loss = 0.4416813850402832, val_loss = 0.5109097361564636\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.4417 - categorical_accuracy: 0.8370 - val_loss: 0.5109 - val_categorical_accuracy: 0.8293\n",
      "Epoch 22: early stopping\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.4573 - categorical_accuracy: 0.8384\n",
      "Epoch 1/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.9159 - categorical_accuracy: 0.0941Epoch 1: loss = 2.911165237426758, val_loss = 2.5674567222595215\n",
      "82/82 [==============================] - 2s 14ms/step - loss: 2.9112 - categorical_accuracy: 0.0945 - val_loss: 2.5675 - val_categorical_accuracy: 0.1813\n",
      "Epoch 2/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 2.2544 - categorical_accuracy: 0.2780Epoch 2: loss = 2.239621877670288, val_loss = 1.8759831190109253\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 2.2396 - categorical_accuracy: 0.2767 - val_loss: 1.8760 - val_categorical_accuracy: 0.3519\n",
      "Epoch 3/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.6922 - categorical_accuracy: 0.4094Epoch 3: loss = 1.6890842914581299, val_loss = 1.3837978839874268\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 1.6891 - categorical_accuracy: 0.4108 - val_loss: 1.3838 - val_categorical_accuracy: 0.5171\n",
      "Epoch 4/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 1.3674 - categorical_accuracy: 0.5164Epoch 4: loss = 1.361017107963562, val_loss = 1.2250429391860962\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 1.3610 - categorical_accuracy: 0.5198 - val_loss: 1.2250 - val_categorical_accuracy: 0.5644\n",
      "Epoch 5/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.1840 - categorical_accuracy: 0.5779Epoch 5: loss = 1.1796109676361084, val_loss = 1.1045713424682617\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 1.1796 - categorical_accuracy: 0.5785 - val_loss: 1.1046 - val_categorical_accuracy: 0.6139\n",
      "Epoch 6/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.0064 - categorical_accuracy: 0.6414Epoch 6: loss = 1.004286289215088, val_loss = 1.0272973775863647\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 1.0043 - categorical_accuracy: 0.6425 - val_loss: 1.0273 - val_categorical_accuracy: 0.6352\n",
      "Epoch 7/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.9082 - categorical_accuracy: 0.6844Epoch 7: loss = 0.9033896327018738, val_loss = 0.8228660225868225\n",
      "82/82 [==============================] - 1s 13ms/step - loss: 0.9034 - categorical_accuracy: 0.6860 - val_loss: 0.8229 - val_categorical_accuracy: 0.7266\n",
      "Epoch 8/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.8714 - categorical_accuracy: 0.6802Epoch 8: loss = 0.869791567325592, val_loss = 0.8402808308601379\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.8698 - categorical_accuracy: 0.6799 - val_loss: 0.8403 - val_categorical_accuracy: 0.7022\n",
      "Epoch 9/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 0.7925 - categorical_accuracy: 0.7125Epoch 9: loss = 0.7917242050170898, val_loss = 0.724471926689148\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.7917 - categorical_accuracy: 0.7134 - val_loss: 0.7245 - val_categorical_accuracy: 0.7365\n",
      "Epoch 10/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.7345 - categorical_accuracy: 0.7207Epoch 10: loss = 0.7334708571434021, val_loss = 0.7190379500389099\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.7335 - categorical_accuracy: 0.7210 - val_loss: 0.7190 - val_categorical_accuracy: 0.7334\n",
      "Epoch 11/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.7588 - categorical_accuracy: 0.7203Epoch 11: loss = 0.7588452100753784, val_loss = 0.6772984266281128\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.7588 - categorical_accuracy: 0.7203 - val_loss: 0.6773 - val_categorical_accuracy: 0.7624\n",
      "Epoch 12/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 0.6989 - categorical_accuracy: 0.7542Epoch 12: loss = 0.6973657608032227, val_loss = 0.6662960052490234\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.6974 - categorical_accuracy: 0.7546 - val_loss: 0.6663 - val_categorical_accuracy: 0.7708\n",
      "Epoch 13/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 0.6329 - categorical_accuracy: 0.7664Epoch 13: loss = 0.6370179653167725, val_loss = 0.6203915476799011\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.6370 - categorical_accuracy: 0.7645 - val_loss: 0.6204 - val_categorical_accuracy: 0.7814\n",
      "Epoch 14/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 0.5633 - categorical_accuracy: 0.7875Epoch 14: loss = 0.5711520314216614, val_loss = 0.640541136264801\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.5712 - categorical_accuracy: 0.7835 - val_loss: 0.6405 - val_categorical_accuracy: 0.7715\n",
      "Epoch 15/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 0.5542 - categorical_accuracy: 0.7883Epoch 15: loss = 0.5468446016311646, val_loss = 0.6142442226409912\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.5468 - categorical_accuracy: 0.7942 - val_loss: 0.6142 - val_categorical_accuracy: 0.7715\n",
      "Epoch 16/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.5513 - categorical_accuracy: 0.7965Epoch 16: loss = 0.5618153214454651, val_loss = 0.5861623287200928\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.5618 - categorical_accuracy: 0.7919 - val_loss: 0.5862 - val_categorical_accuracy: 0.7883\n",
      "Epoch 17/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 0.5967 - categorical_accuracy: 0.7673Epoch 17: loss = 0.5961284637451172, val_loss = 0.5978404879570007\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.5961 - categorical_accuracy: 0.7683 - val_loss: 0.5978 - val_categorical_accuracy: 0.7982\n",
      "Epoch 18/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.5691 - categorical_accuracy: 0.7953Epoch 18: loss = 0.5691289901733398, val_loss = 0.5946613550186157\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.5691 - categorical_accuracy: 0.7950 - val_loss: 0.5947 - val_categorical_accuracy: 0.7768\n",
      "Epoch 19/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 0.5362 - categorical_accuracy: 0.8042Epoch 19: loss = 0.5372901558876038, val_loss = 0.5669106841087341\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.5373 - categorical_accuracy: 0.8041 - val_loss: 0.5669 - val_categorical_accuracy: 0.7928\n",
      "Epoch 20/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 0.4879 - categorical_accuracy: 0.8125Epoch 20: loss = 0.49337637424468994, val_loss = 0.5831665396690369\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.4934 - categorical_accuracy: 0.8102 - val_loss: 0.5832 - val_categorical_accuracy: 0.7936\n",
      "Epoch 21/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.5441 - categorical_accuracy: 0.7933Epoch 21: loss = 0.5364378094673157, val_loss = 0.5246983766555786\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.5364 - categorical_accuracy: 0.7965 - val_loss: 0.5247 - val_categorical_accuracy: 0.8005\n",
      "Epoch 22/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4474 - categorical_accuracy: 0.8300Epoch 22: loss = 0.44744881987571716, val_loss = 0.5028972625732422\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.4474 - categorical_accuracy: 0.8300 - val_loss: 0.5029 - val_categorical_accuracy: 0.8149\n",
      "Epoch 23/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.4752 - categorical_accuracy: 0.8149Epoch 23: loss = 0.46693453192710876, val_loss = 0.5359116196632385\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.4669 - categorical_accuracy: 0.8194 - val_loss: 0.5359 - val_categorical_accuracy: 0.8081\n",
      "Epoch 24/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.4078 - categorical_accuracy: 0.8461Epoch 24: loss = 0.4060201048851013, val_loss = 0.4664299190044403\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.4060 - categorical_accuracy: 0.8468 - val_loss: 0.4664 - val_categorical_accuracy: 0.8317\n",
      "Epoch 25/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.4589 - categorical_accuracy: 0.8117Epoch 25: loss = 0.45466986298561096, val_loss = 0.43705514073371887\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.4547 - categorical_accuracy: 0.8133 - val_loss: 0.4371 - val_categorical_accuracy: 0.8561\n",
      "Epoch 26/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 0.4350 - categorical_accuracy: 0.8449Epoch 26: loss = 0.4333513677120209, val_loss = 0.5746755003929138\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.4334 - categorical_accuracy: 0.8445 - val_loss: 0.5747 - val_categorical_accuracy: 0.7982\n",
      "Epoch 27/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.4367 - categorical_accuracy: 0.8385Epoch 27: loss = 0.4354175329208374, val_loss = 0.5117236971855164\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.4354 - categorical_accuracy: 0.8384 - val_loss: 0.5117 - val_categorical_accuracy: 0.8203\n",
      "Epoch 28/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.4118 - categorical_accuracy: 0.8480Epoch 28: loss = 0.4113200604915619, val_loss = 0.4745944142341614\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.4113 - categorical_accuracy: 0.8483 - val_loss: 0.4746 - val_categorical_accuracy: 0.8355\n",
      "Epoch 29/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 0.4054 - categorical_accuracy: 0.8429Epoch 29: loss = 0.3964654803276062, val_loss = 0.39813706278800964\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.3965 - categorical_accuracy: 0.8460 - val_loss: 0.3981 - val_categorical_accuracy: 0.8660\n",
      "Epoch 30/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.3949 - categorical_accuracy: 0.8490Epoch 30: loss = 0.3971336781978607, val_loss = 0.4197528064250946\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.3971 - categorical_accuracy: 0.8491 - val_loss: 0.4198 - val_categorical_accuracy: 0.8515\n",
      "Epoch 31/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.3870 - categorical_accuracy: 0.8558Epoch 31: loss = 0.3810962438583374, val_loss = 0.5326488018035889\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.3811 - categorical_accuracy: 0.8575 - val_loss: 0.5326 - val_categorical_accuracy: 0.8088\n",
      "Epoch 32/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 0.3737 - categorical_accuracy: 0.8602Epoch 32: loss = 0.3659987449645996, val_loss = 0.3974098861217499\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.3660 - categorical_accuracy: 0.8620 - val_loss: 0.3974 - val_categorical_accuracy: 0.8522\n",
      "Epoch 33/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 0.3502 - categorical_accuracy: 0.8710Epoch 33: loss = 0.3493574559688568, val_loss = 0.4220449924468994\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.3494 - categorical_accuracy: 0.8697 - val_loss: 0.4220 - val_categorical_accuracy: 0.8637\n",
      "Epoch 34/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 0.3927 - categorical_accuracy: 0.8350Epoch 34: loss = 0.3964490592479706, val_loss = 0.5105783939361572\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.3964 - categorical_accuracy: 0.8361 - val_loss: 0.5106 - val_categorical_accuracy: 0.8324\n",
      "Epoch 35/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.3283 - categorical_accuracy: 0.8727Epoch 35: loss = 0.32651790976524353, val_loss = 0.3878322243690491\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.3265 - categorical_accuracy: 0.8727 - val_loss: 0.3878 - val_categorical_accuracy: 0.8728\n",
      "Epoch 36/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 0.3190 - categorical_accuracy: 0.8742Epoch 36: loss = 0.3272680640220642, val_loss = 0.5347980856895447\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.3273 - categorical_accuracy: 0.8742 - val_loss: 0.5348 - val_categorical_accuracy: 0.8241\n",
      "Epoch 37/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.3677 - categorical_accuracy: 0.8549Epoch 37: loss = 0.3649995028972626, val_loss = 0.4589032530784607\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.3650 - categorical_accuracy: 0.8559 - val_loss: 0.4589 - val_categorical_accuracy: 0.8439\n",
      "Epoch 38/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.3082 - categorical_accuracy: 0.8889Epoch 38: loss = 0.3121057152748108, val_loss = 0.3820914030075073\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.3121 - categorical_accuracy: 0.8880 - val_loss: 0.3821 - val_categorical_accuracy: 0.8561\n",
      "Epoch 39/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.2841 - categorical_accuracy: 0.8847Epoch 39: loss = 0.2989460229873657, val_loss = 0.41477352380752563\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.2989 - categorical_accuracy: 0.8811 - val_loss: 0.4148 - val_categorical_accuracy: 0.8545\n",
      "Epoch 40/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.3306 - categorical_accuracy: 0.8718Epoch 40: loss = 0.3259424567222595, val_loss = 0.43056216835975647\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.3259 - categorical_accuracy: 0.8750 - val_loss: 0.4306 - val_categorical_accuracy: 0.8378\n",
      "Epoch 41/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 0.3247 - categorical_accuracy: 0.8725Epoch 41: loss = 0.32306063175201416, val_loss = 0.3143782317638397\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.3231 - categorical_accuracy: 0.8735 - val_loss: 0.3144 - val_categorical_accuracy: 0.9033\n",
      "Epoch 42/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.3080 - categorical_accuracy: 0.8804Epoch 42: loss = 0.3071306049823761, val_loss = 0.4086579978466034\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.3071 - categorical_accuracy: 0.8811 - val_loss: 0.4087 - val_categorical_accuracy: 0.8759\n",
      "Epoch 43/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 0.3994 - categorical_accuracy: 0.8577Epoch 43: loss = 0.3840557336807251, val_loss = 0.4179351329803467\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.3841 - categorical_accuracy: 0.8651 - val_loss: 0.4179 - val_categorical_accuracy: 0.8500\n",
      "Epoch 44/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 0.2662 - categorical_accuracy: 0.8924Epoch 44: loss = 0.2629842758178711, val_loss = 0.32362884283065796\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.2630 - categorical_accuracy: 0.8941 - val_loss: 0.3236 - val_categorical_accuracy: 0.8911\n",
      "Epoch 45/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 0.3195 - categorical_accuracy: 0.8766Epoch 45: loss = 0.31711286306381226, val_loss = 0.5182217359542847\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.3171 - categorical_accuracy: 0.8773 - val_loss: 0.5182 - val_categorical_accuracy: 0.8233\n",
      "Epoch 46/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 0.2827 - categorical_accuracy: 0.8917Restoring model weights from the end of the best epoch: 41.\n",
      "Epoch 46: loss = 0.2853926718235016, val_loss = 0.3908965289592743\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.2854 - categorical_accuracy: 0.8902 - val_loss: 0.3909 - val_categorical_accuracy: 0.8728\n",
      "Epoch 46: early stopping\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3144 - categorical_accuracy: 0.9033\n",
      "Epoch 1/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.9054 - categorical_accuracy: 0.0802Epoch 1: loss = 2.9023640155792236, val_loss = 2.633427143096924\n",
      "83/83 [==============================] - 2s 13ms/step - loss: 2.9024 - categorical_accuracy: 0.0815 - val_loss: 2.6334 - val_categorical_accuracy: 0.0755\n",
      "Epoch 2/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 2.4515 - categorical_accuracy: 0.1987Epoch 2: loss = 2.4417724609375, val_loss = 2.0856118202209473\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 2.4418 - categorical_accuracy: 0.1980 - val_loss: 2.0856 - val_categorical_accuracy: 0.2706\n",
      "Epoch 3/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 2.0040 - categorical_accuracy: 0.2936Epoch 3: loss = 1.999936819076538, val_loss = 1.6689754724502563\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.9999 - categorical_accuracy: 0.2947 - val_loss: 1.6690 - val_categorical_accuracy: 0.4352\n",
      "Epoch 4/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 1.6993 - categorical_accuracy: 0.3766Epoch 4: loss = 1.6921533346176147, val_loss = 1.3879518508911133\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.6922 - categorical_accuracy: 0.3793 - val_loss: 1.3880 - val_categorical_accuracy: 0.5160\n",
      "Epoch 5/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 1.4196 - categorical_accuracy: 0.4878Epoch 5: loss = 1.417847752571106, val_loss = 1.143438458442688\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.4178 - categorical_accuracy: 0.4897 - val_loss: 1.1434 - val_categorical_accuracy: 0.6197\n",
      "Epoch 6/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.1989 - categorical_accuracy: 0.5625Epoch 6: loss = 1.194501280784607, val_loss = 1.0095844268798828\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.1945 - categorical_accuracy: 0.5621 - val_loss: 1.0096 - val_categorical_accuracy: 0.6616\n",
      "Epoch 7/50\n",
      "79/83 [===========================>..] - ETA: 0s - loss: 1.0912 - categorical_accuracy: 0.5862Epoch 7: loss = 1.0922414064407349, val_loss = 0.9351240992546082\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.0922 - categorical_accuracy: 0.5864 - val_loss: 0.9351 - val_categorical_accuracy: 0.6669\n",
      "Epoch 8/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 1.0384 - categorical_accuracy: 0.6193Epoch 8: loss = 1.0313435792922974, val_loss = 0.9035853743553162\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.0313 - categorical_accuracy: 0.6245 - val_loss: 0.9036 - val_categorical_accuracy: 0.6784\n",
      "Epoch 9/50\n",
      "79/83 [===========================>..] - ETA: 0s - loss: 0.9159 - categorical_accuracy: 0.6527Epoch 9: loss = 0.9180657267570496, val_loss = 0.77854984998703\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.9181 - categorical_accuracy: 0.6512 - val_loss: 0.7785 - val_categorical_accuracy: 0.7233\n",
      "Epoch 10/50\n",
      "79/83 [===========================>..] - ETA: 0s - loss: 0.8703 - categorical_accuracy: 0.6780Epoch 10: loss = 0.8777836561203003, val_loss = 0.8137180805206299\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.8778 - categorical_accuracy: 0.6740 - val_loss: 0.8137 - val_categorical_accuracy: 0.7111\n",
      "Epoch 11/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 0.9382 - categorical_accuracy: 0.6645Epoch 11: loss = 0.9289085865020752, val_loss = 0.7623315453529358\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.9289 - categorical_accuracy: 0.6657 - val_loss: 0.7623 - val_categorical_accuracy: 0.7317\n",
      "Epoch 12/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 0.7827 - categorical_accuracy: 0.7078Epoch 12: loss = 0.7778136730194092, val_loss = 0.7535867691040039\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.7778 - categorical_accuracy: 0.7091 - val_loss: 0.7536 - val_categorical_accuracy: 0.7119\n",
      "Epoch 13/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.8100 - categorical_accuracy: 0.7037Epoch 13: loss = 0.8174670338630676, val_loss = 0.6198000907897949\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.8175 - categorical_accuracy: 0.7014 - val_loss: 0.6198 - val_categorical_accuracy: 0.7866\n",
      "Epoch 14/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 0.6720 - categorical_accuracy: 0.7428Epoch 14: loss = 0.6674609780311584, val_loss = 0.7938245534896851\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6675 - categorical_accuracy: 0.7449 - val_loss: 0.7938 - val_categorical_accuracy: 0.7149\n",
      "Epoch 15/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.8222 - categorical_accuracy: 0.7083Epoch 15: loss = 0.8219152092933655, val_loss = 0.7325611114501953\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.8219 - categorical_accuracy: 0.7083 - val_loss: 0.7326 - val_categorical_accuracy: 0.7111\n",
      "Epoch 16/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 0.7590 - categorical_accuracy: 0.7367Epoch 16: loss = 0.7604233026504517, val_loss = 0.5810000896453857\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.7604 - categorical_accuracy: 0.7357 - val_loss: 0.5810 - val_categorical_accuracy: 0.7805\n",
      "Epoch 17/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.6836 - categorical_accuracy: 0.7438Epoch 17: loss = 0.6858960390090942, val_loss = 0.6971244215965271\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6859 - categorical_accuracy: 0.7441 - val_loss: 0.6971 - val_categorical_accuracy: 0.7226\n",
      "Epoch 18/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.7135 - categorical_accuracy: 0.7327Epoch 18: loss = 0.7135164737701416, val_loss = 0.5738577842712402\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.7135 - categorical_accuracy: 0.7327 - val_loss: 0.5739 - val_categorical_accuracy: 0.7797\n",
      "Epoch 19/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.6113 - categorical_accuracy: 0.7645Epoch 19: loss = 0.6111109256744385, val_loss = 0.6640835404396057\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6111 - categorical_accuracy: 0.7647 - val_loss: 0.6641 - val_categorical_accuracy: 0.7317\n",
      "Epoch 20/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.6051 - categorical_accuracy: 0.7713Epoch 20: loss = 0.6046318411827087, val_loss = 0.5025997757911682\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6046 - categorical_accuracy: 0.7715 - val_loss: 0.5026 - val_categorical_accuracy: 0.8247\n",
      "Epoch 21/50\n",
      "79/83 [===========================>..] - ETA: 0s - loss: 0.5379 - categorical_accuracy: 0.7872Epoch 21: loss = 0.5417789220809937, val_loss = 0.573967695236206\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.5418 - categorical_accuracy: 0.7845 - val_loss: 0.5740 - val_categorical_accuracy: 0.7759\n",
      "Epoch 22/50\n",
      "79/83 [===========================>..] - ETA: 0s - loss: 0.5331 - categorical_accuracy: 0.7998Epoch 22: loss = 0.5342298746109009, val_loss = 0.5028842091560364\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.5342 - categorical_accuracy: 0.7974 - val_loss: 0.5029 - val_categorical_accuracy: 0.8064\n",
      "Epoch 23/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 0.4906 - categorical_accuracy: 0.8076Epoch 23: loss = 0.49116218090057373, val_loss = 0.4229283332824707\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4912 - categorical_accuracy: 0.8081 - val_loss: 0.4229 - val_categorical_accuracy: 0.8491\n",
      "Epoch 24/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.5035 - categorical_accuracy: 0.8079Epoch 24: loss = 0.5019561648368835, val_loss = 0.4716537892818451\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.5020 - categorical_accuracy: 0.8081 - val_loss: 0.4717 - val_categorical_accuracy: 0.8148\n",
      "Epoch 25/50\n",
      "77/83 [==========================>...] - ETA: 0s - loss: 0.4696 - categorical_accuracy: 0.8239Epoch 25: loss = 0.47798267006874084, val_loss = 0.41647735238075256\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.4780 - categorical_accuracy: 0.8203 - val_loss: 0.4165 - val_categorical_accuracy: 0.8407\n",
      "Epoch 26/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.4759 - categorical_accuracy: 0.8323Epoch 26: loss = 0.4757906496524811, val_loss = 0.40399110317230225\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.4758 - categorical_accuracy: 0.8324 - val_loss: 0.4040 - val_categorical_accuracy: 0.8514\n",
      "Epoch 27/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 0.4255 - categorical_accuracy: 0.8266Epoch 27: loss = 0.4267587959766388, val_loss = 0.4178541600704193\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.4268 - categorical_accuracy: 0.8271 - val_loss: 0.4179 - val_categorical_accuracy: 0.8460\n",
      "Epoch 28/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.3991 - categorical_accuracy: 0.8498Epoch 28: loss = 0.3988041877746582, val_loss = 0.9240639209747314\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.3988 - categorical_accuracy: 0.8500 - val_loss: 0.9241 - val_categorical_accuracy: 0.7226\n",
      "Epoch 29/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.5312 - categorical_accuracy: 0.8102Epoch 29: loss = 0.5284878611564636, val_loss = 0.49470627307891846\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.5285 - categorical_accuracy: 0.8111 - val_loss: 0.4947 - val_categorical_accuracy: 0.8277\n",
      "Epoch 30/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 0.6974 - categorical_accuracy: 0.7548Epoch 30: loss = 0.6957859396934509, val_loss = 0.4658921957015991\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6958 - categorical_accuracy: 0.7540 - val_loss: 0.4659 - val_categorical_accuracy: 0.8300\n",
      "Epoch 31/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 0.4555 - categorical_accuracy: 0.8317Restoring model weights from the end of the best epoch: 26.\n",
      "Epoch 31: loss = 0.44899070262908936, val_loss = 0.47696569561958313\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.4490 - categorical_accuracy: 0.8340 - val_loss: 0.4770 - val_categorical_accuracy: 0.8117\n",
      "Epoch 31: early stopping\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.4040 - categorical_accuracy: 0.8514\n",
      "Epoch 1/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 2.9575 - categorical_accuracy: 0.0961Epoch 1: loss = 2.949319362640381, val_loss = 2.5880393981933594\n",
      "82/82 [==============================] - 2s 14ms/step - loss: 2.9493 - categorical_accuracy: 0.0953 - val_loss: 2.5880 - val_categorical_accuracy: 0.1577\n",
      "Epoch 2/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.3980 - categorical_accuracy: 0.1905Epoch 2: loss = 2.3980119228363037, val_loss = 2.1578516960144043\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 2.3980 - categorical_accuracy: 0.1905 - val_loss: 2.1579 - val_categorical_accuracy: 0.2818\n",
      "Epoch 3/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.9545 - categorical_accuracy: 0.3133Epoch 3: loss = 1.9575527906417847, val_loss = 1.7805802822113037\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 1.9576 - categorical_accuracy: 0.3125 - val_loss: 1.7806 - val_categorical_accuracy: 0.3625\n",
      "Epoch 4/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.6418 - categorical_accuracy: 0.4352Epoch 4: loss = 1.639333963394165, val_loss = 1.4274358749389648\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 1.6393 - categorical_accuracy: 0.4352 - val_loss: 1.4274 - val_categorical_accuracy: 0.5415\n",
      "Epoch 5/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 1.4534 - categorical_accuracy: 0.4671Epoch 5: loss = 1.4359244108200073, val_loss = 1.1860911846160889\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 1.4359 - categorical_accuracy: 0.4710 - val_loss: 1.1861 - val_categorical_accuracy: 0.6352\n",
      "Epoch 6/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 1.2793 - categorical_accuracy: 0.5352Epoch 6: loss = 1.2828458547592163, val_loss = 1.033661127090454\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 1.2828 - categorical_accuracy: 0.5358 - val_loss: 1.0337 - val_categorical_accuracy: 0.6702\n",
      "Epoch 7/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 1.0975 - categorical_accuracy: 0.6142Epoch 7: loss = 1.102001667022705, val_loss = 1.1440281867980957\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 1.1020 - categorical_accuracy: 0.6082 - val_loss: 1.1440 - val_categorical_accuracy: 0.5720\n",
      "Epoch 8/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 1.0358 - categorical_accuracy: 0.6342Epoch 8: loss = 1.0378729104995728, val_loss = 1.0164507627487183\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 1.0379 - categorical_accuracy: 0.6334 - val_loss: 1.0165 - val_categorical_accuracy: 0.6329\n",
      "Epoch 9/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 0.9393 - categorical_accuracy: 0.6628Epoch 9: loss = 0.9429916739463806, val_loss = 0.8260247111320496\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.9430 - categorical_accuracy: 0.6608 - val_loss: 0.8260 - val_categorical_accuracy: 0.6954\n",
      "Epoch 10/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 0.9313 - categorical_accuracy: 0.6622Epoch 10: loss = 0.9393016695976257, val_loss = 0.8260863423347473\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.9393 - categorical_accuracy: 0.6585 - val_loss: 0.8261 - val_categorical_accuracy: 0.6900\n",
      "Epoch 11/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.8629 - categorical_accuracy: 0.6771Epoch 11: loss = 0.8598103523254395, val_loss = 0.741540253162384\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.8598 - categorical_accuracy: 0.6761 - val_loss: 0.7415 - val_categorical_accuracy: 0.7403\n",
      "Epoch 12/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.7932 - categorical_accuracy: 0.7070Epoch 12: loss = 0.7901349067687988, val_loss = 0.7085515260696411\n",
      "82/82 [==============================] - 1s 14ms/step - loss: 0.7901 - categorical_accuracy: 0.7088 - val_loss: 0.7086 - val_categorical_accuracy: 0.7471\n",
      "Epoch 13/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.7208 - categorical_accuracy: 0.7346Epoch 13: loss = 0.7189833521842957, val_loss = 0.7393855452537537\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.7190 - categorical_accuracy: 0.7325 - val_loss: 0.7394 - val_categorical_accuracy: 0.7327\n",
      "Epoch 14/50\n",
      "76/82 [==========================>...] - ETA: 0s - loss: 0.7559 - categorical_accuracy: 0.7081Epoch 14: loss = 0.7414551377296448, val_loss = 0.720935583114624\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.7415 - categorical_accuracy: 0.7134 - val_loss: 0.7209 - val_categorical_accuracy: 0.7220\n",
      "Epoch 15/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 0.7768 - categorical_accuracy: 0.7223Epoch 15: loss = 0.7657874226570129, val_loss = 0.6664921045303345\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.7658 - categorical_accuracy: 0.7256 - val_loss: 0.6665 - val_categorical_accuracy: 0.7601\n",
      "Epoch 16/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 0.7462 - categorical_accuracy: 0.7207Epoch 16: loss = 0.7446854114532471, val_loss = 0.6141486167907715\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.7447 - categorical_accuracy: 0.7218 - val_loss: 0.6141 - val_categorical_accuracy: 0.7974\n",
      "Epoch 17/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.7255 - categorical_accuracy: 0.7289Epoch 17: loss = 0.7311041951179504, val_loss = 0.7284015417098999\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.7311 - categorical_accuracy: 0.7264 - val_loss: 0.7284 - val_categorical_accuracy: 0.7289\n",
      "Epoch 18/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.6721 - categorical_accuracy: 0.7492Epoch 18: loss = 0.67499178647995, val_loss = 0.6862490177154541\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.6750 - categorical_accuracy: 0.7462 - val_loss: 0.6862 - val_categorical_accuracy: 0.7372\n",
      "Epoch 19/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.6328 - categorical_accuracy: 0.7600Epoch 19: loss = 0.6282059550285339, val_loss = 0.587181568145752\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.6282 - categorical_accuracy: 0.7622 - val_loss: 0.5872 - val_categorical_accuracy: 0.8005\n",
      "Epoch 20/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 0.6855 - categorical_accuracy: 0.7442Epoch 20: loss = 0.6830147504806519, val_loss = 0.690977156162262\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.6830 - categorical_accuracy: 0.7447 - val_loss: 0.6910 - val_categorical_accuracy: 0.7525\n",
      "Epoch 21/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.5936 - categorical_accuracy: 0.7748Epoch 21: loss = 0.5905921459197998, val_loss = 0.5810247659683228\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.5906 - categorical_accuracy: 0.7767 - val_loss: 0.5810 - val_categorical_accuracy: 0.8081\n",
      "Epoch 22/50\n",
      "75/82 [==========================>...] - ETA: 0s - loss: 0.6215 - categorical_accuracy: 0.7758Epoch 22: loss = 0.6149734854698181, val_loss = 0.6175618171691895\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.6150 - categorical_accuracy: 0.7774 - val_loss: 0.6176 - val_categorical_accuracy: 0.7974\n",
      "Epoch 23/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.6103 - categorical_accuracy: 0.7801Epoch 23: loss = 0.6111137270927429, val_loss = 0.6474471092224121\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.6111 - categorical_accuracy: 0.7812 - val_loss: 0.6474 - val_categorical_accuracy: 0.7677\n",
      "Epoch 24/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6044 - categorical_accuracy: 0.7790Epoch 24: loss = 0.6044234037399292, val_loss = 0.5592703223228455\n",
      "82/82 [==============================] - 2s 19ms/step - loss: 0.6044 - categorical_accuracy: 0.7790 - val_loss: 0.5593 - val_categorical_accuracy: 0.8142\n",
      "Epoch 25/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5874 - categorical_accuracy: 0.7820Epoch 25: loss = 0.587387204170227, val_loss = 0.6672383546829224\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.5874 - categorical_accuracy: 0.7820 - val_loss: 0.6672 - val_categorical_accuracy: 0.7563\n",
      "Epoch 26/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.5410 - categorical_accuracy: 0.8013Epoch 26: loss = 0.5399367809295654, val_loss = 0.5416494607925415\n",
      "82/82 [==============================] - 1s 13ms/step - loss: 0.5399 - categorical_accuracy: 0.8003 - val_loss: 0.5416 - val_categorical_accuracy: 0.8050\n",
      "Epoch 27/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.4739 - categorical_accuracy: 0.8117Epoch 27: loss = 0.477414608001709, val_loss = 0.48758193850517273\n",
      "82/82 [==============================] - 1s 14ms/step - loss: 0.4774 - categorical_accuracy: 0.8095 - val_loss: 0.4876 - val_categorical_accuracy: 0.8462\n",
      "Epoch 28/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.5555 - categorical_accuracy: 0.7841Epoch 28: loss = 0.5466150045394897, val_loss = 0.5148687958717346\n",
      "82/82 [==============================] - 1s 16ms/step - loss: 0.5466 - categorical_accuracy: 0.7881 - val_loss: 0.5149 - val_categorical_accuracy: 0.8172\n",
      "Epoch 29/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.4707 - categorical_accuracy: 0.8205Epoch 29: loss = 0.4753478467464447, val_loss = 0.4538736343383789\n",
      "82/82 [==============================] - 1s 13ms/step - loss: 0.4753 - categorical_accuracy: 0.8209 - val_loss: 0.4539 - val_categorical_accuracy: 0.8561\n",
      "Epoch 30/50\n",
      "78/82 [===========================>..] - ETA: 0s - loss: 0.5162 - categorical_accuracy: 0.8061Epoch 30: loss = 0.5150697231292725, val_loss = 0.7527111768722534\n",
      "82/82 [==============================] - 1s 15ms/step - loss: 0.5151 - categorical_accuracy: 0.8041 - val_loss: 0.7527 - val_categorical_accuracy: 0.7570\n",
      "Epoch 31/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5398 - categorical_accuracy: 0.7973Epoch 31: loss = 0.5398025512695312, val_loss = 0.45169562101364136\n",
      "82/82 [==============================] - 1s 13ms/step - loss: 0.5398 - categorical_accuracy: 0.7973 - val_loss: 0.4517 - val_categorical_accuracy: 0.8583\n",
      "Epoch 32/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.4958 - categorical_accuracy: 0.8241Epoch 32: loss = 0.4971618056297302, val_loss = 0.46909037232398987\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.4972 - categorical_accuracy: 0.8239 - val_loss: 0.4691 - val_categorical_accuracy: 0.8439\n",
      "Epoch 33/50\n",
      "80/82 [============================>.] - ETA: 0s - loss: 0.4805 - categorical_accuracy: 0.8180Epoch 33: loss = 0.48204195499420166, val_loss = 0.5468254685401917\n",
      "82/82 [==============================] - 1s 13ms/step - loss: 0.4820 - categorical_accuracy: 0.8186 - val_loss: 0.5468 - val_categorical_accuracy: 0.8180\n",
      "Epoch 34/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.4610 - categorical_accuracy: 0.8255Epoch 34: loss = 0.45183953642845154, val_loss = 0.46286648511886597\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.4518 - categorical_accuracy: 0.8277 - val_loss: 0.4629 - val_categorical_accuracy: 0.8309\n",
      "Epoch 35/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.4303 - categorical_accuracy: 0.8409Epoch 35: loss = 0.42805877327919006, val_loss = 0.5162912011146545\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.4281 - categorical_accuracy: 0.8415 - val_loss: 0.5163 - val_categorical_accuracy: 0.8119\n",
      "Epoch 36/50\n",
      "77/82 [===========================>..] - ETA: 0s - loss: 0.4481 - categorical_accuracy: 0.8255Restoring model weights from the end of the best epoch: 31.\n",
      "Epoch 36: loss = 0.4408353567123413, val_loss = 0.6801824569702148\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.4408 - categorical_accuracy: 0.8300 - val_loss: 0.6802 - val_categorical_accuracy: 0.7753\n",
      "Epoch 36: early stopping\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4517 - categorical_accuracy: 0.8583\n",
      "Epoch 1/50\n",
      "79/83 [===========================>..] - ETA: 0s - loss: 3.0338 - categorical_accuracy: 0.0878Epoch 1: loss = 3.021888494491577, val_loss = 2.664250373840332\n",
      "83/83 [==============================] - 2s 16ms/step - loss: 3.0219 - categorical_accuracy: 0.0883 - val_loss: 2.6643 - val_categorical_accuracy: 0.1875\n",
      "Epoch 2/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 2.5420 - categorical_accuracy: 0.1605Epoch 2: loss = 2.5378923416137695, val_loss = 2.162513256072998\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.5379 - categorical_accuracy: 0.1622 - val_loss: 2.1625 - val_categorical_accuracy: 0.2652\n",
      "Epoch 3/50\n",
      "79/83 [===========================>..] - ETA: 0s - loss: 2.1286 - categorical_accuracy: 0.2603Epoch 3: loss = 2.1152169704437256, val_loss = 1.7167086601257324\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 2.1152 - categorical_accuracy: 0.2620 - val_loss: 1.7167 - val_categorical_accuracy: 0.4444\n",
      "Epoch 4/50\n",
      "79/83 [===========================>..] - ETA: 0s - loss: 1.7634 - categorical_accuracy: 0.3631Epoch 4: loss = 1.7607375383377075, val_loss = 1.5008676052093506\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.7607 - categorical_accuracy: 0.3679 - val_loss: 1.5009 - val_categorical_accuracy: 0.4863\n",
      "Epoch 5/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.5793 - categorical_accuracy: 0.4108Epoch 5: loss = 1.5788925886154175, val_loss = 1.3494086265563965\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.5789 - categorical_accuracy: 0.4113 - val_loss: 1.3494 - val_categorical_accuracy: 0.4771\n",
      "Epoch 6/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.5468 - categorical_accuracy: 0.4444Epoch 6: loss = 1.5464308261871338, val_loss = 1.260801076889038\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.5464 - categorical_accuracy: 0.4448 - val_loss: 1.2608 - val_categorical_accuracy: 0.4893\n",
      "Epoch 7/50\n",
      "79/83 [===========================>..] - ETA: 0s - loss: 1.4085 - categorical_accuracy: 0.4802Epoch 7: loss = 1.428217887878418, val_loss = 1.1942259073257446\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.4282 - categorical_accuracy: 0.4775 - val_loss: 1.1942 - val_categorical_accuracy: 0.5831\n",
      "Epoch 8/50\n",
      "78/83 [===========================>..] - ETA: 0s - loss: 1.1695 - categorical_accuracy: 0.5665Epoch 8: loss = 1.177715539932251, val_loss = 1.113082766532898\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.1777 - categorical_accuracy: 0.5605 - val_loss: 1.1131 - val_categorical_accuracy: 0.5602\n",
      "Epoch 9/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 1.1520 - categorical_accuracy: 0.5709Epoch 9: loss = 1.1521044969558716, val_loss = 0.9584015607833862\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.1521 - categorical_accuracy: 0.5704 - val_loss: 0.9584 - val_categorical_accuracy: 0.6738\n",
      "Epoch 10/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 1.1071 - categorical_accuracy: 0.5891Epoch 10: loss = 1.1040163040161133, val_loss = 1.1324495077133179\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.1040 - categorical_accuracy: 0.5918 - val_loss: 1.1324 - val_categorical_accuracy: 0.5854\n",
      "Epoch 11/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 1.0658 - categorical_accuracy: 0.5880Epoch 11: loss = 1.0670814514160156, val_loss = 0.8062642812728882\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.0671 - categorical_accuracy: 0.5872 - val_loss: 0.8063 - val_categorical_accuracy: 0.7279\n",
      "Epoch 12/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 0.9552 - categorical_accuracy: 0.6320Epoch 12: loss = 0.9547298550605774, val_loss = 0.8182620406150818\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.9547 - categorical_accuracy: 0.6329 - val_loss: 0.8183 - val_categorical_accuracy: 0.6982\n",
      "Epoch 13/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.9376 - categorical_accuracy: 0.6466Epoch 13: loss = 0.9376019239425659, val_loss = 0.9078711271286011\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.9376 - categorical_accuracy: 0.6466 - val_loss: 0.9079 - val_categorical_accuracy: 0.6692\n",
      "Epoch 14/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.9513 - categorical_accuracy: 0.6535Epoch 14: loss = 0.951341986656189, val_loss = 0.7579814791679382\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.9513 - categorical_accuracy: 0.6535 - val_loss: 0.7580 - val_categorical_accuracy: 0.7271\n",
      "Epoch 15/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 1.0315 - categorical_accuracy: 0.6219Epoch 15: loss = 1.024627923965454, val_loss = 0.7819971442222595\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.0246 - categorical_accuracy: 0.6245 - val_loss: 0.7820 - val_categorical_accuracy: 0.7294\n",
      "Epoch 16/50\n",
      "76/83 [==========================>...] - ETA: 0s - loss: 0.8518 - categorical_accuracy: 0.6727Epoch 16: loss = 0.8497065305709839, val_loss = 0.7415403127670288\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.8497 - categorical_accuracy: 0.6725 - val_loss: 0.7415 - val_categorical_accuracy: 0.7256\n",
      "Epoch 17/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.8072 - categorical_accuracy: 0.7037Epoch 17: loss = 0.8071810603141785, val_loss = 0.7583519816398621\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.8072 - categorical_accuracy: 0.7037 - val_loss: 0.7584 - val_categorical_accuracy: 0.7424\n",
      "Epoch 18/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 0.8085 - categorical_accuracy: 0.6852Epoch 18: loss = 0.8047239184379578, val_loss = 0.7833073139190674\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.8047 - categorical_accuracy: 0.6862 - val_loss: 0.7833 - val_categorical_accuracy: 0.7066\n",
      "Epoch 19/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.7569 - categorical_accuracy: 0.7167Epoch 19: loss = 0.7569494247436523, val_loss = 0.6981655955314636\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.7569 - categorical_accuracy: 0.7167 - val_loss: 0.6982 - val_categorical_accuracy: 0.7470\n",
      "Epoch 20/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.9177 - categorical_accuracy: 0.6620Epoch 20: loss = 0.9188946485519409, val_loss = 0.6819424033164978\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.9189 - categorical_accuracy: 0.6611 - val_loss: 0.6819 - val_categorical_accuracy: 0.7767\n",
      "Epoch 21/50\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.9194 - categorical_accuracy: 0.6649Epoch 21: loss = 0.9194257855415344, val_loss = 0.6872578859329224\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.9194 - categorical_accuracy: 0.6649 - val_loss: 0.6873 - val_categorical_accuracy: 0.7622\n",
      "Epoch 22/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 0.7405 - categorical_accuracy: 0.7320Epoch 22: loss = 0.7444047331809998, val_loss = 0.7743746042251587\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.7444 - categorical_accuracy: 0.7289 - val_loss: 0.7744 - val_categorical_accuracy: 0.7317\n",
      "Epoch 23/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.7899 - categorical_accuracy: 0.6991Epoch 23: loss = 0.7934964299201965, val_loss = 0.5943760871887207\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.7935 - categorical_accuracy: 0.6976 - val_loss: 0.5944 - val_categorical_accuracy: 0.8064\n",
      "Epoch 24/50\n",
      "80/83 [===========================>..] - ETA: 0s - loss: 0.6649 - categorical_accuracy: 0.7367Epoch 24: loss = 0.6689524054527283, val_loss = 0.633152961730957\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6690 - categorical_accuracy: 0.7334 - val_loss: 0.6332 - val_categorical_accuracy: 0.7630\n",
      "Epoch 25/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.6928 - categorical_accuracy: 0.7469Epoch 25: loss = 0.6929134726524353, val_loss = 0.5536167621612549\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6929 - categorical_accuracy: 0.7479 - val_loss: 0.5536 - val_categorical_accuracy: 0.8133\n",
      "Epoch 26/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.7097 - categorical_accuracy: 0.7346Epoch 26: loss = 0.7131924033164978, val_loss = 0.604613721370697\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.7132 - categorical_accuracy: 0.7327 - val_loss: 0.6046 - val_categorical_accuracy: 0.7980\n",
      "Epoch 27/50\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.6243 - categorical_accuracy: 0.7477Epoch 27: loss = 0.6268312931060791, val_loss = 0.629598081111908\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6268 - categorical_accuracy: 0.7471 - val_loss: 0.6296 - val_categorical_accuracy: 0.7782\n",
      "Epoch 28/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.7400 - categorical_accuracy: 0.7253Epoch 28: loss = 0.7402867674827576, val_loss = 0.6041582226753235\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.7403 - categorical_accuracy: 0.7251 - val_loss: 0.6042 - val_categorical_accuracy: 0.7729\n",
      "Epoch 29/50\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.6305 - categorical_accuracy: 0.7461Epoch 29: loss = 0.6350941061973572, val_loss = 0.5702186822891235\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6351 - categorical_accuracy: 0.7456 - val_loss: 0.5702 - val_categorical_accuracy: 0.8110\n",
      "Epoch 30/50\n",
      "79/83 [===========================>..] - ETA: 0s - loss: 0.6038 - categorical_accuracy: 0.7682Restoring model weights from the end of the best epoch: 25.\n",
      "Epoch 30: loss = 0.6001705527305603, val_loss = 0.5570178031921387\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6002 - categorical_accuracy: 0.7685 - val_loss: 0.5570 - val_categorical_accuracy: 0.8011\n",
      "Epoch 30: early stopping\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.5536 - categorical_accuracy: 0.8133\n",
      "Epoch 1/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 2.8806 - categorical_accuracy: 0.1151Epoch 1: loss = 2.853642702102661, val_loss = 2.520780324935913\n",
      "41/41 [==============================] - 2s 22ms/step - loss: 2.8536 - categorical_accuracy: 0.1197 - val_loss: 2.5208 - val_categorical_accuracy: 0.1881\n",
      "Epoch 2/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.2518 - categorical_accuracy: 0.2398Epoch 2: loss = 2.2383594512939453, val_loss = 1.8198671340942383\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 2.2384 - categorical_accuracy: 0.2439 - val_loss: 1.8199 - val_categorical_accuracy: 0.3831\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.6704 - categorical_accuracy: 0.4291Epoch 3: loss = 1.67041015625, val_loss = 1.547350287437439\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 1.6704 - categorical_accuracy: 0.4291 - val_loss: 1.5474 - val_categorical_accuracy: 0.5232\n",
      "Epoch 4/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.3253 - categorical_accuracy: 0.5529Epoch 4: loss = 1.310410976409912, val_loss = 1.0896575450897217\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 1.3104 - categorical_accuracy: 0.5572 - val_loss: 1.0897 - val_categorical_accuracy: 0.6451\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0898 - categorical_accuracy: 0.6364Epoch 5: loss = 1.0897842645645142, val_loss = 0.9192153215408325\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 1.0898 - categorical_accuracy: 0.6364 - val_loss: 0.9192 - val_categorical_accuracy: 0.6999\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.8966 - categorical_accuracy: 0.6776Epoch 6: loss = 0.8965875506401062, val_loss = 0.8447751998901367\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.8966 - categorical_accuracy: 0.6776 - val_loss: 0.8448 - val_categorical_accuracy: 0.6999\n",
      "Epoch 7/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.8166 - categorical_accuracy: 0.7027Epoch 7: loss = 0.8059390783309937, val_loss = 0.7938647866249084\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.8059 - categorical_accuracy: 0.7073 - val_loss: 0.7939 - val_categorical_accuracy: 0.7251\n",
      "Epoch 8/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 0.7348 - categorical_accuracy: 0.7410Epoch 8: loss = 0.7324082255363464, val_loss = 0.8184105753898621\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.7324 - categorical_accuracy: 0.7409 - val_loss: 0.8184 - val_categorical_accuracy: 0.7068\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6899 - categorical_accuracy: 0.7477Epoch 9: loss = 0.6898965239524841, val_loss = 0.6709111928939819\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.6899 - categorical_accuracy: 0.7477 - val_loss: 0.6709 - val_categorical_accuracy: 0.7753\n",
      "Epoch 10/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.6507 - categorical_accuracy: 0.7620Epoch 10: loss = 0.6441138982772827, val_loss = 0.7269431352615356\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.6441 - categorical_accuracy: 0.7652 - val_loss: 0.7269 - val_categorical_accuracy: 0.7281\n",
      "Epoch 11/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.6576 - categorical_accuracy: 0.7534Epoch 11: loss = 0.6512445211410522, val_loss = 0.6391756534576416\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.6512 - categorical_accuracy: 0.7538 - val_loss: 0.6392 - val_categorical_accuracy: 0.7738\n",
      "Epoch 12/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.6306 - categorical_accuracy: 0.7695Epoch 12: loss = 0.6241627931594849, val_loss = 0.7854300737380981\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.6242 - categorical_accuracy: 0.7721 - val_loss: 0.7854 - val_categorical_accuracy: 0.7258\n",
      "Epoch 13/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.5916 - categorical_accuracy: 0.7828Epoch 13: loss = 0.5927398204803467, val_loss = 0.5873777270317078\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.5927 - categorical_accuracy: 0.7797 - val_loss: 0.5874 - val_categorical_accuracy: 0.7928\n",
      "Epoch 14/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 0.5087 - categorical_accuracy: 0.8117Epoch 14: loss = 0.5018226504325867, val_loss = 0.5850906372070312\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.5018 - categorical_accuracy: 0.8133 - val_loss: 0.5851 - val_categorical_accuracy: 0.7852\n",
      "Epoch 15/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 0.4746 - categorical_accuracy: 0.8281Epoch 15: loss = 0.4756017029285431, val_loss = 0.5306908488273621\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.4756 - categorical_accuracy: 0.8270 - val_loss: 0.5307 - val_categorical_accuracy: 0.8225\n",
      "Epoch 16/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.4433 - categorical_accuracy: 0.8365Epoch 16: loss = 0.4458991289138794, val_loss = 0.6034425497055054\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.4459 - categorical_accuracy: 0.8338 - val_loss: 0.6034 - val_categorical_accuracy: 0.7761\n",
      "Epoch 17/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.4311 - categorical_accuracy: 0.8359Epoch 17: loss = 0.43592584133148193, val_loss = 0.47094327211380005\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.4359 - categorical_accuracy: 0.8346 - val_loss: 0.4709 - val_categorical_accuracy: 0.8416\n",
      "Epoch 18/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.4794 - categorical_accuracy: 0.8164Epoch 18: loss = 0.4786715507507324, val_loss = 0.5097172856330872\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.4787 - categorical_accuracy: 0.8163 - val_loss: 0.5097 - val_categorical_accuracy: 0.8172\n",
      "Epoch 19/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.4451 - categorical_accuracy: 0.8297Epoch 19: loss = 0.44199585914611816, val_loss = 0.47815564274787903\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.4420 - categorical_accuracy: 0.8316 - val_loss: 0.4782 - val_categorical_accuracy: 0.8302\n",
      "Epoch 20/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.4186 - categorical_accuracy: 0.8462Epoch 20: loss = 0.42011475563049316, val_loss = 0.4574671983718872\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.4201 - categorical_accuracy: 0.8468 - val_loss: 0.4575 - val_categorical_accuracy: 0.8363\n",
      "Epoch 21/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 0.3634 - categorical_accuracy: 0.8717Epoch 21: loss = 0.3661684989929199, val_loss = 0.4710002541542053\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.3662 - categorical_accuracy: 0.8704 - val_loss: 0.4710 - val_categorical_accuracy: 0.8264\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.3837 - categorical_accuracy: 0.8537Epoch 22: loss = 0.3836880326271057, val_loss = 0.4444918930530548\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.3837 - categorical_accuracy: 0.8537 - val_loss: 0.4445 - val_categorical_accuracy: 0.8393\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.3531 - categorical_accuracy: 0.8544Epoch 23: loss = 0.353070467710495, val_loss = 0.40964004397392273\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.3531 - categorical_accuracy: 0.8544 - val_loss: 0.4096 - val_categorical_accuracy: 0.8538\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.3536 - categorical_accuracy: 0.8659Epoch 24: loss = 0.3536072373390198, val_loss = 0.48809513449668884\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.3536 - categorical_accuracy: 0.8659 - val_loss: 0.4881 - val_categorical_accuracy: 0.8218\n",
      "Epoch 25/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.3417 - categorical_accuracy: 0.8641Epoch 25: loss = 0.34313729405403137, val_loss = 0.44496914744377136\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.3431 - categorical_accuracy: 0.8636 - val_loss: 0.4450 - val_categorical_accuracy: 0.8393\n",
      "Epoch 26/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.3047 - categorical_accuracy: 0.8775Epoch 26: loss = 0.30749380588531494, val_loss = 0.45165228843688965\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.3075 - categorical_accuracy: 0.8788 - val_loss: 0.4517 - val_categorical_accuracy: 0.8431\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2810 - categorical_accuracy: 0.8963Epoch 27: loss = 0.28103023767471313, val_loss = 0.3507353663444519\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.2810 - categorical_accuracy: 0.8963 - val_loss: 0.3507 - val_categorical_accuracy: 0.8972\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2852 - categorical_accuracy: 0.8979Epoch 28: loss = 0.28518393635749817, val_loss = 0.4253736734390259\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.2852 - categorical_accuracy: 0.8979 - val_loss: 0.4254 - val_categorical_accuracy: 0.8454\n",
      "Epoch 29/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.2976 - categorical_accuracy: 0.8910Epoch 29: loss = 0.2936665415763855, val_loss = 0.47776326537132263\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.2937 - categorical_accuracy: 0.8941 - val_loss: 0.4778 - val_categorical_accuracy: 0.8408\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2593 - categorical_accuracy: 0.9024Epoch 30: loss = 0.2592954635620117, val_loss = 0.34027260541915894\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.2593 - categorical_accuracy: 0.9024 - val_loss: 0.3403 - val_categorical_accuracy: 0.8850\n",
      "Epoch 31/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.2608 - categorical_accuracy: 0.9054Epoch 31: loss = 0.25689440965652466, val_loss = 0.4107714891433716\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.2569 - categorical_accuracy: 0.9055 - val_loss: 0.4108 - val_categorical_accuracy: 0.8599\n",
      "Epoch 32/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.2536 - categorical_accuracy: 0.9012Epoch 32: loss = 0.2542719542980194, val_loss = 0.3563872277736664\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.2543 - categorical_accuracy: 0.9017 - val_loss: 0.3564 - val_categorical_accuracy: 0.8766\n",
      "Epoch 33/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.2434 - categorical_accuracy: 0.9029Epoch 33: loss = 0.23446571826934814, val_loss = 0.32771140336990356\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.2345 - categorical_accuracy: 0.9070 - val_loss: 0.3277 - val_categorical_accuracy: 0.8896\n",
      "Epoch 34/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.2655 - categorical_accuracy: 0.8922Epoch 34: loss = 0.26995208859443665, val_loss = 0.38442859053611755\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.2700 - categorical_accuracy: 0.8895 - val_loss: 0.3844 - val_categorical_accuracy: 0.8705\n",
      "Epoch 35/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 0.3965 - categorical_accuracy: 0.8462Epoch 35: loss = 0.39301514625549316, val_loss = 0.4260258972644806\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.3930 - categorical_accuracy: 0.8498 - val_loss: 0.4260 - val_categorical_accuracy: 0.8439\n",
      "Epoch 36/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.3063 - categorical_accuracy: 0.8797Epoch 36: loss = 0.3051624000072479, val_loss = 0.36912497878074646\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.3052 - categorical_accuracy: 0.8811 - val_loss: 0.3691 - val_categorical_accuracy: 0.8698\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2670 - categorical_accuracy: 0.8956Epoch 37: loss = 0.26701271533966064, val_loss = 0.2915968596935272\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.2670 - categorical_accuracy: 0.8956 - val_loss: 0.2916 - val_categorical_accuracy: 0.9094\n",
      "Epoch 38/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.2324 - categorical_accuracy: 0.9183Epoch 38: loss = 0.22872775793075562, val_loss = 0.4477783441543579\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.2287 - categorical_accuracy: 0.9192 - val_loss: 0.4478 - val_categorical_accuracy: 0.8439\n",
      "Epoch 39/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.2118 - categorical_accuracy: 0.9183Epoch 39: loss = 0.21473659574985504, val_loss = 0.30614936351776123\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.2147 - categorical_accuracy: 0.9162 - val_loss: 0.3061 - val_categorical_accuracy: 0.8911\n",
      "Epoch 40/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.1874 - categorical_accuracy: 0.9287Epoch 40: loss = 0.18620361387729645, val_loss = 0.26430821418762207\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.1862 - categorical_accuracy: 0.9291 - val_loss: 0.2643 - val_categorical_accuracy: 0.9101\n",
      "Epoch 41/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.2368 - categorical_accuracy: 0.9122Epoch 41: loss = 0.2405010610818863, val_loss = 0.3863319158554077\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.2405 - categorical_accuracy: 0.9116 - val_loss: 0.3863 - val_categorical_accuracy: 0.8682\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2057 - categorical_accuracy: 0.9200Epoch 42: loss = 0.20565328001976013, val_loss = 0.3221096992492676\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.2057 - categorical_accuracy: 0.9200 - val_loss: 0.3221 - val_categorical_accuracy: 0.8865\n",
      "Epoch 43/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.1920 - categorical_accuracy: 0.9295Epoch 43: loss = 0.19244937598705292, val_loss = 0.32689806818962097\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.1924 - categorical_accuracy: 0.9291 - val_loss: 0.3269 - val_categorical_accuracy: 0.8979\n",
      "Epoch 44/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.2179 - categorical_accuracy: 0.9103Epoch 44: loss = 0.21726107597351074, val_loss = 0.322370707988739\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.2173 - categorical_accuracy: 0.9108 - val_loss: 0.3224 - val_categorical_accuracy: 0.8880\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1828 - categorical_accuracy: 0.9322Restoring model weights from the end of the best epoch: 40.\n",
      "Epoch 45: loss = 0.18281632661819458, val_loss = 0.2691951394081116\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.1828 - categorical_accuracy: 0.9322 - val_loss: 0.2692 - val_categorical_accuracy: 0.9185\n",
      "Epoch 45: early stopping\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2643 - categorical_accuracy: 0.9101\n",
      "Epoch 1/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.8421 - categorical_accuracy: 0.1125Epoch 1: loss = 2.829012155532837, val_loss = 2.3684215545654297\n",
      "42/42 [==============================] - 2s 25ms/step - loss: 2.8290 - categorical_accuracy: 0.1127 - val_loss: 2.3684 - val_categorical_accuracy: 0.1989\n",
      "Epoch 2/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 2.2147 - categorical_accuracy: 0.2533Epoch 2: loss = 2.1954219341278076, val_loss = 1.8578182458877563\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 2.1954 - categorical_accuracy: 0.2628 - val_loss: 1.8578 - val_categorical_accuracy: 0.3377\n",
      "Epoch 3/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.7503 - categorical_accuracy: 0.3948Epoch 3: loss = 1.750033974647522, val_loss = 1.5793702602386475\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 1.7500 - categorical_accuracy: 0.3945 - val_loss: 1.5794 - val_categorical_accuracy: 0.4627\n",
      "Epoch 4/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.4818 - categorical_accuracy: 0.4710Epoch 4: loss = 1.4807156324386597, val_loss = 1.1852986812591553\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 1.4807 - categorical_accuracy: 0.4714 - val_loss: 1.1853 - val_categorical_accuracy: 0.6098\n",
      "Epoch 5/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.1843 - categorical_accuracy: 0.5922Epoch 5: loss = 1.1852983236312866, val_loss = 0.9878589510917664\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 1.1853 - categorical_accuracy: 0.5918 - val_loss: 0.9879 - val_categorical_accuracy: 0.6669\n",
      "Epoch 6/50\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 1.1310 - categorical_accuracy: 0.6030Epoch 6: loss = 1.1138322353363037, val_loss = 1.2649465799331665\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.1138 - categorical_accuracy: 0.6085 - val_loss: 1.2649 - val_categorical_accuracy: 0.5938\n",
      "Epoch 7/50\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 1.1997 - categorical_accuracy: 0.5921Epoch 7: loss = 1.1726375818252563, val_loss = 0.9133367538452148\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.1726 - categorical_accuracy: 0.6040 - val_loss: 0.9133 - val_categorical_accuracy: 0.7081\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.9146 - categorical_accuracy: 0.6717Epoch 8: loss = 0.9145551323890686, val_loss = 0.9026566743850708\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.9146 - categorical_accuracy: 0.6717 - val_loss: 0.9027 - val_categorical_accuracy: 0.6784\n",
      "Epoch 9/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.8760 - categorical_accuracy: 0.6803Epoch 9: loss = 0.8672715425491333, val_loss = 0.6942151784896851\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.8673 - categorical_accuracy: 0.6847 - val_loss: 0.6942 - val_categorical_accuracy: 0.7805\n",
      "Epoch 10/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.7797 - categorical_accuracy: 0.7125Epoch 10: loss = 0.7788072824478149, val_loss = 0.6924229860305786\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.7788 - categorical_accuracy: 0.7129 - val_loss: 0.6924 - val_categorical_accuracy: 0.7614\n",
      "Epoch 11/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.6797 - categorical_accuracy: 0.7641Epoch 11: loss = 0.6820250749588013, val_loss = 0.8832366466522217\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.6820 - categorical_accuracy: 0.7631 - val_loss: 0.8832 - val_categorical_accuracy: 0.7233\n",
      "Epoch 12/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.8268 - categorical_accuracy: 0.7027Epoch 12: loss = 0.8264035582542419, val_loss = 0.739630937576294\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.8264 - categorical_accuracy: 0.7030 - val_loss: 0.7396 - val_categorical_accuracy: 0.7317\n",
      "Epoch 13/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.6859 - categorical_accuracy: 0.7453Epoch 13: loss = 0.6830232739448547, val_loss = 0.6235653758049011\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.6830 - categorical_accuracy: 0.7479 - val_loss: 0.6236 - val_categorical_accuracy: 0.7683\n",
      "Epoch 14/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.5955 - categorical_accuracy: 0.7829Epoch 14: loss = 0.6073980927467346, val_loss = 0.8312986493110657\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.6074 - categorical_accuracy: 0.7791 - val_loss: 0.8313 - val_categorical_accuracy: 0.7035\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.7346 - categorical_accuracy: 0.7471Epoch 15: loss = 0.7345916628837585, val_loss = 0.6122041344642639\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7346 - categorical_accuracy: 0.7471 - val_loss: 0.6122 - val_categorical_accuracy: 0.8095\n",
      "Epoch 16/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.5506 - categorical_accuracy: 0.7973Epoch 16: loss = 0.5502711534500122, val_loss = 0.672954797744751\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.5503 - categorical_accuracy: 0.7974 - val_loss: 0.6730 - val_categorical_accuracy: 0.7698\n",
      "Epoch 17/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.5287 - categorical_accuracy: 0.8166Epoch 17: loss = 0.521222710609436, val_loss = 0.45857545733451843\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.5212 - categorical_accuracy: 0.8180 - val_loss: 0.4586 - val_categorical_accuracy: 0.8521\n",
      "Epoch 18/50\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.5092 - categorical_accuracy: 0.8302Epoch 18: loss = 0.5136140584945679, val_loss = 0.513447642326355\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.5136 - categorical_accuracy: 0.8256 - val_loss: 0.5134 - val_categorical_accuracy: 0.8460\n",
      "Epoch 19/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.5286 - categorical_accuracy: 0.8053Epoch 19: loss = 0.5215508341789246, val_loss = 0.5631999373435974\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.5216 - categorical_accuracy: 0.8073 - val_loss: 0.5632 - val_categorical_accuracy: 0.7896\n",
      "Epoch 20/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.4625 - categorical_accuracy: 0.8323Epoch 20: loss = 0.46210554242134094, val_loss = 0.5713236927986145\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.4621 - categorical_accuracy: 0.8324 - val_loss: 0.5713 - val_categorical_accuracy: 0.8133\n",
      "Epoch 21/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.5203 - categorical_accuracy: 0.8101Epoch 21: loss = 0.5161041021347046, val_loss = 0.5326867699623108\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.5161 - categorical_accuracy: 0.8134 - val_loss: 0.5327 - val_categorical_accuracy: 0.8163\n",
      "Epoch 22/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.6112 - categorical_accuracy: 0.7763Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 22: loss = 0.5983049273490906, val_loss = 1.143566370010376\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.5983 - categorical_accuracy: 0.7814 - val_loss: 1.1436 - val_categorical_accuracy: 0.6242\n",
      "Epoch 22: early stopping\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.4586 - categorical_accuracy: 0.8521\n",
      "Epoch 1/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 3.0207 - categorical_accuracy: 0.0888Epoch 1: loss = 2.9960696697235107, val_loss = 2.6326351165771484\n",
      "41/41 [==============================] - 2s 20ms/step - loss: 2.9961 - categorical_accuracy: 0.0945 - val_loss: 2.6326 - val_categorical_accuracy: 0.1904\n",
      "Epoch 2/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.4582 - categorical_accuracy: 0.1891Epoch 2: loss = 2.455345630645752, val_loss = 2.158705234527588\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 2.4553 - categorical_accuracy: 0.1921 - val_loss: 2.1587 - val_categorical_accuracy: 0.3008\n",
      "Epoch 3/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.9676 - categorical_accuracy: 0.3195Epoch 3: loss = 1.9611631631851196, val_loss = 1.7602612972259521\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 1.9612 - categorical_accuracy: 0.3209 - val_loss: 1.7603 - val_categorical_accuracy: 0.4037\n",
      "Epoch 4/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.7051 - categorical_accuracy: 0.4031Epoch 4: loss = 1.6987942457199097, val_loss = 1.4361648559570312\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 1.6988 - categorical_accuracy: 0.4040 - val_loss: 1.4362 - val_categorical_accuracy: 0.5232\n",
      "Epoch 5/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.3864 - categorical_accuracy: 0.5203Epoch 5: loss = 1.3834961652755737, val_loss = 1.1360089778900146\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 1.3835 - categorical_accuracy: 0.5213 - val_loss: 1.1360 - val_categorical_accuracy: 0.6664\n",
      "Epoch 6/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.2192 - categorical_accuracy: 0.5861Epoch 6: loss = 1.2133277654647827, val_loss = 1.0217103958129883\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 1.2133 - categorical_accuracy: 0.5800 - val_loss: 1.0217 - val_categorical_accuracy: 0.6733\n",
      "Epoch 7/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.0029 - categorical_accuracy: 0.6579Epoch 7: loss = 1.0068429708480835, val_loss = 0.9045413136482239\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 1.0068 - categorical_accuracy: 0.6532 - val_loss: 0.9045 - val_categorical_accuracy: 0.6809\n",
      "Epoch 8/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.9207 - categorical_accuracy: 0.6689Epoch 8: loss = 0.91538405418396, val_loss = 0.9342926144599915\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.9154 - categorical_accuracy: 0.6715 - val_loss: 0.9343 - val_categorical_accuracy: 0.6573\n",
      "Epoch 9/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.8920 - categorical_accuracy: 0.6836Epoch 9: loss = 0.8866147398948669, val_loss = 0.8259502053260803\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.8866 - categorical_accuracy: 0.6845 - val_loss: 0.8260 - val_categorical_accuracy: 0.7228\n",
      "Epoch 10/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.8047 - categorical_accuracy: 0.7094Epoch 10: loss = 0.7986943125724792, val_loss = 0.708206832408905\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.7987 - categorical_accuracy: 0.7104 - val_loss: 0.7082 - val_categorical_accuracy: 0.7502\n",
      "Epoch 11/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.7131 - categorical_accuracy: 0.7540Epoch 11: loss = 0.7156805992126465, val_loss = 0.7059731483459473\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.7157 - categorical_accuracy: 0.7515 - val_loss: 0.7060 - val_categorical_accuracy: 0.7464\n",
      "Epoch 12/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 0.7738 - categorical_accuracy: 0.7196Epoch 12: loss = 0.7720469832420349, val_loss = 0.8184574842453003\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.7720 - categorical_accuracy: 0.7233 - val_loss: 0.8185 - val_categorical_accuracy: 0.7327\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6443 - categorical_accuracy: 0.7576Epoch 13: loss = 0.6442509889602661, val_loss = 0.6900448799133301\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.6443 - categorical_accuracy: 0.7576 - val_loss: 0.6900 - val_categorical_accuracy: 0.7479\n",
      "Epoch 14/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.6239 - categorical_accuracy: 0.7669Epoch 14: loss = 0.6232175827026367, val_loss = 0.6463837623596191\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.6232 - categorical_accuracy: 0.7698 - val_loss: 0.6464 - val_categorical_accuracy: 0.7883\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6113 - categorical_accuracy: 0.7713Epoch 15: loss = 0.6112653613090515, val_loss = 0.7547905445098877\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.6113 - categorical_accuracy: 0.7713 - val_loss: 0.7548 - val_categorical_accuracy: 0.7555\n",
      "Epoch 16/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 0.5934 - categorical_accuracy: 0.7755Epoch 16: loss = 0.605150580406189, val_loss = 0.5989291071891785\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.6052 - categorical_accuracy: 0.7706 - val_loss: 0.5989 - val_categorical_accuracy: 0.8012\n",
      "Epoch 17/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.5796 - categorical_accuracy: 0.7852Epoch 17: loss = 0.5775989294052124, val_loss = 0.6042031049728394\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.5776 - categorical_accuracy: 0.7866 - val_loss: 0.6042 - val_categorical_accuracy: 0.7921\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.5566 - categorical_accuracy: 0.7934Epoch 18: loss = 0.5565751791000366, val_loss = 0.622581958770752\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.5566 - categorical_accuracy: 0.7934 - val_loss: 0.6226 - val_categorical_accuracy: 0.7799\n",
      "Epoch 19/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.5643 - categorical_accuracy: 0.7901Epoch 19: loss = 0.5566990971565247, val_loss = 0.5085605382919312\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.5567 - categorical_accuracy: 0.7934 - val_loss: 0.5086 - val_categorical_accuracy: 0.8401\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.5013 - categorical_accuracy: 0.8026Epoch 20: loss = 0.5013439059257507, val_loss = 0.5732758045196533\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.5013 - categorical_accuracy: 0.8026 - val_loss: 0.5733 - val_categorical_accuracy: 0.7883\n",
      "Epoch 21/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.4485 - categorical_accuracy: 0.8235Epoch 21: loss = 0.45171040296554565, val_loss = 0.4718899726867676\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.4517 - categorical_accuracy: 0.8216 - val_loss: 0.4719 - val_categorical_accuracy: 0.8553\n",
      "Epoch 22/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.4515 - categorical_accuracy: 0.8237Epoch 22: loss = 0.45526182651519775, val_loss = 0.5473769903182983\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.4553 - categorical_accuracy: 0.8239 - val_loss: 0.5474 - val_categorical_accuracy: 0.7959\n",
      "Epoch 23/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.4532 - categorical_accuracy: 0.8261Epoch 23: loss = 0.45406314730644226, val_loss = 0.5995519757270813\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.4541 - categorical_accuracy: 0.8270 - val_loss: 0.5996 - val_categorical_accuracy: 0.7867\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.5143 - categorical_accuracy: 0.8064Epoch 24: loss = 0.5142782330513, val_loss = 0.511809229850769\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.5143 - categorical_accuracy: 0.8064 - val_loss: 0.5118 - val_categorical_accuracy: 0.8241\n",
      "Epoch 25/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 0.4061 - categorical_accuracy: 0.8470Epoch 25: loss = 0.40375715494155884, val_loss = 0.47322750091552734\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.4038 - categorical_accuracy: 0.8445 - val_loss: 0.4732 - val_categorical_accuracy: 0.8401\n",
      "Epoch 26/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 0.3842 - categorical_accuracy: 0.8503Restoring model weights from the end of the best epoch: 21.\n",
      "Epoch 26: loss = 0.3993048369884491, val_loss = 0.5089627504348755\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.3993 - categorical_accuracy: 0.8476 - val_loss: 0.5090 - val_categorical_accuracy: 0.8119\n",
      "Epoch 26: early stopping\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4719 - categorical_accuracy: 0.8553\n",
      "Epoch 1/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 2.9986 - categorical_accuracy: 0.0769Epoch 1: loss = 2.9856314659118652, val_loss = 2.6671383380889893\n",
      "42/42 [==============================] - 2s 20ms/step - loss: 2.9856 - categorical_accuracy: 0.0777 - val_loss: 2.6671 - val_categorical_accuracy: 0.1349\n",
      "Epoch 2/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 2.5910 - categorical_accuracy: 0.1530Epoch 2: loss = 2.576122522354126, val_loss = 2.2513999938964844\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 2.5761 - categorical_accuracy: 0.1538 - val_loss: 2.2514 - val_categorical_accuracy: 0.2584\n",
      "Epoch 3/50\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 2.1293 - categorical_accuracy: 0.2677Epoch 3: loss = 2.1045093536376953, val_loss = 1.7489631175994873\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 2.1045 - categorical_accuracy: 0.2727 - val_loss: 1.7490 - val_categorical_accuracy: 0.4306\n",
      "Epoch 4/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.7380 - categorical_accuracy: 0.3953Epoch 4: loss = 1.7467135190963745, val_loss = 1.5231380462646484\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 1.7467 - categorical_accuracy: 0.3907 - val_loss: 1.5231 - val_categorical_accuracy: 0.4421\n",
      "Epoch 5/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.5900 - categorical_accuracy: 0.4195Epoch 5: loss = 1.5915985107421875, val_loss = 1.2387566566467285\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.5916 - categorical_accuracy: 0.4212 - val_loss: 1.2388 - val_categorical_accuracy: 0.6037\n",
      "Epoch 6/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 1.3545 - categorical_accuracy: 0.5104Epoch 6: loss = 1.3365871906280518, val_loss = 1.2038012742996216\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 1.3366 - categorical_accuracy: 0.5194 - val_loss: 1.2038 - val_categorical_accuracy: 0.6372\n",
      "Epoch 7/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 1.3057 - categorical_accuracy: 0.5395Epoch 7: loss = 1.2918493747711182, val_loss = 1.083931803703308\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.2918 - categorical_accuracy: 0.5461 - val_loss: 1.0839 - val_categorical_accuracy: 0.6105\n",
      "Epoch 8/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.1079 - categorical_accuracy: 0.6164Epoch 8: loss = 1.1134446859359741, val_loss = 1.0581438541412354\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 1.1134 - categorical_accuracy: 0.6131 - val_loss: 1.0581 - val_categorical_accuracy: 0.6044\n",
      "Epoch 9/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 1.0174 - categorical_accuracy: 0.6282Epoch 9: loss = 1.014751672744751, val_loss = 0.7943857908248901\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.0148 - categorical_accuracy: 0.6260 - val_loss: 0.7944 - val_categorical_accuracy: 0.7431\n",
      "Epoch 10/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.9134 - categorical_accuracy: 0.6691Epoch 10: loss = 0.910531222820282, val_loss = 0.69017094373703\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.9105 - categorical_accuracy: 0.6717 - val_loss: 0.6902 - val_categorical_accuracy: 0.7805\n",
      "Epoch 11/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.9683 - categorical_accuracy: 0.6578Epoch 11: loss = 0.9692779779434204, val_loss = 0.9233300685882568\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9693 - categorical_accuracy: 0.6573 - val_loss: 0.9233 - val_categorical_accuracy: 0.6471\n",
      "Epoch 12/50\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.8597 - categorical_accuracy: 0.6867Epoch 12: loss = 0.8582620620727539, val_loss = 0.6604015827178955\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.8583 - categorical_accuracy: 0.6877 - val_loss: 0.6604 - val_categorical_accuracy: 0.7752\n",
      "Epoch 13/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.9240 - categorical_accuracy: 0.6538Epoch 13: loss = 0.914585292339325, val_loss = 0.7285195589065552\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9146 - categorical_accuracy: 0.6603 - val_loss: 0.7285 - val_categorical_accuracy: 0.7622\n",
      "Epoch 14/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.8371 - categorical_accuracy: 0.6953Epoch 14: loss = 0.8283113837242126, val_loss = 0.7908608317375183\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.8283 - categorical_accuracy: 0.6992 - val_loss: 0.7909 - val_categorical_accuracy: 0.7363\n",
      "Epoch 15/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.7707 - categorical_accuracy: 0.7234Epoch 15: loss = 0.7615713477134705, val_loss = 0.6914952993392944\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7616 - categorical_accuracy: 0.7273 - val_loss: 0.6915 - val_categorical_accuracy: 0.7706\n",
      "Epoch 16/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.6889 - categorical_accuracy: 0.7452Epoch 16: loss = 0.6956384778022766, val_loss = 0.6754408478736877\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.6956 - categorical_accuracy: 0.7441 - val_loss: 0.6754 - val_categorical_accuracy: 0.7607\n",
      "Epoch 17/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.7556 - categorical_accuracy: 0.7273Epoch 17: loss = 0.7512434124946594, val_loss = 0.5845978260040283\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7512 - categorical_accuracy: 0.7281 - val_loss: 0.5846 - val_categorical_accuracy: 0.8041\n",
      "Epoch 18/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.6609 - categorical_accuracy: 0.7546Epoch 18: loss = 0.6621806621551514, val_loss = 0.7789585590362549\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.6622 - categorical_accuracy: 0.7540 - val_loss: 0.7790 - val_categorical_accuracy: 0.7043\n",
      "Epoch 19/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.8302 - categorical_accuracy: 0.7109Epoch 19: loss = 0.8275882005691528, val_loss = 0.5354933142662048\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.8276 - categorical_accuracy: 0.7136 - val_loss: 0.5355 - val_categorical_accuracy: 0.8148\n",
      "Epoch 20/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.7145 - categorical_accuracy: 0.7401Epoch 20: loss = 0.7139689922332764, val_loss = 0.5371785759925842\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.7140 - categorical_accuracy: 0.7403 - val_loss: 0.5372 - val_categorical_accuracy: 0.8186\n",
      "Epoch 21/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.6075 - categorical_accuracy: 0.7774Epoch 21: loss = 0.6078191995620728, val_loss = 0.6840055584907532\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.6078 - categorical_accuracy: 0.7776 - val_loss: 0.6840 - val_categorical_accuracy: 0.7287\n",
      "Epoch 22/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.6762 - categorical_accuracy: 0.7453Epoch 22: loss = 0.673893928527832, val_loss = 0.5588231682777405\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.6739 - categorical_accuracy: 0.7449 - val_loss: 0.5588 - val_categorical_accuracy: 0.7858\n",
      "Epoch 23/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.5628 - categorical_accuracy: 0.7917Epoch 23: loss = 0.573426365852356, val_loss = 0.4912453293800354\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.5734 - categorical_accuracy: 0.7852 - val_loss: 0.4912 - val_categorical_accuracy: 0.8125\n",
      "Epoch 24/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.5436 - categorical_accuracy: 0.7995Epoch 24: loss = 0.5431789755821228, val_loss = 0.4484221637248993\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.5432 - categorical_accuracy: 0.7997 - val_loss: 0.4484 - val_categorical_accuracy: 0.8468\n",
      "Epoch 25/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.5383 - categorical_accuracy: 0.8069Epoch 25: loss = 0.5385370254516602, val_loss = 0.5387641787528992\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.5385 - categorical_accuracy: 0.8050 - val_loss: 0.5388 - val_categorical_accuracy: 0.8034\n",
      "Epoch 26/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.6312 - categorical_accuracy: 0.7604Epoch 26: loss = 0.6287841796875, val_loss = 0.47653254866600037\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.6288 - categorical_accuracy: 0.7601 - val_loss: 0.4765 - val_categorical_accuracy: 0.8293\n",
      "Epoch 27/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.4982 - categorical_accuracy: 0.8102Epoch 27: loss = 0.49508652091026306, val_loss = 0.47343769669532776\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.4951 - categorical_accuracy: 0.8104 - val_loss: 0.4734 - val_categorical_accuracy: 0.8140\n",
      "Epoch 28/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.4996 - categorical_accuracy: 0.8085Epoch 28: loss = 0.5027124881744385, val_loss = 0.49426209926605225\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.5027 - categorical_accuracy: 0.8073 - val_loss: 0.4943 - val_categorical_accuracy: 0.8155\n",
      "Epoch 29/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.4734 - categorical_accuracy: 0.8213Restoring model weights from the end of the best epoch: 24.\n",
      "Epoch 29: loss = 0.4749391973018646, val_loss = 0.45601803064346313\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.4749 - categorical_accuracy: 0.8187 - val_loss: 0.4560 - val_categorical_accuracy: 0.8415\n",
      "Epoch 29: early stopping\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.4484 - categorical_accuracy: 0.8468\n",
      "Epoch 1/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 3.0267 - categorical_accuracy: 0.0913Epoch 1: loss = 3.007962226867676, val_loss = 2.715205669403076\n",
      "41/41 [==============================] - 2s 23ms/step - loss: 3.0080 - categorical_accuracy: 0.0953 - val_loss: 2.7152 - val_categorical_accuracy: 0.1706\n",
      "Epoch 2/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 2.5569 - categorical_accuracy: 0.1805Epoch 2: loss = 2.5589823722839355, val_loss = 2.335430860519409\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 2.5590 - categorical_accuracy: 0.1784 - val_loss: 2.3354 - val_categorical_accuracy: 0.2666\n",
      "Epoch 3/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 2.1017 - categorical_accuracy: 0.3018Epoch 3: loss = 2.099543571472168, val_loss = 1.8029040098190308\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 2.0995 - categorical_accuracy: 0.2973 - val_loss: 1.8029 - val_categorical_accuracy: 0.4623\n",
      "Epoch 4/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.8007 - categorical_accuracy: 0.3710Epoch 4: loss = 1.7968239784240723, val_loss = 1.6398842334747314\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 1.7968 - categorical_accuracy: 0.3720 - val_loss: 1.6399 - val_categorical_accuracy: 0.4273\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.5333 - categorical_accuracy: 0.4451Epoch 5: loss = 1.5333068370819092, val_loss = 1.3277968168258667\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 1.5333 - categorical_accuracy: 0.4451 - val_loss: 1.3278 - val_categorical_accuracy: 0.5697\n",
      "Epoch 6/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 1.3652 - categorical_accuracy: 0.5017Epoch 6: loss = 1.3406254053115845, val_loss = 1.1603546142578125\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 1.3406 - categorical_accuracy: 0.5160 - val_loss: 1.1604 - val_categorical_accuracy: 0.5689\n",
      "Epoch 7/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 1.1831 - categorical_accuracy: 0.5649Epoch 7: loss = 1.1861073970794678, val_loss = 1.0362440347671509\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 1.1861 - categorical_accuracy: 0.5648 - val_loss: 1.0362 - val_categorical_accuracy: 0.6588\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1324 - categorical_accuracy: 0.6021Epoch 8: loss = 1.132371425628662, val_loss = 1.0281453132629395\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 1.1324 - categorical_accuracy: 0.6021 - val_loss: 1.0281 - val_categorical_accuracy: 0.6405\n",
      "Epoch 9/50\n",
      "36/41 [=========================>....] - ETA: 0s - loss: 1.0407 - categorical_accuracy: 0.6276Epoch 9: loss = 1.0456019639968872, val_loss = 0.9601771235466003\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 1.0456 - categorical_accuracy: 0.6258 - val_loss: 0.9602 - val_categorical_accuracy: 0.6725\n",
      "Epoch 10/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 0.9448 - categorical_accuracy: 0.6554Epoch 10: loss = 0.9572755694389343, val_loss = 0.9617720246315002\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.9573 - categorical_accuracy: 0.6494 - val_loss: 0.9618 - val_categorical_accuracy: 0.6634\n",
      "Epoch 11/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.8758 - categorical_accuracy: 0.6843Epoch 11: loss = 0.8773050904273987, val_loss = 0.8049986958503723\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.8773 - categorical_accuracy: 0.6829 - val_loss: 0.8050 - val_categorical_accuracy: 0.7167\n",
      "Epoch 12/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.8751 - categorical_accuracy: 0.6731Epoch 12: loss = 0.8646842241287231, val_loss = 0.7380150556564331\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.8647 - categorical_accuracy: 0.6768 - val_loss: 0.7380 - val_categorical_accuracy: 0.7570\n",
      "Epoch 13/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.8060 - categorical_accuracy: 0.7083Epoch 13: loss = 0.8067709803581238, val_loss = 0.7278462648391724\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 0.8068 - categorical_accuracy: 0.7058 - val_loss: 0.7278 - val_categorical_accuracy: 0.7692\n",
      "Epoch 14/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.7894 - categorical_accuracy: 0.7047Epoch 14: loss = 0.7813145518302917, val_loss = 0.7748199105262756\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.7813 - categorical_accuracy: 0.7088 - val_loss: 0.7748 - val_categorical_accuracy: 0.7334\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.7339 - categorical_accuracy: 0.7195Epoch 15: loss = 0.7339387536048889, val_loss = 0.7309094071388245\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.7339 - categorical_accuracy: 0.7195 - val_loss: 0.7309 - val_categorical_accuracy: 0.7190\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.7186 - categorical_accuracy: 0.7180Epoch 16: loss = 0.7185767292976379, val_loss = 0.6766142845153809\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.7186 - categorical_accuracy: 0.7180 - val_loss: 0.6766 - val_categorical_accuracy: 0.7532\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6564 - categorical_accuracy: 0.7599Epoch 17: loss = 0.6564306020736694, val_loss = 0.6074493527412415\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.6564 - categorical_accuracy: 0.7599 - val_loss: 0.6074 - val_categorical_accuracy: 0.7883\n",
      "Epoch 18/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.6829 - categorical_accuracy: 0.7492Epoch 18: loss = 0.6827635169029236, val_loss = 0.6922509074211121\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 0.6828 - categorical_accuracy: 0.7515 - val_loss: 0.6923 - val_categorical_accuracy: 0.7449\n",
      "Epoch 19/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.6718 - categorical_accuracy: 0.7523Epoch 19: loss = 0.6737979650497437, val_loss = 0.6138598322868347\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.6738 - categorical_accuracy: 0.7508 - val_loss: 0.6139 - val_categorical_accuracy: 0.7997\n",
      "Epoch 20/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 0.6063 - categorical_accuracy: 0.7796Epoch 20: loss = 0.5906516909599304, val_loss = 0.6284618973731995\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.5907 - categorical_accuracy: 0.7873 - val_loss: 0.6285 - val_categorical_accuracy: 0.7875\n",
      "Epoch 21/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.5946 - categorical_accuracy: 0.7901Epoch 21: loss = 0.5963864326477051, val_loss = 0.5253750085830688\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.5964 - categorical_accuracy: 0.7881 - val_loss: 0.5254 - val_categorical_accuracy: 0.8241\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.5736 - categorical_accuracy: 0.7942Epoch 22: loss = 0.5736357569694519, val_loss = 0.5608828067779541\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.5736 - categorical_accuracy: 0.7942 - val_loss: 0.5609 - val_categorical_accuracy: 0.7997\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.5630 - categorical_accuracy: 0.7934Epoch 23: loss = 0.5630183815956116, val_loss = 0.5043325424194336\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.5630 - categorical_accuracy: 0.7934 - val_loss: 0.5043 - val_categorical_accuracy: 0.8149\n",
      "Epoch 24/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.5350 - categorical_accuracy: 0.7906Epoch 24: loss = 0.5377652049064636, val_loss = 0.553752601146698\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.5378 - categorical_accuracy: 0.7881 - val_loss: 0.5538 - val_categorical_accuracy: 0.7845\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.5099 - categorical_accuracy: 0.8178Epoch 25: loss = 0.5099359154701233, val_loss = 0.5011216998100281\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.5099 - categorical_accuracy: 0.8178 - val_loss: 0.5011 - val_categorical_accuracy: 0.8233\n",
      "Epoch 26/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.5060 - categorical_accuracy: 0.8148Epoch 26: loss = 0.505852997303009, val_loss = 0.4899797737598419\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.5059 - categorical_accuracy: 0.8155 - val_loss: 0.4900 - val_categorical_accuracy: 0.8271\n",
      "Epoch 27/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.5021 - categorical_accuracy: 0.8150Epoch 27: loss = 0.5035597085952759, val_loss = 0.459483802318573\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.5036 - categorical_accuracy: 0.8148 - val_loss: 0.4595 - val_categorical_accuracy: 0.8469\n",
      "Epoch 28/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.5008 - categorical_accuracy: 0.8165Epoch 28: loss = 0.5023865103721619, val_loss = 0.4625856280326843\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.5024 - categorical_accuracy: 0.8140 - val_loss: 0.4626 - val_categorical_accuracy: 0.8446\n",
      "Epoch 29/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.4099 - categorical_accuracy: 0.8430Epoch 29: loss = 0.4126332998275757, val_loss = 0.5293825268745422\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.4126 - categorical_accuracy: 0.8422 - val_loss: 0.5294 - val_categorical_accuracy: 0.8157\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4509 - categorical_accuracy: 0.8300Epoch 30: loss = 0.45085009932518005, val_loss = 0.4153789281845093\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.4509 - categorical_accuracy: 0.8300 - val_loss: 0.4154 - val_categorical_accuracy: 0.8553\n",
      "Epoch 31/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 0.4571 - categorical_accuracy: 0.8141Epoch 31: loss = 0.47091150283813477, val_loss = 0.5573333501815796\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 0.4709 - categorical_accuracy: 0.8102 - val_loss: 0.5573 - val_categorical_accuracy: 0.7822\n",
      "Epoch 32/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 0.4918 - categorical_accuracy: 0.8092Epoch 32: loss = 0.49393677711486816, val_loss = 0.5049997568130493\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.4939 - categorical_accuracy: 0.8087 - val_loss: 0.5050 - val_categorical_accuracy: 0.8264\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4519 - categorical_accuracy: 0.8346Epoch 33: loss = 0.45191746950149536, val_loss = 0.4134185314178467\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.4519 - categorical_accuracy: 0.8346 - val_loss: 0.4134 - val_categorical_accuracy: 0.8621\n",
      "Epoch 34/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.4013 - categorical_accuracy: 0.8570Epoch 34: loss = 0.4046795964241028, val_loss = 0.37721124291419983\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.4047 - categorical_accuracy: 0.8552 - val_loss: 0.3772 - val_categorical_accuracy: 0.8698\n",
      "Epoch 35/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.4019 - categorical_accuracy: 0.8530Epoch 35: loss = 0.41198986768722534, val_loss = 0.5510888695716858\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.4120 - categorical_accuracy: 0.8491 - val_loss: 0.5511 - val_categorical_accuracy: 0.7944\n",
      "Epoch 36/50\n",
      "38/41 [==========================>...] - ETA: 0s - loss: 0.3901 - categorical_accuracy: 0.8421Epoch 36: loss = 0.3918662667274475, val_loss = 0.37174269556999207\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.3919 - categorical_accuracy: 0.8422 - val_loss: 0.3717 - val_categorical_accuracy: 0.8789\n",
      "Epoch 37/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.3623 - categorical_accuracy: 0.8640Epoch 37: loss = 0.36101874709129333, val_loss = 0.413129061460495\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.3610 - categorical_accuracy: 0.8636 - val_loss: 0.4131 - val_categorical_accuracy: 0.8469\n",
      "Epoch 38/50\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.3972 - categorical_accuracy: 0.8414Epoch 38: loss = 0.3941269814968109, val_loss = 0.35918837785720825\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.3941 - categorical_accuracy: 0.8422 - val_loss: 0.3592 - val_categorical_accuracy: 0.8713\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4177 - categorical_accuracy: 0.8399Epoch 39: loss = 0.4177076816558838, val_loss = 0.37183597683906555\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.4177 - categorical_accuracy: 0.8399 - val_loss: 0.3718 - val_categorical_accuracy: 0.8713\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.3532 - categorical_accuracy: 0.8521Epoch 40: loss = 0.35315191745758057, val_loss = 0.41470077633857727\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.3532 - categorical_accuracy: 0.8521 - val_loss: 0.4147 - val_categorical_accuracy: 0.8462\n",
      "Epoch 41/50\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.3572 - categorical_accuracy: 0.8742Epoch 41: loss = 0.3619067370891571, val_loss = 0.4444531202316284\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.3619 - categorical_accuracy: 0.8727 - val_loss: 0.4445 - val_categorical_accuracy: 0.8286\n",
      "Epoch 42/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.4059 - categorical_accuracy: 0.8389Epoch 42: loss = 0.4080188572406769, val_loss = 0.35919398069381714\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.4080 - categorical_accuracy: 0.8392 - val_loss: 0.3592 - val_categorical_accuracy: 0.8713\n",
      "Epoch 43/50\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 0.3993 - categorical_accuracy: 0.8373Restoring model weights from the end of the best epoch: 38.\n",
      "Epoch 43: loss = 0.3999089002609253, val_loss = 0.3739469349384308\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.3999 - categorical_accuracy: 0.8377 - val_loss: 0.3739 - val_categorical_accuracy: 0.8698\n",
      "Epoch 43: early stopping\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3592 - categorical_accuracy: 0.8713\n",
      "Epoch 1/50\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 3.1933 - categorical_accuracy: 0.0524Epoch 1: loss = 3.1675117015838623, val_loss = 2.858649253845215\n",
      "42/42 [==============================] - 2s 22ms/step - loss: 3.1675 - categorical_accuracy: 0.0548 - val_loss: 2.8586 - val_categorical_accuracy: 0.0724\n",
      "Epoch 2/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 2.7865 - categorical_accuracy: 0.0907Epoch 2: loss = 2.7865161895751953, val_loss = 2.6318700313568115\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 2.7865 - categorical_accuracy: 0.0906 - val_loss: 2.6319 - val_categorical_accuracy: 0.1242\n",
      "Epoch 3/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 2.6273 - categorical_accuracy: 0.1386Epoch 3: loss = 2.6217503547668457, val_loss = 2.4057798385620117\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 2.6218 - categorical_accuracy: 0.1386 - val_loss: 2.4058 - val_categorical_accuracy: 0.1913\n",
      "Epoch 4/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 2.4280 - categorical_accuracy: 0.1899Epoch 4: loss = 2.4210734367370605, val_loss = 2.121363639831543\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 2.4211 - categorical_accuracy: 0.1919 - val_loss: 2.1214 - val_categorical_accuracy: 0.3148\n",
      "Epoch 5/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 2.1906 - categorical_accuracy: 0.2516Epoch 5: loss = 2.1818294525146484, val_loss = 1.8178962469100952\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 2.1818 - categorical_accuracy: 0.2536 - val_loss: 1.8179 - val_categorical_accuracy: 0.4078\n",
      "Epoch 6/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 1.9307 - categorical_accuracy: 0.3186Epoch 6: loss = 1.9293739795684814, val_loss = 1.5992671251296997\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 1.9294 - categorical_accuracy: 0.3191 - val_loss: 1.5993 - val_categorical_accuracy: 0.4588\n",
      "Epoch 7/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.6413 - categorical_accuracy: 0.4031Epoch 7: loss = 1.6345770359039307, val_loss = 1.4209215641021729\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.6346 - categorical_accuracy: 0.4059 - val_loss: 1.4209 - val_categorical_accuracy: 0.5030\n",
      "Epoch 8/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.5265 - categorical_accuracy: 0.4492Epoch 8: loss = 1.5237163305282593, val_loss = 1.3820677995681763\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 1.5237 - categorical_accuracy: 0.4501 - val_loss: 1.3821 - val_categorical_accuracy: 0.5221\n",
      "Epoch 9/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 1.4055 - categorical_accuracy: 0.4968Epoch 9: loss = 1.4060865640640259, val_loss = 1.1293116807937622\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.4061 - categorical_accuracy: 0.4950 - val_loss: 1.1293 - val_categorical_accuracy: 0.6159\n",
      "Epoch 10/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.3557 - categorical_accuracy: 0.4977Epoch 10: loss = 1.3498040437698364, val_loss = 1.145013451576233\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 1.3498 - categorical_accuracy: 0.4989 - val_loss: 1.1450 - val_categorical_accuracy: 0.6235\n",
      "Epoch 11/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.3062 - categorical_accuracy: 0.5188Epoch 11: loss = 1.3059841394424438, val_loss = 1.0856579542160034\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.3060 - categorical_accuracy: 0.5171 - val_loss: 1.0857 - val_categorical_accuracy: 0.6486\n",
      "Epoch 12/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 1.3605 - categorical_accuracy: 0.5082Epoch 12: loss = 1.342295527458191, val_loss = 0.9635784029960632\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.3423 - categorical_accuracy: 0.5149 - val_loss: 0.9636 - val_categorical_accuracy: 0.6776\n",
      "Epoch 13/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 1.1327 - categorical_accuracy: 0.5929Epoch 13: loss = 1.1574621200561523, val_loss = 0.9363972544670105\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 1.1575 - categorical_accuracy: 0.5834 - val_loss: 0.9364 - val_categorical_accuracy: 0.6883\n",
      "Epoch 14/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 1.0973 - categorical_accuracy: 0.5855Epoch 14: loss = 1.0943379402160645, val_loss = 0.9248078465461731\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.0943 - categorical_accuracy: 0.5864 - val_loss: 0.9248 - val_categorical_accuracy: 0.7012\n",
      "Epoch 15/50\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 1.1234 - categorical_accuracy: 0.5811Epoch 15: loss = 1.123235821723938, val_loss = 1.177473545074463\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 1.1232 - categorical_accuracy: 0.5811 - val_loss: 1.1775 - val_categorical_accuracy: 0.5663\n",
      "Epoch 16/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.2110 - categorical_accuracy: 0.5766Epoch 16: loss = 1.1976113319396973, val_loss = 0.8763134479522705\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.1976 - categorical_accuracy: 0.5804 - val_loss: 0.8763 - val_categorical_accuracy: 0.6806\n",
      "Epoch 17/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.9464 - categorical_accuracy: 0.6402Epoch 17: loss = 0.9460696578025818, val_loss = 0.8438981175422668\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.9461 - categorical_accuracy: 0.6398 - val_loss: 0.8439 - val_categorical_accuracy: 0.7180\n",
      "Epoch 18/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.9648 - categorical_accuracy: 0.6469Epoch 18: loss = 0.9638388156890869, val_loss = 0.7854839563369751\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9638 - categorical_accuracy: 0.6474 - val_loss: 0.7855 - val_categorical_accuracy: 0.7233\n",
      "Epoch 19/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.9421 - categorical_accuracy: 0.6611Epoch 19: loss = 0.9391234517097473, val_loss = 0.9468914270401001\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.9391 - categorical_accuracy: 0.6634 - val_loss: 0.9469 - val_categorical_accuracy: 0.6631\n",
      "Epoch 20/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 1.4049 - categorical_accuracy: 0.5176Epoch 20: loss = 1.4007896184921265, val_loss = 1.0990111827850342\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.4008 - categorical_accuracy: 0.5194 - val_loss: 1.0990 - val_categorical_accuracy: 0.6319\n",
      "Epoch 21/50\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 1.0817 - categorical_accuracy: 0.5847Epoch 21: loss = 1.080830454826355, val_loss = 0.8736530542373657\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 1.0808 - categorical_accuracy: 0.5849 - val_loss: 0.8737 - val_categorical_accuracy: 0.7134\n",
      "Epoch 22/50\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 1.0330 - categorical_accuracy: 0.6172Epoch 22: loss = 1.0293647050857544, val_loss = 0.8509941101074219\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.0294 - categorical_accuracy: 0.6177 - val_loss: 0.8510 - val_categorical_accuracy: 0.7226\n",
      "Epoch 23/50\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 1.0349 - categorical_accuracy: 0.6306Restoring model weights from the end of the best epoch: 18.\n",
      "Epoch 23: loss = 1.052807092666626, val_loss = 0.8451477885246277\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 1.0528 - categorical_accuracy: 0.6238 - val_loss: 0.8451 - val_categorical_accuracy: 0.7325\n",
      "Epoch 23: early stopping\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.7855 - categorical_accuracy: 0.7233\n",
      "Liczba filtrów: 16, Rozmiar partii: 16, Wskaźnik dropout: 0.1, Średni wynik: 0.8163809478282928\n",
      "Liczba filtrów: 16, Rozmiar partii: 16, Wskaźnik dropout: 0.2, Średni wynik: 0.48447223007678986\n",
      "Liczba filtrów: 16, Rozmiar partii: 16, Wskaźnik dropout: 0.3, Średni wynik: 0.0997877698391676\n",
      "Liczba filtrów: 16, Rozmiar partii: 32, Wskaźnik dropout: 0.1, Średni wynik: 0.675399512052536\n",
      "Liczba filtrów: 16, Rozmiar partii: 32, Wskaźnik dropout: 0.2, Średni wynik: 0.7138746976852417\n",
      "Liczba filtrów: 16, Rozmiar partii: 32, Wskaźnik dropout: 0.3, Średni wynik: 0.4426005482673645\n",
      "Liczba filtrów: 32, Rozmiar partii: 16, Wskaźnik dropout: 0.1, Średni wynik: 0.8959989547729492\n",
      "Liczba filtrów: 32, Rozmiar partii: 16, Wskaźnik dropout: 0.2, Średni wynik: 0.8038047254085541\n",
      "Liczba filtrów: 32, Rozmiar partii: 16, Wskaźnik dropout: 0.3, Średni wynik: 0.7603650987148285\n",
      "Liczba filtrów: 32, Rozmiar partii: 32, Wskaźnik dropout: 0.1, Średni wynik: 0.8342806100845337\n",
      "Liczba filtrów: 32, Rozmiar partii: 32, Wskaźnik dropout: 0.2, Średni wynik: 0.8179003894329071\n",
      "Liczba filtrów: 32, Rozmiar partii: 32, Wskaźnik dropout: 0.3, Średni wynik: 0.5561261177062988\n",
      "Liczba filtrów: 64, Rozmiar partii: 16, Wskaźnik dropout: 0.1, Średni wynik: 0.8704639673233032\n",
      "Liczba filtrów: 64, Rozmiar partii: 16, Wskaźnik dropout: 0.2, Średni wynik: 0.8773234486579895\n",
      "Liczba filtrów: 64, Rozmiar partii: 16, Wskaźnik dropout: 0.3, Średni wynik: 0.8358009457588196\n",
      "Liczba filtrów: 64, Rozmiar partii: 32, Wskaźnik dropout: 0.1, Średni wynik: 0.8811318278312683\n",
      "Liczba filtrów: 64, Rozmiar partii: 32, Wskaźnik dropout: 0.2, Średni wynik: 0.8510459959506989\n",
      "Liczba filtrów: 64, Rozmiar partii: 32, Wskaźnik dropout: 0.3, Średni wynik: 0.7973051369190216\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Callback do logowania strat w każdej epoce\n",
    "class LoggingCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        print(f\"Epoch {epoch+1}: loss = {logs.get('loss')}, val_loss = {logs.get('val_loss')}\")\n",
    "\n",
    "# Funkcja do budowania modelu CNN\n",
    "def build_model(filters=32, activation='relu', dropout_rate=0.1):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters, 3, activation=activation, input_shape=(30, 258)))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Conv1D(filters * 2, 3, activation=activation))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(filters * 2, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(actions.shape[0], activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrapper KerasClassifier\n",
    "model = KerasClassifier(build_fn=build_model, verbose=1)\n",
    "\n",
    "# Definicja siatki hiperparametrów dla Grid Search\n",
    "param_grid = {\n",
    "    'filters': [16, 32, 64],\n",
    "    'batch_size': [16, 32],\n",
    "    'dropout_rate': [0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "# Funkcja do trenowania i ewaluacji modelu\n",
    "def train_and_evaluate(filters, batch_size, dropout_rate, epochs=50):\n",
    "    kf = KFold(n_splits=2)\n",
    "    fold_scores = []\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        # Budowanie modelu\n",
    "        model = build_model(filters=filters, dropout_rate=dropout_rate)\n",
    "\n",
    "        # Trenowanie modelu\n",
    "        history = model.fit(\n",
    "            X_train_fold, y_train_fold, \n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size, \n",
    "            validation_data=(X_val_fold, y_val_fold), \n",
    "            callbacks=[early_stopping, LoggingCallback()]\n",
    "        )\n",
    "\n",
    "        # Ewaluacja modelu\n",
    "        val_loss, val_accuracy = model.evaluate(X_val_fold, y_val_fold)\n",
    "        fold_scores.append(val_accuracy)\n",
    "\n",
    "    mean_score = np.mean(fold_scores)\n",
    "    return mean_score\n",
    "\n",
    "# Przechowywanie wyników\n",
    "results = []\n",
    "\n",
    "# Iteracja przez różne kombinacje hiperparametrów\n",
    "for filters in param_grid['filters']:\n",
    "    for batch_size in param_grid['batch_size']:\n",
    "        for dropout_rate in param_grid['dropout_rate']:\n",
    "            mean_score = train_and_evaluate(filters, batch_size, dropout_rate)\n",
    "            results.append({'filters': filters, 'batch_size': batch_size, 'dropout_rate': dropout_rate, 'mean_score': mean_score})\n",
    "\n",
    "# Konwersja wyników do DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Wyświetlanie wyników\n",
    "for result in results:\n",
    "    print(f\"Liczba filtrów: {result['filters']}, Rozmiar partii: {result['batch_size']}, Wskaźnik dropout: {result['dropout_rate']}, Średni wynik: {result['mean_score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tabela przestawna wyników (Średni wynik testowy):\n",
      "batch_size          16                            32                    \n",
      "dropout_rate       0.1       0.2       0.3       0.1       0.2       0.3\n",
      "filters                                                                 \n",
      "16            0.816381  0.484472  0.099788  0.675400  0.713875  0.442601\n",
      "32            0.895999  0.803805  0.760365  0.834281  0.817900  0.556126\n",
      "64            0.870464  0.877323  0.835801  0.881132  0.851046  0.797305\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Wizualizacja wyników\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.lineplot(x=results_df['filters'], y=results_df['mean_score'], hue=results_df['batch_size'], style=results_df['dropout_rate'], markers=True, dashes=False)\n",
    "plt.xlabel('Liczba filtrów')\n",
    "plt.ylabel('Średni wynik testowy')\n",
    "plt.title('Średni wynik testowy vs liczba filtrów dla różnych rozmiarów partii i wskaźników dropout')\n",
    "plt.legend(title='Rozmiar partii i wskaźnik dropout', loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Wykres rozkładu wyników dla różnych wartości liczby filtrów (Boxplot)\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.boxplot(x='filters', y='mean_score', hue='dropout_rate', data=results_df)\n",
    "plt.xlabel('Liczba filtrów')\n",
    "plt.ylabel('Średni wynik testowy')\n",
    "plt.title('Rozkład średnich wyników testowych dla różnych liczby filtrów i wskaźników dropout')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Tabela przestawna wyników\n",
    "results_table = results_df.pivot(index=\"filters\", columns=[\"batch_size\", \"dropout_rate\"], values=\"mean_score\")\n",
    "print(\"\\nTabela przestawna wyników (Średni wynik testowy):\")\n",
    "print(results_table)\n",
    "\n",
    "# Wykres przestawny wyników\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.heatmap(results_table, annot=True, cmap=\"YlGnBu\")\n",
    "plt.xlabel('Rozmiar partii i wskaźnik dropout')\n",
    "plt.ylabel('Liczba filtrów')\n",
    "plt.title('Mapa cieplna średnich wyników testowych dla różnych liczby filtrów, rozmiarów partii i wskaźników dropout')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
